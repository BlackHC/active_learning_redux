{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp active_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended /home/blackhc/PycharmProjects/bald-ical/src to paths\n",
      "Switched to directory /home/blackhc/PycharmProjects/bald-ical\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "import blackhc.project.script\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learning\n",
    "> Everything needed for Active Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Learning Data\n",
    "\n",
    "For active learning, we need to split the available training data between a training set and a pool set of (unlabelled) data, which we score using our model and acquisition function and add to the training set peu a peu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "import bisect\n",
    "import collections\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-b4c1ccfa5ab7>, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-b4c1ccfa5ab7>\"\u001b[0;36m, line \u001b[0;32m26\u001b[0m\n\u001b[0;31m    self.training_dataset.\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "class ActiveLearningData:\n",
    "    \"\"\"Splits `dataset` into an active dataset and an available dataset.\"\"\"\n",
    "\n",
    "    base_dataset: data.Dataset\n",
    "    training_dataset: data.Subset\n",
    "    pool_dataset: data.Subset\n",
    "    training_mask: np.ndarray\n",
    "    pool_mask: np.ndarray\n",
    "\n",
    "    def __init__(self, dataset: data.Dataset):\n",
    "        super().__init__()\n",
    "        self.base_dataset = dataset\n",
    "        self.training_mask = np.full((len(dataset),), False)\n",
    "        self.pool_mask = np.full((len(dataset),), True)\n",
    "\n",
    "        self.training_dataset = data.Subset(self.base_dataset, None)\n",
    "        self.pool_dataset = data.Subset(self.base_dataset, None)\n",
    "\n",
    "        self._update_indices()\n",
    "\n",
    "    def _update_indices(self):\n",
    "        self.training_dataset.indices = np.nonzero(self.training_mask)[0]\n",
    "        self.pool_dataset.indices = np.nonzero(self.pool_mask)[0]\n",
    "\n",
    "    def get_base_indices(self, pool_indices: List[int]) -> List[int]:\n",
    "        \"\"\"Transform indices (in `pool_dataset`) to indices in the original `dataset`.\"\"\"\n",
    "        indices = self.pool_dataset.indices[pool_indices]\n",
    "        return indices\n",
    "\n",
    "    def acquire(self, pool_indices):\n",
    "        \"\"\"\n",
    "        Acquire elements from the pool dataset into the training dataset.\n",
    "\n",
    "        Add them to training dataset & remove them from the pool dataset.\n",
    "        \"\"\"\n",
    "        base_indices = self.get_base_indices(pool_indices)\n",
    "        self.acquire_base_indices(base_indices)\n",
    "\n",
    "    def acquire_base_indices(self, base_indices):\n",
    "        self.training_mask[base_indices] = True\n",
    "        self.pool_mask[base_indices] = False\n",
    "        self._update_indices()\n",
    "\n",
    "    def remove_from_pool(self, pool_indices):\n",
    "        base_indices = self.get_base_indices(pool_indices)\n",
    "\n",
    "        self.remove_base_indices(base_indices)\n",
    "\n",
    "    def remove_base_indices(self, dataset_indices):\n",
    "        self.pool_mask[dataset_indices] = False\n",
    "        self._update_indices()\n",
    "\n",
    "    def get_random_pool_indices(self, size) -> torch.LongTensor:\n",
    "        assert 0 <= size <= len(self.pool_dataset)\n",
    "        pool_indices = torch.randperm(len(self.pool_dataset))[:size]\n",
    "        return pool_indices\n",
    "\n",
    "    def extract_dataset_from_pool(self, size) -> data.Dataset:\n",
    "        \"\"\"\n",
    "        Extract a dataset randomly from the pool dataset and make those indices unavailable.\n",
    "\n",
    "        Useful for extracting a validation set.\n",
    "        \"\"\"\n",
    "        return self.extract_dataset_from_pool_from_indices(self.get_random_pool_indices(size))\n",
    "\n",
    "    def extract_dataset_from_pool_from_indices(self, pool_indices) -> data.Dataset:\n",
    "        \"\"\"\n",
    "        Extract a dataset from the pool dataset and make those indices unavailable.\n",
    "\n",
    "        Useful for extracting a validation set.\n",
    "        \"\"\"\n",
    "        dataset_indices = self.get_base_indices(pool_indices)\n",
    "\n",
    "        return self.extract_dataset_from_base_indices(dataset_indices)\n",
    "\n",
    "    def extract_dataset_from_base_indices(self, base_indices) -> data.Dataset:\n",
    "        self.remove_base_indices(base_indices)\n",
    "        return data.Subset(self.base_dataset, base_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ActiveLearningData.get_base_indices\" class=\"doc_header\"><code>ActiveLearningData.get_base_indices</code><a href=\"__main__.py#L28\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ActiveLearningData.get_base_indices</code>(**`pool_indices`**:`List`\\[`int`\\])\n",
       "\n",
       "Transform indices (in `pool_dataset`) to indices in the original `dataset`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ActiveLearningData.acquire\" class=\"doc_header\"><code>ActiveLearningData.acquire</code><a href=\"__main__.py#L33\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ActiveLearningData.acquire</code>(**`pool_indices`**)\n",
       "\n",
       "Acquire elements from the pool dataset into the training dataset.\n",
       "\n",
       "Add them to training dataset & remove them from the pool dataset."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ActiveLearningData.remove_from_pool\" class=\"doc_header\"><code>ActiveLearningData.remove_from_pool</code><a href=\"__main__.py#L45\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ActiveLearningData.remove_from_pool</code>(**`pool_indices`**)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ActiveLearningData.get_random_pool_indices\" class=\"doc_header\"><code>ActiveLearningData.get_random_pool_indices</code><a href=\"__main__.py#L51\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ActiveLearningData.get_random_pool_indices</code>(**`size`**)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ActiveLearningData.extract_dataset_from_pool\" class=\"doc_header\"><code>ActiveLearningData.extract_dataset_from_pool</code><a href=\"__main__.py#L56\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ActiveLearningData.extract_dataset_from_pool</code>(**`size`**)\n",
       "\n",
       "Extract a dataset randomly from the pool dataset and make those indices unavailable.\n",
       "\n",
       "Useful for extracting a validation set."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ActiveLearningData.extract_dataset_from_pool_from_indices\" class=\"doc_header\"><code>ActiveLearningData.extract_dataset_from_pool_from_indices</code><a href=\"__main__.py#L64\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ActiveLearningData.extract_dataset_from_pool_from_indices</code>(**`pool_indices`**)\n",
       "\n",
       "Extract a dataset from the pool dataset and make those indices unavailable.\n",
       "\n",
       "Useful for extracting a validation set."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ActiveLearningData.get_base_indices)\n",
    "show_doc(ActiveLearningData.acquire)\n",
    "show_doc(ActiveLearningData.remove_from_pool)\n",
    "show_doc(ActiveLearningData.get_random_pool_indices)\n",
    "show_doc(ActiveLearningData.extract_dataset_from_pool)\n",
    "show_doc(ActiveLearningData.extract_dataset_from_pool_from_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "class RandomFixedLengthSampler(data.Sampler):\n",
    "    \"\"\"\n",
    "    Sometimes, you really want to do more with little data without increasing the number of epochs.\n",
    "    This sampler takes a `dataset` and draws `target_length` samples from it (with repetition).\n",
    "    \"\"\"\n",
    "\n",
    "    dataset: data.Dataset\n",
    "    target_length: int\n",
    "\n",
    "    def __init__(self, dataset: data.Dataset, target_length: int):\n",
    "        super().__init__(dataset)\n",
    "        self.dataset = dataset\n",
    "        self.target_length = target_length\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Ensure that we don't lose data by accident.\n",
    "        if self.target_length < len(self.dataset):\n",
    "            return iter(torch.randperm(len(self.dataset)).tolist())\n",
    "\n",
    "        # Sample slightly more indices to avoid biasing towards start of dataset.\n",
    "        # Have the same number of duplicates for each sample.\n",
    "        indices = torch.randperm(self.target_length + (-self.target_length % len(self.dataset)))\n",
    "\n",
    "        return iter((indices[: self.target_length] % len(self.dataset)).tolist())\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:active_learning]",
   "language": "python",
   "name": "conda-env-active_learning-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
