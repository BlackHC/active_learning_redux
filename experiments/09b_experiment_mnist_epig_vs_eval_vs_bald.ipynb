{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment MNIST: (real EPIG) vs EvalBALD vs BALD\n",
    "> Can we get better by training on our assumptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp experiment_epig_vs_eval_vs_bald"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended /home/blackhc/PycharmProjects/bald-ical/src to paths\n",
      "Switched to directory /home/blackhc/PycharmProjects/bald-ical\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "import blackhc.project.script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules and functions were are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "import dataclasses\n",
    "import traceback\n",
    "\n",
    "from blackhc.project import is_run_from_ipython\n",
    "from blackhc.project.experiment import embedded_experiments\n",
    "\n",
    "import batchbald_redux.acquisition_functions.bald\n",
    "import batchbald_redux.acquisition_functions.epig\n",
    "from batchbald_redux import acquisition_functions\n",
    "from batchbald_redux import baseline_acquisition_functions\n",
    "from batchbald_redux.unified_experiment import UnifiedExperiment\n",
    "from batchbald_redux.experiment_data import StandardExperimentDataConfig\n",
    "\n",
    "from batchbald_redux.models import MnistModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "configs = [\n",
    "    UnifiedExperiment(\n",
    "        experiment_data_config=StandardExperimentDataConfig(\n",
    "            id_dataset_name=\"MNIST\",\n",
    "            id_repetitions=id_repetitions,\n",
    "            initial_training_set_size=20,\n",
    "            validation_set_size=4096,\n",
    "            validation_split_random_state=0,\n",
    "            evaluation_set_size=0,\n",
    "            add_dataset_noise=id_repetitions > 1,\n",
    "            ood_dataset_config=None,\n",
    "        ),\n",
    "        seed=seed + 8945,\n",
    "        acquisition_function=acquisition_function,\n",
    "        acquisition_size=acquisition_size,\n",
    "        num_pool_samples=num_pool_samples,\n",
    "        max_training_set=120,\n",
    "        model_trainer_factory=MnistModelTrainer\n",
    "    )\n",
    "    for acquisition_function in [\n",
    "        baseline_acquisition_functions.BADGE,\n",
    "    ]\n",
    "    for seed in range(5)\n",
    "    for acquisition_size in [2, 5, 20]\n",
    "    for num_pool_samples in [100]\n",
    "    for id_repetitions in [1]\n",
    "] + [\n",
    "    UnifiedExperiment(\n",
    "        experiment_data_config=StandardExperimentDataConfig(\n",
    "            id_dataset_name=\"MNIST\",\n",
    "            id_repetitions=id_repetitions,\n",
    "            initial_training_set_size=20,\n",
    "            validation_set_size=4096,\n",
    "            validation_split_random_state=0,\n",
    "            evaluation_set_size=0,\n",
    "            add_dataset_noise=id_repetitions > 1,\n",
    "            ood_dataset_config=None,\n",
    "        ),\n",
    "        seed=seed + 8945,\n",
    "        acquisition_function=acquisition_function,\n",
    "        acquisition_size=acquisition_size,\n",
    "        num_pool_samples=num_pool_samples,\n",
    "        max_training_set=120,\n",
    "        model_trainer_factory=MnistModelTrainer\n",
    "    )\n",
    "    for acquisition_function in [\n",
    "        baseline_acquisition_functions.BADGE,\n",
    "        batchbald_redux.acquisition_functions.epig.EPIG,\n",
    "        batchbald_redux.acquisition_functions.epig.EvalBALD,\n",
    "        batchbald_redux.acquisition_functions.bald.BALD,\n",
    "    ]\n",
    "    for seed in range(5)\n",
    "    for acquisition_size in [1]\n",
    "    for num_pool_samples in [100]\n",
    "    for id_repetitions in [1]\n",
    "]\n",
    "\n",
    "if not is_run_from_ipython() and __name__ == \"__main__\":\n",
    "    for job_id, store in embedded_experiments(__file__, len(configs)):\n",
    "        config = configs[job_id]\n",
    "        config.seed += job_id\n",
    "        print(config)\n",
    "        store[\"config\"] = dataclasses.asdict(config)\n",
    "        store[\"log\"] = {}\n",
    "\n",
    "        try:\n",
    "            config.run(store=store)\n",
    "        except Exception:\n",
    "            store[\"exception\"] = traceback.format_exc()\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8945,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=1,\n",
      "        max_training_set=120,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8946,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=1,\n",
      "        max_training_set=120,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8947,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=1,\n",
      "        max_training_set=120,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8948,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=1,\n",
      "        max_training_set=120,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8949,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=1,\n",
      "        max_training_set=120,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8945,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=1,\n",
      "        max_training_set=120,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EPIG,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8946,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=1,\n",
      "        max_training_set=120,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EPIG,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8947,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=1,\n",
      "        max_training_set=120,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EPIG,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8948,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=1,\n",
      "        max_training_set=120,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EPIG,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8949,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=1,\n",
      "        max_training_set=120,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EPIG,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8945,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=1,\n",
      "        max_training_set=120,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8946,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=1,\n",
      "        max_training_set=120,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8947,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=1,\n",
      "        max_training_set=120,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8948,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=1,\n",
      "        max_training_set=120,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8949,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=1,\n",
      "        max_training_set=120,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8945,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=1,\n",
      "        max_training_set=120,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8946,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=1,\n",
      "        max_training_set=120,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8947,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=1,\n",
      "        max_training_set=120,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8948,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=1,\n",
      "        max_training_set=120,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8949,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=1,\n",
      "        max_training_set=120,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    )\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import prettyprinter\n",
    "prettyprinter.install_extras({\"dataclasses\"})\n",
    "prettyprinter.pprint(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating: BADGE(\n",
      "\tacquisition_size=1\n",
      ")\n",
      "Creating: MnistModelTrainer(\n",
      "\tdevice=cuda,\n",
      "\tnum_training_samples=1,\n",
      "\tnum_validation_samples=20,\n",
      "\tmax_training_epochs=1\n",
      ")\n",
      "Creating: TrainSelfDistillationEvalModel(\n",
      "\tnum_pool_samples=5\n",
      ")\n",
      "Training set size 20:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n",
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4770681a624540048892a879516107a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/32]   3%|3          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.5322265625, 'crossentropy': 1.880748711526394}\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: 0.5322265625)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.5478, 'crossentropy': tensor(1.7148)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_grad_embeddings:   0%|          | 0/55884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Samps\tTotal Distance\n",
      "CandidateBatch(scores=[0.0], indices=[40429])\n",
      "[('id', 40446)]\n",
      "Acquiring (label, score)s: 0 (0.0)\n",
      "Training set size 21:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355bc2cdb82e46fd95aaea83ef4cc65e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/32]   3%|3          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.5615234375, 'crossentropy': 1.8467455208301544}\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: 0.5615234375)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.6066, 'crossentropy': tensor(1.5495)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_grad_embeddings:   0%|          | 0/55883 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Samps\tTotal Distance\n",
      "CandidateBatch(scores=[0.0], indices=[116])\n",
      "[('id', 116)]\n",
      "Acquiring (label, score)s: 0 (0.0)\n",
      "Training set size 22:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b886a7f5e6d4d1d8be0ec883881102b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/32]   3%|3          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.53173828125, 'crossentropy': 1.842999268323183}\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: 0.53173828125)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.5618, 'crossentropy': tensor(1.6569)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_grad_embeddings:   0%|          | 0/55882 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Samps\tTotal Distance\n",
      "CandidateBatch(scores=[0.0], indices=[19358])\n",
      "[('id', 19365)]\n",
      "Acquiring (label, score)s: 0 (0.0)\n",
      "Training set size 23:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd00057a22ef4814b67b42c85cabe862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/32]   3%|3          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.505859375, 'crossentropy': 1.8935364410281181}\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: 0.505859375)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.4991, 'crossentropy': tensor(1.6983)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_grad_embeddings:   0%|          | 0/55881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Samps\tTotal Distance\n",
      "CandidateBatch(scores=[0.0], indices=[35957])\n",
      "[('id', 35976)]\n",
      "Acquiring (label, score)s: 4 (0.0)\n",
      "Training set size 24:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253e666f87884ac8921101dc9beb62ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/32]   3%|3          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.558349609375, 'crossentropy': 1.814862221479416}\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: 0.558349609375)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.5505, 'crossentropy': tensor(1.6885)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_grad_embeddings:   0%|          | 0/55880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Samps\tTotal Distance\n",
      "CandidateBatch(scores=[0.0], indices=[4586])\n",
      "[('id', 4588)]\n",
      "Acquiring (label, score)s: 0 (0.0)\n",
      "Training set size 25:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d7d66a6e894e3eac7d11e06ca7022b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/32]   3%|3          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.487060546875, 'crossentropy': 1.8638857491314411}\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: 0.487060546875)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.5002, 'crossentropy': tensor(1.6770)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_grad_embeddings:   0%|          | 0/55879 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Samps\tTotal Distance\n",
      "CandidateBatch(scores=[0.0], indices=[10113])\n",
      "[('id', 10117)]\n",
      "Acquiring (label, score)s: 0 (0.0)\n",
      "Training set size 26:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b0c8e4779b3447cb43ddef5c1081a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/32]   3%|3          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.41162109375, 'crossentropy': 1.972345657646656}\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: 0.41162109375)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.3807, 'crossentropy': tensor(1.8047)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6efa14f8066243e0a463ade41a81547a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_grad_embeddings:   0%|          | 0/55878 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-53ebc3871ad4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_pool_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_set_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/unified_experiment.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, store)\u001b[0m\n\u001b[1;32m    246\u001b[0m                                        model_trainer=model_trainer, data=data, device=self.device)\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mactive_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/unified_experiment.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, log)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macquisition_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCandidateBatchComputer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                 \u001b[0mcandidate_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macquisition_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_candidate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macquisition_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEvalDatasetBatchComputer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_dataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/baseline_acquisition_functions.py\u001b[0m in \u001b[0;36mcompute_candidate_batch\u001b[0;34m(self, model, pool_loader, device)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainedModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_loader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     ) -> CandidateBatch:\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mgrad_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_grad_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_embedding_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGradEmbeddingType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLINEAR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mchosen_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_centers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquisition_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/trained_model.py\u001b[0m in \u001b[0;36mget_grad_embeddings\u001b[0;34m(self, loader, num_samples, loss, grad_embedding_type, model_labels, device, storage_device)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mstorage_device\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     ):\n\u001b[0;32m---> 72\u001b[0;31m         grad_embeddings_N_K_E = self.model.get_grad_embeddings(\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/consistent_mc_dropout.py\u001b[0m in \u001b[0;36mget_grad_embeddings\u001b[0;34m(self, num_samples, loader, loss, grad_embedding_type, model_labels, device, storage_device)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mstorage_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     ):\n\u001b[0;32m--> 184\u001b[0;31m         return bmodule_get_grad_embeddings(\n\u001b[0m\u001b[1;32m    185\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/consistent_mc_dropout.py\u001b[0m in \u001b[0;36mbmodule_get_grad_embeddings\u001b[0;34m(self, num_samples, loader, loss, grad_embedding_type, model_labels, device, storage_device)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtoma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_num_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mget_prediction_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mnonlocal\u001b[0m \u001b[0mgrad_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/toma/__init__.py\u001b[0m in \u001b[0;36mexecute_range\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mexecute_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mexplicit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoma_cache_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoma_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mexecute_range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/toma/__init__.py\u001b[0m in \u001b[0;36mrange\u001b[0;34m(func, start, end, initial_step, toma_context, toma_cache_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                 \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m                 \u001b[0mcurrent\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mgc_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/consistent_mc_dropout.py\u001b[0m in \u001b[0;36mget_prediction_batch\u001b[0;34m(start, end)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mbatch_grad_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_embedding_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_grad_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_loss_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0mgrad_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdata_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_grad_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0mdata_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "store={}\n",
    "\n",
    "configs[0].max_training_epochs=1\n",
    "configs[0].num_pool_samples=5\n",
    "configs[0].evaluation_set_size=1024\n",
    "configs[0].run(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:active_learning]",
   "language": "python",
   "name": "conda-env-active_learning-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
