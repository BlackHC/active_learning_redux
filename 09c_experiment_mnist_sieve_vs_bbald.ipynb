{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment MNIST: (real EPIG) vs EvalBALD vs BALD\n",
    "> Can we get better by training on our assumptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp experiment_mnist_sieve_vs_bbald"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended /home/blackhc/PycharmProjects/bald-ical/src to paths\n",
      "Switched to directory /home/blackhc/PycharmProjects/bald-ical\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "import blackhc.project.script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules and functions were are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "import dataclasses\n",
    "import traceback\n",
    "\n",
    "from blackhc.project import is_run_from_ipython\n",
    "from blackhc.project.experiment import embedded_experiments\n",
    "\n",
    "import batchbald_redux.acquisition_functions.batchbald\n",
    "import batchbald_redux.acquisition_functions.sievebald\n",
    "from batchbald_redux import acquisition_functions\n",
    "from batchbald_redux.unified_experiment import UnifiedExperiment\n",
    "from batchbald_redux.experiment_data import StandardExperimentDataConfig\n",
    "\n",
    "from batchbald_redux.models import MnistModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "configs = [\n",
    "    UnifiedExperiment(\n",
    "        experiment_data_config=StandardExperimentDataConfig(\n",
    "            id_dataset_name=\"MNIST\",\n",
    "            id_repetitions=id_repetitions,\n",
    "            initial_training_set_size=20,\n",
    "            validation_set_size=4096,\n",
    "            validation_split_random_state=0,\n",
    "            evaluation_set_size=0,\n",
    "            add_dataset_noise=False,\n",
    "            ood_dataset_config=None,\n",
    "        ),\n",
    "        seed=seed + 6548,\n",
    "        acquisition_function=acquisition_function,\n",
    "        acquisition_size=acquisition_size,\n",
    "        num_pool_samples=num_pool_samples,\n",
    "        max_training_set=320,\n",
    "        model_trainer_factory=MnistModelTrainer\n",
    "    )\n",
    "    for seed in range(5)\n",
    "    for acquisition_function in [\n",
    "        batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
    "    ]\n",
    "    for acquisition_size in [10,20,40]\n",
    "    for num_pool_samples in [100]\n",
    "    for id_repetitions in [1, 4]\n",
    "] +  [UnifiedExperiment(\n",
    "        experiment_data_config=StandardExperimentDataConfig(\n",
    "            id_dataset_name=\"MNIST\",\n",
    "            id_repetitions=id_repetitions,\n",
    "            initial_training_set_size=20,\n",
    "            validation_set_size=4096,\n",
    "            validation_split_random_state=0,\n",
    "            evaluation_set_size=0,\n",
    "            add_dataset_noise=False,\n",
    "            ood_dataset_config=None,\n",
    "        ),\n",
    "        seed=seed + 6548,\n",
    "        acquisition_function=acquisition_function,\n",
    "        acquisition_size=acquisition_size,\n",
    "        num_pool_samples=num_pool_samples,\n",
    "        max_training_set=320,\n",
    "        model_trainer_factory=MnistModelTrainer\n",
    "    )\n",
    "    for seed in range(5)\n",
    "    for acquisition_function in [\n",
    "        batchbald_redux.acquisition_functions.batchbald.BatchBALD,\n",
    "    ]\n",
    "    for acquisition_size in [5, 10]\n",
    "    for num_pool_samples in [100]\n",
    "    for id_repetitions in [1, 4]\n",
    "] \n",
    "# + [\n",
    "#     UnifiedExperiment(\n",
    "#         seed=seed + 6548,\n",
    "#         acquisition_function=acquisition_function,\n",
    "#         acquisition_size=acquisition_size,\n",
    "#         num_pool_samples=num_pool_samples,\n",
    "#         initial_training_set_size=20,\n",
    "#         evaluation_set_size=0,\n",
    "#         max_training_set=300,\n",
    "#         id_dataset_name=\"MNIST\",\n",
    "#         ood_dataset_name=None,\n",
    "#         ood_exposure=False,\n",
    "#         id_repetitions=id_repetitions,\n",
    "#         add_dataset_noise=True,\n",
    "#         model_trainer_factory=MnistModelTrainer\n",
    "#     )\n",
    "#     for seed in range(5)\n",
    "#     for acquisition_function in [\n",
    "#         batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
    "#         batchbald_redux.acquisition_functions.batchbald.BatchBALD,\n",
    "#     ]\n",
    "#     for acquisition_size in [10]\n",
    "#     for num_pool_samples in [100]\n",
    "#     for id_repetitions in [1, 4]\n",
    "# ]\n",
    "\n",
    "if not is_run_from_ipython() and __name__ == \"__main__\":\n",
    "    for job_id, store in embedded_experiments(__file__, len(configs)):\n",
    "        config = configs[job_id]\n",
    "        config.seed += job_id\n",
    "        print(config)\n",
    "        store[\"config\"] = dataclasses.asdict(config)\n",
    "        store[\"log\"] = {}\n",
    "\n",
    "        try:\n",
    "            config.run(store=store)\n",
    "        except Exception:\n",
    "            store[\"exception\"] = traceback.format_exc()\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6548,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=10,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6548,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=4,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=10,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6548,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=20,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6548,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=4,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=20,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6548,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=40,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6548,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=4,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=40,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6549,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=10,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6549,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=4,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=10,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6549,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=20,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6549,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=4,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=20,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6549,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=40,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6549,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=4,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=40,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6550,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=10,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6550,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=4,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=10,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6550,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=20,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6550,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=4,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=20,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6550,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=40,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6550,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=4,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=40,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6551,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=10,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6551,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=4,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=10,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6551,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=20,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6551,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=4,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=20,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6551,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=40,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6551,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=4,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=40,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6552,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=10,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6552,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=4,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=10,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6552,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=20,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6552,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=4,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=20,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6552,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=40,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6552,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=4,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=40,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.sievebald.SieveBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6548,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.batchbald.BatchBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6548,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=4,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.batchbald.BatchBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6548,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=10,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.batchbald.BatchBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6548,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=4,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=10,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.batchbald.BatchBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6549,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.batchbald.BatchBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6549,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=4,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.batchbald.BatchBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6549,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=10,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.batchbald.BatchBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6549,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=4,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=10,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.batchbald.BatchBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6550,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.batchbald.BatchBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6550,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=4,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.batchbald.BatchBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6550,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=10,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.batchbald.BatchBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6550,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=4,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=10,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.batchbald.BatchBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6551,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.batchbald.BatchBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6551,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=4,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.batchbald.BatchBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6551,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=10,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.batchbald.BatchBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6551,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=4,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=10,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.batchbald.BatchBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6552,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.batchbald.BatchBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6552,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=4,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.batchbald.BatchBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6552,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=10,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.batchbald.BatchBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=6552,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='MNIST',\n",
      "            id_repetitions=4,\n",
      "            initial_training_set_size=20,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=10,\n",
      "        max_training_set=320,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.batchbald.BatchBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    )\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import prettyprinter\n",
    "prettyprinter.install_extras({\"dataclasses\"})\n",
    "prettyprinter.pprint(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moatml-andreas-kirsch\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.19 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/blackhc/PycharmProjects/bald-ical/wandb/run-20220623_213957-3r1zq6ph</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/oatml-andreas-kirsch/balds/runs/3r1zq6ph\" target=\"_blank\">vibrant-snow-212</a></strong> to <a href=\"https://wandb.ai/oatml-andreas-kirsch/balds\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardExperimentDataConfig(id_dataset_name='MNIST', id_repetitions=1, initial_training_set_size=20, validation_set_size=4096, validation_split_random_state=0, evaluation_set_size=0, add_dataset_noise=False, ood_dataset_config=None)\n",
      "{'Dataclass': 'batchbald_redux.unified_experiment.UnifiedExperiment', 'seed': 6548, 'experiment_data_config': {'Dataclass': 'batchbald_redux.experiment_data.StandardExperimentDataConfig', 'id_dataset_name': 'MNIST', 'id_repetitions': 1, 'initial_training_set_size': 20, 'validation_set_size': 4096, 'validation_split_random_state': 0, 'evaluation_set_size': 0, 'add_dataset_noise': False, 'ood_dataset_config': None}, 'acquisition_size': 10, 'max_training_set': 320, 'max_training_epochs': 1, 'num_pool_samples': 5, 'num_validation_samples': 20, 'num_training_samples': 1, 'device': 'cuda', 'acquisition_function': 'batchbald_redux.acquisition_functions.sievebald.SieveBALD', 'train_eval_model': 'batchbald_redux.train_eval_model.TrainSelfDistillationEvalModel', 'model_trainer_factory': 'batchbald_redux.models.MnistModelTrainer', 'ensemble_size': 1, 'temperature': 1.0, 'coldness': 1.0, 'stochastic_mode': None, 'epig_bootstrap_type': 'BootstrapType.NO_BOOTSTRAP', 'epig_bootstrap_factor': 1.0, 'epig_dtype': 'torch.float64', 'disable_training_augmentations': False, 'cache_explicit_eval_model': False, 'resnet18_dropout_head': True}\n",
      "Creating: SieveBALD(\n",
      "\tacquisition_size=10,\n",
      "\tnum_pool_samples=5\n",
      ")\n",
      "Creating: MnistModelTrainer(\n",
      "\tdevice=cuda,\n",
      "\tnum_training_samples=1,\n",
      "\tnum_validation_samples=20,\n",
      "\tmax_training_epochs=1\n",
      ")\n",
      "Creating: TrainSelfDistillationEvalModel(\n",
      "\tnum_pool_samples=5\n",
      ")\n",
      "Training set size 20:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n",
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0368f04b4dd54e849bf06b7d85ef158f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/32]   3%|3          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.541748046875, 'crossentropy': 1.6252272129058838}\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: 0.541748046875)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n",
      "{'model_training/val_metrics': <wandb.data_types.Table object at 0x7fcd443f2f40>, 'model_training/best_epoch': 0, 'model_training/best_val_accuracy': 0.541748046875, 'model_training/best_val_crossentropy': 1.6252272129058838}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.4355, 'crossentropy': tensor(1.6748), '_timestamp': 1656016810, '_runtime': 13}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/279420 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/55884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/55884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/55884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/55884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/55884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/55884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/55884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/55884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/55884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/55884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/55884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/55884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CandidateBatch(scores=[0.47402452561636177, 0.7618657287589363, 0.9271730674542276, 1.0254145030870654, 1.0628270998349048, 1.0735321077390076, 1.070011341816099, 1.0604326733006517, 1.0486107998098997, 1.0334733488377839], indices=[25428, 25230, 40157, 35313, 44628, 22048, 21054, 10230, 38347, 40138])\n",
      "[('id', 25439), ('id', 25241), ('id', 40174), ('id', 35330), ('id', 44646), ('id', 22055), ('id', 21061), ('id', 10232), ('id', 38364), ('id', 40155)]\n",
      "Acquiring (label, score)s: 6 (0.474), 0 (0.7619), 2 (0.9272), 1 (1.025), 6 (1.063), 5 (1.074), 7 (1.07), 1 (1.06), 5 (1.049), 5 (1.033)\n",
      "Training set size 30:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559040a2daba430083d7dbf1029fed5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/32]   3%|3          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.3759765625, 'crossentropy': 1.8580782413482666}\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: 0.3759765625)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n",
      "{'model_training/val_metrics': <wandb.data_types.Table object at 0x7fcd442f6250>, 'model_training/best_epoch': 0, 'model_training/best_val_accuracy': 0.3759765625, 'model_training/best_val_crossentropy': 1.8580782413482666}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.395, 'crossentropy': tensor(1.8524), '_timestamp': 1656016906, '_runtime': 109}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/279370 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/55874 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/55874 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/55874 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/55874 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/55874 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/55874 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/55874 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/55874 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/55874 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/55874 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/55874 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/55874 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CandidateBatch(scores=[0.20696576490259466, 0.3538529530364565, 0.47379888330475284, 0.5678419805596411, 0.6504698351727123, 0.7259902241578557, 0.788807508232177, 0.8452024303605647, 0.8931851480272488, 0.9331072023648868], indices=[4768, 33599, 35552, 21363, 38296, 38581, 506, 37019, 19198, 40739])\n",
      "[('id', 4770), ('id', 33620), ('id', 35575), ('id', 21372), ('id', 38319), ('id', 38605), ('id', 506), ('id', 37042), ('id', 19205), ('id', 40765)]\n",
      "Acquiring (label, score)s: 7 (0.207), 1 (0.3539), 7 (0.4738), 0 (0.5678), 2 (0.6505), 0 (0.726), 7 (0.7888), 0 (0.8452), 0 (0.8932), 7 (0.9331)\n",
      "Training set size 40:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2493cd396900410f923160fcd947757f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/32]   3%|3          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.44873046875, 'crossentropy': 1.8458632230758667}\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: 0.44873046875)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n",
      "{'model_training/val_metrics': <wandb.data_types.Table object at 0x7fcd441e80d0>, 'model_training/best_epoch': 0, 'model_training/best_val_accuracy': 0.44873046875, 'model_training/best_val_crossentropy': 1.8458632230758667}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.3675, 'crossentropy': tensor(1.8823), '_timestamp': 1656017002, '_runtime': 205}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/279320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/55864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/55864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/55864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/55864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/55864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/55864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/55864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/55864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2edb3c53e4b428ea297d4b73a8ccc61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/55864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-53ebc3871ad4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_pool_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_set_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/unified_experiment.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, store, project, entity)\u001b[0m\n\u001b[1;32m    301\u001b[0m         )\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0mactive_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/unified_experiment.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, log)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macquisition_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCandidateBatchComputer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0mcandidate_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macquisition_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_candidate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macquisition_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEvalDatasetBatchComputer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_dataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/acquisition_functions/candidate_batch_computers.py\u001b[0m in \u001b[0;36mcompute_candidate_batch\u001b[0;34m(self, model, pool_loader, device)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mlog_probs_N_K_C\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_log_probs_N_K_C\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_pool_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_candidate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs_N_K_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_candidate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs_N_K_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCandidateBatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/acquisition_functions/sievebald.py\u001b[0m in \u001b[0;36mget_candidate_batch\u001b[0;34m(self, log_probs_N_K_C, device)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_candidate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs_N_K_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCandidateBatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# Evaluate BALD scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         candidate_batch = get_sieve_bald_batch(\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mlog_probs_N_K_C\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquisition_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/acquisition_functions/sievebald.py\u001b[0m in \u001b[0;36mget_sieve_bald_batch\u001b[0;34m(log_probs_N_K_C, batch_size, dtype, device)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mjoint_entropy_helper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoint_entropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExactJointEntropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mjoint_entropy_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs_N_K_C\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcandidate_index\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mcandidate_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mjoint_entropies_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoint_entropy_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs_N_K_C\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mdual_mi_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentropies_N\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mentropies_N\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcandidate_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mjoint_entropies_N\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/joint_entropy.py\u001b[0m in \u001b[0;36mcompute_batch\u001b[0;34m(self, log_probs_B_K_C, output_entropies_B)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs_B_K_C\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_entropies_B\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         return self.lazy_compute_batch(\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0mlog_probs_B_K_C\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_probs_B_K_C\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mprevious_entropies_B\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/joint_entropy.py\u001b[0m in \u001b[0;36mlazy_compute_batch\u001b[0;34m(self, log_probs_B_K_C, previous_entropies_B, top_k, output_entropies_B)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mtoma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs_B_K_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         def chunked_joint_entropy(\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0mchunked_log_probs_b_K_C\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         ):\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/toma/__init__.py\u001b[0m in \u001b[0;36mexecute_chunked\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mexecute_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m                 return explicit.chunked(\n\u001b[0m\u001b[1;32m    202\u001b[0m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                     \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/toma/__init__.py\u001b[0m in \u001b[0;36mchunked\u001b[0;34m(func, tensor, initial_step, toma_dimension, toma_context, toma_cache_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoma_dimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         explicit.range(\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/toma/__init__.py\u001b[0m in \u001b[0;36mrange\u001b[0;34m(func, start, end, initial_step, toma_context, toma_cache_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mcurrent\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                 \u001b[0mgc_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mshould_reduce_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/toma/torch_cuda_memory.py\u001b[0m in \u001b[0;36mgc_cuda\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgc_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;34m\"\"\"Gargage collect Torch (CUDA) memory.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "store={}\n",
    "\n",
    "configs[0].max_training_epochs=1\n",
    "configs[0].num_pool_samples=5\n",
    "configs[0].evaluation_set_size=1024\n",
    "configs[0].run(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:active_learning]",
   "language": "python",
   "name": "conda-env-active_learning-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
