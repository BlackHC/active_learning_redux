store = {}
store['timestamp']=1642857998
store['cmdline']=['/auto/users/andsch/github/active_learning_redux/batchbald_redux/experiment_cifar10_cinic10.py', '--id=21']
store['commit']='628ec2d06d6acd1cefb9efa555e9d90a32ee38cd'
store['github_url']='628ec2d06d6acd1cefb9efa555e9d90a32ee38cd'
store['experiment']='/auto/users/andsch/github/active_learning_redux/batchbald_redux/experiment_cifar10_cinic10.py'
store['job_id']=21
store['worker_id']=21
store['num_workers']=96
store['config']={'seed': 1477, 'experiment_data_config': {'id_dataset_name': 'CINIC-10', 'id_repetitions': 1, 'initial_training_set_size': 1000, 'validation_set_size': 1024, 'validation_split_random_state': 0, 'evaluation_set_size': 0, 'add_dataset_noise': False, 'ood_dataset_config': None}, 'acquisition_size': 900, 'max_training_set': 16000, 'max_training_epochs': 105, 'num_pool_samples': 1, 'num_validation_samples': 1, 'num_training_samples': 1, 'device': 'cuda', 'acquisition_function': 'batchbald_redux.baseline_acquisition_functions.BADGE', 'train_eval_model': 'batchbald_redux.train_eval_model.TrainSelfDistillationEvalModel', 'model_trainer_factory': 'batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer', 'ensemble_size': 3, 'temperature': 1.0, 'coldness': 1.0, 'stochastic_mode': None, 'epig_bootstrap_type': 'BootstrapType.NO_BOOTSTRAP', 'epig_bootstrap_factor': 1.0, 'epig_dtype': torch.float64, 'disable_training_augmentations': False, 'cache_explicit_eval_model': False, 'resnet18_dropout_head': False}
store['log']={}
store['dataset_info']={'training': "'CINIC-10 (Train, imagenet_only=False, seed=0, 178976 samples)'", 'test': "'CINIC-10 (Test, imagenet_only={imagenet_only})'"}
store['initial_training_set_indices']=[76885, 146195, 19213, 53579, 106930, 37164, 101544, 52868, 9447, 71788, 132854, 102855, 76169, 45024, 108569, 112047, 156851, 100142, 168871, 174186, 89287, 137274, 131399, 35140, 80898, 120379, 107556, 91127, 116009, 145812, 112396, 130083, 97631, 126960, 132186, 172262, 23897, 173598, 141088, 70464, 128400, 98690, 73417, 29026, 20683, 10569, 163864, 149002, 167628, 114491, 98704, 145829, 129256, 146892, 107593, 121202, 96762, 136914, 98770, 45839, 10001, 39469, 160323, 51867, 47415, 94499, 22571, 38619, 12784, 43762, 32716, 34021, 41188, 43394, 163255, 68280, 57631, 136796, 41657, 146003, 134271, 101007, 13086, 83267, 14005, 123702, 171664, 34041, 40952, 159164, 118860, 100301, 170731, 40575, 12285, 39431, 168605, 65404, 56632, 48659, 17831, 69715, 72448, 121061, 109967, 36769, 139083, 18440, 167443, 107464, 102647, 85381, 66234, 42266, 159714, 8105, 128548, 120343, 15421, 121937, 171743, 104593, 155018, 151717, 10372, 131365, 42813, 2272, 172838, 161162, 107051, 5066, 133960, 214, 25240, 54094, 151164, 14227, 51269, 174105, 163763, 49991, 49281, 13379, 28342, 1997, 15561, 146689, 41015, 171799, 67484, 87821, 169001, 125729, 168688, 153154, 138282, 17423, 33124, 30723, 138877, 10673, 26639, 172995, 100406, 58903, 77991, 76005, 126169, 167872, 41716, 163849, 63475, 150654, 27193, 177262, 18746, 164187, 13260, 61178, 64917, 156642, 72243, 49660, 151872, 57649, 56759, 122800, 154642, 29802, 123700, 20292, 113908, 40047, 143861, 146125, 125442, 88035, 135890, 175507, 52046, 34954, 53841, 100574, 81109, 49845, 120313, 136838, 114959, 19858, 112044, 78270, 133110, 129403, 34074, 44807, 171602, 167984, 1164, 117377, 91009, 25168, 76935, 172882, 96198, 11880, 83096, 159699, 75417, 29952, 134347, 96287, 10472, 35437, 48800, 60798, 55473, 173495, 158780, 117916, 170912, 141063, 52011, 172521, 124872, 74751, 74693, 36618, 169164, 135757, 75236, 25623, 6506, 98001, 46850, 77577, 67261, 178078, 162730, 57593, 178907, 5694, 6031, 88827, 50154, 32354, 141658, 107860, 154059, 61049, 114338, 83891, 160447, 40681, 177846, 83068, 18259, 111771, 110608, 10097, 37287, 56609, 136435, 114650, 31046, 61155, 22990, 57326, 170995, 61105, 66045, 111499, 25851, 175522, 75711, 69968, 169293, 81696, 104632, 15207, 57721, 137573, 107954, 100648, 68701, 99116, 48866, 175501, 81464, 70700, 147986, 118299, 130400, 94019, 31213, 103592, 77332, 145155, 87094, 2134, 95563, 52767, 47523, 158899, 106837, 48151, 43352, 15667, 23743, 89834, 90767, 98597, 155060, 1994, 110970, 88264, 169876, 100472, 121856, 47909, 157561, 164762, 9766, 174004, 29238, 106764, 87988, 164852, 47915, 23907, 172588, 135310, 151409, 41034, 118150, 81281, 88557, 150663, 112978, 64184, 175782, 123505, 57482, 156462, 96828, 108797, 54694, 128756, 80494, 109972, 79514, 87633, 56277, 162651, 120423, 153497, 96310, 74094, 115562, 81357, 166708, 112363, 9518, 177176, 62659, 107671, 50551, 54347, 172286, 177736, 57237, 86388, 24421, 35020, 15050, 126782, 20934, 15287, 5905, 112004, 74214, 130176, 36705, 90504, 177535, 69783, 93945, 34953, 136768, 149367, 28261, 150530, 134493, 163362, 25544, 46682, 166422, 135450, 161310, 157742, 97555, 37835, 65213, 22000, 59608, 17520, 128457, 88456, 127035, 67601, 131467, 8156, 164042, 29515, 80368, 95796, 27672, 45926, 2148, 162379, 102651, 121561, 162459, 11180, 63249, 18818, 79497, 124968, 153720, 40079, 147681, 89343, 20801, 9494, 62473, 144970, 5040, 139308, 57622, 2969, 1542, 110890, 142822, 80941, 136753, 88668, 9400, 174121, 117075, 76557, 158003, 150903, 133442, 239, 58265, 175086, 88569, 526, 145077, 114795, 164466, 15268, 2891, 74639, 140250, 167421, 68885, 9814, 167225, 170765, 49350, 146545, 35977, 33550, 88216, 29257, 128931, 35958, 54293, 110684, 80435, 43594, 111445, 26940, 129859, 16077, 114639, 71305, 36309, 95324, 121532, 53586, 111974, 125152, 88181, 329, 96380, 138974, 29537, 43380, 29615, 123639, 171552, 107060, 108971, 156933, 111663, 64371, 110671, 112601, 103251, 104444, 148666, 98561, 155, 147140, 163632, 145977, 165826, 77758, 77854, 32729, 79471, 147047, 155895, 167790, 64131, 94963, 91687, 49098, 29336, 94844, 171258, 94490, 940, 66471, 76500, 51557, 25538, 156352, 160254, 159711, 35152, 10622, 23669, 68316, 124956, 152579, 98293, 128718, 156793, 137268, 168538, 2463, 152418, 11316, 82759, 61373, 57499, 111998, 3545, 108406, 70643, 16759, 68669, 138582, 131040, 160957, 77384, 69211, 69106, 41555, 19676, 103831, 9779, 53079, 67435, 172856, 146205, 46149, 29901, 129491, 68821, 53320, 24305, 49608, 109195, 17700, 29014, 81136, 106123, 98526, 11139, 136582, 176321, 162544, 84321, 162737, 124038, 112651, 173536, 171999, 92301, 157679, 74487, 91316, 10401, 128446, 89544, 156693, 55998, 52883, 5165, 129529, 168209, 171338, 26094, 52523, 173680, 76690, 135279, 98598, 76915, 178122, 168657, 151711, 13142, 86061, 124563, 17404, 37655, 69886, 170190, 25926, 97172, 123634, 104991, 22602, 158831, 71415, 81457, 81521, 126454, 9050, 141341, 85382, 53089, 163649, 130572, 42904, 93766, 76307, 76584, 45760, 34625, 120526, 79798, 107978, 98182, 56201, 166167, 23995, 50830, 39240, 53279, 154040, 61679, 118061, 161356, 109923, 138114, 163578, 170600, 127752, 34827, 10775, 13077, 88683, 161400, 115003, 65206, 101518, 8721, 132563, 157315, 98594, 12953, 32773, 82065, 13035, 9359, 75960, 127433, 137297, 167843, 55788, 14292, 23598, 77843, 101220, 166906, 38517, 33360, 104487, 147505, 74126, 83087, 13452, 16201, 165565, 3795, 166766, 53872, 67167, 114377, 13737, 130455, 60093, 167042, 166131, 110629, 130044, 163842, 20298, 56749, 101548, 145213, 78309, 4711, 63300, 17671, 66844, 46596, 147482, 61796, 69583, 19800, 7217, 130835, 17143, 131191, 39357, 176376, 3173, 107403, 160449, 150573, 14926, 139315, 29383, 53641, 40446, 25107, 79792, 118725, 28636, 71340, 89936, 86451, 174690, 91401, 57667, 112400, 74549, 143243, 169543, 99835, 7304, 113399, 143932, 21024, 104415, 97580, 39990, 116262, 29347, 14500, 98114, 159497, 6188, 127293, 174139, 3744, 91976, 118778, 27987, 38791, 108009, 5307, 95171, 146462, 84539, 117495, 81391, 6725, 24715, 162774, 148442, 10471, 6484, 65394, 64922, 131746, 75638, 174297, 1695, 154740, 81278, 66524, 140972, 6748, 29417, 57990, 139695, 128858, 8223, 98567, 171939, 98795, 48411, 97649, 122210, 120441, 57132, 53619, 52757, 161503, 67081, 62926, 73399, 171754, 160211, 64028, 72439, 121529, 85139, 147304, 48814, 95689, 146917, 25081, 28663, 168487, 21610, 140469, 161417, 176135, 126349, 99068, 90242, 77470, 108179, 88275, 5665, 44018, 147007, 44202, 174898, 45820, 8056, 9738, 122671, 125718, 51859, 130658, 160155, 46701, 116779, 158099, 104161, 44147, 61097, 105528, 29958, 109667, 36246, 14055, 70628, 49697, 177496, 123209, 160398, 53034, 11904, 36582, 96908, 40884, 151243, 137287, 124380, 106430, 34935, 71132, 53616, 165602, 70209, 136218, 86888, 81347, 46007, 32519, 27912, 128784, 42942, 35173, 11334, 23391, 97336, 176499, 31754, 69765, 78911, 148312, 58461, 37800, 143741, 125155, 107931, 41441, 34665, 147595, 89238, 55, 95887, 97701, 174201, 156162, 152017, 135726, 72303, 117127, 28103, 127609, 119547, 87138, 172374, 112401, 149829, 72817, 8520, 66072, 97228, 62498, 140482, 60976, 117900, 25733, 53542, 2876, 151513, 117401, 67704, 106151, 60743, 141588, 71166, 104934, 43333, 9086, 97857, 140590, 14499, 171477, 77911, 119510, 113173, 130669, 17056, 150518, 114872, 93077, 167597, 107003, 24166, 28175, 55032, 117602, 26636, 131981, 110157]
store['evaluation_set_indices']=[]
store['seed']=3567271588120654209
store['active_learning_steps']=[]
store['active_learning_steps'].append({})
store['active_learning_steps'][0]['training']={}
store['active_learning_steps'][0]['training']['ensemble']=[]
store['active_learning_steps'][0]['training']['ensemble'].append({})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs']=[]
store['active_learning_steps'][0]['training']['ensemble'][0]['era_epochs']=[]
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.2099609375, 'crossentropy': 2.235482692718506})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.2021484375, 'crossentropy': 2.1598143577575684})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.2255859375, 'crossentropy': 2.2011313438415527})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.26171875, 'crossentropy': 2.0119950771331787})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.2646484375, 'crossentropy': 2.0285470485687256})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.294921875, 'crossentropy': 2.0489940643310547})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.287109375, 'crossentropy': 2.098942279815674})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.3154296875, 'crossentropy': 1.9181396961212158})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.3505859375, 'crossentropy': 1.8607385158538818})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.3466796875, 'crossentropy': 1.9933600425720215})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.3291015625, 'crossentropy': 1.9379247426986694})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.337890625, 'crossentropy': 1.9539072513580322})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.349609375, 'crossentropy': 1.8694735765457153})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.349609375, 'crossentropy': 1.8905298709869385})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.353515625, 'crossentropy': 2.0662426948547363})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.3486328125, 'crossentropy': 1.8905152082443237})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.3681640625, 'crossentropy': 1.9355043172836304})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.37890625, 'crossentropy': 1.881981372833252})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.31640625, 'crossentropy': 2.652617931365967})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.35546875, 'crossentropy': 2.093642473220825})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.33203125, 'crossentropy': 2.2224154472351074})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.380859375, 'crossentropy': 1.9886722564697266})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.3671875, 'crossentropy': 2.1217706203460693})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.3740234375, 'crossentropy': 2.225025177001953})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.3759765625, 'crossentropy': 2.132021427154541})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.3671875, 'crossentropy': 2.410217523574829})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.3349609375, 'crossentropy': 2.4569129943847656})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.3671875, 'crossentropy': 2.2686619758605957})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.4013671875, 'crossentropy': 2.1472370624542236})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.3583984375, 'crossentropy': 2.4050168991088867})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.3837890625, 'crossentropy': 2.2195816040039062})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.3916015625, 'crossentropy': 2.3509578704833984})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.3681640625, 'crossentropy': 2.9265317916870117})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.3369140625, 'crossentropy': 3.0114405155181885})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.3759765625, 'crossentropy': 2.5704479217529297})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.357421875, 'crossentropy': 2.567049264907837})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.365234375, 'crossentropy': 2.684347152709961})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.3759765625, 'crossentropy': 2.6567060947418213})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.34375, 'crossentropy': 3.0447583198547363})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.3740234375, 'crossentropy': 2.973458766937256})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.375, 'crossentropy': 2.887701988220215})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.34765625, 'crossentropy': 2.808424472808838})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.3759765625, 'crossentropy': 2.8808159828186035})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.359375, 'crossentropy': 2.615200996398926})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.3515625, 'crossentropy': 3.0207529067993164})
store['active_learning_steps'][0]['training']['ensemble'][0]['era_epochs'].append(45)
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.408203125, 'crossentropy': 2.013463020324707})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.4169921875, 'crossentropy': 1.976672887802124})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.421875, 'crossentropy': 1.9429032802581787})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.427734375, 'crossentropy': 1.9304672479629517})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.423828125, 'crossentropy': 1.9418575763702393})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.4326171875, 'crossentropy': 1.9679157733917236})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.431640625, 'crossentropy': 1.9792327880859375})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.431640625, 'crossentropy': 1.9875056743621826})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.439453125, 'crossentropy': 2.002589464187622})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.4248046875, 'crossentropy': 2.0162010192871094})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.41796875, 'crossentropy': 2.032649040222168})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.4228515625, 'crossentropy': 2.041698694229126})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.41796875, 'crossentropy': 2.0531582832336426})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.4208984375, 'crossentropy': 2.041687250137329})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.431640625, 'crossentropy': 2.0572521686553955})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.43359375, 'crossentropy': 2.0487828254699707})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.4248046875, 'crossentropy': 2.073444128036499})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.4326171875, 'crossentropy': 2.1149182319641113})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.4384765625, 'crossentropy': 2.126992702484131})
store['active_learning_steps'][0]['training']['ensemble'][0]['epochs'].append({'accuracy': 0.4375, 'crossentropy': 2.108368396759033})
store['active_learning_steps'][0]['training']['ensemble'].append({})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs']=[]
store['active_learning_steps'][0]['training']['ensemble'][1]['era_epochs']=[]
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.1494140625, 'crossentropy': 2.2924046516418457})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.203125, 'crossentropy': 2.1717987060546875})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.2041015625, 'crossentropy': 2.0680766105651855})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.2890625, 'crossentropy': 1.9936704635620117})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.265625, 'crossentropy': 2.0842275619506836})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.2880859375, 'crossentropy': 1.9965488910675049})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.2646484375, 'crossentropy': 2.012991428375244})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.265625, 'crossentropy': 2.1697840690612793})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.298828125, 'crossentropy': 1.9510364532470703})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.2998046875, 'crossentropy': 1.934281826019287})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.3095703125, 'crossentropy': 2.2256956100463867})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.294921875, 'crossentropy': 2.0014266967773438})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.34765625, 'crossentropy': 1.9215977191925049})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.33984375, 'crossentropy': 1.9413032531738281})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.3037109375, 'crossentropy': 2.330888271331787})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.3720703125, 'crossentropy': 1.9629647731781006})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.3369140625, 'crossentropy': 2.0730576515197754})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.3486328125, 'crossentropy': 2.0649209022521973})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.3681640625, 'crossentropy': 1.9766048192977905})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.3291015625, 'crossentropy': 2.121739387512207})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.3515625, 'crossentropy': 2.056457042694092})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.3583984375, 'crossentropy': 2.229010581970215})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.361328125, 'crossentropy': 2.1116228103637695})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.3642578125, 'crossentropy': 2.069552183151245})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.34765625, 'crossentropy': 2.1248302459716797})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.349609375, 'crossentropy': 2.330970048904419})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.3583984375, 'crossentropy': 2.7062394618988037})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.3564453125, 'crossentropy': 2.3110735416412354})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.33984375, 'crossentropy': 2.3047146797180176})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.3623046875, 'crossentropy': 2.115229606628418})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.33203125, 'crossentropy': 2.8352646827697754})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.359375, 'crossentropy': 2.3038249015808105})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.36328125, 'crossentropy': 2.3914480209350586})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.392578125, 'crossentropy': 2.349656581878662})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.30859375, 'crossentropy': 3.523421287536621})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.357421875, 'crossentropy': 2.531737804412842})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.365234375, 'crossentropy': 2.855278968811035})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.3779296875, 'crossentropy': 2.4961843490600586})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.3388671875, 'crossentropy': 3.018531084060669})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.3388671875, 'crossentropy': 2.8622374534606934})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.3798828125, 'crossentropy': 2.993093252182007})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.3662109375, 'crossentropy': 3.2870922088623047})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.38671875, 'crossentropy': 2.7234654426574707})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.38671875, 'crossentropy': 2.9449331760406494})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.359375, 'crossentropy': 2.7737584114074707})
store['active_learning_steps'][0]['training']['ensemble'][1]['era_epochs'].append(45)
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.400390625, 'crossentropy': 2.220088481903076})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.4072265625, 'crossentropy': 2.2166595458984375})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.4091796875, 'crossentropy': 2.218005895614624})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.4228515625, 'crossentropy': 2.188840389251709})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.419921875, 'crossentropy': 2.1886532306671143})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.41796875, 'crossentropy': 2.1899752616882324})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.40625, 'crossentropy': 2.197615623474121})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.4091796875, 'crossentropy': 2.2013778686523438})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.4140625, 'crossentropy': 2.2123889923095703})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.412109375, 'crossentropy': 2.209097385406494})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.416015625, 'crossentropy': 2.2240188121795654})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.412109375, 'crossentropy': 2.2340259552001953})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.4111328125, 'crossentropy': 2.2266855239868164})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.4052734375, 'crossentropy': 2.2508625984191895})
store['active_learning_steps'][0]['training']['ensemble'][1]['epochs'].append({'accuracy': 0.4111328125, 'crossentropy': 2.2883663177490234})
store['active_learning_steps'][0]['training']['ensemble'].append({})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs']=[]
store['active_learning_steps'][0]['training']['ensemble'][2]['era_epochs']=[]
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.1796875, 'crossentropy': 2.3339176177978516})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.177734375, 'crossentropy': 2.2040085792541504})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.2197265625, 'crossentropy': 2.039618492126465})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.2685546875, 'crossentropy': 2.097301483154297})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.3125, 'crossentropy': 1.872365117073059})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.302734375, 'crossentropy': 1.9411373138427734})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.31640625, 'crossentropy': 1.9096875190734863})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.3076171875, 'crossentropy': 1.9383832216262817})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.298828125, 'crossentropy': 2.2934675216674805})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.3115234375, 'crossentropy': 1.955089807510376})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.34765625, 'crossentropy': 1.881012201309204})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.314453125, 'crossentropy': 1.9699115753173828})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.3544921875, 'crossentropy': 1.8480956554412842})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.3369140625, 'crossentropy': 2.0364980697631836})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.3525390625, 'crossentropy': 2.0313332080841064})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.326171875, 'crossentropy': 1.9714033603668213})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.326171875, 'crossentropy': 2.7004151344299316})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.34375, 'crossentropy': 2.0347774028778076})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.318359375, 'crossentropy': 2.411391258239746})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.3056640625, 'crossentropy': 2.0920634269714355})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.357421875, 'crossentropy': 2.3317408561706543})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.37109375, 'crossentropy': 2.0055832862854004})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.3671875, 'crossentropy': 2.0637824535369873})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.35546875, 'crossentropy': 2.092224597930908})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.3359375, 'crossentropy': 2.245544910430908})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.3818359375, 'crossentropy': 2.357828140258789})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.3564453125, 'crossentropy': 2.3238868713378906})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.36328125, 'crossentropy': 2.176206111907959})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.3759765625, 'crossentropy': 2.3639183044433594})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.3837890625, 'crossentropy': 2.246584892272949})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.3623046875, 'crossentropy': 2.5132226943969727})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.3583984375, 'crossentropy': 2.7763030529022217})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.3408203125, 'crossentropy': 2.752668857574463})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.41015625, 'crossentropy': 2.4688720703125})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.3349609375, 'crossentropy': 2.552969455718994})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.392578125, 'crossentropy': 2.493091106414795})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.3779296875, 'crossentropy': 2.499457597732544})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.3486328125, 'crossentropy': 2.6440582275390625})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.3525390625, 'crossentropy': 2.995602607727051})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.3359375, 'crossentropy': 3.690814256668091})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.3359375, 'crossentropy': 3.308708667755127})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.3857421875, 'crossentropy': 2.7771942615509033})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.357421875, 'crossentropy': 3.028144121170044})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.3759765625, 'crossentropy': 2.8342909812927246})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.3701171875, 'crossentropy': 2.9197418689727783})
store['active_learning_steps'][0]['training']['ensemble'][2]['era_epochs'].append(45)
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.4140625, 'crossentropy': 2.295111656188965})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.4267578125, 'crossentropy': 2.212815523147583})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.40234375, 'crossentropy': 2.2150344848632812})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.4140625, 'crossentropy': 2.2104320526123047})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.41796875, 'crossentropy': 2.201272964477539})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.4228515625, 'crossentropy': 2.214613437652588})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.4228515625, 'crossentropy': 2.22395920753479})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.41796875, 'crossentropy': 2.221700668334961})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.4130859375, 'crossentropy': 2.2568302154541016})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.4150390625, 'crossentropy': 2.2710633277893066})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.419921875, 'crossentropy': 2.269630193710327})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.4130859375, 'crossentropy': 2.2923874855041504})
store['active_learning_steps'][0]['training']['ensemble'][2]['epochs'].append({'accuracy': 0.4091796875, 'crossentropy': 2.3321642875671387})
store['active_learning_steps'][0]['evaluation_metrics']={'accuracy': 0.4015666666666667, 'crossentropy': 1.972129464149475}
store['exception']='Traceback (most recent call last):\n  File "/auto/users/andsch/github/active_learning_redux/batchbald_redux/experiment_cifar10_cinic10.py", line 208, in <module>\n    config.run(store=store)\n  File "/auto/users/andsch/github/active_learning_redux/batchbald_redux/unified_experiment.py", line 271, in run\n    active_learner(store)\n  File "/auto/users/andsch/github/active_learning_redux/batchbald_redux/unified_experiment.py", line 130, in __call__\n    candidate_batch = acquisition_function.compute_candidate_batch(trained_model, pool_loader, self.device)\n  File "/auto/users/andsch/github/active_learning_redux/batchbald_redux/baseline_acquisition_functions.py", line 65, in compute_candidate_batch\n    chosen_indices = init_centers(grad_embeddings.squeeze(1).numpy(), self.acquisition_size)\n  File "/auto/users/andsch/github/active_learning_redux/batchbald_redux/baseline_acquisition_functions.py", line 39, in init_centers\n    D2 = pairwise_distances(X, mu).ravel().astype(float)\n  File "/scratch-ssd/andsch/tmp/conda_envs/job-28788/lib/python3.8/site-packages/sklearn/metrics/pairwise.py", line 1889, in pairwise_distances\n    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)\n  File "/scratch-ssd/andsch/tmp/conda_envs/job-28788/lib/python3.8/site-packages/sklearn/metrics/pairwise.py", line 1430, in _parallel_pairwise\n    return func(X, Y, **kwds)\n  File "/scratch-ssd/andsch/tmp/conda_envs/job-28788/lib/python3.8/site-packages/sklearn/metrics/pairwise.py", line 302, in euclidean_distances\n    X, Y = check_pairwise_arrays(X, Y)\n  File "/scratch-ssd/andsch/tmp/conda_envs/job-28788/lib/python3.8/site-packages/sklearn/metrics/pairwise.py", line 156, in check_pairwise_arrays\n    X = check_array(\n  File "/scratch-ssd/andsch/tmp/conda_envs/job-28788/lib/python3.8/site-packages/sklearn/utils/validation.py", line 794, in check_array\n    raise ValueError(\nValueError: Found array with dim 3. check_pairwise_arrays expected <= 2.\n'
