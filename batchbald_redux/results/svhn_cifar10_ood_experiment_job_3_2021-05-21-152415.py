store = {}
store['timestamp']=1621607055
store['cmdline']=['/home/kell4989/git/active_learning_redux/batchbald_redux/svhn_cifar10_ood_experiment.py', '--id=3']
store['commit']='682214513771357d0cdd3c2eb17f027e50839d3c'
store['github_url']='682214513771357d0cdd3c2eb17f027e50839d3c'
store['experiment']='/home/kell4989/git/active_learning_redux/batchbald_redux/svhn_cifar10_ood_experiment.py'
store['job_id']=3
store['worker_id']=3
store['num_workers']=24
store['config']={'seed': 1237, 'uniform_ood': False, 'id_dataset_name': 'SVHN', 'ood_dataset_name': 'CIFAR-10', 'initial_training_set_size': 0, 'validation_set_size': 1024, 'evaluation_set_size': 1024, 'id_repetitions': 1, 'ood_repetitions': 1, 'add_dataset_noise': False, 'validation_split_random_state': 0, 'acquisition_size': 5, 'max_training_set': 200, 'num_pool_samples': 100, 'num_validation_samples': 20, 'num_training_samples': 1, 'num_patience_epochs': 3, 'max_training_epochs': 60, 'training_batch_size': 64, 'device': 'cuda', 'min_samples_per_epoch': 5056, 'acquisition_function': 'batchbald_redux.acquisition_functions.BatchEvalBALD', 'train_eval_model': 'batchbald_redux.train_eval_model.TrainSelfDistillationEvalModel', 'model_optimizer_factory': 'batchbald_redux.resnet_models.Cifar10BayesianResnetFactory', 'acquisition_function_args': None, 'temperature': 0.0}
store['log']={}
store['exception']='Traceback (most recent call last):\n  File "/home/kell4989/git/active_learning_redux/batchbald_redux/svhn_cifar10_ood_experiment.py", line 410, in <module>\n    config.run(store=store)\n  File "/home/kell4989/git/active_learning_redux/batchbald_redux/svhn_cifar10_ood_experiment.py", line 243, in run\n    data = self.load_experiment_data()\n  File "/home/kell4989/git/active_learning_redux/batchbald_redux/svhn_cifar10_ood_experiment.py", line 227, in load_experiment_data\n    return edc.load()\n  File "/home/kell4989/git/active_learning_redux/batchbald_redux/svhn_cifar10_ood_experiment.py", line 86, in load\n    return load_experiment_data(\n  File "/home/kell4989/git/active_learning_redux/batchbald_redux/svhn_cifar10_ood_experiment.py", line 115, in load_experiment_data\n    split_dataset = get_dataset(id_dataset_name, root="data", train_augmentation=True, validation_set_size=validation_set_size,\n  File "/home/kell4989/git/active_learning_redux/batchbald_redux/datasets.py", line 254, in get_dataset\n    split_dataset = dataset_factories[name](\n  File "/home/kell4989/git/active_learning_redux/batchbald_redux/datasets.py", line 91, in get_SVHN\n    test_dataset = datasets.SVHN(root + "/SVHN", split="test", transform=transform, download=True)\n  File "/tmp/conda_envs/job-1595218/lib/python3.8/site-packages/torchvision/datasets/svhn.py", line 59, in __init__\n    self.download()\n  File "/tmp/conda_envs/job-1595218/lib/python3.8/site-packages/torchvision/datasets/svhn.py", line 118, in download\n    download_url(self.url, self.root, self.filename, md5)\n  File "/tmp/conda_envs/job-1595218/lib/python3.8/site-packages/torchvision/datasets/utils.py", line 145, in download_url\n    raise RuntimeError("File not found or corrupted.")\nRuntimeError: File not found or corrupted.\n'
