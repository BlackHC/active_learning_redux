# AUTOGENERATED! DO NOT EDIT! File to edit: 07_black_box_training.ipynb (unless otherwise specified).

__all__ = ['train', 'create_metrics', 'configure_tb_logger', 'LOG_INTERVAL', 'HEAVY_LOG_INTERVAL']

# Internal Cell

import torch
from torch import nn

from ignite.contrib.engines.common import setup_common_training_handlers, \
    add_early_stopping_by_val_score
from ignite.contrib.handlers import TensorboardLogger
from ignite.contrib.handlers.tensorboard_logger import OutputHandler, OptimizerParamsHandler, \
    WeightsScalarHandler, WeightsHistHandler, GradsScalarHandler, GradsHistHandler
from ignite.engine import create_supervised_trainer, create_supervised_evaluator, Events
from ignite.metrics import Accuracy, Loss

# Cell


LOG_INTERVAL = 10
HEAVY_LOG_INTERVAL = 100


def train(*, model, train_loader, val_loader, metric_loader,
          patience:int, max_epochs:int, tb_log_dir:str, device:str):
    """
    :param model:
    :param train_loader:
    :param val_loader:
    :param metric_loader: We compute metrics for debugging and introspection purposes with this data.
    :param patience: How many epochs to wait for early-stopping.
    :param max_epochs:
    :param tb_log_dir:
    :param device:
    :return: Optimizer that was used for training.
    """
    # Move model before creating optimizer

    model.to(device)

    optimizer = torch.optim.AdamW(model.parameters())
    criterion = nn.CrossEntropyLoss()

    trainer = create_supervised_trainer(model, optimizer, criterion, device=device)

    metrics = create_metrics(criterion)

    metric_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)
    validation_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)

    @trainer.on(Events.EPOCH_COMPLETED)
    def compute_metrics(engine):
        metric_evaluator.run(metric_loader)
        validation_evaluator.run(val_loader)

    setup_common_training_handlers(trainer, log_every_iters=LOG_INTERVAL)

    if tb_log_dir:
        tb_logger = TensorboardLogger(log_dir=tb_log_dir)
        configure_tb_logger(tb_logger, model, trainer, metric_evaluator, validation_evaluator)

    # Add early stopping
    add_early_stopping_by_val_score(patience, validation_evaluator, trainer, "accuracy")

    # kick everything off
    trainer.run(train_loader, max_epochs=max_epochs)
    tb_logger.close()

    # Return the optimizer in case we want to continue training.
    return optimizer


# Dummy before we come up with the actual metrics.

def create_metrics(criterion):
    return {"accuracy": Accuracy(), "loss": Loss(criterion)}


def configure_tb_logger(tb_logger, model, trainer, train_evaluator, validation_evaluator):
    def global_step_transform(_, __):
        return trainer.state.iteration

    # Compared to the default tb_logger behavior it is better to log everything using a single step counter
    # and log epoch numbers separately.
    tb_logger.attach(
            trainer,
            log_handler=lambda engine, logger, event_name: logger.writer.add_scalar("epoch", engine.state.epoch,
                                                                                    engine.state.iteration),
            event_name=Events.ITERATION_COMPLETED(every=LOG_INTERVAL),
        )

    # Log trainer metrics
    tb_logger.attach(
            trainer,
            log_handler=OutputHandler(
                tag="training", output_transform=lambda loss: {"batchloss": loss}, metric_names="all",
                global_step_transform=global_step_transform
            ),
            event_name=Events.ITERATION_COMPLETED(every=LOG_INTERVAL),
        )

    # Log validation evaluator metrics.
    tb_logger.attach(
            validation_evaluator,
            log_handler=OutputHandler(tag="validation", metric_names="all", global_step_transform=global_step_transform),
            event_name=Events.EPOCH_COMPLETED,
        )

    # Log weights and gradients.
    tb_logger.attach(trainer, log_handler=WeightsScalarHandler(model),
                         event_name=Events.ITERATION_COMPLETED(every=HEAVY_LOG_INTERVAL))
    tb_logger.attach(trainer, log_handler=WeightsHistHandler(model),
                         event_name=Events.ITERATION_COMPLETED(every=HEAVY_LOG_INTERVAL))
    tb_logger.attach(trainer, log_handler=GradsScalarHandler(model),
                         event_name=Events.ITERATION_COMPLETED(every=HEAVY_LOG_INTERVAL))
    tb_logger.attach(trainer, log_handler=GradsHistHandler(model),
                         event_name=Events.ITERATION_COMPLETED(every=HEAVY_LOG_INTERVAL))