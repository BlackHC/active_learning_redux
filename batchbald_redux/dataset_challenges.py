# AUTOGENERATED! DO NOT EDIT! File to edit: 05d_dataset_challenges.ipynb (unless otherwise specified).

__all__ = ['NamedDataset', 'get_base_dataset', 'get_class_indices', 'ImbalancedDataset', 'ImbalancedClassSplitDataset',
           'OneHotDataset', 'SubsetDataset', 'ConstantTargetDataset', 'UniformTargetDataset']

# Cell

import bisect
from typing import Optional, Union

import numpy as np
import torch
import torch.utils.data as data

# Cell


class _NamedDataset(data.Dataset):
    dataset: data.Dataset
    name: str

    def __init__(self, dataset: data.Dataset, name: str):
        self.dataset = dataset
        self.name = name

    def __getitem__(self, idx):
        return self.dataset[idx]

    def __len__(self):
        return len(self.dataset)

    def __repr__(self):
        return self.name

    def __add__(self, other):
        return _NamedDataset(data.ConcatDataset([self, other]), f"{self} + {other}")

    def __mul__(self, factor):
        return SubsetDataset(self, factor=factor, seed=0)


class NamedDataset(_NamedDataset):
    def __init__(self, dataset: data.Dataset, name: str):
        super().__init__(dataset, name)


def get_base_dataset(dataset, index):
    if isinstance(dataset, NamedDataset):
        return dataset
    elif isinstance(dataset, data.ConcatDataset):
        if idx < 0:
            if -idx > len(self):
                raise ValueError("absolute value of index should not exceed dataset length")
            idx = len(self) + idx
        dataset_idx = bisect.bisect_right(self.cumulative_sizes, idx)
        if dataset_idx == 0:
            sample_idx = idx
        else:
            sample_idx = idx - self.cumulative_sizes[dataset_idx - 1]
        return get_base_dataset(dataset.datasets[dataset_idx], sample_idx)
    elif isinstance(dataset, _NamedDataset):
        return get_base_dataset(dataset.dataset, index)
    return dataset

# Cell


def get_class_indices(dataset: data.Dataset, *, class_counts: list, generator: np.random.Generator):
    class_counts = list(class_counts)

    subset_indices = []

    remaining_samples = sum(class_counts)

    indices = generator.permutation(len(dataset))
    for index in indices:
        _, y = dataset[index]

        if class_counts[y] > 0:
            subset_indices.append(index)
            class_counts[y] -= 1
            remaining_samples -= 1

            if remaining_samples <= 0:
                break

    return subset_indices


class ImbalancedDataset(_NamedDataset):
    options: dict
    indices: list

    def __init__(self, dataset: data.Dataset, *, class_counts: list, seed: int):
        options = dict(class_counts=class_counts, seed=seed)
        super().__init__(dataset, f"ImbalancedDataset(dataset={dataset}, {options})")
        self.options = options

        generator = np.random.default_rng(seed)
        self.indices = get_class_indices(dataset, class_counts=class_counts, generator=generator)

    def __getitem__(self, idx):
        return self.dataset[self.indices[idx]]

    def __len__(self):
        return len(self.indices)


class ImbalancedClassSplitDataset(_NamedDataset):
    dataset: data.Dataset
    options: dict
    indices: list

    def __init__(self, dataset: data.Dataset, *, num_classes: int, majority_percentage: int, seed: int):
        assert (num_classes % 2) == 0

        super().__init__(dataset, None)

        N_class = len(dataset) // num_classes
        N_majority = N_class * majority_percentage // 100
        N_minority = N_class * (100 - majority_percentage) // 100

        generator = np.random.default_rng(seed)

        class_counts = [N_majority] * (num_classes // 2) + [N_minority] * (num_classes // 2)
        class_counts = generator.permuted(class_counts)

        self.options = dict(
            num_classes=num_classes, majority_percentage=majority_percentage, seed=seed, class_counts=class_counts
        )
        self.name = f"ImbalancedDataset(dataset={self.dataset}, {self.options})"

        self.indices = get_class_indices(dataset, class_counts=class_counts, generator=generator)

    def __getitem__(self, idx):
        return self.dataset[self.indices[idx]]

    def __len__(self):
        return len(self.indices)

# Cell

# Convert label dataset to one hot
class OneHotDataset(_NamedDataset):
    options: dict
    targets: list

    def __init__(self, dataset: data.Dataset, *, num_classes: int, dtype=None, device=None):
        options = dict(num_classes=num_classes)

        super().__init__(dataset, f"OneHotDataset({dataset}, {options})")
        self.options = options

        N = len(dataset)
        targets = torch.zeros(len(dataset), num_classes, dtype=dtype, device=device)
        for i, (_, label) in enumerate(dataset):
            targets[i, label] = 1.0

        self.targets = targets

    def __getitem__(self, idx):
        data, _ = self.dataset[idx]
        return data, self.targets[idx]


class SubsetDataset(_NamedDataset):
    dataset: data.Dataset
    options: dict
    indices: list

    def __init__(self, dataset: data.Dataset, *, size: Optional[int] = None, factor: Optional[float] = None, seed: int):
        options = dict(size=size, factor=factor, seed=seed)
        super().__init__(dataset, f"SubsetDataset(dataset={dataset}, {options})")
        self.options = options

        generator = np.random.default_rng(seed)

        assert ((size is not None) or (factor is not None)) and not (size is None and factor is None)
        if size is not None:
            subset_size = size
        elif factor is not None:
            subset_size = int(len(dataset) * factor)
            if seed == 0:
                self.name = f"{dataset} * {factor}"

        self.indices = generator.choice(len(dataset), size=subset_size, replace=subset_size > len(dataset))

    def __getitem__(self, idx):
        return self.dataset[self.indices[idx]]

    def __len__(self):
        return len(self.indices)


class ConstantTargetDataset(_NamedDataset):
    target: object

    def __init__(self, dataset: data.Dataset, target: object):
        super().__init__(dataset, f"ConstantTargetDataset({dataset}, {target})")
        self.target = target

    def __getitem__(self, idx):
        data, _ = self.dataset[idx]
        return data, self.target


def UniformTargetDataset(dataset: data.Dataset, *, num_classes: int, device: str = None):
    target = torch.ones(num_classes, device=device) / num_classes
    result = ConstantTargetDataset(dataset, target)
    result.options = dict(num_classes=num_classes)
    result.name = f"UniformTargetDataset({dataset}, {result.options})"
    return result