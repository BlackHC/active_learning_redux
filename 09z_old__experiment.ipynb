{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment\n",
    "> Can we get better by training on our assumptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp old___experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import blackhc.project.script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules and functions were are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "import dataclasses\n",
    "import traceback\n",
    "from dataclasses import dataclass\n",
    "from typing import Type, Union\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from blackhc.project import is_run_from_ipython\n",
    "from blackhc.project.experiment import embedded_experiments\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import batchbald_redux.acquisition_functions as acquisition_functions\n",
    "from batchbald_redux.acquisition_functions import (\n",
    "    CandidateBatchComputer,\n",
    "    EvalModelBatchComputer,\n",
    ")\n",
    "from batchbald_redux.active_learning import ActiveLearningData\n",
    "from batchbald_redux.black_box_model_training import evaluate\n",
    "from batchbald_redux.dataset_challenges import (\n",
    "    create_repeated_MNIST_dataset,\n",
    "    get_base_dataset_index,\n",
    "    get_target,\n",
    ")\n",
    "from batchbald_redux.di import DependencyInjection\n",
    "from batchbald_redux.models import MnistModelTrainer\n",
    "from batchbald_redux.experiment_data import ExperimentData, ExperimentDataConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "from batchbald_redux.train_eval_model import (\n",
    "    TrainEvalModel,\n",
    "    TrainSelfDistillationEvalModel,\n",
    ")\n",
    "from batchbald_redux.trained_model import ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Experiment:\n",
    "    seed: int = 1337\n",
    "    acquisition_size: int = 5\n",
    "    max_training_set: int = 300\n",
    "    num_pool_samples: int = 20\n",
    "    num_validation_samples: int = 20\n",
    "    num_training_samples: int = 1\n",
    "    num_patience_epochs: int = 5 * 4\n",
    "    max_training_epochs: int = 30 * 4\n",
    "    training_batch_size: int = 64\n",
    "    device: str = \"cuda\"\n",
    "    validation_set_size: int = 2048\n",
    "    initial_set_size: int = 20\n",
    "    min_samples_per_epoch: int = 1024\n",
    "    repeated_mnist_repetitions: int = 1\n",
    "    add_dataset_noise: bool = False\n",
    "    acquisition_function: Union[\n",
    "        Type[CandidateBatchComputer], Type[EvalModelBatchComputer]\n",
    "    ] = acquisition_functions.BALD\n",
    "    train_eval_model_factory: Type[TrainEvalModel] = TrainSelfDistillationEvalModel\n",
    "    model_trainer_factory: Type[ModelTrainer] = MnistModelTrainer\n",
    "    acquisition_function_args: dict = None\n",
    "    temperature: float = 0.0\n",
    "\n",
    "    def load_dataset(self) -> (ActiveLearningData, Dataset, Dataset):\n",
    "        experiment_data_config = ExperimentDataConfig(id_dataset_name=\"MNIST\",\n",
    "                                                      id_repetitions=self.repeated_mnist_repetitions,\n",
    "                                                      initial_training_set_size=self.initial_set_size,\n",
    "                                                      evaluation_set_size=0,\n",
    "                                                      validation_split_random_state=0,\n",
    "                                                      validation_set_size=self.validation_set_size,\n",
    "                                                      add_dataset_noise=self.add_dataset_noise, ood_dataset_config=None,\n",
    "                                                      device=self.device)\n",
    "        experiment_data = experiment_data_config.load()\n",
    "\n",
    "        return experiment_data.active_learning, experiment_data.validation_dataset, experiment_data.test_dataset\n",
    "\n",
    "    # Simple Dependency Injection\n",
    "    def create_acquisition_function(self):\n",
    "        di = DependencyInjection(vars(self))\n",
    "        return di.create_dataclass_type(self.acquisition_function)\n",
    "\n",
    "    def create_train_eval_model(self, runtime_config) -> TrainEvalModel:\n",
    "        config = {**vars(self), **runtime_config}\n",
    "        di = DependencyInjection(config, [])\n",
    "        return di.create_dataclass_type(self.train_eval_model_factory)\n",
    "\n",
    "    def create_model_trainer(self) -> ModelTrainer:\n",
    "        di = DependencyInjection(vars(self))\n",
    "        return di.create_dataclass_type(self.model_trainer_factory)\n",
    "\n",
    "    def run(self, store):\n",
    "        torch.manual_seed(self.seed)\n",
    "\n",
    "        # Active Learning setup\n",
    "        active_learning_data, validation_dataset, test_dataset = self.load_dataset()\n",
    "        store[\"dataset_info\"] = dict(training=repr(active_learning_data.base_dataset), test=repr(test_dataset))\n",
    "\n",
    "        model_trainer = self.create_model_trainer()\n",
    "\n",
    "        train_loader = model_trainer.get_train_dataloader(active_learning_data.training_dataset)\n",
    "        pool_loader = model_trainer.get_evaluation_dataloader(active_learning_data.pool_dataset)\n",
    "        validation_loader = model_trainer.get_evaluation_dataloader(validation_dataset)\n",
    "        test_loader = model_trainer.get_evaluation_dataloader(test_dataset)\n",
    "\n",
    "        store[\"active_learning_steps\"] = []\n",
    "        active_learning_steps = store[\"active_learning_steps\"]\n",
    "\n",
    "        acquisition_function = self.create_acquisition_function()\n",
    "\n",
    "        # Active Training Loop\n",
    "        while True:\n",
    "            training_set_size = len(active_learning_data.training_dataset)\n",
    "            print(f\"Training set size {training_set_size}:\")\n",
    "\n",
    "            # iteration_log = dict(training={}, pool_training={}, evaluation_metrics=None, acquisition=None)\n",
    "            active_learning_steps.append({})\n",
    "            iteration_log = active_learning_steps[-1]\n",
    "\n",
    "            iteration_log[\"training\"] = {}\n",
    "            trained_model = model_trainer.get_trained(train_loader=train_loader, train_augmentations=None,\n",
    "                                                      validation_loader=validation_loader,\n",
    "                                                      log=iteration_log[\"training\"])\n",
    "\n",
    "            evaluation_metrics = evaluate(model=trained_model, num_samples=self.num_validation_samples,\n",
    "                                          loader=test_loader, device=self.device, storage_device=\"cpu\")\n",
    "\n",
    "            iteration_log[\"evaluation_metrics\"] = evaluation_metrics\n",
    "            print(f\"Perf after training {evaluation_metrics}\")\n",
    "\n",
    "            if training_set_size >= self.max_training_set:\n",
    "                print(\"Done.\")\n",
    "                break\n",
    "\n",
    "            if isinstance(acquisition_function, CandidateBatchComputer):\n",
    "                candidate_batch = acquisition_function.compute_candidate_batch(trained_model, pool_loader, self.device)\n",
    "            elif isinstance(acquisition_function, EvalModelBatchComputer):\n",
    "                train_eval_model = self.create_train_eval_model(\n",
    "                    dict(\n",
    "                        model_trainer=model_trainer,\n",
    "                        training_dataset=active_learning_data.training_dataset,\n",
    "                        eval_dataset=active_learning_data.pool_dataset,\n",
    "                        validation_loader=validation_loader,\n",
    "                        trained_model=trained_model,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                iteration_log[\"eval_training\"] = {}\n",
    "                trained_eval_model = train_eval_model(training_log=iteration_log[\"eval_training\"], device=self.device)\n",
    "\n",
    "                candidate_batch = acquisition_function.compute_candidate_batch(\n",
    "                    trained_model, trained_eval_model, pool_loader, device=self.device\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown acquisition function {acquisition_function}!\")\n",
    "\n",
    "            candidate_global_indices = [\n",
    "                get_base_dataset_index(active_learning_data.pool_dataset, index).index\n",
    "                for index in candidate_batch.indices\n",
    "            ]\n",
    "            candidate_labels = [\n",
    "                get_target(active_learning_data.base_dataset, index).item() for index in candidate_global_indices\n",
    "            ]\n",
    "\n",
    "            iteration_log[\"acquisition\"] = dict(\n",
    "                indices=candidate_global_indices, labels=candidate_labels, scores=candidate_batch.scores\n",
    "            )\n",
    "\n",
    "            active_learning_data.acquire(candidate_batch.indices)\n",
    "\n",
    "            ls = \", \".join(f\"{label} ({score:.4})\" for label, score in zip(candidate_labels, candidate_batch.scores))\n",
    "            print(f\"Acquiring (label, score)s: {ls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating: MnistModelTrainer(\n",
      "\tdevice=cuda,\n",
      "\tnum_training_samples=1,\n",
      "\tnum_validation_samples=20,\n",
      "\tnum_patience_epochs=20,\n",
      "\tmax_training_epochs=2,\n",
      "\tmin_samples_per_epoch=1024\n",
      ")\n",
      "Creating: BatchEvalBALD(\n",
      "\tacquisition_size=2,\n",
      "\tnum_pool_samples=20\n",
      ")\n",
      "Training set size 20:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243b74a168d246debdb688b5b519517e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " 50%|#####     | 1/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.59033203125, 'crossentropy': 1.8616515100002289}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.6083984375, 'crossentropy': 1.8942454904317856}\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: 0.6083984375)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.618, 'crossentropy': tensor(1.2012)}\n",
      "Creating: TrainSelfDistillationEvalModel(\n",
      "\tnum_pool_samples=20,\n",
      "\ttraining_dataset=<torch.utils.data.dataset.Subset object at 0x7f47bb7397c0>,\n",
      "\teval_dataset=<torch.utils.data.dataset.Subset object at 0x7f47bb739820>,\n",
      "\tvalidation_loader=<torch.utils.data.dataloader.DataLoader object at 0x7f47bb739b20>,\n",
      "\ttraining_batch_size=64,\n",
      "\ttrained_model=TrainedBayesianModel(model=BayesianMNISTCNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv1_drop): ConsistentMCDropout2d(p=0.5)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): ConsistentMCDropout2d(p=0.5)\n",
      "  (fc1): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  (fc1_drop): ConsistentMCDropout(p=0.5)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")),\n",
      "\tmodel_trainer=MnistModelTrainer(device='cuda', num_training_samples=1, num_validation_samples=20, num_patience_epochs=20, max_training_epochs=2, min_samples_per_epoch=1024, num_training_batch_size=64, num_evaluation_batch_size=128),\n",
      "\tmin_samples_per_epoch=1024\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/1159040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd73b2a66544489d8611ea22ce05977e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " 50%|#####     | 1/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.42822265625, 'crossentropy': 1.880868785083294}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.60302734375, 'crossentropy': 1.4887847229838371}\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: 0.60302734375)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/1158640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/1158640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/57932 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/57932 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BatchBALD:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/57932 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/57932 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/57932 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/57932 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquiring (label, score)s: 2 (0.7566), 9 (1.271)\n",
      "Training set size 22:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68440a2aa0354546bf094852c419197b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " 50%|#####     | 1/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.3779296875, 'crossentropy': 2.0181569680571556}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.63671875, 'crossentropy': 1.607244811952114}\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: 0.63671875)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.6702, 'crossentropy': tensor(1.1064)}\n",
      "Creating: TrainSelfDistillationEvalModel(\n",
      "\tnum_pool_samples=20,\n",
      "\ttraining_dataset=<torch.utils.data.dataset.Subset object at 0x7f47bb7397c0>,\n",
      "\teval_dataset=<torch.utils.data.dataset.Subset object at 0x7f47bb739820>,\n",
      "\tvalidation_loader=<torch.utils.data.dataloader.DataLoader object at 0x7f47bb739b20>,\n",
      "\ttraining_batch_size=64,\n",
      "\ttrained_model=TrainedBayesianModel(model=BayesianMNISTCNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv1_drop): ConsistentMCDropout2d(p=0.5)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): ConsistentMCDropout2d(p=0.5)\n",
      "  (fc1): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  (fc1_drop): ConsistentMCDropout(p=0.5)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")),\n",
      "\tmodel_trainer=MnistModelTrainer(device='cuda', num_training_samples=1, num_validation_samples=20, num_patience_epochs=20, max_training_epochs=2, min_samples_per_epoch=1024, num_training_batch_size=64, num_evaluation_batch_size=128),\n",
      "\tmin_samples_per_epoch=1024\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/1159040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c5d0a83c53844a3b7271dfca9cbc50c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " 50%|#####     | 1/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.27734375, 'crossentropy': 2.078089661896229}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.5341796875, 'crossentropy': 1.5239248871803284}\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: 0.5341796875)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b73d6c6fe64f47b4d2ae08564b79da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/1158600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48714/432131889.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_48714/3205471907.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, store)\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mtrained_eval_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_eval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_log\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miteration_log\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval_training\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                 candidate_batch = acquisition_function.compute_candidate_batch(\n\u001b[0m\u001b[1;32m    121\u001b[0m                     \u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_eval_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 )\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/acquisition_functions.py\u001b[0m in \u001b[0;36mcompute_candidate_batch\u001b[0;34m(self, model, eval_model, pool_loader, device)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainedModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainedModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_loader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     ) -> CandidateBatch:\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mlog_probs_N_K_C\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_log_probs_N_K_C\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_pool_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m         \u001b[0mlog_eval_probs_N_K_C\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_log_probs_N_K_C\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_pool_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/trained_model.py\u001b[0m in \u001b[0;36mget_log_probs_N_K_C\u001b[0;34m(self, loader, num_samples, device)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_log_probs_N_K_C\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_log_probs_N_K_C_labels_N\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/trained_model.py\u001b[0m in \u001b[0;36mget_log_probs_N_K_C_labels_N\u001b[0;34m(self, loader, num_samples, device)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_log_probs_N_K_C_labels_N\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         log_probs_N_K_C, labels_B = self.model.get_predictions_labels(\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/consistent_mc_dropout.py\u001b[0m in \u001b[0;36mget_predictions_labels\u001b[0;34m(self, num_samples, loader, device)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mtoma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mget_prediction_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0;32mnonlocal\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mnonlocal\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/toma/__init__.py\u001b[0m in \u001b[0;36mexecute_range\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mexecute_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mexplicit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoma_cache_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoma_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mexecute_range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/toma/__init__.py\u001b[0m in \u001b[0;36mrange\u001b[0;34m(func, start, end, initial_step, toma_context, toma_cache_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                 \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m                 \u001b[0mcurrent\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mgc_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/consistent_mc_dropout.py\u001b[0m in \u001b[0;36mget_prediction_batch\u001b[0;34m(start, end)\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0mdata_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_sub_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/blackhc/progress_bar/details.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, delta_processed)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_processed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta_processed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0;31m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1224\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ema_dn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ema_dt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlock_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1227\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_miniters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m                     \u001b[0;31m# If no `miniters` was specified, adjust automatically to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self, nolock, lock_args)\u001b[0m\n\u001b[1;32m   1327\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnolock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# experiment\n",
    "\n",
    "experiment = Experiment(\n",
    "    seed=1120,\n",
    "    max_training_epochs=2,\n",
    "    max_training_set=130,\n",
    "    acquisition_function=acquisition_functions.BatchEvalBALD,\n",
    "    acquisition_size=2,\n",
    "    num_pool_samples=20,\n",
    "    temperature=8,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "results = {}\n",
    "experiment.run(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'initial_training_set_indices': [38043,\n",
       "  40091,\n",
       "  17418,\n",
       "  2094,\n",
       "  39879,\n",
       "  3133,\n",
       "  5011,\n",
       "  40683,\n",
       "  54379,\n",
       "  24287,\n",
       "  9849,\n",
       "  59305,\n",
       "  39508,\n",
       "  39356,\n",
       "  8758,\n",
       "  52579,\n",
       "  13655,\n",
       "  7636,\n",
       "  21562,\n",
       "  41329],\n",
       " 'dataset_info': {'training': \"'FastMNIST (Train)'\",\n",
       "  'test': \"'FastMNIST (Test)'\"},\n",
       " 'active_learning_steps': [{'training': {'epochs': [{'accuracy': 0.59033203125,\n",
       "      'crossentropy': 1.8616515100002289},\n",
       "     {'accuracy': 0.6083984375, 'crossentropy': 1.8942454904317856}],\n",
       "    'best_epoch': 2},\n",
       "   'evaluation_metrics': {'accuracy': 0.618, 'crossentropy': tensor(1.2012)},\n",
       "   'eval_training': {'epochs': [{'accuracy': 0.42822265625,\n",
       "      'crossentropy': 1.880868785083294},\n",
       "     {'accuracy': 0.60302734375, 'crossentropy': 1.4887847229838371}],\n",
       "    'best_epoch': 2},\n",
       "   'acquisition': {'indices': [54709, 24497],\n",
       "    'labels': [2, 9],\n",
       "    'scores': [0.7566147013141693, 1.2705203278051234]}},\n",
       "  {'training': {'epochs': [{'accuracy': 0.3779296875,\n",
       "      'crossentropy': 2.0181569680571556},\n",
       "     {'accuracy': 0.63671875, 'crossentropy': 1.607244811952114}],\n",
       "    'best_epoch': 2},\n",
       "   'evaluation_metrics': {'accuracy': 0.6702, 'crossentropy': tensor(1.1064)},\n",
       "   'eval_training': {'epochs': [{'accuracy': 0.27734375,\n",
       "      'crossentropy': 2.078089661896229},\n",
       "     {'accuracy': 0.5341796875, 'crossentropy': 1.5239248871803284}],\n",
       "    'best_epoch': 2}}]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size 20:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3fc327793734c0eb2f361164ad86451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/384]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/64]   2%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RestoringEarlyStopping: Restoring best parameters. (Score: -6.529030114412308)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/157]   1%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.5367, 'crossentropy': 6.438035237884521}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions:   0%|          | 0/463616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382711f4f7ad4ec7980c856e0f9d229e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1811]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/64]   2%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RestoringEarlyStopping: Restoring best parameters. (Score: -5.1637596152722836)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions:   0%|          | 0/2317680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions:   0%|          | 0/2317680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/115884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/115884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/115884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/115884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquiring (label, score)s: 8 (0.8711), 8 (0.8687), 3 (0.876), 3 (0.8465), 3 (0.8811)\n",
      "Training set size 25:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c326c4165e48eab908014b4064f795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/384]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/64]   2%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RestoringEarlyStopping: Restoring best parameters. (Score: -4.6851686127483845)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/157]   1%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.6256, 'crossentropy': 4.484497045135498}\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'initial_training_set_indices': [38043,\n",
       "  40091,\n",
       "  17418,\n",
       "  2094,\n",
       "  39879,\n",
       "  3133,\n",
       "  5011,\n",
       "  40683,\n",
       "  54379,\n",
       "  24287,\n",
       "  9849,\n",
       "  59305,\n",
       "  39508,\n",
       "  39356,\n",
       "  8758,\n",
       "  52579,\n",
       "  13655,\n",
       "  7636,\n",
       "  21562,\n",
       "  41329],\n",
       " 'active_learning_steps': [{'training': {'epochs': [{'accuracy': 0.538818359375,\n",
       "      'crossentropy': 6.529030114412308}],\n",
       "    'best_epoch': 1},\n",
       "   'evalution_metrics': {'accuracy': 0.5367,\n",
       "    'crossentropy': 6.438035237884521},\n",
       "   'pool_training': {'epochs': [{'accuracy': 0.531005859375,\n",
       "      'crossentropy': 5.1637596152722836}],\n",
       "    'best_epoch': 1},\n",
       "   'acquisition': {'indices': [63338, 10856, 63452, 81864, 109287],\n",
       "    'labels': [8, 8, 3, 3, 3],\n",
       "    'scores': [0.8710822958846325,\n",
       "     0.8687216999221631,\n",
       "     0.8759664372823723,\n",
       "     0.8464646732511746,\n",
       "     0.8810812784952251]}},\n",
       "  {'training': {'epochs': [{'accuracy': 0.62255859375,\n",
       "      'crossentropy': 4.6851686127483845}],\n",
       "    'best_epoch': 1},\n",
       "   'evalution_metrics': {'accuracy': 0.6256,\n",
       "    'crossentropy': 4.484497045135498}}]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment\n",
    "\n",
    "experiment = Experiment(\n",
    "    max_training_epochs=1, max_training_set=25, acquisition_function=AcquisitionFunction.randombaldical\n",
    ")\n",
    "\n",
    "results = {}\n",
    "experiment.run(results)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    configs = (\n",
    "        [\n",
    "            Experiment(\n",
    "                seed=seed + 120,\n",
    "                acquisition_function=acquisition_function,\n",
    "                acquisition_size=acquisition_size,\n",
    "                num_pool_samples=100,\n",
    "            )\n",
    "            for seed in range(5)\n",
    "            for acquisition_size in [5, 10]\n",
    "            for acquisition_function in [AcquisitionFunction.batchbald, AcquisitionFunction.batchbaldical]\n",
    "        ]\n",
    "        + [\n",
    "            Experiment(\n",
    "                seed=seed + 120,\n",
    "                acquisition_function=acquisition_function,\n",
    "                acquisition_size=acquisition_size,\n",
    "                num_pool_samples=max(20, acquisition_size),\n",
    "            )\n",
    "            for seed in range(5)\n",
    "            for acquisition_size in [5, 10, 20, 50]\n",
    "            for acquisition_function in [\n",
    "                AcquisitionFunction.bald,\n",
    "                AcquisitionFunction.thompsonbald,\n",
    "                AcquisitionFunction.randombald,\n",
    "            ]\n",
    "        ]\n",
    "        + [\n",
    "            Experiment(\n",
    "                seed=seed + 120,\n",
    "                acquisition_function=AcquisitionFunction.random,\n",
    "                acquisition_size=5,\n",
    "                num_pool_samples=20,\n",
    "            )\n",
    "            for seed in range(40)\n",
    "            for acquisition_size in [5]\n",
    "        ]\n",
    "    )\n",
    "if False:\n",
    "    configs = [\n",
    "        Experiment(\n",
    "            seed=seed + 240,\n",
    "            acquisition_function=acquisition_function,\n",
    "            acquisition_size=acquisition_size,\n",
    "            num_pool_samples=max(20, acquisition_size),\n",
    "        )\n",
    "        for seed in range(5)\n",
    "        for acquisition_size in [5, 10, 20, 50]\n",
    "        for acquisition_function in [\n",
    "            AcquisitionFunction.baldical,\n",
    "            AcquisitionFunction.randombaldical,\n",
    "        ]\n",
    "    ]\n",
    "if False:\n",
    "    configs = [\n",
    "        Experiment(\n",
    "            seed=seed + 340,\n",
    "            acquisition_function=acquisition_function,\n",
    "            acquisition_size=acquisition_size,\n",
    "            num_pool_samples=20,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        for seed in range(5)\n",
    "        for acquisition_size in [5, 10, 20, 50]\n",
    "        for acquisition_function in [\n",
    "            AcquisitionFunction.temperedbald,\n",
    "        ]\n",
    "        for temperature in [13, 15, 18]\n",
    "    ]\n",
    "if False:\n",
    "    configs = [\n",
    "        Experiment(\n",
    "            seed=seed + 340,\n",
    "            acquisition_function=acquisition_function,\n",
    "            acquisition_size=acquisition_size,\n",
    "            num_pool_samples=20,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        for seed in range(5)\n",
    "        for acquisition_size in [5, 10, 20, 50]\n",
    "        for acquisition_function in [\n",
    "            AcquisitionFunction.temperedbald,\n",
    "        ]\n",
    "        for temperature in [8, 10]\n",
    "    ] + [\n",
    "        Experiment(\n",
    "            seed=seed + 340,\n",
    "            acquisition_function=acquisition_function,\n",
    "            acquisition_size=acquisition_size,\n",
    "            num_pool_samples=20,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        for seed in range(5)\n",
    "        for acquisition_size in [5, 10, 20, 50]\n",
    "        for acquisition_function in [\n",
    "            AcquisitionFunction.temperedbaldical,\n",
    "        ]\n",
    "        for temperature in [8, 10, 13]\n",
    "    ]\n",
    "if False:\n",
    "    configs = [\n",
    "        Experiment(\n",
    "            seed=seed + 500,\n",
    "            acquisition_function=acquisition_function,\n",
    "            acquisition_size=acquisition_size,\n",
    "            num_pool_samples=20,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        for seed in range(5)\n",
    "        for acquisition_size in [5, 10, 20, 50]\n",
    "        for acquisition_function in [\n",
    "            AcquisitionFunction.temperedical,\n",
    "        ]\n",
    "        for temperature in [5, 8, 11]\n",
    "    ] + [\n",
    "        Experiment(\n",
    "            seed=seed + 600,\n",
    "            acquisition_function=acquisition_function,\n",
    "            acquisition_size=acquisition_size,\n",
    "            num_pool_samples=20,\n",
    "        )\n",
    "        for seed in range(5)\n",
    "        for acquisition_size in [5, 10, 20, 50]\n",
    "        for acquisition_function in [\n",
    "            AcquisitionFunction.ical,\n",
    "        ]\n",
    "    ]\n",
    "if False:\n",
    "    configs = (\n",
    "        [\n",
    "            Experiment(\n",
    "                seed=seed + 1000,\n",
    "                acquisition_function=acquisition_function,\n",
    "                acquisition_size=acquisition_size,\n",
    "                num_pool_samples=num_pool_samples,\n",
    "                temperature=temperature,\n",
    "            )\n",
    "            for seed in range(5)\n",
    "            for acquisition_size in [5, 10, 20, 50]\n",
    "            for num_pool_samples in [20, 100]\n",
    "            for acquisition_function in [\n",
    "                AcquisitionFunction.temperedical,\n",
    "                AcquisitionFunction.temperedbald,\n",
    "                AcquisitionFunction.temperedbaldical,\n",
    "            ]\n",
    "            for temperature in [2, 5, 8]\n",
    "        ]\n",
    "        + [\n",
    "            Experiment(\n",
    "                seed=seed + 2000,\n",
    "                acquisition_function=acquisition_function,\n",
    "                acquisition_size=acquisition_size,\n",
    "                num_pool_samples=num_pool_samples,\n",
    "            )\n",
    "            for seed in range(5)\n",
    "            for acquisition_size in [5, 10, 20, 50]\n",
    "            for num_pool_samples in [20, 100]\n",
    "            for acquisition_function in [\n",
    "                AcquisitionFunction.ical,\n",
    "                AcquisitionFunction.bald,\n",
    "                AcquisitionFunction.baldical,\n",
    "                AcquisitionFunction.randombald,\n",
    "            ]\n",
    "        ]\n",
    "        + [\n",
    "            Experiment(\n",
    "                seed=seed + 2000,\n",
    "                acquisition_function=acquisition_function,\n",
    "                acquisition_size=acquisition_size,\n",
    "                num_pool_samples=max(num_pool_samples, acquisition_size),\n",
    "            )\n",
    "            for seed in range(5)\n",
    "            for acquisition_size in [5, 10, 20, 50]\n",
    "            for num_pool_samples in [20, 100]\n",
    "            for acquisition_function in [\n",
    "                AcquisitionFunction.thompsonbald,\n",
    "            ]\n",
    "        ]\n",
    "        + [\n",
    "            Experiment(\n",
    "                seed=seed + 3000,\n",
    "                acquisition_function=acquisition_function,\n",
    "                acquisition_size=acquisition_size,\n",
    "                num_pool_samples=100,\n",
    "            )\n",
    "            for seed in range(5)\n",
    "            for acquisition_size in [5]\n",
    "            for acquisition_function in [\n",
    "                AcquisitionFunction.batchbaldical,\n",
    "                AcquisitionFunction.batchbald,\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "if False:\n",
    "    configs = [\n",
    "    Experiment(\n",
    "        seed=seed,\n",
    "        acquisition_function=acquisition_functions.BALD,\n",
    "        acquisition_size=acquisition_size,\n",
    "        num_pool_samples=num_pool_samples,\n",
    "    )\n",
    "    for seed in range(5)\n",
    "    for acquisition_size in [5, 10, 20, 50]\n",
    "    for num_pool_samples in [10, 20, 50, 100]\n",
    "] + [\n",
    "    Experiment(\n",
    "        seed=seed,\n",
    "        acquisition_function=acquisition_functions.Random,\n",
    "        acquisition_size=5,\n",
    "        num_pool_samples=20,\n",
    "    )\n",
    "    for seed in range(20)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "configs = [\n",
    "    Experiment(\n",
    "        seed=seed + 315,\n",
    "        acquisition_function=acquisition_function,\n",
    "        acquisition_size=acquisition_size,\n",
    "        num_pool_samples=num_pool_samples,\n",
    "        repeated_mnist_repetitions=repeated_mnist_repetitions,\n",
    "        add_dataset_noise=repeated_mnist_repetitions > 1,\n",
    "        temperature=temperature,\n",
    "        max_training_set=150,\n",
    "    )\n",
    "    for seed in range(5)\n",
    "    for acquisition_function in [\n",
    "        acquisition_functions.SoftmaxBALD,\n",
    "    ]\n",
    "    for temperature in [1 / 32, 1 / 64, 1 / 128, 1 / 256]\n",
    "    for acquisition_size in [5]\n",
    "    for num_pool_samples in [100]\n",
    "    for repeated_mnist_repetitions in [2]\n",
    "]\n",
    "\n",
    "if not is_run_from_ipython() and __name__ == \"__main__\":\n",
    "    for job_id, store in embedded_experiments(__file__, len(configs)):\n",
    "        config = configs[job_id]\n",
    "        config.seed += job_id\n",
    "        print(config)\n",
    "        store[\"config\"] = dataclasses.asdict(config)\n",
    "        store[\"log\"] = {}\n",
    "\n",
    "        try:\n",
    "            config.run(store=store)\n",
    "        except Exception:\n",
    "            store[\"exception\"] = traceback.format_exc()\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    Experiment(\n",
      "        seed=115,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=0.0625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=115,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=0.125\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=115,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=0.25\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=115,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=0.5\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=115,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=1\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=115,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=2\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=115,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=4\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=115,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=8\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=115,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=16\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=115,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=0.0625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=115,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=0.125\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=115,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=0.25\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=115,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=0.5\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=115,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=1\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=115,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=2\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=115,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=4\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=115,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=8\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=115,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=16\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=116,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=0.0625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=116,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=0.125\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=116,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=0.25\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=116,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=0.5\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=116,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=1\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=116,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=2\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=116,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=4\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=116,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=8\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=116,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=16\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=116,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=0.0625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=116,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=0.125\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=116,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=0.25\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=116,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=0.5\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=116,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=1\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=116,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=2\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=116,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=4\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=116,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=8\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=116,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=16\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=117,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=0.0625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=117,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=0.125\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=117,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=0.25\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=117,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=0.5\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=117,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=1\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=117,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=2\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=117,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=4\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=117,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=8\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=117,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=16\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=117,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=0.0625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=117,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=0.125\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=117,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=0.25\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=117,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=0.5\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=117,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=1\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=117,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=2\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=117,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=4\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=117,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=8\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=117,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=16\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=118,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=0.0625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=118,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=0.125\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=118,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=0.25\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=118,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=0.5\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=118,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=1\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=118,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=2\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=118,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=4\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=118,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=8\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=118,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=16\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=118,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=0.0625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=118,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=0.125\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=118,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=0.25\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=118,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=0.5\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=118,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=1\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=118,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=2\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=118,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=4\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=118,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=8\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=118,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=16\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=119,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=0.0625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=119,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=0.125\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=119,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=0.25\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=119,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=0.5\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=119,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=1\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=119,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=2\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=119,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=4\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=119,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=8\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=119,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        temperature=16\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=119,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=0.0625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=119,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=0.125\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=119,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=0.25\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=119,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=0.5\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=119,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=1\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=119,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=2\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=119,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=4\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=119,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=8\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=119,\n",
      "        max_training_set=150,\n",
      "        num_pool_samples=100,\n",
      "        repeated_mnist_repetitions=2,\n",
      "        add_dataset_noise=True,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.TemperedBALD,\n",
      "        temperature=16\n",
      "    )\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# slow\n",
    "import prettyprinter\n",
    "\n",
    "prettyprinter.install_extras(include={\"dataclasses\"})\n",
    "\n",
    "prettyprinter.pprint(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:active_learning]",
   "language": "python",
   "name": "conda-env-active_learning-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
