{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended /home/blackhc/PycharmProjects/bald-ical/src to paths\n",
      "Switched to directory /home/blackhc/PycharmProjects/bald-ical\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "import blackhc.project.script\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquisition Function: CoreSet\n",
    "> Greedy algorithm and score computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will implement two helper classes to compute conditional entropies $H[y_i|w]$ and entropies $H[y_i]$. \n",
    "Then, we will implement BatchBALD and BALD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from blackhc.progress_bar import create_progress_bar\n",
    "from toma import toma\n",
    "\n",
    "from batchbald_redux.acquisition_functions.coreset import * \n",
    "from batchbald_redux.joint_entropy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to define a couple of sampled distributions to use for our testing our code.\n",
    "\n",
    "$K=20$ means 20 inference samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-3d0d22441a54>:23: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068694/work/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  return torch.stack(list(map(torch.as_tensor, l)))\n"
     ]
    }
   ],
   "source": [
    "def get_mixture_prob_dist(p1, p2, m):\n",
    "    return (1.0 - m) * np.asarray(p1) + m * np.asarray(p2)\n",
    "\n",
    "\n",
    "p1 = [0.7, 0.1, 0.1, 0.1]\n",
    "p2 = [0.3, 0.3, 0.2, 0.2]\n",
    "y1_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "p1 = [0.1, 0.7, 0.1, 0.1]\n",
    "p2 = [0.2, 0.3, 0.3, 0.2]\n",
    "y2_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "p1 = [0.1, 0.1, 0.7, 0.1]\n",
    "p2 = [0.2, 0.2, 0.3, 0.3]\n",
    "y3_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "p1 = [0.1, 0.1, 0.1, 0.7]\n",
    "p2 = [0.3, 0.2, 0.2, 0.3]\n",
    "y4_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "\n",
    "def nested_to_tensor(l):\n",
    "    return torch.stack(list(map(torch.as_tensor, l)))\n",
    "\n",
    "\n",
    "ys_ws = nested_to_tensor([y1_ws, y2_ws, y3_ws, y4_ws])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "\n",
    "p = [0.25, 0.25, 0.25, 0.25]\n",
    "yu_ws = [p for m in range(K)]\n",
    "yus_ws = nested_to_tensor([yu_ws] * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 20, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_ws.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, our neural networks usually use a `log_softmax` as final layer. To avoid having to call `.exp_()`, which is easy to miss and annoying to debug, we will instead use a version that uses `log_probs` instead of `probs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "# Make sure everything is computed correctly.\n",
    "assert np.allclose(compute_conditional_entropy(yus_ws.log()), [1.3863, 1.3863, 1.3863, 1.3863], atol=0.1)\n",
    "assert np.allclose(compute_entropy(yus_ws.log()), [1.3863, 1.3863, 1.3863, 1.3863], atol=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2069, 1.2069, 1.2069, 1.2069], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "conditional_entropies = compute_conditional_entropy(ys_ws.log())\n",
    "\n",
    "print(conditional_entropies)\n",
    "\n",
    "assert np.allclose(conditional_entropies, [1.2069, 1.2069, 1.2069, 1.2069], atol=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2376, 1.2376, 1.2376, 1.2376], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "entropies = compute_entropy(ys_ws.log())\n",
    "\n",
    "print(entropies)\n",
    "\n",
    "assert np.allclose(entropies, [1.2376, 1.2376, 1.2376, 1.2376], atol=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Gain\n",
    "\n",
    "(Following the new notation.)\n",
    "\n",
    "Instead of computing $I[Y;\\omega|x]$, we use our knowledge of the labels and compute: $$I[y;\\omega|x]= H[y|x] - \\mathbb{E}_{p(\\omega|y,x)} H[y|x,\\omega].$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0300, 0.0300, 0.0300, 0.0300], dtype=torch.float64),\n",
       " [tensor([0.0300, 0.0207, 0.0207, 0.0474], dtype=torch.float64),\n",
       "  tensor([0.0474, 0.0300, 0.0207, 0.0207], dtype=torch.float64),\n",
       "  tensor([0.0207, 0.0474, 0.0300, 0.0207], dtype=torch.float64)])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_coreset_bald_scores(ys_ws.log().double(), torch.tensor([0, 1, 2, 3])), [\n",
    "    get_coreset_bald_scores(ys_ws.log().double(), torch.tensor([i, i, i, i])) for i in range(3)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Information Gain\n",
    "\n",
    "(Following the new notation.)\n",
    "\n",
    "The batch version of this acquisition function can be computed more easily:\n",
    "\n",
    "$$ \\operatorname{I}[(y)_B;\\omega|(x)_B] = \\operatorname{H}[(y)_B|(x)_B] - \\mathbb{E}_{p(\\omega|(y)_B, (x)_B)} \\operatorname{H}[(y)_B|(x)_B, \\omega], $$\n",
    "\n",
    "where $p(\\omega|(y)_B, (x)_B) = \\frac{ p((y)_B| (x)_B, \\omega) p(\\omega) }{ p((y)_B| (x)_B) }$ as usual, and we make use of the independence of the $(y)_B$ given $\\omega$.\n",
    "\n",
    "We can make this efficient for computing scores in parallel by using:\n",
    "$$p((y)_B|(x)_B, \\omega) = p(y_B|x_B, \\omega) \\; p((y)_{B-1}|(x)_{B-1}, \\omega).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do we have sub-modularity?\n",
    "\n",
    "Unclear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_coreset_bald_batch_simpler(\n",
    "    log_probs_N_K_C: torch.Tensor, labels_N: torch.Tensor, *, batch_size: int, dtype=None, device=None\n",
    ") -> CandidateBatch:\n",
    "    # We want to compute (note this does not follow the notation from below):\n",
    "    # CoreSetBALD = H[y_1, ..., y_n ] - E_p(w) p(y_1, ..., y_n | w) / p(y_1, ..., y_n) H[y_1, ..., y_n | w]\n",
    "    # H[y_1, ..., y_n | w] = H[y_1, ..., y_{n-1} | w] + H[y_n | w] because y_i _||_ y_j | w\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    candidate_indices = []\n",
    "    candidate_scores = []\n",
    "\n",
    "    if batch_size == 0:\n",
    "        return CandidateBatch(candidate_scores, candidate_indices)\n",
    "\n",
    "    labels_N_1_1 = labels_N[:, None, None]\n",
    "    log_probs_N_K = (\n",
    "        joint_entropy.gather_expand(log_probs_N_K_C, dim=2, index=labels_N_1_1)\n",
    "        .squeeze(2)\n",
    "        .to(dtype=dtype, device=device)\n",
    "    )\n",
    "\n",
    "    # p((y)_{B-1}|(x)_{B-1}, \\omega)\n",
    "    log_probs_conditional_joint_batch_K = torch.zeros_like(log_probs_N_K[0], dtype=dtype, device=device)\n",
    "\n",
    "    for i in with_progress_bar(range(batch_size), tqdm_args=dict(desc=\"BatchCoreSetBALD\", leave=False)):\n",
    "        # p((y)_B|(x)_B, \\omega) = p(y_B|x_B, \\omega) * p((y)_{B-1}|(x)_{B-1}, \\omega)\n",
    "        log_prob_conditional_joint_N_K = log_probs_N_K + log_probs_conditional_joint_batch_K[None, :]\n",
    "\n",
    "        # Marginalize over w (but using sum not mean):\n",
    "        # p((y)_B|(x)_B) = E_p(\\omega) p((y)_B|(x)_B, \\omega)\n",
    "        log_prob_joint_N_1 = log_prob_conditional_joint_N_K.logsumexp(dim=1, keepdim=True) - np.log(K)\n",
    "\n",
    "        # \\frac{ p((y)_B| (x)_B, \\omega) }{ p((y)_B| (x)_B) }\n",
    "        log_ratio_N_K = log_prob_conditional_joint_N_K - log_prob_joint_N_1\n",
    "        conditional_entropy_joint_N = -torch.mean(log_ratio_N_K.exp() * log_prob_conditional_joint_N_K, dim=1)\n",
    "        entropy_joint_N = -log_prob_joint_N_1.squeeze(1)\n",
    "        scores_N = entropy_joint_N - conditional_entropy_joint_N\n",
    "\n",
    "        # Select candidate\n",
    "        scores_N[candidate_indices] = -float(\"inf\")\n",
    "\n",
    "        candidate_score, candidate_index = scores_N.max(dim=0)\n",
    "\n",
    "        candidate_indices.append(candidate_index.item())\n",
    "        candidate_scores.append(candidate_score.item())\n",
    "\n",
    "        # Update log_probs_conditional_joint_batch_K\n",
    "        log_probs_conditional_joint_batch_K = log_prob_conditional_joint_N_K[candidate_index]\n",
    "\n",
    "    return CandidateBatch(candidate_scores, candidate_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.03002132, 0.03002132, 0.03002132, 0.03002132]),\n",
       " [tensor([0.0300, 0.0207, 0.0207, 0.0474], dtype=torch.float64),\n",
       "  tensor([0.0474, 0.0300, 0.0207, 0.0207], dtype=torch.float64),\n",
       "  tensor([0.0207, 0.0474, 0.0300, 0.0207], dtype=torch.float64)])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_coreset_bald_scores(ys_ws.log().double(), torch.tensor([0, 1, 2, 3])).numpy(), [\n",
    "    get_coreset_bald_scores(ys_ws.log().double(), torch.tensor([i, i, i, i])) for i in range(3)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 20, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_ws.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BatchCoreSetBALD:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.030021323375763576, 0.10871562110954991, 0.2168431672489275, 0.3375447132429139], indices=[0, 1, 2, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch_coreset_bald_batch(ys_ws.log().double(), torch.tensor([0, 1, 2, 3]), batch_size=4, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BatchCoreSetBALD:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.030021323375763687, 0.10871562110954991, 0.2168431672489275, 0.3375447132429139], indices=[0, 1, 2, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch_coreset_bald_batch_simpler(ys_ws.log().double(), torch.tensor([0, 1, 2, 3]), batch_size=4, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoreSet-PIG & Coreset-PIG-BALD\n",
    "\n",
    "Combining EIG with CoreSets to use $I[y_{eval}; y_{batch} | x_{eval}; x_{batch}, D_{train}]$.\n",
    "\n",
    "This is really easy to compute as $H[y_{batch} | x_{batch}, D_{train}] - H[y_{batch} | y_{eval}, x_{eval}; x_{batch}, D_{train}]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_coreset_eig_scores(\n",
    "    training_log_probs_N_K_C=ys_ws.log().double(),\n",
    "    eval_log_probs_N_K_C=ys_ws.log().double(),\n",
    "    labels_N=torch.tensor([0, 1, 2, 3]),\n",
    "    dtype=torch.double,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_coreset_eig_bald_scores(\n",
    "    training_log_probs_N_K_C=ys_ws.log().double(),\n",
    "    eval_log_probs_N_K_C=ys_ws.log().double(),\n",
    "    labels_N=torch.tensor([0, 1, 2, 3]),\n",
    "    dtype=torch.double,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:active_learning]",
   "language": "python",
   "name": "conda-env-active_learning-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
