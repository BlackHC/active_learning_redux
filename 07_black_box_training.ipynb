{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Black Box Model Training\n",
    "> No worries, no cry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at a simple example experiment, it is worth looking at the big picture. The big picture requires us to train different models with differently-sized datasets.\n",
    "\n",
    "We don't want to worry about fine-tuning training too much. Because we cannot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# default_exp black_box_model_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended /home/blackhc/PycharmProjects/bald-ical/src to paths\n",
      "Switched to directory /home/blackhc/PycharmProjects/bald-ical\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import blackhc.project.script\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "\n",
    "* Log as much as possible by default.\n",
    "* Avoid magic numbers. Magic numbers don't work very well when everything keeps changing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from ignite.contrib.engines.common import setup_common_training_handlers, \\\n",
    "    add_early_stopping_by_val_score\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "from ignite.engine import create_supervised_trainer, create_supervised_evaluator, Events\n",
    "from ignite.metrics import Accuracy, Loss, RunningAverage\n",
    "from ignite.utils import apply_to_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#exports\n",
    "\n",
    "\n",
    "LOG_INTERVAL = 10\n",
    "HEAVY_LOG_INTERVAL = 100\n",
    "\n",
    "\n",
    "def train(*, model, train_loader, val_loader,\n",
    "          patience:int, max_epochs:int, device:str, epochs_log:list, loss=None):\n",
    "    \"\"\"\n",
    "    :param model:\n",
    "    :param train_loader:\n",
    "    :param val_loader:\n",
    "    :param metric_loader: We compute metrics for debugging and introspection purposes with this data.\n",
    "    :param patience: How many epochs to wait for early-stopping.\n",
    "    :param max_epochs:\n",
    "    :param tb_log_dir:\n",
    "    :param device:\n",
    "    :return: Optimizer that was used for training.\n",
    "    \"\"\"\n",
    "    if loss is None:\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Move model before creating optimizer\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), weight_decay=5e-4)    \n",
    "    \n",
    "    trainer = create_supervised_trainer(model, optimizer, loss, device=device)\n",
    "\n",
    "    metrics = create_metrics(loss)\n",
    "\n",
    "    validation_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def compute_metrics(engine):\n",
    "        validation_evaluator.run(val_loader)\n",
    "        \n",
    "    RunningAverage(output_transform=lambda x: x).attach(trainer, 'crossentropy')\n",
    "        \n",
    "    setup_common_training_handlers(trainer, with_gpu_stats=True, log_every_iters=LOG_INTERVAL)\n",
    "        \n",
    "\n",
    "    ProgressBar(persist=False).attach(validation_evaluator, metric_names=\"all\",\n",
    "                                      event_name=Events.ITERATION_COMPLETED(every=LOG_INTERVAL))\n",
    "    \n",
    "    @validation_evaluator.on(Events.EPOCH_COMPLETED)\n",
    "    def log_training_results(engine):\n",
    "        metrics = engine.state.metrics\n",
    "        epochs_log.append(str(metrics))\n",
    "        \n",
    "    # Add early stopping\n",
    "    add_early_stopping_by_val_score(patience, validation_evaluator, trainer, \"accuracy\")\n",
    "\n",
    "    # kick everything off\n",
    "    trainer.run(train_loader, max_epochs=max_epochs)\n",
    "\n",
    "    # Return the optimizer in case we want to continue training.\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def create_metrics(loss):\n",
    "    return {\"accuracy\": Accuracy(), \"crossentropy\": Loss(loss)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We want to use metrics that allow us to capture the quality of the produced uncertainty during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa78e6a38914176b3b2f011f7275b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=938.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=938.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=938.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=938.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=938.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=938.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"{'accuracy': 0.9507, 'crossentropy': 0.16540256378240883}\",\n",
       " \"{'accuracy': 0.9603833333333334, 'crossentropy': 0.13504049125565215}\",\n",
       " \"{'accuracy': 0.9656833333333333, 'crossentropy': 0.11748369302990226}\"]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment\n",
    "\n",
    "from batchbald_redux.fast_mnist import FastMNIST\n",
    "from batchbald_redux.consistent_mc_dropout import SamplerModel\n",
    "from batchbald_redux.example_models import BayesianMNISTCNN\n",
    "from batchbald_redux.repeated_mnist import create_repeated_MNIST_dataset\n",
    "import torch.utils.data\n",
    "\n",
    "train_dataset, test_dataset = create_repeated_MNIST_dataset(num_repetitions=1, add_noise=False)\n",
    "\n",
    "model = SamplerModel(BayesianMNISTCNN(), 1)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "epochs_log = []\n",
    "\n",
    "train(model=model, \n",
    "      train_loader=train_loader,\n",
    "      val_loader=train_loader, \n",
    "      patience=3, \n",
    "      max_epochs=3, \n",
    "      device=\"cuda\",\n",
    "      epochs_log=epochs_log)\n",
    "\n",
    "epochs_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining predictions\n",
    "\n",
    "Sometimes, we want to obtain predictions from our models, instead of pure evaluation metrics... I know right?\n",
    "\n",
    "The following helper method registers an event handler with an Ignite Engine that stores the predictions in a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "\n",
    "def handler_save_predictions(engine, target_list):\n",
    "    @engine.on(Events.ITERATION_COMPLETED)\n",
    "    def iteration_completed(engine):\n",
    "        target_list.extend(engine.state.output[0])\n",
    "        \n",
    "def get_predictions(*, model, loader, device:str):\n",
    "    evaluator = create_supervised_evaluator(model, device=device)\n",
    "    \n",
    "    predictions = []\n",
    "    handler_save_predictions(evaluator, predictions)\n",
    "    \n",
    "    ProgressBar(persist=False).attach(evaluator, metric_names=\"all\",\n",
    "                                      event_name=Events.ITERATION_COMPLETED(every=LOG_INTERVAL))\n",
    "    \n",
    "    evaluator.run(loader)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=157.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment\n",
    "\n",
    "predictions = get_predictions(model=model, loader=test_loader, device=\"cuda\")\n",
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-52.1431, -53.4922, -40.7442, -40.1009, -44.2619, -44.9161, -78.0699,\n",
       "           0.0000, -48.4833, -27.3636], device='cuda:0'),\n",
       " tensor([-22.3552, -21.4889,   0.0000, -25.8736, -25.5011, -29.1754, -20.9751,\n",
       "         -36.6820, -22.6187, -39.2213], device='cuda:0'),\n",
       " tensor([-2.6418e+01, -5.9605e-07, -2.4454e+01, -2.8485e+01, -1.4397e+01,\n",
       "         -1.9134e+01, -2.5368e+01, -1.7937e+01, -1.9470e+01, -1.7325e+01],\n",
       "        device='cuda:0'),\n",
       " tensor([-1.5497e-05, -2.3048e+01, -1.8644e+01, -2.3828e+01, -1.9778e+01,\n",
       "         -1.5977e+01, -1.1162e+01, -2.2100e+01, -1.5301e+01, -1.3860e+01],\n",
       "        device='cuda:0'),\n",
       " tensor([-2.9340e+01, -3.4066e+01, -2.7912e+01, -2.5837e+01, -5.5762e-04,\n",
       "         -2.1208e+01, -2.4429e+01, -2.7754e+01, -1.8389e+01, -7.4921e+00],\n",
       "        device='cuda:0'),\n",
       " tensor([-2.8714e+01, -1.1921e-07, -2.8676e+01, -3.2414e+01, -1.5823e+01,\n",
       "         -2.2883e+01, -2.9513e+01, -1.7877e+01, -2.2081e+01, -1.8668e+01],\n",
       "        device='cuda:0'),\n",
       " tensor([-4.2945e+01, -2.8410e+01, -3.9480e+01, -3.3821e+01, -2.7418e-06,\n",
       "         -2.2880e+01, -3.3392e+01, -2.3219e+01, -1.3470e+01, -1.3586e+01],\n",
       "        device='cuda:0'),\n",
       " tensor([-2.9558e+01, -3.3524e+01, -3.5105e+01, -1.8628e+01, -1.1260e+01,\n",
       "         -1.0337e+01, -3.4189e+01, -1.9418e+01, -1.3129e+01, -4.7325e-05],\n",
       "        device='cuda:0'),\n",
       " tensor([-1.8679e+01, -3.7581e+01, -3.0990e+01, -2.9334e+01, -2.4717e+01,\n",
       "         -4.2438e-05, -1.2105e+01, -2.9539e+01, -1.0800e+01, -1.1018e+01],\n",
       "        device='cuda:0'),\n",
       " tensor([-5.2808e+01, -5.4929e+01, -5.6604e+01, -3.9991e+01, -1.9713e+01,\n",
       "         -2.7582e+01, -6.4895e+01, -1.5083e+01, -2.6636e+01, -2.3842e-07],\n",
       "        device='cuda:0')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:active_learning]",
   "language": "python",
   "name": "conda-env-active_learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
