{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uniform Target OOD Experiment\n",
    "> Can we get better by training on our assumptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp uniform_target_ood_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended /home/blackhc/PycharmProjects/bald-ical/src to paths\n",
      "Switched to directory /home/blackhc/PycharmProjects/bald-ical\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "import blackhc.project.script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules and functions were are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "import dataclasses\n",
    "import traceback\n",
    "from dataclasses import dataclass\n",
    "from typing import Type, Union\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from blackhc.project import is_run_from_ipython\n",
    "from blackhc.project.experiment import embedded_experiments\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import batchbald_redux.acquisition_functions as acquisition_functions\n",
    "from batchbald_redux.acquisition_functions import (\n",
    "    CandidateBatchComputer,\n",
    "    EvalCandidateBatchComputer,\n",
    ")\n",
    "from batchbald_redux.active_learning import ActiveLearningData, RandomFixedLengthSampler\n",
    "from batchbald_redux.black_box_model_training import evaluate, train\n",
    "from batchbald_redux.dataset_challenges import (\n",
    "    AdditiveGaussianNoise,\n",
    "    AliasDataset,\n",
    "    NamedDataset,\n",
    "    get_base_dataset_index,\n",
    "    get_target,\n",
    "    get_balanced_sample_indices_by_class,\n",
    ")\n",
    "from batchbald_redux.datasets import train_validation_split\n",
    "from batchbald_redux.di import DependencyInjection\n",
    "from batchbald_redux.fast_mnist import FastFashionMNIST, FastMNIST\n",
    "from batchbald_redux.model_optimizer_factory import ModelOptimizerFactory\n",
    "from batchbald_redux.models import MnistOptimizerFactory\n",
    "from batchbald_redux.train_eval_model import (\n",
    "    TrainEvalModel,\n",
    "    TrainSelfDistillationEvalModel,\n",
    ")\n",
    "from batchbald_redux.trained_model import TrainedMCDropoutModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ExperimentData:\n",
    "    active_learning: ActiveLearningData\n",
    "    ood_dataset: NamedDataset\n",
    "    validation_dataset: Dataset\n",
    "    test_dataset: Dataset\n",
    "    evaluation_dataset: Dataset\n",
    "    initial_training_set_indices: [int]\n",
    "    evaluation_set_indices: [int]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class UniformTargetOodExperiment:\n",
    "    seed: int = 1337\n",
    "    acquisition_size: int = 5\n",
    "    max_training_set: int = 450\n",
    "    num_pool_samples: int = 20\n",
    "    num_validation_samples: int = 20\n",
    "    num_training_samples: int = 1\n",
    "    num_patience_epochs: int = 3\n",
    "    max_training_epochs: int = 30\n",
    "    training_batch_size: int = 64\n",
    "    device: str = \"cuda\"\n",
    "    validation_set_size: int = 1024\n",
    "    evaluation_set_size: int = 10 * 10\n",
    "    validation_split_random_state: int = 0\n",
    "    initial_training_set_size: int = 20\n",
    "    min_samples_per_epoch: int = 5056\n",
    "    mnist_repetitions: float = 1\n",
    "    ood_fmnist_repetitions: float = 1\n",
    "    add_dataset_noise: bool = False\n",
    "    acquisition_function: Union[\n",
    "        Type[CandidateBatchComputer], Type[EvalCandidateBatchComputer]\n",
    "    ] = acquisition_functions.BALD\n",
    "    train_eval_model: TrainEvalModel = TrainSelfDistillationEvalModel\n",
    "    model_optimizer_factory: Type[ModelOptimizerFactory] = MnistOptimizerFactory\n",
    "    acquisition_function_args: dict = None\n",
    "    temperature: float = 0.0\n",
    "\n",
    "    def load_experiment_data(self) -> ExperimentData:\n",
    "        # num_classes = 10, input_size = 28\n",
    "        full_train_dataset = NamedDataset(\n",
    "            FastMNIST(\"data\", train=True, download=True, device=self.device), \"FastMNIST (train)\"\n",
    "        )\n",
    "\n",
    "        ood_dataset = FastFashionMNIST(\"data\", train=True, download=True, device=self.device)\n",
    "        ood_dataset = NamedDataset(ood_dataset, f\"OoD Dataset ({len(ood_dataset)} samples)\")\n",
    "        if self.ood_fmnist_repetitions > 1:\n",
    "            ood_dataset = ood_dataset * self.ood_fmnist_repetitions\n",
    "\n",
    "        train_dataset, validation_dataset = train_validation_split(\n",
    "            full_train_dataset=full_train_dataset,\n",
    "            full_validation_dataset=full_train_dataset,\n",
    "            train_labels=full_train_dataset.get_targets().cpu(),\n",
    "            validation_set_size=self.validation_set_size,\n",
    "            validation_split_random_state=self.validation_split_random_state,\n",
    "        )\n",
    "\n",
    "        train_dataset = AliasDataset(train_dataset, f\"FastMNIST (train; {len(train_dataset)} samples)\")\n",
    "        validation_dataset = AliasDataset(\n",
    "            validation_dataset, f\"FastMNIST (validation; {len(validation_dataset)} samples)\"\n",
    "        )\n",
    "\n",
    "        # If we reduce the train set, we need to do so before picking the initial train set.\n",
    "        if self.mnist_repetitions < 1:\n",
    "            train_dataset = train_dataset * self.mnist_repetitions\n",
    "\n",
    "        num_classes = train_dataset.get_num_classes()\n",
    "        initial_samples_per_class = self.initial_training_set_size // num_classes\n",
    "        evaluation_set_samples_per_class = self.evaluation_set_size // num_classes\n",
    "        samples_per_class = initial_samples_per_class + evaluation_set_samples_per_class\n",
    "        balanced_samples_indices = get_balanced_sample_indices_by_class(\n",
    "            train_dataset,\n",
    "            num_classes=num_classes,\n",
    "            samples_per_class=samples_per_class,\n",
    "            seed=self.validation_split_random_state,\n",
    "        )\n",
    "        initial_training_set_indices = [\n",
    "            idx for by_class in balanced_samples_indices.values() for idx in by_class[:initial_samples_per_class]\n",
    "        ]\n",
    "        evaluation_set_indices = [\n",
    "            idx for by_class in balanced_samples_indices.values() for idx in by_class[initial_samples_per_class:]\n",
    "        ]\n",
    "\n",
    "        # If we over-sample the train set, we do so after picking the initial train set to avoid duplicates.\n",
    "        if self.mnist_repetitions > 1:\n",
    "            train_dataset = train_dataset * self.mnist_repetitions\n",
    "\n",
    "        train_dataset = train_dataset.one_hot(device=self.device) + ood_dataset.uniform_target(device=self.device)\n",
    "\n",
    "        if self.add_dataset_noise:\n",
    "            train_dataset = AdditiveGaussianNoise(train_dataset, 0.1)\n",
    "\n",
    "        test_dataset = FastMNIST(\"data\", train=False, device=None)\n",
    "        test_dataset = NamedDataset(test_dataset, f\"FastMNIST (test, {len(test_dataset)} samples)\")\n",
    "\n",
    "        active_learning_data = ActiveLearningData(train_dataset)\n",
    "\n",
    "        active_learning_data.acquire_base_indices(initial_training_set_indices)\n",
    "        evaluation_dataset = AliasDataset(\n",
    "            active_learning_data.extract_dataset_from_base_indices(evaluation_set_indices),\n",
    "            f\"Evaluation Set ({len(evaluation_set_indices)} samples)\",\n",
    "        )\n",
    "\n",
    "        return ExperimentData(\n",
    "            active_learning=active_learning_data,\n",
    "            ood_dataset=ood_dataset,\n",
    "            validation_dataset=validation_dataset,\n",
    "            test_dataset=test_dataset,\n",
    "            evaluation_dataset=evaluation_dataset,\n",
    "            initial_training_set_indices=initial_training_set_indices,\n",
    "            evaluation_set_indices=evaluation_set_indices,\n",
    "        )\n",
    "\n",
    "    # Simple Dependency Injection\n",
    "    def create_acquisition_function(self):\n",
    "        di = DependencyInjection(vars(self))\n",
    "        return di.create_dataclass_type(self.acquisition_function)\n",
    "\n",
    "    def create_train_eval_model(self, runtime_config) -> TrainEvalModel:\n",
    "        config = {**vars(self), **runtime_config}\n",
    "        di = DependencyInjection(config, [])\n",
    "        return di.create_dataclass_type(self.train_eval_model)\n",
    "\n",
    "    def run(self, store):\n",
    "        torch.manual_seed(self.seed)\n",
    "\n",
    "        # Active Learning setup\n",
    "        data = self.load_experiment_data()\n",
    "        store[\"dataset_info\"] = dict(training=repr(data.active_learning.base_dataset), test=repr(data.test_dataset))\n",
    "        store[\"initial_training_set_indices\"] = data.initial_training_set_indices\n",
    "        store[\"evaluation_set_indices\"] = data.evaluation_set_indices\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            data.active_learning.training_dataset,\n",
    "            batch_size=self.training_batch_size,\n",
    "            sampler=RandomFixedLengthSampler(data.active_learning.training_dataset, self.min_samples_per_epoch),\n",
    "            drop_last=True,\n",
    "        )\n",
    "        pool_loader = torch.utils.data.DataLoader(\n",
    "            data.active_learning.pool_dataset, batch_size=128, drop_last=False, shuffle=False\n",
    "        )\n",
    "\n",
    "        validation_loader = torch.utils.data.DataLoader(data.validation_dataset, batch_size=512, drop_last=False)\n",
    "        test_loader = torch.utils.data.DataLoader(data.test_dataset, batch_size=512, drop_last=False)\n",
    "\n",
    "        store[\"active_learning_steps\"] = []\n",
    "        active_learning_steps = store[\"active_learning_steps\"]\n",
    "\n",
    "        acquisition_function = self.create_acquisition_function()\n",
    "\n",
    "        # Active Training Loop\n",
    "        while True:\n",
    "            training_set_size = len(data.active_learning.training_dataset)\n",
    "            print(f\"Training set size {training_set_size}:\")\n",
    "\n",
    "            # iteration_log = dict(training={}, pool_training={}, evaluation_metrics=None, acquisition=None)\n",
    "            active_learning_steps.append({})\n",
    "            iteration_log = active_learning_steps[-1]\n",
    "\n",
    "            iteration_log[\"training\"] = {}\n",
    "\n",
    "            model_optimizer = self.model_optimizer_factory().create_model_optimizer()\n",
    "\n",
    "            loss = torch.nn.KLDivLoss(log_target=False, reduction=\"batchmean\")\n",
    "\n",
    "            train(\n",
    "                model=model_optimizer.model,\n",
    "                optimizer=model_optimizer.optimizer,\n",
    "                training_samples=self.num_training_samples,\n",
    "                validation_samples=self.num_validation_samples,\n",
    "                train_loader=train_loader,\n",
    "                validation_loader=validation_loader,\n",
    "                patience=self.num_patience_epochs,\n",
    "                max_epochs=self.max_training_epochs,\n",
    "                device=self.device,\n",
    "                training_log=iteration_log[\"training\"],\n",
    "                loss=loss,\n",
    "                validation_loss=torch.nn.NLLLoss(),\n",
    "            )\n",
    "\n",
    "            evaluation_metrics = evaluate(\n",
    "                model=model_optimizer.model,\n",
    "                num_samples=self.num_validation_samples,\n",
    "                loader=test_loader,\n",
    "                device=self.device,\n",
    "            )\n",
    "            iteration_log[\"evaluation_metrics\"] = evaluation_metrics\n",
    "            print(f\"Perf after training {evaluation_metrics}\")\n",
    "\n",
    "            if training_set_size >= self.max_training_set:\n",
    "                print(\"Done.\")\n",
    "                break\n",
    "\n",
    "            trained_model = TrainedMCDropoutModel(num_samples=self.num_pool_samples, model=model_optimizer.model)\n",
    "\n",
    "            if isinstance(acquisition_function, CandidateBatchComputer):\n",
    "                candidate_batch = acquisition_function.compute_candidate_batch(trained_model, pool_loader, self.device)\n",
    "            elif isinstance(acquisition_function, EvalCandidateBatchComputer):\n",
    "                current_max_epochs = iteration_log[\"training\"][\"best_epoch\"]\n",
    "\n",
    "                if self.evaluation_set_size:\n",
    "                    eval_dataset = data.evaluation_dataset\n",
    "                else:\n",
    "                    eval_dataset = data.active_learning.pool_dataset\n",
    "\n",
    "                train_eval_model = self.create_train_eval_model(\n",
    "                    dict(\n",
    "                        max_epochs=current_max_epochs + 2,\n",
    "                        training_dataset=data.active_learning.training_dataset,\n",
    "                        eval_dataset=eval_dataset,\n",
    "                        validation_loader=validation_loader,\n",
    "                        trained_model=trained_model,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                iteration_log[\"eval_training\"] = {}\n",
    "                trained_eval_model = train_eval_model(training_log=iteration_log[\"eval_training\"], device=self.device)\n",
    "\n",
    "                candidate_batch = acquisition_function.compute_candidate_batch(\n",
    "                    trained_model, trained_eval_model, pool_loader, device=self.device\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown acquisition function {acquisition_function}!\")\n",
    "\n",
    "            candidate_global_dataset_indices = []\n",
    "            candidate_labels = []\n",
    "            for index in candidate_batch.indices:\n",
    "                base_di = get_base_dataset_index(data.active_learning.pool_dataset, index)\n",
    "                dataset_type = \"ood\" if base_di.dataset == data.ood_dataset else \"id\"\n",
    "                candidate_global_dataset_indices.append((dataset_type, base_di.index))\n",
    "                label = get_target(data.active_learning.pool_dataset, index)\n",
    "                candidate_labels.append(label)\n",
    "\n",
    "            iteration_log[\"acquisition\"] = dict(\n",
    "                indices=candidate_global_dataset_indices, labels=candidate_labels, scores=candidate_batch.scores\n",
    "            )\n",
    "\n",
    "            data.active_learning.acquire(candidate_batch.indices)\n",
    "\n",
    "            print(candidate_batch)\n",
    "            print(candidate_global_dataset_indices)\n",
    "\n",
    "            ls = \", \".join(f\"{label} ({score:.4})\" for label, score in zip(candidate_labels, candidate_batch.scores))\n",
    "            print(f\"Acquiring (label, score)s: {ls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((FastMNIST (train; 58976 samples))~x0.1 | one_hot_targets{'num_classes': 10}) + ('OoD Dataset (60000 samples)' | uniform_targets{'num_classes': 10})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment\n",
    "\n",
    "UniformTargetOodExperiment(mnist_repetitions=0.1,device=\"cpu\").load_experiment_data().active_learning.base_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolved: BALD with {'acquisition_size': 10}\n",
      "Creating: BALD(acquisition_size=10)\n",
      "Training set size 20:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc10e0e7baa450c8b880851d20c6005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/79]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.6611328125, 'crossentropy': 2.279507040977478}\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: -2.279507040977478)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/20]   5%|5          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.6939, 'crossentropy': 1.8995209411621095}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/237712 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/118856 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/118856 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CandidateBatch(scores=[0.6928115487098694, 0.6924754567444324, 0.6923950463533401, 0.6923141628503799, 0.6922618746757507, 0.6921998299658298, 0.6921993028372526, 0.6921881128801033, 0.6921360490377992, 0.6921246605925262], indices=[28055, 44134, 1732, 13166, 3774, 39971, 49867, 27407, 33211, 4981])\n",
      "[('id', 12186), ('id', 20395), ('id', 9592), ('id', 4767), ('id', 24248), ('id', 14823), ('id', 23357), ('id', 48109), ('id', 55653), ('id', 7576)]\n",
      "Acquiring (label, score)s: tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0') (0.6928), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') (0.6925), tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0') (0.6924), tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], device='cuda:0') (0.6923), tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0') (0.6923), tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0') (0.6922), tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], device='cuda:0') (0.6922), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') (0.6922), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') (0.6921), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') (0.6921)\n",
      "Training set size 30:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79e95cf55a1640288c1a50758a17f216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/79]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.671875, 'crossentropy': 1.9831183552742004}\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: -1.9831183552742004)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/20]   5%|5          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.7112, 'crossentropy': 1.9220587146759034}\n",
      "Done.\n",
      "Resolved: EvalBALD with {'acquisition_size': 10}\n",
      "Creating: EvalBALD(acquisition_size=10)\n",
      "Training set size 20:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac160b79527e434eb4cdec2eeec22106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/79]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.6591796875, 'crossentropy': 2.298063039779663}\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: -2.298063039779663)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/20]   5%|5          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.6933, 'crossentropy': 1.9134324710845947}\n",
      "Resolved: TrainSelfDistillationEvalModel with {'num_pool_samples': 2, 'num_training_samples': 1, 'num_validation_samples': 20, 'num_patience_epochs': 1, 'max_epochs': 1, 'training_dataset': <torch.utils.data.dataset.Subset object at 0x7f1420089f40>, 'eval_dataset': Evaluation Set (100 samples), 'validation_loader': <torch.utils.data.dataloader.DataLoader object at 0x7f1420089af0>, 'training_batch_size': 64, 'model_optimizer_factory': <class 'batchbald_redux.models.MnistOptimizerFactory'>, 'trained_model': TrainedMCDropoutModel(num_samples=2, model=BayesianMNISTCNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv1_drop): ConsistentMCDropout2d(p=0.5)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): ConsistentMCDropout2d(p=0.5)\n",
      "  (fc1): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  (fc1_drop): ConsistentMCDropout(p=0.5)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")), 'min_samples_per_epoch': 5056}\n",
      "Creating: TrainSelfDistillationEvalModel(num_pool_samples=2,num_training_samples=1,num_validation_samples=20,num_patience_epochs=1,max_epochs=1,training_dataset=<torch.utils.data.dataset.Subset object at 0x7f1420089f40>,eval_dataset=Evaluation Set (100 samples),validation_loader=<torch.utils.data.dataloader.DataLoader object at 0x7f1420089af0>,training_batch_size=64,model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>,trained_model=TrainedMCDropoutModel(num_samples=2, model=BayesianMNISTCNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv1_drop): ConsistentMCDropout2d(p=0.5)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): ConsistentMCDropout2d(p=0.5)\n",
      "  (fc1): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  (fc1_drop): ConsistentMCDropout(p=0.5)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")),min_samples_per_epoch=5056)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab7e79aafc3483db87df2d157352cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/79]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.6005859375, 'crossentropy': 1.467793881893158}\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: -1.467793881893158)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/237712 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/237712 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/118856 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/118856 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/118856 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/118856 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CandidateBatch(scores=[0.683699443936348, 0.6795189324766397, 0.6782244741916656, 0.6775030717253685, 0.6772962100803852, 0.6772275269031525, 0.677149573341012, 0.6770125590264797, 0.6770039573311806, 0.676617156714201], indices=[6747, 43819, 2764, 16924, 49048, 47858, 12736, 40279, 49723, 38716])\n",
      "[('id', 10350), ('id', 27315), ('id', 2891), ('id', 16856), ('id', 56699), ('id', 18905), ('id', 16540), ('id', 1448), ('id', 4488), ('id', 38960)]\n",
      "Acquiring (label, score)s: tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0') (0.6837), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0') (0.6795), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0') (0.6782), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0') (0.6775), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0') (0.6773), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0') (0.6772), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') (0.6771), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0') (0.677), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') (0.677), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], device='cuda:0') (0.6766)\n",
      "Training set size 30:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41de5c7f9a6b44ef86d38277ad6ba661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/79]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.6494140625, 'crossentropy': 2.4017910957336426}\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: -2.4017910957336426)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/20]   5%|5          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.6843, 'crossentropy': 1.9613335731506347}\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# experiment\n",
    "\n",
    "experiment = UniformTargetOodExperiment(\n",
    "    seed=1120,\n",
    "    max_training_epochs=1,\n",
    "    num_patience_epochs=1,\n",
    "    max_training_set=20+10,\n",
    "    acquisition_function=acquisition_functions.BALD,\n",
    "    acquisition_size=10,\n",
    "    num_pool_samples=2,\n",
    "    temperature=8,\n",
    "    mnist_repetitions=1,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "results = {}\n",
    "experiment.run(results)\n",
    "\n",
    "experiment = UniformTargetOodExperiment(\n",
    "    seed=1120,\n",
    "    max_training_epochs=1,\n",
    "    num_patience_epochs=1,\n",
    "    max_training_set=20+10,\n",
    "    acquisition_function=acquisition_functions.EvalBALD,\n",
    "    acquisition_size=10,\n",
    "    num_pool_samples=2,\n",
    "    temperature=8,\n",
    "    mnist_repetitions=1,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "results = {}\n",
    "experiment.run(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_info': {'training': \"(FastMNIST (train; 58976 samples)) + ('OoD Dataset (60000 samples)' | constant_target{'target': tensor(-1, device='cuda:0'), 'num_classes': 10})\",\n",
       "  'test': \"'FastMNIST (test, 10000 samples)'\"},\n",
       " 'initial_training_set_indices': [30392,\n",
       "  53434,\n",
       "  12640,\n",
       "  8533,\n",
       "  22304,\n",
       "  37915,\n",
       "  58226,\n",
       "  44119,\n",
       "  3091,\n",
       "  14640,\n",
       "  58125,\n",
       "  39579,\n",
       "  43812,\n",
       "  53689,\n",
       "  52296,\n",
       "  46037,\n",
       "  22015,\n",
       "  40334,\n",
       "  57520,\n",
       "  43803],\n",
       " 'active_learning_steps': [{'training': {'epochs': [], 'best_epoch': None},\n",
       "   'evaluation_metrics': {'accuracy': 0.1129,\n",
       "    'crossentropy': 2.35244740562439},\n",
       "   'acquisition': {'indices': [('ood', 27822),\n",
       "     ('id', 32367),\n",
       "     ('id', 55086),\n",
       "     ('id', 53929),\n",
       "     ('id', 48696),\n",
       "     ('ood', 37815),\n",
       "     ('ood', 47304),\n",
       "     ('ood', 28667),\n",
       "     ('ood', 40866),\n",
       "     ('ood', 35119)],\n",
       "    'labels': [-1, 1, 7, 6, 2, -1, -1, -1, -1, -1],\n",
       "    'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}},\n",
       "  {'training': {'epochs': [], 'best_epoch': None},\n",
       "   'evaluation_metrics': {'accuracy': 0.071,\n",
       "    'crossentropy': 2.376102001571655},\n",
       "   'acquisition': {'indices': [('id', 41002),\n",
       "     ('id', 35972),\n",
       "     ('ood', 49270),\n",
       "     ('id', 37994),\n",
       "     ('id', 44052),\n",
       "     ('ood', 16809),\n",
       "     ('ood', 24609),\n",
       "     ('ood', 33944),\n",
       "     ('id', 58767),\n",
       "     ('id', 6319)],\n",
       "    'labels': [7, 0, -1, 7, 4, -1, -1, -1, 1, 7],\n",
       "    'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}},\n",
       "  {'training': {'epochs': [], 'best_epoch': None},\n",
       "   'evaluation_metrics': {'accuracy': 0.111,\n",
       "    'crossentropy': 2.3350587436676027},\n",
       "   'acquisition': {'indices': [('ood', 56587),\n",
       "     ('id', 20397),\n",
       "     ('id', 6873),\n",
       "     ('id', 56019),\n",
       "     ('id', 48733),\n",
       "     ('ood', 1957),\n",
       "     ('id', 26231),\n",
       "     ('ood', 14359),\n",
       "     ('id', 41930),\n",
       "     ('id', 1835)],\n",
       "    'labels': [-1, 3, 8, 8, 5, -1, 8, -1, 4, 6],\n",
       "    'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}},\n",
       "  {'training': {'epochs': [], 'best_epoch': None},\n",
       "   'evaluation_metrics': {'accuracy': 0.1119,\n",
       "    'crossentropy': 2.3316191219329836},\n",
       "   'acquisition': {'indices': [('id', 43865),\n",
       "     ('id', 53636),\n",
       "     ('id', 27693),\n",
       "     ('id', 35820),\n",
       "     ('id', 2731),\n",
       "     ('ood', 7893),\n",
       "     ('ood', 1823),\n",
       "     ('id', 31015),\n",
       "     ('ood', 39435),\n",
       "     ('ood', 14496)],\n",
       "    'labels': [3, 8, 1, 1, 1, -1, -1, 0, -1, -1],\n",
       "    'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}},\n",
       "  {'training': {'epochs': [], 'best_epoch': None},\n",
       "   'evaluation_metrics': {'accuracy': 0.1152,\n",
       "    'crossentropy': 2.3408010501861574},\n",
       "   'acquisition': {'indices': [('ood', 22190),\n",
       "     ('ood', 49199),\n",
       "     ('ood', 40750),\n",
       "     ('ood', 33436),\n",
       "     ('ood', 30495),\n",
       "     ('ood', 57037),\n",
       "     ('ood', 11806),\n",
       "     ('id', 13194),\n",
       "     ('id', 33972),\n",
       "     ('ood', 48450)],\n",
       "    'labels': [-1, -1, -1, -1, -1, -1, -1, 9, 5, -1],\n",
       "    'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}},\n",
       "  {'training': {'epochs': [], 'best_epoch': None},\n",
       "   'evaluation_metrics': {'accuracy': 0.0855,\n",
       "    'crossentropy': 2.3611250312805176},\n",
       "   'acquisition': {'indices': [('ood', 39262),\n",
       "     ('id', 34937),\n",
       "     ('id', 15956),\n",
       "     ('id', 1193),\n",
       "     ('id', 44982),\n",
       "     ('id', 24303),\n",
       "     ('id', 30815),\n",
       "     ('ood', 35232),\n",
       "     ('ood', 36119),\n",
       "     ('id', 17484)],\n",
       "    'labels': [-1, 1, 8, 8, 9, 2, 4, -1, -1, 6],\n",
       "    'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}},\n",
       "  {'training': {'epochs': [], 'best_epoch': None},\n",
       "   'evaluation_metrics': {'accuracy': 0.0985,\n",
       "    'crossentropy': 2.33388900718689},\n",
       "   'acquisition': {'indices': [('ood', 19019),\n",
       "     ('ood', 50212),\n",
       "     ('ood', 25348),\n",
       "     ('ood', 21148),\n",
       "     ('ood', 21958),\n",
       "     ('id', 28372),\n",
       "     ('ood', 4170),\n",
       "     ('id', 40862),\n",
       "     ('id', 6085),\n",
       "     ('ood', 4347)],\n",
       "    'labels': [-1, -1, -1, -1, -1, 5, -1, 6, 6, -1],\n",
       "    'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}},\n",
       "  {'training': {'epochs': [], 'best_epoch': None},\n",
       "   'evaluation_metrics': {'accuracy': 0.1075,\n",
       "    'crossentropy': 2.3253658111572264},\n",
       "   'acquisition': {'indices': [('ood', 5177),\n",
       "     ('id', 46455),\n",
       "     ('ood', 35272),\n",
       "     ('ood', 22434),\n",
       "     ('ood', 308),\n",
       "     ('ood', 16607),\n",
       "     ('id', 50405),\n",
       "     ('ood', 26672),\n",
       "     ('ood', 12838),\n",
       "     ('id', 21140)],\n",
       "    'labels': [-1, 6, -1, -1, -1, -1, 4, -1, -1, 4],\n",
       "    'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}},\n",
       "  {'training': {'epochs': [], 'best_epoch': None},\n",
       "   'evaluation_metrics': {'accuracy': 0.1254,\n",
       "    'crossentropy': 2.3452716808319094},\n",
       "   'acquisition': {'indices': [('ood', 21307),\n",
       "     ('id', 45937),\n",
       "     ('id', 35010),\n",
       "     ('ood', 3929),\n",
       "     ('ood', 49439),\n",
       "     ('ood', 26422),\n",
       "     ('id', 15513),\n",
       "     ('ood', 12990),\n",
       "     ('id', 46837),\n",
       "     ('ood', 43248)],\n",
       "    'labels': [-1, 7, 3, -1, -1, -1, 7, -1, 0, -1],\n",
       "    'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}},\n",
       "  {'training': {'epochs': [], 'best_epoch': None},\n",
       "   'evaluation_metrics': {'accuracy': 0.0982,\n",
       "    'crossentropy': 2.338535634994507},\n",
       "   'acquisition': {'indices': [('ood', 2970),\n",
       "     ('id', 33981),\n",
       "     ('id', 17247),\n",
       "     ('id', 28983),\n",
       "     ('id', 22921),\n",
       "     ('id', 43607),\n",
       "     ('ood', 8139),\n",
       "     ('id', 45633),\n",
       "     ('id', 48652),\n",
       "     ('ood', 46241)],\n",
       "    'labels': [-1, 9, 5, 3, 7, 7, -1, 6, 8, -1],\n",
       "    'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}},\n",
       "  {'training': {'epochs': [], 'best_epoch': None},\n",
       "   'evaluation_metrics': {'accuracy': 0.1139,\n",
       "    'crossentropy': 2.3268737857818604},\n",
       "   'acquisition': {'indices': [('ood', 5285),\n",
       "     ('ood', 33865),\n",
       "     ('ood', 26001),\n",
       "     ('id', 47531),\n",
       "     ('ood', 11312),\n",
       "     ('ood', 1265),\n",
       "     ('id', 56554),\n",
       "     ('id', 16369),\n",
       "     ('ood', 40025),\n",
       "     ('id', 19670)],\n",
       "    'labels': [-1, -1, -1, 2, -1, -1, 5, 7, -1, 5],\n",
       "    'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}},\n",
       "  {'training': {'epochs': [], 'best_epoch': None},\n",
       "   'evaluation_metrics': {'accuracy': 0.0858,\n",
       "    'crossentropy': 2.340250019454956},\n",
       "   'acquisition': {'indices': [('ood', 52831),\n",
       "     ('ood', 22388),\n",
       "     ('id', 17241),\n",
       "     ('ood', 20468),\n",
       "     ('id', 22538),\n",
       "     ('ood', 45415),\n",
       "     ('id', 56063),\n",
       "     ('id', 20651),\n",
       "     ('id', 52190),\n",
       "     ('id', 48078)],\n",
       "    'labels': [-1, -1, 2, -1, 1, -1, 5, 4, 5, 5],\n",
       "    'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}},\n",
       "  {'training': {'epochs': [], 'best_epoch': None},\n",
       "   'evaluation_metrics': {'accuracy': 0.1047,\n",
       "    'crossentropy': 2.3441019859313963},\n",
       "   'acquisition': {'indices': [('ood', 23255),\n",
       "     ('id', 49078),\n",
       "     ('id', 34456),\n",
       "     ('id', 7426),\n",
       "     ('id', 32375),\n",
       "     ('ood', 28384),\n",
       "     ('id', 53279),\n",
       "     ('ood', 46297),\n",
       "     ('id', 23174),\n",
       "     ('ood', 722)],\n",
       "    'labels': [-1, 4, 6, 4, 8, -1, 9, -1, 4, -1],\n",
       "    'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}},\n",
       "  {'training': {'epochs': [], 'best_epoch': None},\n",
       "   'evaluation_metrics': {'accuracy': 0.1025,\n",
       "    'crossentropy': 2.3361153217315676},\n",
       "   'acquisition': {'indices': [('ood', 56973),\n",
       "     ('ood', 12847),\n",
       "     ('ood', 52008),\n",
       "     ('ood', 35025),\n",
       "     ('id', 14647),\n",
       "     ('id', 48238),\n",
       "     ('id', 41955),\n",
       "     ('id', 44784),\n",
       "     ('id', 37767),\n",
       "     ('id', 5447)],\n",
       "    'labels': [-1, -1, -1, -1, 9, 2, 2, 2, 4, 7],\n",
       "    'scores': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}},\n",
       "  {'training': {'epochs': [], 'best_epoch': None}}]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size 20:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3fc327793734c0eb2f361164ad86451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/384]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/64]   2%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RestoringEarlyStopping: Restoring best parameters. (Score: -6.529030114412308)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/157]   1%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.5367, 'crossentropy': 6.438035237884521}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions:   0%|          | 0/463616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382711f4f7ad4ec7980c856e0f9d229e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1811]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/64]   2%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RestoringEarlyStopping: Restoring best parameters. (Score: -5.1637596152722836)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions:   0%|          | 0/2317680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions:   0%|          | 0/2317680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/115884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/115884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/115884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/115884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquiring (label, score)s: 8 (0.8711), 8 (0.8687), 3 (0.876), 3 (0.8465), 3 (0.8811)\n",
      "Training set size 25:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c326c4165e48eab908014b4064f795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/384]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/64]   2%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RestoringEarlyStopping: Restoring best parameters. (Score: -4.6851686127483845)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/157]   1%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.6256, 'crossentropy': 4.484497045135498}\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'initial_training_set_indices': [38043,\n",
       "  40091,\n",
       "  17418,\n",
       "  2094,\n",
       "  39879,\n",
       "  3133,\n",
       "  5011,\n",
       "  40683,\n",
       "  54379,\n",
       "  24287,\n",
       "  9849,\n",
       "  59305,\n",
       "  39508,\n",
       "  39356,\n",
       "  8758,\n",
       "  52579,\n",
       "  13655,\n",
       "  7636,\n",
       "  21562,\n",
       "  41329],\n",
       " 'active_learning_steps': [{'training': {'epochs': [{'accuracy': 0.538818359375,\n",
       "      'crossentropy': 6.529030114412308}],\n",
       "    'best_epoch': 1},\n",
       "   'evalution_metrics': {'accuracy': 0.5367,\n",
       "    'crossentropy': 6.438035237884521},\n",
       "   'pool_training': {'epochs': [{'accuracy': 0.531005859375,\n",
       "      'crossentropy': 5.1637596152722836}],\n",
       "    'best_epoch': 1},\n",
       "   'acquisition': {'indices': [63338, 10856, 63452, 81864, 109287],\n",
       "    'labels': [8, 8, 3, 3, 3],\n",
       "    'scores': [0.8710822958846325,\n",
       "     0.8687216999221631,\n",
       "     0.8759664372823723,\n",
       "     0.8464646732511746,\n",
       "     0.8810812784952251]}},\n",
       "  {'training': {'epochs': [{'accuracy': 0.62255859375,\n",
       "      'crossentropy': 4.6851686127483845}],\n",
       "    'best_epoch': 1},\n",
       "   'evalution_metrics': {'accuracy': 0.6256,\n",
       "    'crossentropy': 4.484497045135498}}]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment\n",
    "\n",
    "experiment = Experiment(\n",
    "    max_training_epochs=1, max_training_set=25, acquisition_function=AcquisitionFunction.randombaldical\n",
    ")\n",
    "\n",
    "results = {}\n",
    "experiment.run(results)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "configs = [\n",
    "    UniformTargetOodExperiment(\n",
    "        seed=seed,\n",
    "        acquisition_function=acquisition_functions.TemperedEvalBALD,\n",
    "        acquisition_size=acquisition_size,\n",
    "        num_pool_samples=num_pool_samples,\n",
    "        temperature=8,\n",
    "    )\n",
    "    for seed in range(5)\n",
    "    for acquisition_size in [5, 10, 20, 50]\n",
    "    for num_pool_samples in [100]\n",
    "] + [\n",
    "    UniformTargetOodExperiment(\n",
    "        seed=seed,\n",
    "        acquisition_function=acquisition_functions.Random,\n",
    "        acquisition_size=5,\n",
    "    )\n",
    "    for seed in range(20)\n",
    "]\n",
    "\n",
    "if not is_run_from_ipython() and __name__ == \"__main__\":\n",
    "    for job_id, store in embedded_experiments(__file__, len(configs)):\n",
    "        config = configs[job_id]\n",
    "        config.seed += job_id\n",
    "        print(config)\n",
    "        store[\"config\"] = dataclasses.asdict(config)\n",
    "        store[\"log\"] = {}\n",
    "\n",
    "        try:\n",
    "            config.run(store=store)\n",
    "        except Exception:\n",
    "            store[\"exception\"] = traceback.format_exc()\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RejectionOodExperiment(seed=0, acquisition_size=5, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.TemperedBALD'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=8),\n",
       " RejectionOodExperiment(seed=0, acquisition_size=10, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.TemperedBALD'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=8),\n",
       " RejectionOodExperiment(seed=0, acquisition_size=20, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.TemperedBALD'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=8),\n",
       " RejectionOodExperiment(seed=0, acquisition_size=50, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.TemperedBALD'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=8),\n",
       " RejectionOodExperiment(seed=1, acquisition_size=5, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.TemperedBALD'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=8),\n",
       " RejectionOodExperiment(seed=1, acquisition_size=10, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.TemperedBALD'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=8),\n",
       " RejectionOodExperiment(seed=1, acquisition_size=20, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.TemperedBALD'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=8),\n",
       " RejectionOodExperiment(seed=1, acquisition_size=50, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.TemperedBALD'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=8),\n",
       " RejectionOodExperiment(seed=2, acquisition_size=5, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.TemperedBALD'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=8),\n",
       " RejectionOodExperiment(seed=2, acquisition_size=10, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.TemperedBALD'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=8),\n",
       " RejectionOodExperiment(seed=2, acquisition_size=20, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.TemperedBALD'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=8),\n",
       " RejectionOodExperiment(seed=2, acquisition_size=50, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.TemperedBALD'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=8),\n",
       " RejectionOodExperiment(seed=3, acquisition_size=5, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.TemperedBALD'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=8),\n",
       " RejectionOodExperiment(seed=3, acquisition_size=10, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.TemperedBALD'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=8),\n",
       " RejectionOodExperiment(seed=3, acquisition_size=20, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.TemperedBALD'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=8),\n",
       " RejectionOodExperiment(seed=3, acquisition_size=50, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.TemperedBALD'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=8),\n",
       " RejectionOodExperiment(seed=4, acquisition_size=5, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.TemperedBALD'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=8),\n",
       " RejectionOodExperiment(seed=4, acquisition_size=10, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.TemperedBALD'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=8),\n",
       " RejectionOodExperiment(seed=4, acquisition_size=20, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.TemperedBALD'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=8),\n",
       " RejectionOodExperiment(seed=4, acquisition_size=50, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.TemperedBALD'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=8),\n",
       " RejectionOodExperiment(seed=0, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.Random'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=0.0),\n",
       " RejectionOodExperiment(seed=1, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.Random'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=0.0),\n",
       " RejectionOodExperiment(seed=2, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.Random'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=0.0),\n",
       " RejectionOodExperiment(seed=3, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.Random'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=0.0),\n",
       " RejectionOodExperiment(seed=4, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.Random'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=0.0),\n",
       " RejectionOodExperiment(seed=5, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.Random'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=0.0),\n",
       " RejectionOodExperiment(seed=6, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.Random'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=0.0),\n",
       " RejectionOodExperiment(seed=7, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.Random'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=0.0),\n",
       " RejectionOodExperiment(seed=8, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.Random'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=0.0),\n",
       " RejectionOodExperiment(seed=9, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.Random'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=0.0),\n",
       " RejectionOodExperiment(seed=10, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.Random'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=0.0),\n",
       " RejectionOodExperiment(seed=11, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.Random'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=0.0),\n",
       " RejectionOodExperiment(seed=12, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.Random'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=0.0),\n",
       " RejectionOodExperiment(seed=13, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.Random'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=0.0),\n",
       " RejectionOodExperiment(seed=14, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.Random'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=0.0),\n",
       " RejectionOodExperiment(seed=15, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.Random'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=0.0),\n",
       " RejectionOodExperiment(seed=16, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.Random'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=0.0),\n",
       " RejectionOodExperiment(seed=17, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.Random'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=0.0),\n",
       " RejectionOodExperiment(seed=18, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.Random'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=0.0),\n",
       " RejectionOodExperiment(seed=19, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device='cuda', validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, min_samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=<class 'batchbald_redux.acquisition_functions.Random'>, train_eval_model=<class 'batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel'>, model_optimizer_factory=<class 'batchbald_redux.models.MnistOptimizerFactory'>, acquisition_function_args=None, temperature=0.0)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:active_learning]",
   "language": "python",
   "name": "conda-env-active_learning-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
