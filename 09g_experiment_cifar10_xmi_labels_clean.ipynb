{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment XMI Labels Clean\n",
    "> Can we get better by training on our assumptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp experiment_cifar10_xmi_labels_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended /home/blackhc/PycharmProjects/bald-ical/src to paths\n",
      "Switched to directory /home/blackhc/PycharmProjects/bald-ical\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "import blackhc.project.script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules and functions were are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "import dataclasses\n",
    "import traceback\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Type, Union\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from blackhc.project import is_run_from_ipython\n",
    "from blackhc.project.experiment import embedded_experiments\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import batchbald_redux.acquisition_functions as acquisition_functions\n",
    "import batchbald_redux.acquisition_functions.bald\n",
    "import batchbald_redux.acquisition_functions.coreset\n",
    "from batchbald_redux.acquisition_functions import (\n",
    "    CandidateBatchComputer,\n",
    "    EvalModelBatchComputer,\n",
    ")\n",
    "from batchbald_redux.active_learning import ActiveLearningData, RandomFixedLengthSampler\n",
    "from batchbald_redux.black_box_model_training import evaluate\n",
    "from batchbald_redux.dataset_operations import (\n",
    "    get_base_dataset_index,\n",
    "    get_target, AdditiveGaussianNoise, AliasDataset, get_balanced_sample_indices_by_class,\n",
    ")\n",
    "from batchbald_redux.datasets import get_dataset\n",
    "from batchbald_redux.di import DependencyInjection\n",
    "from batchbald_redux.resnet_models import Cifar10BayesianResnetFactory\n",
    "from batchbald_redux.resnet_models import Cifar10ModelTrainer\n",
    "from batchbald_redux.train_eval_model import (\n",
    "    TrainEvalModel,\n",
    "    TrainSelfDistillationEvalModel,\n",
    ")\n",
    "from batchbald_redux.trained_model import ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "from blackhc.progress_bar import create_progress_bar\n",
    "from toma import toma\n",
    "\n",
    "\n",
    "def compute_entropy_from_probs(probs_N_K_C: torch.Tensor) -> torch.Tensor:\n",
    "    N, K, C = probs_N_K_C.shape\n",
    "\n",
    "    entropies_N = torch.empty(N, dtype=torch.double)\n",
    "\n",
    "    pbar = create_progress_bar(N, tqdm_args=dict(desc=\"Entropy\", leave=False))\n",
    "    pbar.start()\n",
    "\n",
    "    @toma.execute.chunked(probs_N_K_C, 1024)\n",
    "    def compute(probs_n_K_C, start: int, end: int):\n",
    "        mean_probs_n_C = probs_n_K_C.mean(dim=1)\n",
    "        nats_n_C = mean_probs_n_C * torch.log(mean_probs_n_C)\n",
    "        nats_n_C[mean_probs_n_C == 0] = 0.0\n",
    "\n",
    "        entropies_N[start:end].copy_(-torch.sum(nats_n_C, dim=1))\n",
    "        pbar.update(end - start)\n",
    "\n",
    "    pbar.finish()\n",
    "\n",
    "    return entropies_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/cifar10_train_predictions.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-87d4f2695ccf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/cifar10_train_predictions.pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_entropies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_entropy_from_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_predictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/cifar10_train_predictions.pt'"
     ]
    }
   ],
   "source": [
    "train_predictions = torch.load(\"./data/cifar10_train_predictions.pt\", map_location=\"cpu\")\n",
    "train_entropies = compute_entropy_from_probs(train_predictions[:, None, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([41483.,  2997.,   840.,   396.,   284.,   227.,   176.,   159.,\n",
       "          150.,   117.]),\n",
       " array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_entropies.cpu().numpy(), range=[0, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "@dataclass\n",
    "class ExperimentData:\n",
    "    active_learning: ActiveLearningData\n",
    "    train_dataset: Dataset\n",
    "    train_augmentations: nn.Module\n",
    "    validation_dataset: Dataset\n",
    "    test_dataset: Dataset\n",
    "    evaluation_dataset: Dataset\n",
    "    initial_training_set_indices: [int]\n",
    "    evaluation_set_indices: [int]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ExperimentDataConfig:\n",
    "    id_dataset_name: str\n",
    "    initial_training_set_size: int\n",
    "    validation_set_size: int\n",
    "    evaluation_set_size: int\n",
    "    id_repetitions: float\n",
    "    add_dataset_noise: bool\n",
    "    validation_split_random_state: int\n",
    "\n",
    "    device: str\n",
    "\n",
    "    def load(self) -> ExperimentData:\n",
    "        return load_experiment_data(\n",
    "            id_dataset_name=self.id_dataset_name,\n",
    "            initial_training_set_size=self.initial_training_set_size,\n",
    "            validation_set_size=self.validation_set_size,\n",
    "            evaluation_set_size=self.evaluation_set_size,\n",
    "            id_repetitions=self.id_repetitions,\n",
    "            add_dataset_noise=self.add_dataset_noise,\n",
    "            validation_split_random_state=self.validation_split_random_state,\n",
    "            device=self.device,\n",
    "        )\n",
    "\n",
    "\n",
    "def load_experiment_data(\n",
    "    *,\n",
    "    id_dataset_name: str,\n",
    "    initial_training_set_size: int,\n",
    "    validation_set_size: int,\n",
    "    evaluation_set_size: int,\n",
    "    id_repetitions: float,\n",
    "    add_dataset_noise: bool,\n",
    "    validation_split_random_state: int,\n",
    "    device: str,\n",
    ") -> ExperimentData:\n",
    "    split_dataset = get_dataset(id_dataset_name, root=\"data\", validation_set_size=validation_set_size,\n",
    "                                validation_split_random_state=validation_split_random_state, normalize_like_cifar10=True)\n",
    "\n",
    "    assert id_dataset_name == \"CIFAR-10\"\n",
    "    train_predictions = torch.load(\"./data/cifar10_train_predictions.pt\", map_location=device)\n",
    "\n",
    "    train_dataset = split_dataset.train\n",
    "    train_indices = train_dataset.dataset.indices\n",
    "    train_dataset = train_dataset.override_targets(targets=train_predictions[train_indices].argmax(dim=1))\n",
    "\n",
    "    train_entropies = compute_entropy_from_probs(train_predictions[train_indices, None, :])\n",
    "\n",
    "    entropy_threshold = 0.01\n",
    "    allowed_indices = torch.nonzero(train_entropies < entropy_threshold, as_tuple=True)[0].numpy()\n",
    "    print(f\"Removing {len(train_dataset) - len(allowed_indices)} training samples with entropy >= {entropy_threshold}.\")\n",
    "\n",
    "    train_dataset = train_dataset.subset(allowed_indices)\n",
    "\n",
    "    # If we reduce the train set, we need to do so before picking the initial train set.\n",
    "    if id_repetitions < 1:\n",
    "        train_dataset = train_dataset * id_repetitions\n",
    "\n",
    "    targets = train_dataset.get_targets()\n",
    "    num_classes = train_dataset.get_num_classes()\n",
    "    initial_samples_per_class = initial_training_set_size // num_classes\n",
    "    evaluation_set_samples_per_class = evaluation_set_size // num_classes\n",
    "    samples_per_class = initial_samples_per_class + evaluation_set_samples_per_class\n",
    "    balanced_samples_indices = get_balanced_sample_indices_by_class(\n",
    "        targets=targets,\n",
    "        num_classes=num_classes,\n",
    "        samples_per_class=samples_per_class,\n",
    "        seed=validation_split_random_state,\n",
    "    )\n",
    "\n",
    "    initial_training_set_indices = [\n",
    "        idx for by_class in balanced_samples_indices.values() for idx in by_class[:initial_samples_per_class]\n",
    "    ]\n",
    "    evaluation_set_indices = [\n",
    "        idx for by_class in balanced_samples_indices.values() for idx in by_class[initial_samples_per_class:]\n",
    "    ]\n",
    "\n",
    "    # If we over-sample the train set, we do so after picking the initial train set to avoid duplicates.\n",
    "    if id_repetitions > 1:\n",
    "        train_dataset = train_dataset * id_repetitions\n",
    "\n",
    "    if add_dataset_noise:\n",
    "        train_dataset = AdditiveGaussianNoise(train_dataset, 0.1)\n",
    "\n",
    "    active_learning_data = ActiveLearningData(train_dataset)\n",
    "\n",
    "    active_learning_data.acquire_base_indices(initial_training_set_indices)\n",
    "\n",
    "    evaluation_dataset = AliasDataset(\n",
    "        active_learning_data.extract_dataset_from_base_indices(evaluation_set_indices),\n",
    "        f\"Evaluation Set ({len(evaluation_set_indices)} samples)\",\n",
    "    )\n",
    "\n",
    "    return ExperimentData(\n",
    "        active_learning=active_learning_data,\n",
    "        train_dataset=train_dataset,\n",
    "        # NO AUGMENTATIONS!\n",
    "        train_augmentations=None,\n",
    "        validation_dataset=split_dataset.validation,\n",
    "        test_dataset=split_dataset.test,\n",
    "        evaluation_dataset=evaluation_dataset,\n",
    "        initial_training_set_indices=initial_training_set_indices,\n",
    "        evaluation_set_indices=evaluation_set_indices,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "@dataclass\n",
    "class Experiment:\n",
    "    seed: int\n",
    "\n",
    "    id_dataset_name: str = \"CIFAR-10\"\n",
    "    initial_training_set_size: int = 1000\n",
    "    validation_set_size: int = 5000\n",
    "    evaluation_set_size: int = 0\n",
    "    id_repetitions: float = 1\n",
    "    add_dataset_noise: bool = False\n",
    "    validation_split_random_state: int = 0\n",
    "\n",
    "    acquisition_size: int = 5\n",
    "    max_training_set: int = 300\n",
    "    num_pool_samples: int = 20\n",
    "    num_validation_samples: int = 20\n",
    "    num_training_samples: int = 1\n",
    "    max_training_epochs: int = 120\n",
    "    training_batch_size: int = 128\n",
    "    device: str = \"cuda\"\n",
    "    min_samples_per_epoch: int = 5056\n",
    "    patience_schedule: [int] = (6, 4, 3)\n",
    "    factor_schedule: [int] = (0.1,)\n",
    "    acquisition_function: Union[\n",
    "        Type[CandidateBatchComputer], Type[EvalModelBatchComputer]\n",
    "    ] = batchbald_redux.acquisition_functions.bald.BALD\n",
    "    train_eval_model: Type[TrainEvalModel] = TrainSelfDistillationEvalModel\n",
    "    model_trainer_factory: Type[ModelTrainer] = Cifar10ModelTrainer\n",
    "    acquisition_function_args: dict = None\n",
    "    temperature: float = 0.0\n",
    "    prefer_accuracy: bool = True\n",
    "\n",
    "    def load_experiment_data(self) -> ExperimentData:\n",
    "        di = DependencyInjection(vars(self))\n",
    "        edc: ExperimentDataConfig = di.create_dataclass_type(ExperimentDataConfig)\n",
    "        return edc.load()\n",
    "\n",
    "    # Simple Dependency Injection\n",
    "    def create_acquisition_function(self):\n",
    "        di = DependencyInjection(vars(self))\n",
    "        return di.create_dataclass_type(self.acquisition_function)\n",
    "\n",
    "    def create_train_eval_model(self, runtime_config) -> TrainEvalModel:\n",
    "        config = {**vars(self), **runtime_config}\n",
    "        di = DependencyInjection(config, [])\n",
    "        return di.create_dataclass_type(self.train_eval_model)\n",
    "\n",
    "    def create_model_trainer(self) -> ModelTrainer:\n",
    "        di = DependencyInjection(vars(self))\n",
    "        return di.create_dataclass_type(self.model_trainer_factory)\n",
    "\n",
    "    def run(self, store):\n",
    "        torch.manual_seed(self.seed)\n",
    "\n",
    "        # Active Learning setup\n",
    "        data = self.load_experiment_data()\n",
    "        store[\"dataset_info\"] = dict(training=repr(data.active_learning.base_dataset), test=repr(data.test_dataset))\n",
    "        store[\"initial_training_set_indices\"] = data.initial_training_set_indices\n",
    "        store[\"evaluation_set_indices\"] = data.evaluation_set_indices\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            data.active_learning.training_dataset,\n",
    "            batch_size=self.training_batch_size,\n",
    "            sampler=RandomFixedLengthSampler(data.active_learning.training_dataset, self.min_samples_per_epoch),\n",
    "            drop_last=True,\n",
    "        )\n",
    "        pool_loader = torch.utils.data.DataLoader(\n",
    "            data.active_learning.pool_dataset, batch_size=128, drop_last=False, shuffle=False\n",
    "        )\n",
    "\n",
    "        validation_loader = torch.utils.data.DataLoader(data.validation_dataset, batch_size=512, drop_last=False)\n",
    "        test_loader = torch.utils.data.DataLoader(data.test_dataset, batch_size=512, drop_last=False)\n",
    "\n",
    "        store[\"active_learning_steps\"] = []\n",
    "        active_learning_steps = store[\"active_learning_steps\"]\n",
    "\n",
    "        acquisition_function = self.create_acquisition_function()\n",
    "        model_trainer = self.create_model_trainer()\n",
    "\n",
    "        loss = validation_loss = torch.nn.NLLLoss()\n",
    "\n",
    "        # Active Training Loop\n",
    "        while True:\n",
    "            training_set_size = len(data.active_learning.training_dataset)\n",
    "            print(f\"Training set size {training_set_size}:\")\n",
    "\n",
    "            # iteration_log = dict(training={}, pool_training={}, evaluation_metrics=None, acquisition=None)\n",
    "            active_learning_steps.append({})\n",
    "            iteration_log = active_learning_steps[-1]\n",
    "\n",
    "            iteration_log[\"training\"] = {}\n",
    "\n",
    "            trained_model = model_trainer.get_trained(train_loader=train_loader,\n",
    "                                                      train_augmentations=data.train_augmentations,\n",
    "                                                      validation_loader=validation_loader,\n",
    "                                                      log=iteration_log[\"training\"], loss=loss,\n",
    "                                                      validation_loss=validation_loss)\n",
    "\n",
    "            evaluation_metrics = evaluate(model=trained_model, num_samples=self.num_validation_samples,\n",
    "                                          loader=test_loader, device=self.device, storage_device=\"cpu\")\n",
    "\n",
    "            iteration_log[\"evaluation_metrics\"] = evaluation_metrics\n",
    "            print(f\"Perf after training {evaluation_metrics}\")\n",
    "\n",
    "            if training_set_size >= self.max_training_set:\n",
    "                print(\"Done.\")\n",
    "                break\n",
    "\n",
    "            if isinstance(acquisition_function, CandidateBatchComputer):\n",
    "                candidate_batch = acquisition_function.compute_candidate_batch(trained_model, pool_loader, self.device)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown acquisition function {acquisition_function}!\")\n",
    "\n",
    "            candidate_global_indices = [\n",
    "                get_base_dataset_index(data.active_learning.pool_dataset, index).index\n",
    "                for index in candidate_batch.indices\n",
    "            ]\n",
    "            candidate_labels = [\n",
    "                get_target(data.active_learning.pool_dataset, index).item() for index in candidate_batch.indices\n",
    "            ]\n",
    "\n",
    "            iteration_log[\"acquisition\"] = dict(\n",
    "                indices=candidate_global_indices, labels=candidate_labels, scores=candidate_batch.scores\n",
    "            )\n",
    "\n",
    "            data.active_learning.acquire(candidate_batch.indices)\n",
    "\n",
    "            ls = \", \".join(f\"{label} ({score:.4})\" for label, score in zip(candidate_labels, candidate_batch.scores))\n",
    "            print(f\"Acquiring (label, score)s: {ls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating: ExperimentDataConfig(\n",
      "\tid_dataset_name=CIFAR-10,\n",
      "\tinitial_training_set_size=20000,\n",
      "\tvalidation_set_size=5000,\n",
      "\tevaluation_set_size=0,\n",
      "\tid_repetitions=1,\n",
      "\tadd_dataset_noise=False,\n",
      "\tvalidation_split_random_state=0,\n",
      "\tdevice=cuda\n",
      ")\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n",
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/45000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 7623 training samples with entropy >= 0.01.\n",
      "Creating: BatchCoreSetBALD(\n",
      "\tacquisition_size=5,\n",
      "\tnum_pool_samples=20\n",
      ")\n",
      "Creating: Cifar10ModelTrainer(\n",
      "\tdevice=cuda,\n",
      "\tnum_training_samples=1,\n",
      "\tnum_validation_samples=20,\n",
      "\tmax_training_epochs=1,\n",
      "\tpatience_schedule=(6, 4, 3),\n",
      "\tfactor_schedule=(0.1,),\n",
      "\tmin_samples_per_epoch=5000\n",
      ")\n",
      "Training set size 20000:\n",
      "Cosine Annealing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1db25d277e06440ca5290c3d43320170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/156]   1%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/10]  10%|#          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 metrics: {'accuracy': 0.3344, 'crossentropy': 1.7623895263671876}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.3408, 'crossentropy': tensor(1.7030)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/347540 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BatchCoreSetBALD:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquiring (label, score)s: 3 (1.029), 5 (2.093), 5 (2.698), 3 (2.903), 3 (2.966)\n",
      "Training set size 20005:\n",
      "Cosine Annealing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "712ec70cfcb149b3bb5852bf2b05d432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/156]   1%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/10]  10%|#          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 metrics: {'accuracy': 0.3298, 'crossentropy': 1.7995323238372802}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.3295, 'crossentropy': tensor(1.7435)}\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# experiment\n",
    "\n",
    "experiment = Experiment(\n",
    "    seed=1120,\n",
    "    max_training_epochs=1,\n",
    "    max_training_set=20005,\n",
    "    acquisition_function=acquisition_functions.BatchCoreSetBALD,\n",
    "    acquisition_size=5,\n",
    "    num_pool_samples=20,\n",
    "    initial_training_set_size=20000,\n",
    "    temperature=8,\n",
    "    min_samples_per_epoch=5000,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "results = {}\n",
    "experiment.run(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'initial_training_set_indices': [38043,\n",
       "  40091,\n",
       "  17418,\n",
       "  2094,\n",
       "  39879,\n",
       "  3133,\n",
       "  5011,\n",
       "  40683,\n",
       "  54379,\n",
       "  24287,\n",
       "  9849,\n",
       "  59305,\n",
       "  39508,\n",
       "  39356,\n",
       "  8758,\n",
       "  52579,\n",
       "  13655,\n",
       "  7636,\n",
       "  21562,\n",
       "  41329],\n",
       " 'dataset_info': {'training': \"'FastMNIST (Train)'\",\n",
       "  'test': \"'FastMNIST (Test)'\"},\n",
       " 'active_learning_steps': [{'training': {'epochs': [{'accuracy': 0.62109375,\n",
       "      'crossentropy': 2.6530187726020813},\n",
       "     {'accuracy': 0.6376953125, 'crossentropy': 2.762658029794693},\n",
       "     {'accuracy': 0.646484375, 'crossentropy': 3.056214064359665},\n",
       "     {'accuracy': 0.6416015625, 'crossentropy': 3.1257119178771973}],\n",
       "    'best_epoch': 1},\n",
       "   'evaluation_metrics': {'accuracy': 0.631,\n",
       "    'crossentropy': 2.6251225173950195}}]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size 20:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3fc327793734c0eb2f361164ad86451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/384]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/64]   2%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RestoringEarlyStopping: Restoring best parameters. (Score: -6.529030114412308)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/157]   1%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.5367, 'crossentropy': 6.438035237884521}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions:   0%|          | 0/463616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382711f4f7ad4ec7980c856e0f9d229e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1811]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/64]   2%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RestoringEarlyStopping: Restoring best parameters. (Score: -5.1637596152722836)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions:   0%|          | 0/2317680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions:   0%|          | 0/2317680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/115884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/115884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/115884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/115884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquiring (label, score)s: 8 (0.8711), 8 (0.8687), 3 (0.876), 3 (0.8465), 3 (0.8811)\n",
      "Training set size 25:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c326c4165e48eab908014b4064f795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/384]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/64]   2%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RestoringEarlyStopping: Restoring best parameters. (Score: -4.6851686127483845)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/157]   1%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.6256, 'crossentropy': 4.484497045135498}\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'initial_training_set_indices': [38043,\n",
       "  40091,\n",
       "  17418,\n",
       "  2094,\n",
       "  39879,\n",
       "  3133,\n",
       "  5011,\n",
       "  40683,\n",
       "  54379,\n",
       "  24287,\n",
       "  9849,\n",
       "  59305,\n",
       "  39508,\n",
       "  39356,\n",
       "  8758,\n",
       "  52579,\n",
       "  13655,\n",
       "  7636,\n",
       "  21562,\n",
       "  41329],\n",
       " 'active_learning_steps': [{'training': {'epochs': [{'accuracy': 0.538818359375,\n",
       "      'crossentropy': 6.529030114412308}],\n",
       "    'best_epoch': 1},\n",
       "   'evalution_metrics': {'accuracy': 0.5367,\n",
       "    'crossentropy': 6.438035237884521},\n",
       "   'pool_training': {'epochs': [{'accuracy': 0.531005859375,\n",
       "      'crossentropy': 5.1637596152722836}],\n",
       "    'best_epoch': 1},\n",
       "   'acquisition': {'indices': [63338, 10856, 63452, 81864, 109287],\n",
       "    'labels': [8, 8, 3, 3, 3],\n",
       "    'scores': [0.8710822958846325,\n",
       "     0.8687216999221631,\n",
       "     0.8759664372823723,\n",
       "     0.8464646732511746,\n",
       "     0.8810812784952251]}},\n",
       "  {'training': {'epochs': [{'accuracy': 0.62255859375,\n",
       "      'crossentropy': 4.6851686127483845}],\n",
       "    'best_epoch': 1},\n",
       "   'evalution_metrics': {'accuracy': 0.6256,\n",
       "    'crossentropy': 4.484497045135498}}]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment\n",
    "\n",
    "experiment = Experiment(\n",
    "    max_training_epochs=1, max_training_set=25, acquisition_function=AcquisitionFunction.randombaldical\n",
    ")\n",
    "\n",
    "results = {}\n",
    "experiment.run(results)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIRST EXPERIMENT SET\n",
    "\n",
    "configs = [\n",
    "    Experiment(\n",
    "        seed=seed,\n",
    "        acquisition_function=acquisition_function,\n",
    "        acquisition_size=acquisition_size,\n",
    "        num_pool_samples=num_pool_samples,\n",
    "        temperature=8,\n",
    "    )\n",
    "    for seed in range(5)\n",
    "    for acquisition_function in [\n",
    "        acquisition_functions.BALD,\n",
    "        acquisition_functions.CoreSetBALD,\n",
    "    ]\n",
    "    for acquisition_size in [1]\n",
    "    for num_pool_samples in [100]\n",
    "] + [\n",
    "    Experiment(\n",
    "        seed=seed,\n",
    "        acquisition_function=acquisition_functions.Random,\n",
    "        acquisition_size=5,\n",
    "        num_pool_samples=1,\n",
    "    )\n",
    "    for seed in range(5)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "configs = [\n",
    "    Experiment(\n",
    "        seed=seed + 7777,\n",
    "        acquisition_function=acquisition_function,\n",
    "        acquisition_size=acquisition_size,\n",
    "        num_pool_samples=num_pool_samples,\n",
    "        initial_training_set_size=0,\n",
    "        max_training_set=250,\n",
    "        prefer_accuracy=True\n",
    "    )\n",
    "    for seed in range(5)\n",
    "    for acquisition_function in [\n",
    "        batchbald_redux.acquisition_functions.coreset.CoreSetBALD,\n",
    "        batchbald_redux.acquisition_functions.bald.BALD,\n",
    "        #acquisition_functions.Random,\n",
    "    ]\n",
    "    for acquisition_size in [1]\n",
    "    for num_pool_samples in [100]\n",
    "]\n",
    "\n",
    "if not is_run_from_ipython() and __name__ == \"__main__\":\n",
    "    for job_id, store in embedded_experiments(__file__, len(configs)):\n",
    "        config = configs[job_id]\n",
    "        config.seed += job_id\n",
    "        print(config)\n",
    "        store[\"config\"] = dataclasses.asdict(config)\n",
    "        store[\"log\"] = {}\n",
    "\n",
    "        try:\n",
    "            config.run(store=store)\n",
    "        except Exception:\n",
    "            store[\"exception\"] = traceback.format_exc()\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    Experiment(\n",
      "        seed=7777,\n",
      "        initial_training_set_size=0,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=250,\n",
      "        num_pool_samples=100,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.CoreSetBALD\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=7777,\n",
      "        initial_training_set_size=0,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=250,\n",
      "        num_pool_samples=100\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=7778,\n",
      "        initial_training_set_size=0,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=250,\n",
      "        num_pool_samples=100,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.CoreSetBALD\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=7778,\n",
      "        initial_training_set_size=0,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=250,\n",
      "        num_pool_samples=100\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=7779,\n",
      "        initial_training_set_size=0,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=250,\n",
      "        num_pool_samples=100,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.CoreSetBALD\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=7779,\n",
      "        initial_training_set_size=0,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=250,\n",
      "        num_pool_samples=100\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=7780,\n",
      "        initial_training_set_size=0,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=250,\n",
      "        num_pool_samples=100,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.CoreSetBALD\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=7780,\n",
      "        initial_training_set_size=0,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=250,\n",
      "        num_pool_samples=100\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=7781,\n",
      "        initial_training_set_size=0,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=250,\n",
      "        num_pool_samples=100,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.CoreSetBALD\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=7781,\n",
      "        initial_training_set_size=0,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=250,\n",
      "        num_pool_samples=100\n",
      "    )\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import prettyprinter\n",
    "prettyprinter.install_extras({\"dataclasses\"})\n",
    "prettyprinter.pprint(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:active_learning]",
   "language": "python",
   "name": "conda-env-active_learning-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
