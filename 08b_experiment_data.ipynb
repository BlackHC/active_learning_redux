{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mineral-archive",
   "metadata": {},
   "source": [
    "# Experiment Data (Setup)\n",
    "> No empirical experiments without data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp experiment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-mechanics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended /home/blackhc/PycharmProjects/bald-ical/src to paths\n",
      "Switched to directory /home/blackhc/PycharmProjects/bald-ical\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "import blackhc.project.script\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-corner",
   "metadata": {},
   "source": [
    "Import modules and functions were are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-coral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Set\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from batchbald_redux.active_learning import ActiveLearningData\n",
    "from batchbald_redux.dataset_operations import (\n",
    "    AdditiveGaussianNoise,\n",
    "    AliasDataset,\n",
    "    NamedDataset,\n",
    "    get_balanced_sample_indices,\n",
    "    get_balanced_sample_indices_by_class,\n",
    "    get_class_indices,\n",
    "    get_class_indices_by_class,\n",
    "    get_targets,\n",
    ")\n",
    "from batchbald_redux.datasets.factories import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ExperimentData:\n",
    "    active_learning: ActiveLearningData\n",
    "    validation_dataset: Dataset\n",
    "    evaluation_dataset: Dataset\n",
    "    test_dataset: Dataset\n",
    "\n",
    "    train_augmentations: nn.Module\n",
    "\n",
    "    initial_training_set_indices: List[int]\n",
    "    evaluation_set_indices: List[int]\n",
    "\n",
    "    ood_dataset: Optional[NamedDataset]\n",
    "\n",
    "    # TODO: replace this with dataset info on the targets\n",
    "    ood_exposure: bool\n",
    "\n",
    "    device: str\n",
    "\n",
    "\n",
    "class ExperimentDataConfig:\n",
    "    def load(self, device) -> ExperimentData:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class OoDDatasetConfig:\n",
    "    ood_dataset_name: str\n",
    "    ood_repetitions: float\n",
    "    ood_exposure: bool\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class StandardExperimentDataConfig(ExperimentDataConfig):\n",
    "    id_dataset_name: str\n",
    "    id_repetitions: float\n",
    "\n",
    "    initial_training_set_size: int\n",
    "\n",
    "    validation_set_size: int\n",
    "    validation_split_random_state: int\n",
    "\n",
    "    evaluation_set_size: int\n",
    "\n",
    "    add_dataset_noise: bool\n",
    "\n",
    "    ood_dataset_config: Optional[OoDDatasetConfig]\n",
    "\n",
    "    def load(self, device) -> ExperimentData:\n",
    "        return load_standard_experiment_data(\n",
    "            id_dataset_name=self.id_dataset_name,\n",
    "            id_repetitions=self.id_repetitions,\n",
    "            initial_training_set_size=self.initial_training_set_size,\n",
    "            validation_set_size=self.validation_set_size,\n",
    "            validation_split_random_state=self.validation_split_random_state,\n",
    "            evaluation_set_size=self.evaluation_set_size,\n",
    "            add_dataset_noise=self.add_dataset_noise,\n",
    "            ood_dataset_config=self.ood_dataset_config,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "\n",
    "def load_standard_experiment_data(\n",
    "    *,\n",
    "    id_dataset_name: str,\n",
    "    id_repetitions: float,\n",
    "    initial_training_set_size: int,\n",
    "    validation_set_size: int,\n",
    "    validation_split_random_state: int,\n",
    "    evaluation_set_size: int,\n",
    "    add_dataset_noise: bool,\n",
    "    ood_dataset_config: Optional[OoDDatasetConfig],\n",
    "    device: str,\n",
    ") -> ExperimentData:\n",
    "    split_dataset = get_dataset(\n",
    "        id_dataset_name,\n",
    "        root=\"data\",\n",
    "        validation_set_size=validation_set_size,\n",
    "        validation_split_random_state=validation_split_random_state,\n",
    "        normalize_like_cifar10=True,\n",
    "        device_hint=device,\n",
    "    )\n",
    "\n",
    "    train_dataset = split_dataset.train\n",
    "\n",
    "    # TODO: add hook here to further process the train dataset?\n",
    "\n",
    "    # If we reduce the train set, we need to do so before picking the initial train set.\n",
    "    if id_repetitions < 1:\n",
    "        train_dataset = train_dataset * id_repetitions\n",
    "\n",
    "    targets = train_dataset.get_targets()\n",
    "    num_classes = train_dataset.get_num_classes()\n",
    "    initial_samples_per_class = initial_training_set_size // num_classes\n",
    "    evaluation_set_samples_per_class = evaluation_set_size // num_classes\n",
    "    samples_per_class = initial_samples_per_class + evaluation_set_samples_per_class\n",
    "\n",
    "    balanced_samples_indices = get_balanced_sample_indices_by_class(\n",
    "        targets=targets,\n",
    "        num_classes=num_classes,\n",
    "        samples_per_class=samples_per_class,\n",
    "        seed=validation_split_random_state,\n",
    "    )\n",
    "\n",
    "    initial_training_set_indices = [\n",
    "        idx for by_class in balanced_samples_indices.values() for idx in by_class[:initial_samples_per_class]\n",
    "    ]\n",
    "    evaluation_set_indices = [\n",
    "        idx for by_class in balanced_samples_indices.values() for idx in by_class[initial_samples_per_class:]\n",
    "    ]\n",
    "\n",
    "    # If we over-sample the train set, we do so after picking the initial train set to avoid duplicates\n",
    "    # (duplicates within the initial train set).\n",
    "    if id_repetitions > 1:\n",
    "        train_dataset = train_dataset * id_repetitions\n",
    "\n",
    "    if ood_dataset_config:\n",
    "        ood_exposure = ood_dataset_config.ood_exposure\n",
    "        odd_split_dataset = get_dataset(\n",
    "            ood_dataset_config.ood_dataset_name, root=\"data\", normalize_like_cifar10=True, device_hint=device\n",
    "        )\n",
    "        assert split_dataset.device == odd_split_dataset.device, (\n",
    "            f\"ID dataset resides on {split_dataset.device}, while OOD dataset is on {odd_split_dataset.device};\"\n",
    "            'try to put both on \"cpu\"!'\n",
    "        )\n",
    "        original_ood_dataset = odd_split_dataset.train\n",
    "        if ood_exposure:\n",
    "            train_dataset = train_dataset.one_hot(device=split_dataset.device)\n",
    "            ood_dataset = original_ood_dataset.uniform_target(\n",
    "                device=split_dataset.device, num_classes=train_dataset.get_num_classes()\n",
    "            )\n",
    "        else:\n",
    "            ood_dataset = original_ood_dataset.constant_target(\n",
    "                target=torch.tensor(-1, device=split_dataset.device), num_classes=train_dataset.get_num_classes()\n",
    "            )\n",
    "\n",
    "        if ood_dataset_config.ood_repetitions != 1:\n",
    "            ood_dataset = ood_dataset * ood_dataset_config.ood_repetitions\n",
    "\n",
    "        train_dataset = train_dataset + ood_dataset\n",
    "    else:\n",
    "        original_ood_dataset = None\n",
    "        ood_exposure = False\n",
    "\n",
    "    if add_dataset_noise:\n",
    "        train_dataset = AdditiveGaussianNoise(train_dataset, 0.1)\n",
    "    else:\n",
    "        if id_repetitions > 1 or (ood_dataset_config is not None and ood_dataset_config.ood_repetitions) > 1:\n",
    "            raise RuntimeError(\"`add_dataset_noise`==False, even though repeated id or ood data!\")\n",
    "\n",
    "    active_learning_data = ActiveLearningData(train_dataset)\n",
    "\n",
    "    active_learning_data.acquire_base_indices(initial_training_set_indices)\n",
    "\n",
    "    evaluation_dataset = AliasDataset(\n",
    "        active_learning_data.extract_dataset_from_base_indices(evaluation_set_indices),\n",
    "        f\"Evaluation Set ({len(evaluation_set_indices)} samples)\",\n",
    "    )\n",
    "\n",
    "    return ExperimentData(\n",
    "        active_learning=active_learning_data,\n",
    "        validation_dataset=split_dataset.validation,\n",
    "        test_dataset=split_dataset.test,\n",
    "        evaluation_dataset=evaluation_dataset,\n",
    "        train_augmentations=split_dataset.train_augmentations,\n",
    "        initial_training_set_indices=initial_training_set_indices,\n",
    "        evaluation_set_indices=evaluation_set_indices,\n",
    "        ood_dataset=original_ood_dataset,\n",
    "        ood_exposure=ood_exposure,\n",
    "        device=split_dataset.device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-jamaica",
   "metadata": {},
   "source": [
    "## `load_standard_experiment_data` tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-pound",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n",
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExperimentData(active_learning=ActiveLearningData(base_dataset='MNIST (Train, seed=0, 59968 samples)', num_training_samples=20, num_pool_samples=59938), validation_dataset='MNIST (Validation, seed=0, 32 samples)', evaluation_dataset=Evaluation Set (10 samples), test_dataset='MNIST (Test)', train_augmentations=Sequential(), initial_training_set_indices=[46413, 55726, 25576, 55469, 39617, 35783, 36962, 56698, 4436, 24251, 27760, 7593, 15110, 21413, 31797, 42500, 34791, 46864, 47424, 57533], evaluation_set_indices=[43895, 47051, 56807, 13452, 39664, 38002, 53721, 37072, 18635, 52360], ood_dataset=None, ood_exposure=False, device='cuda')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "load_standard_experiment_data(\n",
    "    id_dataset_name=\"MNIST\",\n",
    "    initial_training_set_size=20,\n",
    "    validation_set_size=32,\n",
    "    evaluation_set_size=16,\n",
    "    id_repetitions=1.0,\n",
    "    add_dataset_noise=False,\n",
    "    validation_split_random_state=0,\n",
    "    ood_dataset_config=None,\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-blanket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n",
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExperimentData(active_learning=ActiveLearningData(base_dataset='CIFAR-10 (Train, seed=0, 49968 samples)', num_training_samples=20, num_pool_samples=49938), validation_dataset='CIFAR-10 (Validation, seed=0, 32 samples)', evaluation_dataset=Evaluation Set (10 samples), test_dataset='CIFAR-10 (Test)', train_augmentations=Sequential(\n",
       "  (0): RandomCrop(crop_size=(32, 32), padding=4, fill=0, pad_if_needed=False, padding_mode=constant, resample=BILINEAR, p=1.0, p_batch=1.0, same_on_batch=False, return_transform=False)\n",
       "  (1): RandomHorizontalFlip(p=0.5, p_batch=1.0, same_on_batch=False, return_transform=None)\n",
       "), initial_training_set_indices=[5618, 30732, 1910, 25225, 6409, 17895, 49063, 49577, 41071, 10377, 27423, 811, 27285, 22836, 26253, 5916, 49126, 40676, 31804, 13474], evaluation_set_indices=[36153, 11586, 36207, 16977, 1000, 10548, 11403, 2005, 41796, 25579], ood_dataset=None, ood_exposure=False, device='cpu')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "load_standard_experiment_data(\n",
    "    id_dataset_name=\"CIFAR-10\",\n",
    "    initial_training_set_size=20,\n",
    "    validation_set_size=32,\n",
    "    evaluation_set_size=16,\n",
    "    id_repetitions=1.0,\n",
    "    add_dataset_noise=False,\n",
    "    validation_split_random_state=0,\n",
    "    ood_dataset_config=None,\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-domain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n",
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "ID dataset resides on cpu, while OOD dataset is on cuda;try to put both on \"cpu\"!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6fc73b12bf96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m load_standard_experiment_data(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mid_dataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"CIFAR-10\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minitial_training_set_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-f95f2ad17d94>\u001b[0m in \u001b[0;36mload_standard_experiment_data\u001b[0;34m(id_dataset_name, id_repetitions, initial_training_set_size, validation_set_size, validation_split_random_state, evaluation_set_size, add_dataset_noise, ood_dataset_config, device)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mood_dataset_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mood_dataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize_like_cifar10\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         )\n\u001b[0;32m---> 97\u001b[0;31m         assert split_dataset.device == odd_split_dataset.device, (\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0;34mf\"ID dataset resides on {split_dataset.device}, while OOD dataset is on {odd_split_dataset.device};\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;34m'try to put both on \"cpu\"!'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: ID dataset resides on cpu, while OOD dataset is on cuda;try to put both on \"cpu\"!"
     ]
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "load_standard_experiment_data(\n",
    "    id_dataset_name=\"CIFAR-10\",\n",
    "    initial_training_set_size=20,\n",
    "    validation_set_size=32,\n",
    "    evaluation_set_size=16,\n",
    "    id_repetitions=1.0,\n",
    "    add_dataset_noise=False,\n",
    "    validation_split_random_state=0,\n",
    "    ood_dataset_config=OoDDatasetConfig(ood_dataset_name=\"MNIST\", ood_repetitions=1.0, ood_exposure=False),\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "# THIS OUGHT TO CRASH! BUT TELL YOU WHAT TO DO INSTEAD :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-promise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExperimentData(active_learning=<batchbald_redux.active_learning.ActiveLearningData object at 0x7ff6f58d5c40>, validation_dataset='CIFAR-10 (Validation, seed=0, 32 samples)', evaluation_dataset=Evaluation Set (10 samples), test_dataset='CIFAR-10 (Test)', train_augmentations=Sequential(\n",
       "  (0): RandomCrop(crop_size=(32, 32), padding=4, fill=0, pad_if_needed=False, padding_mode=constant, resample=BILINEAR, p=1.0, p_batch=1.0, same_on_batch=False, return_transform=False)\n",
       "  (1): RandomHorizontalFlip(p=0.5, p_batch=1.0, same_on_batch=False, return_transform=None)\n",
       "), initial_training_set_indices=[5618, 30732, 1910, 25225, 6409, 17895, 49063, 49577, 41071, 10377, 27423, 811, 27285, 22836, 26253, 5916, 49126, 40676, 31804, 13474], evaluation_set_indices=[36153, 11586, 36207, 16977, 1000, 10548, 11403, 2005, 41796, 25579], ood_dataset='MNIST (Train, seed=0, 60000 samples)', device='cpu')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "load_standard_experiment_data(\n",
    "    id_dataset_name=\"CIFAR-10\",\n",
    "    initial_training_set_size=20,\n",
    "    validation_set_size=32,\n",
    "    evaluation_set_size=16,\n",
    "    id_repetitions=1.0,\n",
    "    add_dataset_noise=False,\n",
    "    validation_split_random_state=0,\n",
    "    ood_dataset_config=OoDDatasetConfig(ood_dataset_name=\"MNIST\", ood_repetitions=1.0, ood_exposure=False),\n",
    "    device=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-collectible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExperimentData(active_learning=<batchbald_redux.active_learning.ActiveLearningData object at 0x7f434cd5ca90>, validation_dataset='CIFAR-10 (Validation, seed=0, 32 samples)', evaluation_dataset=Evaluation Set (10 samples), test_dataset='CIFAR-10 (Test)', train_augmentations=Sequential(\n",
       "  (0): RandomCrop(crop_size=(32, 32), padding=4, fill=0, pad_if_needed=False, padding_mode=constant, resample=BILINEAR, p=1.0, p_batch=1.0, same_on_batch=False, return_transform=False)\n",
       "  (1): RandomHorizontalFlip(p=0.5, p_batch=1.0, same_on_batch=False, return_transform=None)\n",
       "), initial_training_set_indices=[5618, 30732, 1910, 25225, 6409, 17895, 49063, 49577, 41071, 10377, 27423, 811, 27285, 22836, 26253, 5916, 49126, 40676, 31804, 13474], evaluation_set_indices=[36153, 11586, 36207, 16977, 1000, 10548, 11403, 2005, 41796, 25579], ood_dataset='CIFAR-100 (Train, seed=0, 50000 samples)')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "load_standard_experiment_data(\n",
    "    id_dataset_name=\"CIFAR-10\",\n",
    "    initial_training_set_size=20,\n",
    "    validation_set_size=32,\n",
    "    evaluation_set_size=16,\n",
    "    id_repetitions=1.0,\n",
    "    add_dataset_noise=False,\n",
    "    validation_split_random_state=0,\n",
    "    ood_dataset_config=OoDDatasetConfig(ood_dataset_name=\"CIFAR-100\", ood_repetitions=1.0, ood_exposure=False),\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-clock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExperimentData(active_learning=<batchbald_redux.active_learning.ActiveLearningData object at 0x7f434db5f2e0>, validation_dataset='CIFAR-10 (Validation, seed=0, 32 samples)', evaluation_dataset=Evaluation Set (10 samples), test_dataset='CIFAR-10 (Test)', train_augmentations=Sequential(\n",
       "  (0): RandomCrop(crop_size=(32, 32), padding=4, fill=0, pad_if_needed=False, padding_mode=constant, resample=BILINEAR, p=1.0, p_batch=1.0, same_on_batch=False, return_transform=False)\n",
       "  (1): RandomHorizontalFlip(p=0.5, p_batch=1.0, same_on_batch=False, return_transform=None)\n",
       "), initial_training_set_indices=[5618, 30732, 1910, 25225, 6409, 17895, 49063, 49577, 41071, 10377, 27423, 811, 27285, 22836, 26253, 5916, 49126, 40676, 31804, 13474], evaluation_set_indices=[36153, 11586, 36207, 16977, 1000, 10548, 11403, 2005, 41796, 25579], ood_dataset='CIFAR-100 (Train, seed=0, 50000 samples)')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "load_standard_experiment_data(\n",
    "    id_dataset_name=\"CIFAR-10\",\n",
    "    initial_training_set_size=20,\n",
    "    validation_set_size=32,\n",
    "    evaluation_set_size=16,\n",
    "    id_repetitions=1.0,\n",
    "    add_dataset_noise=False,\n",
    "    validation_split_random_state=0,\n",
    "    ood_dataset_config=OoDDatasetConfig(ood_dataset_name=\"CIFAR-100\", ood_repetitions=1.0, ood_exposure=True),\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-convenience",
   "metadata": {},
   "source": [
    "# `ImbalancedTestDistributionExperimentDataConfig`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-boxing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ImbalancedTestDistributionExperimentDataConfig(ExperimentDataConfig):\n",
    "    \"\"\"Make the test set and evaluation set imbalanced\"\"\"\n",
    "\n",
    "    dataset_name: str\n",
    "    repetitions: float\n",
    "\n",
    "    initial_training_set_size: int\n",
    "\n",
    "    validation_set_size: int\n",
    "    validation_split_random_state: int\n",
    "\n",
    "    evaluation_set_size: int\n",
    "\n",
    "    add_dataset_noise: bool\n",
    "\n",
    "    minority_classes: Set[int]\n",
    "    minority_class_percentage: float\n",
    "\n",
    "    def load(self, device) -> ExperimentData:\n",
    "        return load_imbalanced_experiment_data(\n",
    "            dataset_name=self.dataset_name,\n",
    "            repetitions=self.repetitions,\n",
    "            initial_training_set_size=self.initial_training_set_size,\n",
    "            validation_set_size=self.validation_set_size,\n",
    "            validation_split_random_state=self.validation_split_random_state,\n",
    "            evaluation_set_size=self.evaluation_set_size,\n",
    "            add_dataset_noise=self.add_dataset_noise,\n",
    "            minority_classes=self.minority_classes,\n",
    "            minority_class_percentage=self.minority_class_percentage,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "\n",
    "def load_imbalanced_experiment_data(\n",
    "    *,\n",
    "    dataset_name: str,\n",
    "    repetitions: float,\n",
    "    initial_training_set_size: int,\n",
    "    validation_set_size: int,\n",
    "    validation_split_random_state: int,\n",
    "    evaluation_set_size: int,\n",
    "    add_dataset_noise: bool,\n",
    "    minority_classes: Set[int],\n",
    "    minority_class_percentage: float,\n",
    "    device: str,\n",
    ") -> ExperimentData:\n",
    "    split_dataset = get_dataset(\n",
    "        dataset_name,\n",
    "        root=\"data\",\n",
    "        validation_set_size=validation_set_size,\n",
    "        validation_split_random_state=validation_split_random_state,\n",
    "        normalize_like_cifar10=True,\n",
    "        device_hint=device,\n",
    "    )\n",
    "\n",
    "    train_dataset = split_dataset.train\n",
    "\n",
    "    # If we reduce the train set, we need to do so before picking the initial train set.\n",
    "    if repetitions < 1:\n",
    "        train_dataset = train_dataset * repetitions\n",
    "\n",
    "    num_classes = train_dataset.get_num_classes()\n",
    "    # Keep the initial training set balanced at least.\n",
    "    initial_samples_per_class = initial_training_set_size // num_classes\n",
    "    weighted_num_classes = num_classes - len(minority_classes) * (1 - minority_class_percentage / 100)\n",
    "\n",
    "    evaluation_set_samples_per_class = int(evaluation_set_size / weighted_num_classes)\n",
    "    evaluation_set_class_counts = [\n",
    "        int(evaluation_set_samples_per_class * minority_class_percentage / 100)\n",
    "        if i in minority_classes\n",
    "        else evaluation_set_samples_per_class\n",
    "        for i in range(num_classes)\n",
    "    ]\n",
    "\n",
    "    print(\"Evaluation Set Class Counts:\", evaluation_set_class_counts)\n",
    "\n",
    "    generator = np.random.default_rng(validation_split_random_state)\n",
    "    class_indices_by_class = get_class_indices_by_class(\n",
    "        train_dataset.get_targets(),\n",
    "        class_counts=[\n",
    "            initial_samples_per_class + evaluation_set_class_count\n",
    "            for evaluation_set_class_count in evaluation_set_class_counts\n",
    "        ],\n",
    "        generator=generator,\n",
    "    )\n",
    "\n",
    "    initial_training_set_indices = [\n",
    "        idx for by_class in class_indices_by_class.values() for idx in by_class[:initial_samples_per_class]\n",
    "    ]\n",
    "    evaluation_set_indices = [\n",
    "        idx for by_class in class_indices_by_class.values() for idx in by_class[initial_samples_per_class:]\n",
    "    ]\n",
    "\n",
    "    # If we over-sample the train set, we do so after picking the initial train set to avoid duplicates.\n",
    "    if repetitions > 1:\n",
    "        train_dataset = train_dataset * repetitions\n",
    "\n",
    "    if add_dataset_noise:\n",
    "        train_dataset = AdditiveGaussianNoise(train_dataset, 0.1)\n",
    "    else:\n",
    "        if repetitions > 1:\n",
    "            raise RuntimeError(\"`add_dataset_noise`==False, even though repeated id!\")\n",
    "\n",
    "    active_learning_data = ActiveLearningData(train_dataset)\n",
    "\n",
    "    active_learning_data.acquire_base_indices(initial_training_set_indices)\n",
    "\n",
    "    evaluation_dataset = AliasDataset(\n",
    "        active_learning_data.extract_dataset_from_base_indices(evaluation_set_indices),\n",
    "        f\"Evaluation Set ({len(evaluation_set_indices)} samples)\",\n",
    "    )\n",
    "\n",
    "    test_dataset = split_dataset.test.imbalance_subsample(\n",
    "        minority_classes=minority_classes,\n",
    "        minority_percentage=minority_class_percentage,\n",
    "        seed=validation_split_random_state,\n",
    "    )\n",
    "    validation_dataset = split_dataset.validation.imbalance_subsample(\n",
    "        minority_classes=minority_classes,\n",
    "        minority_percentage=minority_class_percentage,\n",
    "        seed=validation_split_random_state,\n",
    "    )\n",
    "\n",
    "    return ExperimentData(\n",
    "        active_learning=active_learning_data,\n",
    "        validation_dataset=validation_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        evaluation_dataset=evaluation_dataset,\n",
    "        train_augmentations=split_dataset.train_augmentations,\n",
    "        initial_training_set_indices=initial_training_set_indices,\n",
    "        evaluation_set_indices=evaluation_set_indices,\n",
    "        ood_dataset=None,\n",
    "        ood_exposure=False,\n",
    "        device=split_dataset.device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-airport",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-rhythm",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n",
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Set Class Counts: [147, 29, 29, 147, 147, 29, 147, 147, 29, 147]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExperimentData(active_learning=ActiveLearningData(base_dataset='MNIST (Train, seed=0, 55000 samples)', num_training_samples=20, num_pool_samples=53982), validation_dataset=ImbalancedClassSplitDataset(dataset='MNIST (Validation, seed=0, 5000 samples)', {'minority_classes': {8, 1, 2, 5}, 'minority_percentage': 20, 'seed': 0, 'class_counts': [500, 100, 100, 500, 500, 100, 500, 500, 100, 500]}), evaluation_dataset=Evaluation Set (998 samples), test_dataset=ImbalancedClassSplitDataset(dataset='MNIST (Test)', {'minority_classes': {8, 1, 2, 5}, 'minority_percentage': 20, 'seed': 0, 'class_counts': [1000, 200, 200, 1000, 1000, 200, 1000, 1000, 200, 1000]}), train_augmentations=Sequential(), initial_training_set_indices=[33294, 1023, 978, 2538, 25764, 30627, 9954, 8642, 1608, 23054, 39798, 24785, 29444, 7316, 13075, 30426, 14915, 37374, 42515, 3029], evaluation_set_indices=[26100, 3612, 35806, 25748, 2738, 3717, 5686, 30976, 11659, 49732, 27975, 38073, 6695, 24587, 11606, 4100, 44524, 53294, 50990, 43347, 28303, 49578, 39454, 33051, 4140, 22070, 4727, 24232, 30685, 3718, 29334, 22432, 27792, 14683, 5605, 42968, 39474, 38502, 39659, 21746, 7791, 26121, 36725, 42771, 38097, 53582, 28369, 21385, 10024, 167, 30830, 50416, 54657, 45500, 9094, 53736, 2773, 8612, 13057, 25783, 46787, 11261, 5892, 20441, 50054, 34292, 19676, 3040, 52902, 3312, 54003, 10542, 17710, 27624, 20302, 3821, 43884, 16704, 52862, 10870, 48332, 47205, 42311, 28478, 12834, 21426, 26040, 12716, 8680, 23021, 11387, 21241, 49009, 37854, 26111, 39520, 52744, 46807, 21095, 23115, 40174, 1026, 36010, 21397, 4765, 31946, 54519, 37976, 36347, 7304, 10244, 39038, 9131, 9, 27644, 40937, 19472, 16016, 33440, 21647, 27280, 3931, 14696, 20229, 51675, 47523, 7181, 405, 22834, 49897, 531, 45340, 2572, 54143, 49490, 52939, 14863, 72, 23342, 33794, 44859, 27740, 31683, 13950, 47823, 25352, 33343, 50147, 45111, 36745, 30727, 45689, 11083, 44352, 23197, 47329, 27580, 2976, 32078, 5528, 593, 776, 26885, 21108, 46616, 13946, 50614, 40187, 11994, 37870, 39823, 53273, 52085, 1867, 44408, 44098, 38850, 11683, 52844, 20636, 51134, 41851, 52214, 12020, 20962, 31359, 30340, 54345, 3943, 14629, 12926, 12370, 33235, 39705, 21352, 21059, 51998, 12615, 23240, 26897, 40120, 7121, 43456, 12131, 19554, 14740, 11449, 38001, 6215, 41806, 39866, 29042, 2644, 45709, 15184, 39225, 4686, 495, 41336, 33943, 33535, 45005, 13911, 557, 12201, 35522, 4390, 45876, 46425, 11702, 14062, 36719, 38499, 18095, 23378, 18415, 53060, 54745, 15303, 9935, 17447, 9032, 45010, 695, 8617, 54104, 46820, 43138, 45845, 41466, 45142, 19369, 31217, 26017, 40488, 7167, 20530, 32869, 5461, 40427, 43987, 2393, 8478, 24577, 4305, 8852, 52120, 7723, 24689, 52390, 45213, 8108, 1961, 39378, 19989, 24731, 46253, 46027, 14450, 39789, 45749, 28722, 47466, 26394, 31374, 15275, 17389, 14170, 14019, 7002, 18594, 37244, 25491, 22381, 49, 29065, 48653, 9592, 11512, 2797, 48245, 16370, 19170, 32385, 15773, 19099, 13186, 38235, 20085, 40571, 34084, 9814, 40804, 13747, 3448, 51676, 12273, 46224, 44464, 47900, 6944, 4841, 54005, 30081, 27186, 53569, 6848, 21432, 33258, 1924, 27260, 50746, 24149, 39762, 35530, 1241, 54468, 52455, 41945, 39393, 29810, 50062, 20508, 17241, 26151, 19209, 39710, 51461, 36977, 41815, 27827, 14473, 29138, 19100, 17926, 8000, 24557, 14547, 32410, 48712, 26924, 53905, 28921, 18461, 13027, 8256, 5551, 28468, 13848, 48726, 34859, 4869, 46373, 33504, 7677, 25621, 31809, 5305, 51088, 34215, 18886, 18778, 182, 7426, 13074, 31764, 11585, 26295, 52008, 5156, 29400, 4574, 7971, 11139, 3822, 3953, 7199, 14185, 54551, 42225, 848, 36021, 31031, 45703, 27950, 34181, 28186, 31145, 43500, 5834, 35381, 46335, 15101, 50839, 40810, 22893, 35314, 22164, 27725, 35443, 29409, 42016, 51966, 4767, 48383, 33444, 30292, 20486, 22345, 13536, 37569, 11289, 30681, 20872, 14545, 28898, 23549, 29803, 50569, 5268, 33378, 49413, 47635, 17150, 35695, 39942, 17900, 12565, 1134, 3528, 31112, 352, 17463, 7896, 31745, 23850, 24705, 52320, 25003, 24883, 15174, 40388, 19379, 38877, 19889, 19849, 10507, 5455, 711, 44755, 16889, 18453, 35106, 27211, 31805, 466, 10428, 13212, 51634, 42937, 31436, 19714, 14642, 8141, 9921, 43552, 16698, 54279, 16969, 5462, 22473, 44645, 42486, 28576, 47826, 17118, 35790, 52005, 38176, 26815, 42106, 18363, 47688, 51934, 17878, 52419, 45585, 20853, 50172, 34554, 2561, 4977, 38342, 172, 10637, 14612, 39288, 32256, 37457, 12763, 25023, 45089, 51097, 17082, 1799, 9541, 12917, 42997, 18741, 13648, 43240, 41086, 23314, 19892, 29472, 41679, 40152, 25634, 3816, 26325, 8243, 11092, 20248, 40245, 13473, 19121, 307, 24709, 32237, 1459, 33017, 10681, 47962, 8342, 41483, 27328, 32511, 33204, 30919, 26765, 27808, 28894, 17948, 48596, 27409, 17964, 22130, 9414, 20688, 32252, 51474, 31936, 26853, 31511, 42341, 1707, 4015, 23391, 28089, 29032, 32529, 11371, 44265, 41775, 25903, 50051, 20777, 20955, 48117, 40316, 3995, 20291, 36845, 45481, 43769, 46884, 21179, 36042, 1079, 11618, 16910, 2737, 17814, 218, 40266, 45276, 10688, 43664, 35126, 49806, 28347, 38879, 24958, 15832, 49014, 3175, 13887, 25865, 45844, 42196, 38614, 44438, 5821, 19744, 17615, 45936, 5870, 47151, 9574, 23552, 4421, 11369, 49968, 41937, 27426, 23752, 32924, 45518, 2036, 19197, 9386, 36611, 31522, 30489, 30445, 31295, 50872, 27291, 38928, 9403, 43578, 26522, 14537, 44656, 52412, 28560, 32678, 20668, 34435, 29499, 25014, 51610, 4411, 22037, 54347, 21033, 47996, 25624, 1507, 27083, 45758, 54634, 38637, 26353, 1071, 2896, 7026, 908, 17968, 32291, 54177, 257, 22353, 31742, 28077, 36768, 33841, 38735, 51726, 25928, 53798, 17594, 16248, 15354, 9807, 4300, 14243, 24421, 38969, 3241, 20349, 33937, 2670, 34230, 17470, 54855, 54220, 15845, 1077, 42733, 14276, 7030, 36212, 54930, 32212, 25823, 4030, 6449, 1854, 5033, 46791, 25219, 30586, 17189, 41691, 35864, 31413, 25325, 37459, 46429, 49173, 18975, 46520, 22429, 29523, 20360, 39524, 6505, 49922, 42360, 19352, 35043, 26462, 9781, 2876, 433, 3054, 44027, 40596, 46155, 19164, 34318, 51324, 17477, 50459, 34225, 7159, 41166, 29025, 33651, 38550, 4240, 30997, 15870, 51376, 16605, 6777, 30147, 25323, 26205, 9615, 28673, 8073, 53457, 54042, 53317, 44340, 34274, 38932, 8956, 53280, 3478, 52973, 6284, 12702, 22504, 6315, 51272, 24842, 34529, 49817, 31361, 30116, 35958, 42234, 47752, 25154, 46182, 19428, 7249, 5755, 20294, 3244, 3733, 7269, 45459, 10472, 47802, 15638, 45399, 37553, 5210, 19742, 26330, 18794, 3547, 47397, 13334, 37225, 40519, 39092, 26771, 19698, 34803, 519, 23902, 52582, 41710, 2400, 22403, 52263, 32563, 36484, 3126, 838, 30314, 13843, 51337, 32416, 34736, 1844, 36637, 49588, 3905, 31896, 35061, 18693, 20564, 50302, 22512, 47169, 8126, 26071, 28697, 13609, 5874, 10254, 596, 43165, 28958, 38438, 25816, 19512, 33829, 53026, 48901, 32006, 41252, 18916, 14300, 32153, 14689, 15143, 36712, 5508, 27906, 42110, 26201, 33711, 29775, 43569, 45927, 36437, 18404, 38237, 6011, 34190, 21914, 54527, 5994, 49165, 41626, 39438, 24216, 23058, 28685, 26224, 16744, 33828, 41064, 48169, 25642, 48442, 28812, 33382, 15233, 37917, 48276, 37937, 29476, 10089, 33087, 29191, 46495, 29312, 49180, 48033, 42019, 54642, 34357, 6275, 23967, 6234, 44807, 25241, 46358, 13406, 32922, 26597, 32925, 21904, 33299, 30828, 27267, 50728, 45752, 19145, 949, 10837, 5932, 7807, 21433, 26182, 22591, 45868, 44140, 18858, 6051, 13702, 10417, 30952, 11554, 31523, 30989, 50779, 54582, 28167, 33963, 5226, 19407, 35072, 16719, 15312, 19273, 36841, 40301, 2989, 41130, 42429, 21909, 8366, 6443, 11910, 18681, 15091, 44847, 16716, 38784, 25231, 10710, 46781, 49740, 28451, 25779, 4402, 42942, 37233, 12957, 41848, 34580, 32219, 22363, 1504, 12010, 17936, 853, 7080, 42223], ood_dataset=None, ood_exposure=False, device='cuda')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "load_imbalanced_experiment_data(\n",
    "    dataset_name=\"MNIST\",\n",
    "    repetitions=1.0,\n",
    "    initial_training_set_size=20,\n",
    "    validation_set_size=5000,\n",
    "    validation_split_random_state=0,\n",
    "    evaluation_set_size=1000,\n",
    "    minority_classes={1, 2, 5, 8},\n",
    "    minority_class_percentage=20,\n",
    "    add_dataset_noise=False,\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-singer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n",
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Set Class Counts: [166, 0, 0, 166, 166, 0, 166, 166, 0, 166]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExperimentData(active_learning=ActiveLearningData(base_dataset='MNIST (Train, seed=0, 55000 samples)' + 𝓝(0;σ=0.1), num_training_samples=20, num_pool_samples=53984), validation_dataset=ImbalancedClassSplitDataset(dataset='MNIST (Validation, seed=0, 5000 samples)', {'minority_classes': {8, 1, 2, 5}, 'minority_percentage': 0, 'seed': 0, 'class_counts': [500, 0, 0, 500, 500, 0, 500, 500, 0, 500]}), evaluation_dataset=Evaluation Set (996 samples), test_dataset=ImbalancedClassSplitDataset(dataset='MNIST (Test)', {'minority_classes': {8, 1, 2, 5}, 'minority_percentage': 0, 'seed': 0, 'class_counts': [1000, 0, 0, 1000, 1000, 0, 1000, 1000, 0, 1000]}), train_augmentations=Sequential(), initial_training_set_indices=[33294, 1023, 978, 2538, 25764, 30627, 9954, 8642, 1608, 23054, 39798, 24785, 29444, 7316, 13075, 30426, 14915, 37374, 42515, 3029], evaluation_set_indices=[26100, 3612, 35806, 25748, 2738, 3717, 5686, 30976, 11659, 49732, 27975, 38073, 6695, 24587, 11606, 4100, 44524, 53294, 50990, 43347, 28303, 49578, 39454, 33051, 4140, 22070, 4727, 24232, 30685, 3718, 29334, 22432, 27792, 14683, 5605, 42968, 39474, 38502, 39659, 21746, 7791, 26121, 36725, 42771, 38097, 53582, 28369, 21385, 10024, 167, 30830, 50416, 54657, 45500, 9094, 53736, 2773, 8612, 13057, 25783, 46787, 11261, 5892, 20441, 50054, 34292, 19676, 3040, 52902, 3312, 54003, 10542, 17710, 27624, 20302, 3821, 43884, 16704, 52862, 10870, 48332, 47205, 42311, 28478, 12834, 21426, 26040, 12716, 8680, 23021, 11387, 21241, 49009, 37854, 26111, 39520, 52744, 46807, 21095, 23115, 40174, 1026, 36010, 21397, 4765, 31946, 54519, 37976, 36347, 7304, 10244, 39038, 9131, 9, 27644, 40937, 19472, 16016, 33440, 21647, 27280, 3931, 14696, 20229, 51675, 47523, 7181, 405, 22834, 49897, 531, 45340, 2572, 54143, 49490, 52939, 14863, 72, 23342, 33794, 44859, 27740, 31683, 13950, 47823, 25352, 33343, 12069, 30610, 21219, 24105, 2137, 29248, 52193, 893, 31050, 25664, 39155, 12850, 20108, 30498, 17799, 52867, 46680, 40392, 2180, 14740, 11449, 38001, 6215, 41806, 39866, 29042, 2644, 45709, 15184, 39225, 4686, 495, 41336, 33943, 33535, 45005, 13911, 557, 12201, 35522, 4390, 45876, 46425, 11702, 14062, 36719, 38499, 18095, 23378, 18415, 53060, 54745, 15303, 9935, 17447, 9032, 45010, 695, 8617, 54104, 46820, 43138, 45845, 41466, 45142, 19369, 31217, 26017, 40488, 7167, 20530, 32869, 5461, 40427, 43987, 2393, 8478, 24577, 4305, 8852, 52120, 7723, 24689, 52390, 45213, 8108, 1961, 39378, 19989, 24731, 46253, 46027, 14450, 39789, 45749, 28722, 47466, 26394, 31374, 15275, 17389, 14170, 14019, 7002, 18594, 37244, 25491, 22381, 49, 29065, 48653, 9592, 11512, 2797, 48245, 16370, 19170, 32385, 15773, 19099, 13186, 38235, 20085, 40571, 34084, 9814, 40804, 13747, 3448, 51676, 12273, 46224, 44464, 47900, 6944, 4841, 54005, 30081, 27186, 53569, 6848, 21432, 33258, 1924, 27260, 50746, 24149, 39762, 35530, 1241, 54468, 52455, 41945, 39393, 29810, 50062, 20508, 17241, 26151, 19209, 39710, 51461, 36977, 41815, 27827, 14473, 11564, 12005, 19463, 14758, 21708, 44171, 31481, 9759, 4315, 45479, 8297, 30477, 28392, 4233, 7949, 7225, 503, 44637, 24449, 29138, 19100, 17926, 8000, 24557, 14547, 32410, 48712, 26924, 53905, 28921, 18461, 13027, 8256, 5551, 28468, 13848, 48726, 34859, 4869, 46373, 33504, 7677, 25621, 31809, 5305, 51088, 34215, 18886, 18778, 182, 7426, 13074, 31764, 11585, 26295, 52008, 5156, 29400, 4574, 7971, 11139, 3822, 3953, 7199, 14185, 54551, 42225, 848, 36021, 31031, 45703, 27950, 34181, 28186, 31145, 43500, 5834, 35381, 46335, 15101, 50839, 40810, 22893, 35314, 22164, 27725, 35443, 29409, 42016, 51966, 4767, 48383, 33444, 30292, 20486, 22345, 13536, 37569, 11289, 30681, 20872, 14545, 28898, 23549, 29803, 50569, 5268, 33378, 49413, 47635, 17150, 35695, 39942, 17900, 12565, 1134, 3528, 31112, 352, 17463, 7896, 31745, 23850, 24705, 52320, 25003, 24883, 15174, 40388, 19379, 38877, 19889, 19849, 10507, 5455, 711, 44755, 16889, 18453, 35106, 27211, 31805, 466, 10428, 13212, 51634, 42937, 31436, 19714, 14642, 8141, 9921, 43552, 16698, 54279, 16969, 5462, 22473, 44645, 42486, 28576, 47826, 17118, 35790, 52005, 38176, 40123, 11182, 36732, 12634, 20543, 10078, 51864, 8959, 11812, 27379, 25313, 48734, 30371, 28852, 23883, 39617, 27631, 31556, 48483, 18741, 13648, 43240, 41086, 23314, 19892, 29472, 41679, 40152, 25634, 3816, 26325, 8243, 11092, 20248, 40245, 13473, 19121, 307, 24709, 32237, 1459, 33017, 10681, 47962, 8342, 41483, 27328, 32511, 33204, 30919, 26765, 27808, 28894, 17948, 48596, 27409, 17964, 22130, 9414, 20688, 32252, 51474, 31936, 26853, 31511, 42341, 1707, 4015, 23391, 28089, 29032, 32529, 11371, 44265, 41775, 25903, 50051, 20777, 20955, 48117, 40316, 3995, 20291, 36845, 45481, 43769, 46884, 21179, 36042, 1079, 11618, 16910, 2737, 17814, 218, 40266, 45276, 10688, 43664, 35126, 49806, 28347, 38879, 24958, 15832, 49014, 3175, 13887, 25865, 45844, 42196, 38614, 44438, 5821, 19744, 17615, 45936, 5870, 47151, 9574, 23552, 4421, 11369, 49968, 41937, 27426, 23752, 32924, 45518, 2036, 19197, 9386, 36611, 31522, 30489, 30445, 31295, 50872, 27291, 38928, 9403, 43578, 26522, 14537, 44656, 52412, 28560, 32678, 20668, 34435, 29499, 25014, 51610, 4411, 22037, 54347, 21033, 47996, 25624, 1507, 27083, 45758, 54634, 38637, 26353, 1071, 29728, 27363, 4355, 33439, 31846, 53104, 546, 42650, 10907, 29616, 25589, 11974, 37036, 54427, 38172, 14781, 22702, 29604, 50464, 2896, 7026, 908, 17968, 32291, 54177, 257, 22353, 31742, 28077, 36768, 33841, 38735, 51726, 25928, 53798, 17594, 16248, 15354, 9807, 4300, 14243, 24421, 38969, 3241, 20349, 33937, 2670, 34230, 17470, 54855, 54220, 15845, 1077, 42733, 14276, 7030, 36212, 54930, 32212, 25823, 4030, 6449, 1854, 5033, 46791, 25219, 30586, 17189, 41691, 35864, 31413, 25325, 37459, 46429, 49173, 18975, 46520, 22429, 29523, 20360, 39524, 6505, 49922, 42360, 19352, 35043, 26462, 9781, 2876, 433, 3054, 44027, 40596, 46155, 19164, 34318, 51324, 17477, 50459, 34225, 7159, 41166, 29025, 33651, 38550, 4240, 30997, 15870, 51376, 16605, 6777, 30147, 25323, 26205, 9615, 28673, 8073, 53457, 54042, 53317, 44340, 34274, 38932, 8956, 53280, 3478, 52973, 6284, 12702, 22504, 6315, 51272, 24842, 34529, 49817, 31361, 30116, 35958, 42234, 47752, 25154, 46182, 19428, 7249, 5755, 20294, 3244, 3733, 7269, 45459, 10472, 47802, 15638, 45399, 37553, 5210, 19742, 26330, 18794, 3547, 47397, 13334, 37225, 40519, 39092, 26771, 35330, 54463, 4675, 33639, 36169, 16718, 14146, 20211, 34486, 11675, 30741, 50410, 30243, 6994, 22436, 32684, 1936, 19952, 50187, 8126, 26071, 28697, 13609, 5874, 10254, 596, 43165, 28958, 38438, 25816, 19512, 33829, 53026, 48901, 32006, 41252, 18916, 14300, 32153, 14689, 15143, 36712, 5508, 27906, 42110, 26201, 33711, 29775, 43569, 45927, 36437, 18404, 38237, 6011, 34190, 21914, 54527, 5994, 49165, 41626, 39438, 24216, 23058, 28685, 26224, 16744, 33828, 41064, 48169, 25642, 48442, 28812, 33382, 15233, 37917, 48276, 37937, 29476, 10089, 33087, 29191, 46495, 29312, 49180, 48033, 42019, 54642, 34357, 6275, 23967, 6234, 44807, 25241, 46358, 13406, 32922, 26597, 32925, 21904, 33299, 30828, 27267, 50728, 45752, 19145, 949, 10837, 5932, 7807, 21433, 26182, 22591, 45868, 44140, 18858, 6051, 13702, 10417, 30952, 11554, 31523, 30989, 50779, 54582, 28167, 33963, 5226, 19407, 35072, 16719, 15312, 19273, 36841, 40301, 2989, 41130, 42429, 21909, 8366, 6443, 11910, 18681, 15091, 44847, 16716, 38784, 25231, 10710, 46781, 49740, 28451, 25779, 4402, 42942, 37233, 12957, 41848, 34580, 32219, 22363, 1504, 12010, 17936, 853, 7080, 42223, 54550, 17148, 42738, 49288, 43675, 43103, 9994, 8157, 21548, 39874, 46592, 30773, 16580, 15119, 5439, 41696, 30350, 43437, 50157], ood_dataset=None, ood_exposure=False, device='cuda')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "load_imbalanced_experiment_data(\n",
    "    dataset_name=\"MNIST\",\n",
    "    repetitions=1.0,\n",
    "    initial_training_set_size=20,\n",
    "    validation_set_size=5000,\n",
    "    validation_split_random_state=0,\n",
    "    evaluation_set_size=1000,\n",
    "    minority_classes={1, 2, 5, 8},\n",
    "    minority_class_percentage=0,\n",
    "    add_dataset_noise=True,\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-poison",
   "metadata": {},
   "source": [
    "# `OODClassesDistributionExperimentDataConfig`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class OODClassesDistributionExperimentDataConfig(ExperimentDataConfig):\n",
    "    \"\"\"Make the test set and evaluation set imbalanced\"\"\"\n",
    "\n",
    "    dataset_name: str\n",
    "    repetitions: float\n",
    "\n",
    "    initial_training_set_size: int\n",
    "\n",
    "    validation_set_size: int\n",
    "    validation_split_random_state: int\n",
    "\n",
    "    evaluation_set_size: int\n",
    "\n",
    "    add_dataset_noise: bool\n",
    "\n",
    "    ood_classes: Set[int]\n",
    "    ood_repetitions: float\n",
    "    ood_exposure: bool\n",
    "\n",
    "    def load(self, device) -> ExperimentData:\n",
    "        return load_ood_classes_experiment_data(\n",
    "            dataset_name=self.dataset_name,\n",
    "            repetitions=self.repetitions,\n",
    "            initial_training_set_size=self.initial_training_set_size,\n",
    "            validation_set_size=self.validation_set_size,\n",
    "            validation_split_random_state=self.validation_split_random_state,\n",
    "            evaluation_set_size=self.evaluation_set_size,\n",
    "            add_dataset_noise=self.add_dataset_noise,\n",
    "            ood_classes=self.ood_classes,\n",
    "            ood_exposure=self.ood_exposure,\n",
    "            ood_repetitions=self.ood_repetitions,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "\n",
    "def load_ood_classes_experiment_data(\n",
    "    *,\n",
    "    dataset_name: str,\n",
    "    repetitions: float,\n",
    "    initial_training_set_size: int,\n",
    "    validation_set_size: int,\n",
    "    validation_split_random_state: int,\n",
    "    evaluation_set_size: int,\n",
    "    add_dataset_noise: bool,\n",
    "    ood_classes: Set[int],\n",
    "    ood_exposure: bool,\n",
    "    ood_repetitions: float,\n",
    "    device: str,\n",
    ") -> ExperimentData:\n",
    "    split_dataset = get_dataset(\n",
    "        dataset_name,\n",
    "        root=\"data\",\n",
    "        validation_set_size=validation_set_size,\n",
    "        validation_split_random_state=validation_split_random_state,\n",
    "        normalize_like_cifar10=True,\n",
    "        device_hint=device,\n",
    "    )\n",
    "\n",
    "    # Split off OOD dataset\n",
    "    train_targets = get_targets(split_dataset.train)\n",
    "    id_indices = [index for index, target in enumerate(train_targets) if int(target) not in ood_classes]\n",
    "    ood_indices = [index for index, target in enumerate(train_targets) if int(target) in ood_classes]\n",
    "\n",
    "    original_ood_dataset = NamedDataset(\n",
    "        split_dataset.train.subset(ood_indices), f\"{split_dataset.train}[target in {ood_classes}]\"\n",
    "    )\n",
    "    id_dataset = AliasDataset(\n",
    "        split_dataset.train.subset(id_indices), f\"{split_dataset.train}[target not in {ood_classes}]\"\n",
    "    )\n",
    "\n",
    "    # If we reduce the train set, we need to do so before picking the initial train set.\n",
    "    if repetitions < 1:\n",
    "        id_dataset = id_dataset * repetitions\n",
    "\n",
    "    num_classes = split_dataset.train.get_num_classes()\n",
    "    num_id_classes = num_classes - len(ood_classes)\n",
    "    assert num_id_classes > 0\n",
    "\n",
    "    # Keep the initial training set balanced at least.\n",
    "    initial_samples_per_class = initial_training_set_size // num_id_classes\n",
    "    evaluation_set_samples_per_class = evaluation_set_size // num_id_classes\n",
    "\n",
    "    class_counts = [\n",
    "        0 if i in ood_classes else initial_samples_per_class + evaluation_set_samples_per_class\n",
    "        for i in range(num_classes)\n",
    "    ]\n",
    "\n",
    "    print(\"Initial Samples + Evaluation Set Class Counts:\", class_counts)\n",
    "\n",
    "    generator = np.random.default_rng(validation_split_random_state)\n",
    "    class_indices_by_class = get_class_indices_by_class(get_targets(id_dataset), class_counts=class_counts, generator=generator)\n",
    "\n",
    "    initial_training_set_indices = [\n",
    "        idx for by_class in class_indices_by_class.values() for idx in by_class[:initial_samples_per_class]\n",
    "    ]\n",
    "    evaluation_set_indices = [\n",
    "        idx for by_class in class_indices_by_class.values() for idx in by_class[initial_samples_per_class:]\n",
    "    ]\n",
    "\n",
    "    # If we over-sample the train set, we do so after picking the initial train set to avoid duplicates.\n",
    "    if repetitions > 1:\n",
    "        id_dataset = id_dataset * repetitions\n",
    "\n",
    "    if ood_exposure:\n",
    "        id_dataset = id_dataset.one_hot(device=split_dataset.device)\n",
    "        ood_dataset = original_ood_dataset.uniform_target(device=split_dataset.device, num_classes=num_classes)\n",
    "    else:\n",
    "        ood_dataset = original_ood_dataset.constant_target(\n",
    "            target=torch.tensor(-1, device=split_dataset.device), num_classes=num_classes\n",
    "        )\n",
    "\n",
    "    if ood_repetitions != 1:\n",
    "        ood_dataset = ood_dataset * ood_repetitions\n",
    "\n",
    "    train_dataset = id_dataset + ood_dataset\n",
    "\n",
    "    if add_dataset_noise:\n",
    "        train_dataset = AdditiveGaussianNoise(train_dataset, 0.1)\n",
    "    else:\n",
    "        if repetitions > 1:\n",
    "            raise RuntimeError(\"`add_dataset_noise`==False, even though repeated id!\")\n",
    "\n",
    "    active_learning_data = ActiveLearningData(train_dataset)\n",
    "\n",
    "    active_learning_data.acquire_base_indices(initial_training_set_indices)\n",
    "\n",
    "    evaluation_dataset = AliasDataset(\n",
    "        active_learning_data.extract_dataset_from_base_indices(evaluation_set_indices),\n",
    "        f\"Evaluation Set ({len(evaluation_set_indices)} samples)\",\n",
    "    )\n",
    "\n",
    "    test_dataset = split_dataset.test.imbalance_subsample(\n",
    "        minority_classes=ood_classes, minority_percentage=0, seed=validation_split_random_state\n",
    "    )\n",
    "    validation_dataset = split_dataset.validation.imbalance_subsample(\n",
    "        minority_classes=ood_classes, minority_percentage=0, seed=validation_split_random_state\n",
    "    )\n",
    "\n",
    "    return ExperimentData(\n",
    "        active_learning=active_learning_data,\n",
    "        validation_dataset=validation_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        evaluation_dataset=evaluation_dataset,\n",
    "        train_augmentations=split_dataset.train_augmentations,\n",
    "        initial_training_set_indices=initial_training_set_indices,\n",
    "        evaluation_set_indices=evaluation_set_indices,\n",
    "        ood_dataset=original_ood_dataset,\n",
    "        ood_exposure=ood_exposure,\n",
    "        device=split_dataset.device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-samba",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-winner",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n",
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33025\n",
      "21975\n",
      "Initial Samples + Evaluation Set Class Counts: [169, 0, 0, 169, 169, 0, 169, 169, 0, 169]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExperimentData(active_learning=ActiveLearningData(base_dataset='MNIST (Train, seed=0, 55000 samples)'[target not in {8, 1, 2, 5}] | one_hot_targets{'num_classes': 10} + 'MNIST (Train, seed=0, 55000 samples)'[target in {8, 1, 2, 5}] | uniform_targets{'num_classes': 10} + 𝓝(0;σ=0.1), num_training_samples=18, num_pool_samples=53986), validation_dataset=ImbalancedClassSplitDataset(dataset='MNIST (Validation, seed=0, 5000 samples)', {'minority_classes': {8, 1, 2, 5}, 'minority_percentage': 0, 'seed': 0, 'class_counts': [500, 0, 0, 500, 500, 0, 500, 500, 0, 500]}), evaluation_dataset=Evaluation Set (996 samples), test_dataset=ImbalancedClassSplitDataset(dataset='MNIST (Test)', {'minority_classes': {8, 1, 2, 5}, 'minority_percentage': 0, 'seed': 0, 'class_counts': [1000, 0, 0, 1000, 1000, 0, 1000, 1000, 0, 1000]}), train_augmentations=Sequential(), initial_training_set_indices=[8278, 24082, 9356, 28456, 30930, 26581, 7107, 15612, 20067, 18098, 18619, 26280, 1849, 16652, 162, 19205, 8484, 25004], evaluation_set_indices=[4425, 6309, 10360, 31532, 16242, 9739, 3385, 18300, 31667, 8731, 1066, 15222, 17669, 11140, 12911, 13935, 3578, 17931, 3598, 27838, 28073, 2005, 1154, 15842, 22699, 17223, 1508, 8432, 19798, 28579, 14957, 29300, 6467, 21513, 29405, 16072, 25638, 30782, 31767, 27058, 2483, 27822, 21792, 1749, 13208, 17309, 31299, 4043, 26231, 31659, 949, 22886, 27013, 20644, 27567, 8239, 9791, 20291, 28316, 23855, 10530, 24030, 11034, 18566, 14980, 20612, 30420, 25008, 719, 12132, 22069, 29447, 26006, 8497, 29338, 12532, 16573, 31773, 3711, 8294, 21989, 25563, 9137, 1490, 29901, 4008, 30259, 27235, 12205, 6221, 12692, 28807, 538, 4956, 3086, 18405, 3199, 10983, 25429, 11548, 20986, 18660, 31805, 7250, 31372, 29927, 28180, 25404, 1867, 6761, 21147, 16113, 10326, 4276, 30138, 10646, 10145, 15389, 21811, 11102, 16255, 13867, 24779, 16587, 11293, 28417, 30561, 3802, 2703, 1968, 6978, 15044, 32886, 22534, 15422, 11160, 23010, 32547, 22873, 32772, 3267, 23085, 25723, 15911, 32161, 32705, 15460, 26899, 20983, 16922, 3035, 3891, 20116, 9266, 27486, 1337, 8819, 21496, 12558, 4614, 32470, 11195, 25540, 28022, 12250, 1482, 11588, 16532, 25073, 15780, 30243, 20278, 26454, 30792, 28244, 25758, 593, 32858, 1975, 30032, 1520, 22986, 4863, 10574, 30735, 30348, 23152, 12032, 4324, 16682, 25775, 24736, 11745, 14573, 12876, 1666, 19231, 13444, 14698, 695, 21314, 19619, 5945, 16776, 4573, 8190, 24139, 4778, 24634, 14747, 14160, 14095, 5376, 13462, 23913, 13883, 14032, 31189, 18041, 25233, 26350, 12600, 17301, 9731, 19625, 15202, 1093, 29028, 4495, 29932, 25900, 13489, 20717, 17490, 16845, 8873, 4622, 6386, 19337, 11657, 16721, 4689, 12852, 2412, 17105, 18607, 20183, 18142, 23519, 14080, 29595, 18596, 28924, 19401, 5363, 5932, 20965, 23726, 28110, 14832, 20361, 25046, 27964, 16976, 8989, 13463, 29912, 4261, 31895, 30208, 29545, 29579, 10940, 14237, 16853, 16526, 27503, 9442, 23596, 1963, 5790, 15880, 32345, 3996, 10322, 22111, 17257, 30281, 31549, 2023, 22113, 14844, 24414, 31368, 11502, 10218, 4909, 12636, 31976, 24919, 14492, 5633, 3372, 6285, 1419, 2281, 22481, 20209, 428, 26973, 18901, 13026, 32541, 1188, 30657, 16889, 29386, 18214, 14987, 2479, 24862, 6733, 3116, 4071, 4894, 16308, 31108, 13550, 10528, 8882, 24624, 2294, 12386, 533, 23060, 21058, 25770, 30200, 7985, 28637, 31979, 32754, 32836, 11879, 13336, 13979, 12001, 31404, 17796, 9640, 9060, 6307, 2248, 2207, 31246, 17887, 10766, 5473, 24600, 7361, 21712, 20998, 5512, 6756, 691, 22279, 27912, 17880, 1717, 22160, 22511, 320, 4063, 31396, 19151, 8072, 26821, 17626, 3398, 1053, 19163, 13968, 365, 23651, 3235, 16247, 15957, 16453, 31058, 12920, 9542, 746, 14937, 14164, 3669, 6502, 30130, 5937, 672, 23989, 11263, 14688, 20453, 4317, 26255, 18111, 24373, 978, 18674, 4988, 20284, 10682, 7052, 10277, 15809, 3844, 11294, 16195, 12915, 24157, 21655, 19970, 11189, 26032, 15561, 23974, 22729, 23941, 21946, 26455, 2577, 31678, 1920, 13303, 5719, 12923, 20671, 19372, 17564, 26204, 5073, 21845, 28534, 4929, 31654, 11310, 4336, 2810, 9856, 201, 31861, 6539, 30496, 29766, 18438, 21716, 21827, 2733, 16125, 1192, 13309, 29730, 16119, 15402, 20241, 15635, 23154, 17103, 1385, 14661, 24805, 14294, 30000, 3724, 3349, 27325, 31098, 31870, 21462, 8918, 29115, 5087, 13693, 26655, 31248, 21717, 20189, 2241, 29973, 5618, 4733, 2094, 16454, 32335, 23656, 7505, 10586, 18422, 26303, 31483, 13631, 23157, 25960, 10848, 5401, 15399, 19554, 31025, 984, 1483, 10960, 923, 2437, 4015, 11159, 28559, 12898, 18934, 32511, 27259, 28726, 22103, 27506, 13582, 25331, 12328, 14364, 23128, 21940, 17414, 32269, 7769, 32635, 25278, 20461, 5943, 11075, 7230, 3982, 28061, 8969, 31385, 6210, 15008, 2430, 14189, 15147, 21551, 13885, 29728, 26756, 21698, 14882, 11237, 25643, 11162, 31568, 5147, 13953, 23907, 650, 29383, 23924, 14755, 23302, 7188, 3316, 17295, 9973, 10393, 32204, 17148, 10909, 16459, 16174, 3776, 848, 26699, 23729, 24204, 30170, 23042, 7828, 3634, 7780, 30236, 18097, 9677, 29450, 4683, 26886, 31561, 5683, 32548, 12660, 8503, 22471, 7742, 2464, 9406, 725, 13490, 16183, 2833, 7501, 26884, 13460, 7946, 12751, 6968, 17623, 22061, 26270, 3253, 404, 12708, 19265, 8075, 22520, 5084, 3606, 23717, 25969, 14439, 6545, 19815, 13729, 24184, 26919, 18353, 4491, 18958, 12831, 27382, 18287, 19958, 5574, 14093, 12913, 5665, 30245, 800, 28535, 27570, 11280, 10592, 4695, 29568, 2013, 18432, 10036, 19123, 19628, 13875, 7629, 19839, 24465, 24032, 24109, 524, 360, 21336, 27289, 6957, 13874, 7464, 3845, 1997, 468, 3682, 2931, 14144, 18496, 26367, 21198, 4133, 13769, 5812, 25470, 15560, 14797, 2491, 30945, 9048, 31567, 17690, 12570, 14727, 18016, 30422, 26967, 20188, 30725, 2086, 12068, 2185, 12079, 15917, 8963, 2845, 15758, 5188, 28569, 9311, 15113, 32903, 12647, 29888, 28964, 32284, 23439, 27764, 11674, 1344, 16978, 12860, 21701, 2782, 21958, 28332, 4792, 2, 29428, 9350, 32909, 10390, 30285, 32152, 20966, 3853, 30344, 3196, 20662, 12849, 20967, 8317, 29312, 21486, 11565, 24525, 21204, 5158, 31765, 4883, 32677, 14881, 20766, 18754, 939, 25778, 2448, 4480, 25205, 5246, 31087, 30353, 12544, 23973, 22448, 7262, 11306, 28704, 3705, 22796, 18752, 30869, 10844, 4313, 29103, 7003, 20038, 20481, 28755, 4427, 19895, 3127, 28949, 23167, 6064, 28460, 28296, 9740, 5786, 24950, 23477, 28840, 10466, 12525, 3081, 20606, 21686, 13178, 30424, 23873, 17455, 32000, 11830, 25109, 17729, 10488, 28597, 30896, 4337, 29290, 31430, 18064, 20846, 8691, 26932, 21312, 6274, 32159, 21051, 296, 30655, 11603, 8367, 6900, 3471, 4159, 12361, 2374, 20177, 21238, 24542, 25194, 8193, 27578, 23877, 26794, 1196, 11964, 31083, 13651, 29536, 26453, 883, 6216, 18296, 26427, 29838, 269, 19787, 23909, 15382, 22935, 25869, 3238, 4447, 29509, 11771, 26411, 30948, 94, 2976, 4005, 25535, 14617, 31156, 6984, 742, 31684, 8893, 26547, 4952, 4770, 27183, 27610, 26936, 15373, 23231, 12335, 12940, 3073, 23209, 2283, 5866, 14547, 12357, 4080, 29741, 26267, 5417, 28415, 26321, 11997, 8065, 2818, 20099, 20049, 26593, 7167, 7779, 28058, 26991, 12476, 9818, 18222, 4913, 23949, 11878, 21477, 20863, 4072, 21327, 32802, 30126, 29180, 30759, 6448, 18826, 22626, 18397, 11515, 25609, 24304, 24371, 2709, 10854, 6728, 26361, 7182, 10431, 30517, 24929, 15451, 1417, 7683, 181, 21719, 3236, 31500, 27236, 22585, 7991, 31791, 24352, 25522, 3458, 4029, 19483, 24413, 10877, 24545, 22575, 30834, 29648, 2036, 4592, 7974, 4554, 14740, 32216, 14270, 4582, 14038, 3528, 11320, 16311, 20757, 25611, 18399, 29080, 20338, 20442, 7956, 28943, 20139, 7914, 3756, 11193, 11181, 20897, 3938, 29717, 31095, 24943, 17750, 16552, 6362, 7668, 21276, 1710, 1131, 16398, 20292, 16718, 12089, 25453, 21481, 2949, 27927, 23273, 10379, 31199, 4464], ood_dataset='MNIST (Train, seed=0, 55000 samples)'[target in {8, 1, 2, 5}], ood_exposure=True, device='cuda')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "load_ood_classes_experiment_data(\n",
    "    dataset_name=\"MNIST\",\n",
    "    repetitions=1.0,\n",
    "    initial_training_set_size=20,\n",
    "    validation_set_size=5000,\n",
    "    validation_split_random_state=0,\n",
    "    evaluation_set_size=1000,\n",
    "    ood_classes={1, 2, 5, 8},\n",
    "    ood_exposure=True,\n",
    "    ood_repetitions=1.0,\n",
    "    add_dataset_noise=True,\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-thanks",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n",
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33025\n",
      "21975\n",
      "Initial Samples + Evaluation Set Class Counts: [169, 0, 0, 169, 169, 0, 169, 169, 0, 169]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExperimentData(active_learning=ActiveLearningData(base_dataset='MNIST (Train, seed=0, 55000 samples)'[target not in {8, 1, 2, 5}] + 'MNIST (Train, seed=0, 55000 samples)'[target in {8, 1, 2, 5}] | constant_target{'target': tensor(-1, device='cuda:0'), 'num_classes': 10} + 𝓝(0;σ=0.1), num_training_samples=18, num_pool_samples=53986), validation_dataset=ImbalancedClassSplitDataset(dataset='MNIST (Validation, seed=0, 5000 samples)', {'minority_classes': {8, 1, 2, 5}, 'minority_percentage': 0, 'seed': 0, 'class_counts': [500, 0, 0, 500, 500, 0, 500, 500, 0, 500]}), evaluation_dataset=Evaluation Set (996 samples), test_dataset=ImbalancedClassSplitDataset(dataset='MNIST (Test)', {'minority_classes': {8, 1, 2, 5}, 'minority_percentage': 0, 'seed': 0, 'class_counts': [1000, 0, 0, 1000, 1000, 0, 1000, 1000, 0, 1000]}), train_augmentations=Sequential(), initial_training_set_indices=[8278, 24082, 9356, 28456, 30930, 26581, 7107, 15612, 20067, 18098, 18619, 26280, 1849, 16652, 162, 19205, 8484, 25004], evaluation_set_indices=[4425, 6309, 10360, 31532, 16242, 9739, 3385, 18300, 31667, 8731, 1066, 15222, 17669, 11140, 12911, 13935, 3578, 17931, 3598, 27838, 28073, 2005, 1154, 15842, 22699, 17223, 1508, 8432, 19798, 28579, 14957, 29300, 6467, 21513, 29405, 16072, 25638, 30782, 31767, 27058, 2483, 27822, 21792, 1749, 13208, 17309, 31299, 4043, 26231, 31659, 949, 22886, 27013, 20644, 27567, 8239, 9791, 20291, 28316, 23855, 10530, 24030, 11034, 18566, 14980, 20612, 30420, 25008, 719, 12132, 22069, 29447, 26006, 8497, 29338, 12532, 16573, 31773, 3711, 8294, 21989, 25563, 9137, 1490, 29901, 4008, 30259, 27235, 12205, 6221, 12692, 28807, 538, 4956, 3086, 18405, 3199, 10983, 25429, 11548, 20986, 18660, 31805, 7250, 31372, 29927, 28180, 25404, 1867, 6761, 21147, 16113, 10326, 4276, 30138, 10646, 10145, 15389, 21811, 11102, 16255, 13867, 24779, 16587, 11293, 28417, 30561, 3802, 2703, 1968, 6978, 15044, 32886, 22534, 15422, 11160, 23010, 32547, 22873, 32772, 3267, 23085, 25723, 15911, 32161, 32705, 15460, 26899, 20983, 16922, 3035, 3891, 20116, 9266, 27486, 1337, 8819, 21496, 12558, 4614, 32470, 11195, 25540, 28022, 12250, 1482, 11588, 16532, 25073, 15780, 30243, 20278, 26454, 30792, 28244, 25758, 593, 32858, 1975, 30032, 1520, 22986, 4863, 10574, 30735, 30348, 23152, 12032, 4324, 16682, 25775, 24736, 11745, 14573, 12876, 1666, 19231, 13444, 14698, 695, 21314, 19619, 5945, 16776, 4573, 8190, 24139, 4778, 24634, 14747, 14160, 14095, 5376, 13462, 23913, 13883, 14032, 31189, 18041, 25233, 26350, 12600, 17301, 9731, 19625, 15202, 1093, 29028, 4495, 29932, 25900, 13489, 20717, 17490, 16845, 8873, 4622, 6386, 19337, 11657, 16721, 4689, 12852, 2412, 17105, 18607, 20183, 18142, 23519, 14080, 29595, 18596, 28924, 19401, 5363, 5932, 20965, 23726, 28110, 14832, 20361, 25046, 27964, 16976, 8989, 13463, 29912, 4261, 31895, 30208, 29545, 29579, 10940, 14237, 16853, 16526, 27503, 9442, 23596, 1963, 5790, 15880, 32345, 3996, 10322, 22111, 17257, 30281, 31549, 2023, 22113, 14844, 24414, 31368, 11502, 10218, 4909, 12636, 31976, 24919, 14492, 5633, 3372, 6285, 1419, 2281, 22481, 20209, 428, 26973, 18901, 13026, 32541, 1188, 30657, 16889, 29386, 18214, 14987, 2479, 24862, 6733, 3116, 4071, 4894, 16308, 31108, 13550, 10528, 8882, 24624, 2294, 12386, 533, 23060, 21058, 25770, 30200, 7985, 28637, 31979, 32754, 32836, 11879, 13336, 13979, 12001, 31404, 17796, 9640, 9060, 6307, 2248, 2207, 31246, 17887, 10766, 5473, 24600, 7361, 21712, 20998, 5512, 6756, 691, 22279, 27912, 17880, 1717, 22160, 22511, 320, 4063, 31396, 19151, 8072, 26821, 17626, 3398, 1053, 19163, 13968, 365, 23651, 3235, 16247, 15957, 16453, 31058, 12920, 9542, 746, 14937, 14164, 3669, 6502, 30130, 5937, 672, 23989, 11263, 14688, 20453, 4317, 26255, 18111, 24373, 978, 18674, 4988, 20284, 10682, 7052, 10277, 15809, 3844, 11294, 16195, 12915, 24157, 21655, 19970, 11189, 26032, 15561, 23974, 22729, 23941, 21946, 26455, 2577, 31678, 1920, 13303, 5719, 12923, 20671, 19372, 17564, 26204, 5073, 21845, 28534, 4929, 31654, 11310, 4336, 2810, 9856, 201, 31861, 6539, 30496, 29766, 18438, 21716, 21827, 2733, 16125, 1192, 13309, 29730, 16119, 15402, 20241, 15635, 23154, 17103, 1385, 14661, 24805, 14294, 30000, 3724, 3349, 27325, 31098, 31870, 21462, 8918, 29115, 5087, 13693, 26655, 31248, 21717, 20189, 2241, 29973, 5618, 4733, 2094, 16454, 32335, 23656, 7505, 10586, 18422, 26303, 31483, 13631, 23157, 25960, 10848, 5401, 15399, 19554, 31025, 984, 1483, 10960, 923, 2437, 4015, 11159, 28559, 12898, 18934, 32511, 27259, 28726, 22103, 27506, 13582, 25331, 12328, 14364, 23128, 21940, 17414, 32269, 7769, 32635, 25278, 20461, 5943, 11075, 7230, 3982, 28061, 8969, 31385, 6210, 15008, 2430, 14189, 15147, 21551, 13885, 29728, 26756, 21698, 14882, 11237, 25643, 11162, 31568, 5147, 13953, 23907, 650, 29383, 23924, 14755, 23302, 7188, 3316, 17295, 9973, 10393, 32204, 17148, 10909, 16459, 16174, 3776, 848, 26699, 23729, 24204, 30170, 23042, 7828, 3634, 7780, 30236, 18097, 9677, 29450, 4683, 26886, 31561, 5683, 32548, 12660, 8503, 22471, 7742, 2464, 9406, 725, 13490, 16183, 2833, 7501, 26884, 13460, 7946, 12751, 6968, 17623, 22061, 26270, 3253, 404, 12708, 19265, 8075, 22520, 5084, 3606, 23717, 25969, 14439, 6545, 19815, 13729, 24184, 26919, 18353, 4491, 18958, 12831, 27382, 18287, 19958, 5574, 14093, 12913, 5665, 30245, 800, 28535, 27570, 11280, 10592, 4695, 29568, 2013, 18432, 10036, 19123, 19628, 13875, 7629, 19839, 24465, 24032, 24109, 524, 360, 21336, 27289, 6957, 13874, 7464, 3845, 1997, 468, 3682, 2931, 14144, 18496, 26367, 21198, 4133, 13769, 5812, 25470, 15560, 14797, 2491, 30945, 9048, 31567, 17690, 12570, 14727, 18016, 30422, 26967, 20188, 30725, 2086, 12068, 2185, 12079, 15917, 8963, 2845, 15758, 5188, 28569, 9311, 15113, 32903, 12647, 29888, 28964, 32284, 23439, 27764, 11674, 1344, 16978, 12860, 21701, 2782, 21958, 28332, 4792, 2, 29428, 9350, 32909, 10390, 30285, 32152, 20966, 3853, 30344, 3196, 20662, 12849, 20967, 8317, 29312, 21486, 11565, 24525, 21204, 5158, 31765, 4883, 32677, 14881, 20766, 18754, 939, 25778, 2448, 4480, 25205, 5246, 31087, 30353, 12544, 23973, 22448, 7262, 11306, 28704, 3705, 22796, 18752, 30869, 10844, 4313, 29103, 7003, 20038, 20481, 28755, 4427, 19895, 3127, 28949, 23167, 6064, 28460, 28296, 9740, 5786, 24950, 23477, 28840, 10466, 12525, 3081, 20606, 21686, 13178, 30424, 23873, 17455, 32000, 11830, 25109, 17729, 10488, 28597, 30896, 4337, 29290, 31430, 18064, 20846, 8691, 26932, 21312, 6274, 32159, 21051, 296, 30655, 11603, 8367, 6900, 3471, 4159, 12361, 2374, 20177, 21238, 24542, 25194, 8193, 27578, 23877, 26794, 1196, 11964, 31083, 13651, 29536, 26453, 883, 6216, 18296, 26427, 29838, 269, 19787, 23909, 15382, 22935, 25869, 3238, 4447, 29509, 11771, 26411, 30948, 94, 2976, 4005, 25535, 14617, 31156, 6984, 742, 31684, 8893, 26547, 4952, 4770, 27183, 27610, 26936, 15373, 23231, 12335, 12940, 3073, 23209, 2283, 5866, 14547, 12357, 4080, 29741, 26267, 5417, 28415, 26321, 11997, 8065, 2818, 20099, 20049, 26593, 7167, 7779, 28058, 26991, 12476, 9818, 18222, 4913, 23949, 11878, 21477, 20863, 4072, 21327, 32802, 30126, 29180, 30759, 6448, 18826, 22626, 18397, 11515, 25609, 24304, 24371, 2709, 10854, 6728, 26361, 7182, 10431, 30517, 24929, 15451, 1417, 7683, 181, 21719, 3236, 31500, 27236, 22585, 7991, 31791, 24352, 25522, 3458, 4029, 19483, 24413, 10877, 24545, 22575, 30834, 29648, 2036, 4592, 7974, 4554, 14740, 32216, 14270, 4582, 14038, 3528, 11320, 16311, 20757, 25611, 18399, 29080, 20338, 20442, 7956, 28943, 20139, 7914, 3756, 11193, 11181, 20897, 3938, 29717, 31095, 24943, 17750, 16552, 6362, 7668, 21276, 1710, 1131, 16398, 20292, 16718, 12089, 25453, 21481, 2949, 27927, 23273, 10379, 31199, 4464], ood_dataset='MNIST (Train, seed=0, 55000 samples)'[target in {8, 1, 2, 5}], ood_exposure=False, device='cuda')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "load_ood_classes_experiment_data(\n",
    "    dataset_name=\"MNIST\",\n",
    "    repetitions=1.0,\n",
    "    initial_training_set_size=20,\n",
    "    validation_set_size=5000,\n",
    "    validation_split_random_state=0,\n",
    "    evaluation_set_size=1000,\n",
    "    ood_classes={1, 2, 5, 8},\n",
    "    ood_exposure=False,\n",
    "    ood_repetitions=1.0,\n",
    "    add_dataset_noise=True,\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-mumbai",
   "metadata": {},
   "source": [
    "# `CinicCifarShiftExperimentDataConfig`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CinicCifarShiftExperimentDataConfig(ExperimentDataConfig):\n",
    "    \"\"\"CINIC-10 as train set, CIFAR-10 as test/eval set.\"\"\"\n",
    "\n",
    "    train_imagenet_only: bool\n",
    "\n",
    "    initial_training_set_size: int\n",
    "\n",
    "    validation_set_size: int\n",
    "    validation_split_random_state: int\n",
    "\n",
    "    evaluation_set_size: int\n",
    "\n",
    "    def load(self, device) -> ExperimentData:\n",
    "        return load_cinic_cifar_shift_experiment_data(\n",
    "            train_imagenet_only=self.train_imagenet_only,\n",
    "            initial_training_set_size=self.initial_training_set_size,\n",
    "            validation_set_size=self.validation_set_size,\n",
    "            validation_split_random_state=self.validation_split_random_state,\n",
    "            evaluation_set_size=self.evaluation_set_size,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "\n",
    "def load_cinic_cifar_shift_experiment_data(\n",
    "    *,\n",
    "    train_imagenet_only: bool,\n",
    "    initial_training_set_size: int,\n",
    "    validation_set_size: int,\n",
    "    validation_split_random_state: int,\n",
    "    evaluation_set_size: int,\n",
    "    device: str,\n",
    ") -> ExperimentData:\n",
    "    split_imagenet_cinic10_dataset = get_dataset(\n",
    "        name=\"IMAGENET-CINIC-10\",\n",
    "        root=\"data\",\n",
    "        validation_set_size=0,\n",
    "        validation_split_random_state=validation_split_random_state,\n",
    "        normalize_like_cifar10=True,\n",
    "        device_hint=device,\n",
    "    )\n",
    "\n",
    "    split_cifar10_dataset = get_dataset(\n",
    "        name=\"CIFAR-10\",\n",
    "        root=\"data\",\n",
    "        validation_set_size=validation_set_size,\n",
    "        validation_split_random_state=validation_split_random_state,\n",
    "        normalize_like_cifar10=True,\n",
    "        device_hint=device,\n",
    "    )\n",
    "\n",
    "    assert split_imagenet_cinic10_dataset.device == split_cifar10_dataset.device\n",
    "\n",
    "    train_dataset = split_imagenet_cinic10_dataset.train\n",
    "    validation_dataset = split_cifar10_dataset.validation\n",
    "    test_dataset = split_cifar10_dataset.test\n",
    "\n",
    "    num_classes = split_cifar10_dataset.train.get_num_classes()\n",
    "    evaluation_set_samples_per_class = evaluation_set_size // num_classes\n",
    "    balanced_evaluation_indices = get_balanced_sample_indices(\n",
    "        targets=split_cifar10_dataset.train.get_targets(),\n",
    "        num_classes=num_classes,\n",
    "        samples_per_class=evaluation_set_samples_per_class,\n",
    "        seed=validation_split_random_state,\n",
    "    )\n",
    "\n",
    "    evaluation_dataset, cifar10_train_dataset = split_cifar10_dataset.train.split(balanced_evaluation_indices)\n",
    "\n",
    "    # If we add CIFAR-10 back, exclude the evaluation samples.\n",
    "    if not train_imagenet_only:\n",
    "        train_dataset += cifar10_train_dataset\n",
    "\n",
    "    initial_samples_per_class = initial_training_set_size // num_classes\n",
    "    balanced_initial_indices = get_balanced_sample_indices(\n",
    "        targets=train_dataset.get_targets(),\n",
    "        num_classes=num_classes,\n",
    "        samples_per_class=initial_samples_per_class,\n",
    "        seed=validation_split_random_state,\n",
    "    )\n",
    "\n",
    "    active_learning_data = ActiveLearningData(train_dataset)\n",
    "    active_learning_data.acquire_base_indices(balanced_initial_indices)\n",
    "\n",
    "    return ExperimentData(\n",
    "        active_learning=active_learning_data,\n",
    "        validation_dataset=validation_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        evaluation_dataset=evaluation_dataset,\n",
    "        train_augmentations=split_imagenet_cinic10_dataset.train_augmentations,\n",
    "        initial_training_set_indices=balanced_initial_indices,\n",
    "        evaluation_set_indices=balanced_evaluation_indices,\n",
    "        ood_dataset=None,\n",
    "        ood_exposure=False,\n",
    "        device=split_imagenet_cinic10_dataset.device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-triple",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-arbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n",
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExperimentData(active_learning=ActiveLearningData(base_dataset=('CINIC-10 (Train, imagenet_only=True, seed=0, 140000 samples)') + 'CIFAR-10 (Train, seed=0, 45000 samples)'[~[28964, 11411, 14886, 9609, 39292, 398, 3431, 21404, 44846, 11777, 6361, 36817, 5044, 37231, 14346, 24286, 4294, 28590, 16297, 12733, 19940, 27283, 27046, 17495, 4417, 40795, 10717, 3957, 14535, 20341, 27604, 43757, 26320, 40449, 10574, 12396, 14656, 21304, 44149, 12180, 27762, 22949, 32997, 11309, 29865, 36001, 20338, 24032, 34368, 9137, 23376, 13769, 44858, 15640, 40594, 407, 40764, 7166, 17277, 15347, 7175, 10233, 14617, 35065, 39662, 32385, 28273, 15891, 26145, 27266, 38700, 14319, 31039, 4596, 21831, 6428, 27461, 6582, 518, 20455, 6795, 21079, 30299, 33470, 38939, 27229, 22701, 33968, 19425, 6796, 5874, 32641, 32181, 5994, 43189, 38244, 32894, 18469, 34402, 20303, 20577, 32160, 36055, 40702, 27739, 32548, 34043, 37950, 485, 6804, 21241, 28762, 5895, 23667, 24825, 6571, 35106, 32930, 30491, 2144, 44711, 31990, 15621, 32067, 10979, 916, 12500, 37223, 2137, 5283, 19115, 5821, 42995, 29630, 3453, 13920, 43781, 28462, 6978, 5403, 95, 41092, 37595, 5074, 17779, 9361, 42814, 5915, 19029, 38211, 36126, 3585, 39096, 38059, 29091, 9536, 10188, 17837, 44226, 26950, 34699, 22029, 5367, 31753, 21825, 9641, 14769, 40708, 24651, 21536, 3733, 2481, 6508, 18527, 37142, 33274, 11940, 38604, 23653, 727, 16303, 1494, 32012, 29854, 2117, 7636, 21532, 3035, 5884, 17045, 20356, 42661, 8141, 13077, 16269, 41826, 3650, 43444, 8142, 27344, 9311, 4314, 25107, 12417, 21348, 15195, 39748, 7770, 34079, 4078, 16889, 20428, 8612, 32225, 44742, 32366, 27471, 11588, 19717, 39109, 17573, 21932, 38856, 801, 213, 34638, 7316, 34142, 26652, 39486, 10185, 42552, 2670, 23751, 39981, 18697, 35767, 16929, 17490, 12239, 31040, 22160, 1837, 6459, 35597, 43275, 29300, 2171, 10242, 27590, 22621, 27715, 9916, 32269, 24171, 13386, 12706, 4373, 10668, 22772, 5000, 25984, 41721, 14835, 6262, 17527, 35059, 32566, 19074, 44523, 40307, 27415, 7162, 21325, 12013, 40118, 4846, 42102, 15213, 21465, 6588, 23697, 29977, 33843, 25295, 2026, 21345, 1100, 36644, 1884, 41879, 27225, 35830, 44925, 22757, 41397, 24656, 1472, 32545, 37757, 40285, 32276, 30733, 988, 12852, 3505, 32891, 11600, 44626, 9843, 15515, 13337, 7960, 8046, 42623, 38999, 24009, 34433, 17084, 25919, 36629, 37633, 22600, 30073, 20413, 35155, 38410, 44425, 15256, 41146, 13424, 13718, 2817, 11598, 22503, 43762, 31732, 32658, 37670, 26847, 41491, 1479, 23316, 201, 3100, 13678, 20294, 9927, 22064, 18607, 43962, 11942, 15658, 12519, 20407, 42332, 44377, 29132, 37189, 23989, 14641, 5279, 31407, 5352, 20081, 3548, 20984, 39176, 2321, 16074, 14572, 24303, 29067, 23725, 8177, 13597, 7768, 30278, 8114, 7765, 37138, 4300, 39932, 1618, 44719, 31839, 6369, 40427, 25321, 34473, 3097, 26174, 10787, 732, 25515, 9692, 37052, 32424, 26665, 23586, 16388, 22261, 31560, 42122, 13009, 3235, 8474, 23342, 27799, 29893, 32971, 38859, 18158, 30888, 9577, 1381, 11211, 25664, 30941, 22158, 153, 43065, 17279, 15138, 22640, 14330, 15176, 28488, 32744, 584, 15979, 24675, 32727, 22866, 44208, 9524, 4592, 13552, 13066, 3923, 21004, 21927, 1154, 3238, 9042, 14957, 21447, 3705, 21137, 36092, 23287, 6137, 29521, 26586, 6727, 38502, 32351, 10066, 23924, 3659, 24368, 10366, 15911, 30362, 40511, 11129, 4184, 38350, 31236, 1335, 13243, 5435, 28268, 40129, 37215, 13567, 41038, 17810, 38917, 40675, 8958, 42828, 30412, 31290, 7088, 32431, 14387, 44763, 14190, 18948, 24095, 28166, 25264, 26124, 26423, 23505, 12478, 42132, 16726, 38121, 16729, 3698, 20135, 2336, 41063, 9654, 22801, 4309, 28254, 29597, 12976, 5550, 3862, 37154, 31682, 20402, 22405, 8504, 9162, 30830, 20764, 6527, 37213, 24370, 992, 28090, 43101, 218, 10649, 13083, 4863, 13327, 32680, 44814, 44245, 4301, 8476, 25872, 35244, 2477, 8680, 16264, 42387, 23597, 14317, 35655, 17387, 15117, 5148, 29156, 41053, 32010, 3503, 21250, 23217, 42545, 37777, 42666, 17460, 41140, 25246, 12398, 43515, 27391, 42871, 13129, 5207, 1247, 27147, 28228, 42921, 7878, 36265, 4164, 10893, 20972, 21647, 41997, 5987, 20481, 37490, 13713, 27204, 33194, 12011, 21290, 11364, 22897, 40482, 42483, 24166, 17506, 36789, 16855, 23677, 1774, 42766, 14852, 29652, 15915, 23801, 3041, 14062, 25917, 2043, 44544, 42324, 23258, 157, 28542, 5655, 9170, 43593, 10469, 10546, 35097, 17033, 1598, 4052, 3860, 21941, 4797, 31101, 6184, 8724, 30207, 28173, 15316, 8625, 11471, 13362, 33740, 41226, 24324, 34960, 19654, 19178, 12979, 18289, 5091, 11773, 23569, 5192, 43513, 12900, 39985, 38206, 8617, 35486, 41714, 12878, 34305, 7767, 24609, 21134, 44261, 43714, 17240, 6083, 7348, 43026, 17123, 42076, 8682, 36146, 7585, 16774, 26689, 22835, 3121, 30173, 40491, 19600, 4589, 19494, 29211, 1710, 31704, 37560, 27413, 540, 14995, 25903, 33909, 5049, 35918, 3598, 16107, 42062, 37042, 2094, 39908, 22034, 30984, 17570, 33960, 37341, 20506, 36815, 26914, 7221, 27659, 25907, 18857, 33559, 29324, 27672, 25662, 10984, 39381, 37686, 44753, 3228, 41455, 42736, 29332, 31118, 27935, 18589, 15821, 3632, 43395, 27118, 3684, 1966, 25960, 10644, 39693, 41748, 10956, 1310, 22035, 6234, 41104, 24694, 8134, 11280, 20642, 38018, 35066, 18558, 18539, 38768, 17020, 12821, 8670, 17923, 8826, 35734, 18664, 2616, 1631, 9217, 11416, 7618, 29473, 1795, 13396, 30549, 27911, 24497, 12999, 18207, 35271, 18661, 26235, 33494, 42442, 29945, 33727, 19449, 29736, 24339, 42220, 14902, 31467, 10538, 8077, 21147, 42868, 22593, 18622, 36960, 25618, 36578, 35287, 31519, 37342, 35122, 23161, 31510, 15619, 41907, 6487, 12263, 44329, 19506, 3036, 27398, 14204, 26438, 31244, 40065, 40655, 2290, 3982, 9730, 40707, 34364, 24598, 39406, 34259, 5961, 6273, 18394, 29056, 19701, 11087, 18076, 8672, 24114, 44166, 7298, 28377, 13613, 19801, 27616, 31239, 18871, 9877, 32877, 38328, 28183, 26428, 25528, 35474, 29740, 18497, 9547, 36157, 35819, 44982, 18616, 16325, 11498, 3127, 42690, 14727, 12440, 13323, 23243, 37799, 20483, 17550, 38937, 40276, 17722, 10951, 25611, 4765, 4254, 17162, 15015, 34196, 3200, 39627, 39251, 22777, 31859, 11765, 30827, 34338, 7888, 30731, 3606, 32904, 17022, 12669, 25850, 10990, 23077, 44758, 19830, 38591, 36695, 8196, 38355, 8212, 43196, 34054, 16601, 7005, 27602, 29876, 22624, 30975, 37150, 11969, 2404, 35054, 9333, 24295, 33810, 33313, 30979, 25424, 3613, 16721, 8494, 35574, 41555, 44983, 33792, 38745, 4922, 14208, 38450, 35366, 39253, 36068, 7407, 20326, 6368, 17578, 10254, 3134, 34972, 16470, 32416, 21482, 10628, 32407, 11433, 34728, 4335, 6607, 19795, 1301, 24969, 1852, 37725, 3919, 40177, 39338, 25337, 10159, 12027, 32030, 11943, 43447, 13702, 20807, 26331, 35602, 21385, 527, 5115, 39223, 13173, 32032, 26087, 1488, 23676, 44148, 6687, 42375, 33286, 7930, 30033, 40333, 4402, 9570, 31200, 41729, 18863, 15593, 12782, 24577, 38270, 26108, 26430, 26166, 32295, 20337, 3407, 43989, 41776, 29384, 18881, 43652, 4053, 13468, 1225, 4212, 29206, 37646, 13648, 16986, 35294, 10838]], num_training_samples=20, num_pool_samples=183980), validation_dataset='CIFAR-10 (Validation, seed=0, 5000 samples)', evaluation_dataset='CIFAR-10 (Train, seed=0, 45000 samples)'[[28964, 11411, 14886, 9609, 39292, 398, 3431, 21404, 44846, 11777, 6361, 36817, 5044, 37231, 14346, 24286, 4294, 28590, 16297, 12733, 19940, 27283, 27046, 17495, 4417, 40795, 10717, 3957, 14535, 20341, 27604, 43757, 26320, 40449, 10574, 12396, 14656, 21304, 44149, 12180, 27762, 22949, 32997, 11309, 29865, 36001, 20338, 24032, 34368, 9137, 23376, 13769, 44858, 15640, 40594, 407, 40764, 7166, 17277, 15347, 7175, 10233, 14617, 35065, 39662, 32385, 28273, 15891, 26145, 27266, 38700, 14319, 31039, 4596, 21831, 6428, 27461, 6582, 518, 20455, 6795, 21079, 30299, 33470, 38939, 27229, 22701, 33968, 19425, 6796, 5874, 32641, 32181, 5994, 43189, 38244, 32894, 18469, 34402, 20303, 20577, 32160, 36055, 40702, 27739, 32548, 34043, 37950, 485, 6804, 21241, 28762, 5895, 23667, 24825, 6571, 35106, 32930, 30491, 2144, 44711, 31990, 15621, 32067, 10979, 916, 12500, 37223, 2137, 5283, 19115, 5821, 42995, 29630, 3453, 13920, 43781, 28462, 6978, 5403, 95, 41092, 37595, 5074, 17779, 9361, 42814, 5915, 19029, 38211, 36126, 3585, 39096, 38059, 29091, 9536, 10188, 17837, 44226, 26950, 34699, 22029, 5367, 31753, 21825, 9641, 14769, 40708, 24651, 21536, 3733, 2481, 6508, 18527, 37142, 33274, 11940, 38604, 23653, 727, 16303, 1494, 32012, 29854, 2117, 7636, 21532, 3035, 5884, 17045, 20356, 42661, 8141, 13077, 16269, 41826, 3650, 43444, 8142, 27344, 9311, 4314, 25107, 12417, 21348, 15195, 39748, 7770, 34079, 4078, 16889, 20428, 8612, 32225, 44742, 32366, 27471, 11588, 19717, 39109, 17573, 21932, 38856, 801, 213, 34638, 7316, 34142, 26652, 39486, 10185, 42552, 2670, 23751, 39981, 18697, 35767, 16929, 17490, 12239, 31040, 22160, 1837, 6459, 35597, 43275, 29300, 2171, 10242, 27590, 22621, 27715, 9916, 32269, 24171, 13386, 12706, 4373, 10668, 22772, 5000, 25984, 41721, 14835, 6262, 17527, 35059, 32566, 19074, 44523, 40307, 27415, 7162, 21325, 12013, 40118, 4846, 42102, 15213, 21465, 6588, 23697, 29977, 33843, 25295, 2026, 21345, 1100, 36644, 1884, 41879, 27225, 35830, 44925, 22757, 41397, 24656, 1472, 32545, 37757, 40285, 32276, 30733, 988, 12852, 3505, 32891, 11600, 44626, 9843, 15515, 13337, 7960, 8046, 42623, 38999, 24009, 34433, 17084, 25919, 36629, 37633, 22600, 30073, 20413, 35155, 38410, 44425, 15256, 41146, 13424, 13718, 2817, 11598, 22503, 43762, 31732, 32658, 37670, 26847, 41491, 1479, 23316, 201, 3100, 13678, 20294, 9927, 22064, 18607, 43962, 11942, 15658, 12519, 20407, 42332, 44377, 29132, 37189, 23989, 14641, 5279, 31407, 5352, 20081, 3548, 20984, 39176, 2321, 16074, 14572, 24303, 29067, 23725, 8177, 13597, 7768, 30278, 8114, 7765, 37138, 4300, 39932, 1618, 44719, 31839, 6369, 40427, 25321, 34473, 3097, 26174, 10787, 732, 25515, 9692, 37052, 32424, 26665, 23586, 16388, 22261, 31560, 42122, 13009, 3235, 8474, 23342, 27799, 29893, 32971, 38859, 18158, 30888, 9577, 1381, 11211, 25664, 30941, 22158, 153, 43065, 17279, 15138, 22640, 14330, 15176, 28488, 32744, 584, 15979, 24675, 32727, 22866, 44208, 9524, 4592, 13552, 13066, 3923, 21004, 21927, 1154, 3238, 9042, 14957, 21447, 3705, 21137, 36092, 23287, 6137, 29521, 26586, 6727, 38502, 32351, 10066, 23924, 3659, 24368, 10366, 15911, 30362, 40511, 11129, 4184, 38350, 31236, 1335, 13243, 5435, 28268, 40129, 37215, 13567, 41038, 17810, 38917, 40675, 8958, 42828, 30412, 31290, 7088, 32431, 14387, 44763, 14190, 18948, 24095, 28166, 25264, 26124, 26423, 23505, 12478, 42132, 16726, 38121, 16729, 3698, 20135, 2336, 41063, 9654, 22801, 4309, 28254, 29597, 12976, 5550, 3862, 37154, 31682, 20402, 22405, 8504, 9162, 30830, 20764, 6527, 37213, 24370, 992, 28090, 43101, 218, 10649, 13083, 4863, 13327, 32680, 44814, 44245, 4301, 8476, 25872, 35244, 2477, 8680, 16264, 42387, 23597, 14317, 35655, 17387, 15117, 5148, 29156, 41053, 32010, 3503, 21250, 23217, 42545, 37777, 42666, 17460, 41140, 25246, 12398, 43515, 27391, 42871, 13129, 5207, 1247, 27147, 28228, 42921, 7878, 36265, 4164, 10893, 20972, 21647, 41997, 5987, 20481, 37490, 13713, 27204, 33194, 12011, 21290, 11364, 22897, 40482, 42483, 24166, 17506, 36789, 16855, 23677, 1774, 42766, 14852, 29652, 15915, 23801, 3041, 14062, 25917, 2043, 44544, 42324, 23258, 157, 28542, 5655, 9170, 43593, 10469, 10546, 35097, 17033, 1598, 4052, 3860, 21941, 4797, 31101, 6184, 8724, 30207, 28173, 15316, 8625, 11471, 13362, 33740, 41226, 24324, 34960, 19654, 19178, 12979, 18289, 5091, 11773, 23569, 5192, 43513, 12900, 39985, 38206, 8617, 35486, 41714, 12878, 34305, 7767, 24609, 21134, 44261, 43714, 17240, 6083, 7348, 43026, 17123, 42076, 8682, 36146, 7585, 16774, 26689, 22835, 3121, 30173, 40491, 19600, 4589, 19494, 29211, 1710, 31704, 37560, 27413, 540, 14995, 25903, 33909, 5049, 35918, 3598, 16107, 42062, 37042, 2094, 39908, 22034, 30984, 17570, 33960, 37341, 20506, 36815, 26914, 7221, 27659, 25907, 18857, 33559, 29324, 27672, 25662, 10984, 39381, 37686, 44753, 3228, 41455, 42736, 29332, 31118, 27935, 18589, 15821, 3632, 43395, 27118, 3684, 1966, 25960, 10644, 39693, 41748, 10956, 1310, 22035, 6234, 41104, 24694, 8134, 11280, 20642, 38018, 35066, 18558, 18539, 38768, 17020, 12821, 8670, 17923, 8826, 35734, 18664, 2616, 1631, 9217, 11416, 7618, 29473, 1795, 13396, 30549, 27911, 24497, 12999, 18207, 35271, 18661, 26235, 33494, 42442, 29945, 33727, 19449, 29736, 24339, 42220, 14902, 31467, 10538, 8077, 21147, 42868, 22593, 18622, 36960, 25618, 36578, 35287, 31519, 37342, 35122, 23161, 31510, 15619, 41907, 6487, 12263, 44329, 19506, 3036, 27398, 14204, 26438, 31244, 40065, 40655, 2290, 3982, 9730, 40707, 34364, 24598, 39406, 34259, 5961, 6273, 18394, 29056, 19701, 11087, 18076, 8672, 24114, 44166, 7298, 28377, 13613, 19801, 27616, 31239, 18871, 9877, 32877, 38328, 28183, 26428, 25528, 35474, 29740, 18497, 9547, 36157, 35819, 44982, 18616, 16325, 11498, 3127, 42690, 14727, 12440, 13323, 23243, 37799, 20483, 17550, 38937, 40276, 17722, 10951, 25611, 4765, 4254, 17162, 15015, 34196, 3200, 39627, 39251, 22777, 31859, 11765, 30827, 34338, 7888, 30731, 3606, 32904, 17022, 12669, 25850, 10990, 23077, 44758, 19830, 38591, 36695, 8196, 38355, 8212, 43196, 34054, 16601, 7005, 27602, 29876, 22624, 30975, 37150, 11969, 2404, 35054, 9333, 24295, 33810, 33313, 30979, 25424, 3613, 16721, 8494, 35574, 41555, 44983, 33792, 38745, 4922, 14208, 38450, 35366, 39253, 36068, 7407, 20326, 6368, 17578, 10254, 3134, 34972, 16470, 32416, 21482, 10628, 32407, 11433, 34728, 4335, 6607, 19795, 1301, 24969, 1852, 37725, 3919, 40177, 39338, 25337, 10159, 12027, 32030, 11943, 43447, 13702, 20807, 26331, 35602, 21385, 527, 5115, 39223, 13173, 32032, 26087, 1488, 23676, 44148, 6687, 42375, 33286, 7930, 30033, 40333, 4402, 9570, 31200, 41729, 18863, 15593, 12782, 24577, 38270, 26108, 26430, 26166, 32295, 20337, 3407, 43989, 41776, 29384, 18881, 43652, 4053, 13468, 1225, 4212, 29206, 37646, 13648, 16986, 35294, 10838]], test_dataset='CIFAR-10 (Test)', train_augmentations=Sequential(\n",
       "  (0): RandomCrop(crop_size=(32, 32), padding=4, fill=0, pad_if_needed=False, padding_mode=constant, resample=BILINEAR, p=1.0, p_batch=1.0, same_on_batch=False, return_transform=False)\n",
       "  (1): RandomHorizontalFlip(p=0.5, p_batch=1.0, same_on_batch=False, return_transform=None)\n",
       "), initial_training_set_indices=[70785, 73399, 77839, 83581, 16140, 88102, 95039, 24162, 179177, 30921, 180600, 180069, 169640, 44461, 119946, 55251, 178823, 62079, 66526, 64780], evaluation_set_indices=[28964, 11411, 14886, 9609, 39292, 398, 3431, 21404, 44846, 11777, 6361, 36817, 5044, 37231, 14346, 24286, 4294, 28590, 16297, 12733, 19940, 27283, 27046, 17495, 4417, 40795, 10717, 3957, 14535, 20341, 27604, 43757, 26320, 40449, 10574, 12396, 14656, 21304, 44149, 12180, 27762, 22949, 32997, 11309, 29865, 36001, 20338, 24032, 34368, 9137, 23376, 13769, 44858, 15640, 40594, 407, 40764, 7166, 17277, 15347, 7175, 10233, 14617, 35065, 39662, 32385, 28273, 15891, 26145, 27266, 38700, 14319, 31039, 4596, 21831, 6428, 27461, 6582, 518, 20455, 6795, 21079, 30299, 33470, 38939, 27229, 22701, 33968, 19425, 6796, 5874, 32641, 32181, 5994, 43189, 38244, 32894, 18469, 34402, 20303, 20577, 32160, 36055, 40702, 27739, 32548, 34043, 37950, 485, 6804, 21241, 28762, 5895, 23667, 24825, 6571, 35106, 32930, 30491, 2144, 44711, 31990, 15621, 32067, 10979, 916, 12500, 37223, 2137, 5283, 19115, 5821, 42995, 29630, 3453, 13920, 43781, 28462, 6978, 5403, 95, 41092, 37595, 5074, 17779, 9361, 42814, 5915, 19029, 38211, 36126, 3585, 39096, 38059, 29091, 9536, 10188, 17837, 44226, 26950, 34699, 22029, 5367, 31753, 21825, 9641, 14769, 40708, 24651, 21536, 3733, 2481, 6508, 18527, 37142, 33274, 11940, 38604, 23653, 727, 16303, 1494, 32012, 29854, 2117, 7636, 21532, 3035, 5884, 17045, 20356, 42661, 8141, 13077, 16269, 41826, 3650, 43444, 8142, 27344, 9311, 4314, 25107, 12417, 21348, 15195, 39748, 7770, 34079, 4078, 16889, 20428, 8612, 32225, 44742, 32366, 27471, 11588, 19717, 39109, 17573, 21932, 38856, 801, 213, 34638, 7316, 34142, 26652, 39486, 10185, 42552, 2670, 23751, 39981, 18697, 35767, 16929, 17490, 12239, 31040, 22160, 1837, 6459, 35597, 43275, 29300, 2171, 10242, 27590, 22621, 27715, 9916, 32269, 24171, 13386, 12706, 4373, 10668, 22772, 5000, 25984, 41721, 14835, 6262, 17527, 35059, 32566, 19074, 44523, 40307, 27415, 7162, 21325, 12013, 40118, 4846, 42102, 15213, 21465, 6588, 23697, 29977, 33843, 25295, 2026, 21345, 1100, 36644, 1884, 41879, 27225, 35830, 44925, 22757, 41397, 24656, 1472, 32545, 37757, 40285, 32276, 30733, 988, 12852, 3505, 32891, 11600, 44626, 9843, 15515, 13337, 7960, 8046, 42623, 38999, 24009, 34433, 17084, 25919, 36629, 37633, 22600, 30073, 20413, 35155, 38410, 44425, 15256, 41146, 13424, 13718, 2817, 11598, 22503, 43762, 31732, 32658, 37670, 26847, 41491, 1479, 23316, 201, 3100, 13678, 20294, 9927, 22064, 18607, 43962, 11942, 15658, 12519, 20407, 42332, 44377, 29132, 37189, 23989, 14641, 5279, 31407, 5352, 20081, 3548, 20984, 39176, 2321, 16074, 14572, 24303, 29067, 23725, 8177, 13597, 7768, 30278, 8114, 7765, 37138, 4300, 39932, 1618, 44719, 31839, 6369, 40427, 25321, 34473, 3097, 26174, 10787, 732, 25515, 9692, 37052, 32424, 26665, 23586, 16388, 22261, 31560, 42122, 13009, 3235, 8474, 23342, 27799, 29893, 32971, 38859, 18158, 30888, 9577, 1381, 11211, 25664, 30941, 22158, 153, 43065, 17279, 15138, 22640, 14330, 15176, 28488, 32744, 584, 15979, 24675, 32727, 22866, 44208, 9524, 4592, 13552, 13066, 3923, 21004, 21927, 1154, 3238, 9042, 14957, 21447, 3705, 21137, 36092, 23287, 6137, 29521, 26586, 6727, 38502, 32351, 10066, 23924, 3659, 24368, 10366, 15911, 30362, 40511, 11129, 4184, 38350, 31236, 1335, 13243, 5435, 28268, 40129, 37215, 13567, 41038, 17810, 38917, 40675, 8958, 42828, 30412, 31290, 7088, 32431, 14387, 44763, 14190, 18948, 24095, 28166, 25264, 26124, 26423, 23505, 12478, 42132, 16726, 38121, 16729, 3698, 20135, 2336, 41063, 9654, 22801, 4309, 28254, 29597, 12976, 5550, 3862, 37154, 31682, 20402, 22405, 8504, 9162, 30830, 20764, 6527, 37213, 24370, 992, 28090, 43101, 218, 10649, 13083, 4863, 13327, 32680, 44814, 44245, 4301, 8476, 25872, 35244, 2477, 8680, 16264, 42387, 23597, 14317, 35655, 17387, 15117, 5148, 29156, 41053, 32010, 3503, 21250, 23217, 42545, 37777, 42666, 17460, 41140, 25246, 12398, 43515, 27391, 42871, 13129, 5207, 1247, 27147, 28228, 42921, 7878, 36265, 4164, 10893, 20972, 21647, 41997, 5987, 20481, 37490, 13713, 27204, 33194, 12011, 21290, 11364, 22897, 40482, 42483, 24166, 17506, 36789, 16855, 23677, 1774, 42766, 14852, 29652, 15915, 23801, 3041, 14062, 25917, 2043, 44544, 42324, 23258, 157, 28542, 5655, 9170, 43593, 10469, 10546, 35097, 17033, 1598, 4052, 3860, 21941, 4797, 31101, 6184, 8724, 30207, 28173, 15316, 8625, 11471, 13362, 33740, 41226, 24324, 34960, 19654, 19178, 12979, 18289, 5091, 11773, 23569, 5192, 43513, 12900, 39985, 38206, 8617, 35486, 41714, 12878, 34305, 7767, 24609, 21134, 44261, 43714, 17240, 6083, 7348, 43026, 17123, 42076, 8682, 36146, 7585, 16774, 26689, 22835, 3121, 30173, 40491, 19600, 4589, 19494, 29211, 1710, 31704, 37560, 27413, 540, 14995, 25903, 33909, 5049, 35918, 3598, 16107, 42062, 37042, 2094, 39908, 22034, 30984, 17570, 33960, 37341, 20506, 36815, 26914, 7221, 27659, 25907, 18857, 33559, 29324, 27672, 25662, 10984, 39381, 37686, 44753, 3228, 41455, 42736, 29332, 31118, 27935, 18589, 15821, 3632, 43395, 27118, 3684, 1966, 25960, 10644, 39693, 41748, 10956, 1310, 22035, 6234, 41104, 24694, 8134, 11280, 20642, 38018, 35066, 18558, 18539, 38768, 17020, 12821, 8670, 17923, 8826, 35734, 18664, 2616, 1631, 9217, 11416, 7618, 29473, 1795, 13396, 30549, 27911, 24497, 12999, 18207, 35271, 18661, 26235, 33494, 42442, 29945, 33727, 19449, 29736, 24339, 42220, 14902, 31467, 10538, 8077, 21147, 42868, 22593, 18622, 36960, 25618, 36578, 35287, 31519, 37342, 35122, 23161, 31510, 15619, 41907, 6487, 12263, 44329, 19506, 3036, 27398, 14204, 26438, 31244, 40065, 40655, 2290, 3982, 9730, 40707, 34364, 24598, 39406, 34259, 5961, 6273, 18394, 29056, 19701, 11087, 18076, 8672, 24114, 44166, 7298, 28377, 13613, 19801, 27616, 31239, 18871, 9877, 32877, 38328, 28183, 26428, 25528, 35474, 29740, 18497, 9547, 36157, 35819, 44982, 18616, 16325, 11498, 3127, 42690, 14727, 12440, 13323, 23243, 37799, 20483, 17550, 38937, 40276, 17722, 10951, 25611, 4765, 4254, 17162, 15015, 34196, 3200, 39627, 39251, 22777, 31859, 11765, 30827, 34338, 7888, 30731, 3606, 32904, 17022, 12669, 25850, 10990, 23077, 44758, 19830, 38591, 36695, 8196, 38355, 8212, 43196, 34054, 16601, 7005, 27602, 29876, 22624, 30975, 37150, 11969, 2404, 35054, 9333, 24295, 33810, 33313, 30979, 25424, 3613, 16721, 8494, 35574, 41555, 44983, 33792, 38745, 4922, 14208, 38450, 35366, 39253, 36068, 7407, 20326, 6368, 17578, 10254, 3134, 34972, 16470, 32416, 21482, 10628, 32407, 11433, 34728, 4335, 6607, 19795, 1301, 24969, 1852, 37725, 3919, 40177, 39338, 25337, 10159, 12027, 32030, 11943, 43447, 13702, 20807, 26331, 35602, 21385, 527, 5115, 39223, 13173, 32032, 26087, 1488, 23676, 44148, 6687, 42375, 33286, 7930, 30033, 40333, 4402, 9570, 31200, 41729, 18863, 15593, 12782, 24577, 38270, 26108, 26430, 26166, 32295, 20337, 3407, 43989, 41776, 29384, 18881, 43652, 4053, 13468, 1225, 4212, 29206, 37646, 13648, 16986, 35294, 10838], ood_dataset=None, ood_exposure=False, device='cpu')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "load_cinic_cifar_shift_experiment_data(\n",
    "    train_imagenet_only=False,\n",
    "    initial_training_set_size=20,\n",
    "    validation_set_size=5000,\n",
    "    validation_split_random_state=0,\n",
    "    evaluation_set_size=1000,\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-pharmacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n",
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExperimentData(active_learning=ActiveLearningData(base_dataset='CINIC-10 (Train, imagenet_only=True, seed=0, 140000 samples)', num_training_samples=20, num_pool_samples=139980), validation_dataset='CIFAR-10 (Validation, seed=0, 5000 samples)', evaluation_dataset='CIFAR-10 (Train, seed=0, 45000 samples)'[[28964, 11411, 14886, 9609, 39292, 398, 3431, 21404, 44846, 11777, 6361, 36817, 5044, 37231, 14346, 24286, 4294, 28590, 16297, 12733, 19940, 27283, 27046, 17495, 4417, 40795, 10717, 3957, 14535, 20341, 27604, 43757, 26320, 40449, 10574, 12396, 14656, 21304, 44149, 12180, 27762, 22949, 32997, 11309, 29865, 36001, 20338, 24032, 34368, 9137, 23376, 13769, 44858, 15640, 40594, 407, 40764, 7166, 17277, 15347, 7175, 10233, 14617, 35065, 39662, 32385, 28273, 15891, 26145, 27266, 38700, 14319, 31039, 4596, 21831, 6428, 27461, 6582, 518, 20455, 6795, 21079, 30299, 33470, 38939, 27229, 22701, 33968, 19425, 6796, 5874, 32641, 32181, 5994, 43189, 38244, 32894, 18469, 34402, 20303, 20577, 32160, 36055, 40702, 27739, 32548, 34043, 37950, 485, 6804, 21241, 28762, 5895, 23667, 24825, 6571, 35106, 32930, 30491, 2144, 44711, 31990, 15621, 32067, 10979, 916, 12500, 37223, 2137, 5283, 19115, 5821, 42995, 29630, 3453, 13920, 43781, 28462, 6978, 5403, 95, 41092, 37595, 5074, 17779, 9361, 42814, 5915, 19029, 38211, 36126, 3585, 39096, 38059, 29091, 9536, 10188, 17837, 44226, 26950, 34699, 22029, 5367, 31753, 21825, 9641, 14769, 40708, 24651, 21536, 3733, 2481, 6508, 18527, 37142, 33274, 11940, 38604, 23653, 727, 16303, 1494, 32012, 29854, 2117, 7636, 21532, 3035, 5884, 17045, 20356, 42661, 8141, 13077, 16269, 41826, 3650, 43444, 8142, 27344, 9311, 4314, 25107, 12417, 21348, 15195, 39748, 7770, 34079, 4078, 16889, 20428, 8612, 32225, 44742, 32366, 27471, 11588, 19717, 39109, 17573, 21932, 38856, 801, 213, 34638, 7316, 34142, 26652, 39486, 10185, 42552, 2670, 23751, 39981, 18697, 35767, 16929, 17490, 12239, 31040, 22160, 1837, 6459, 35597, 43275, 29300, 2171, 10242, 27590, 22621, 27715, 9916, 32269, 24171, 13386, 12706, 4373, 10668, 22772, 5000, 25984, 41721, 14835, 6262, 17527, 35059, 32566, 19074, 44523, 40307, 27415, 7162, 21325, 12013, 40118, 4846, 42102, 15213, 21465, 6588, 23697, 29977, 33843, 25295, 2026, 21345, 1100, 36644, 1884, 41879, 27225, 35830, 44925, 22757, 41397, 24656, 1472, 32545, 37757, 40285, 32276, 30733, 988, 12852, 3505, 32891, 11600, 44626, 9843, 15515, 13337, 7960, 8046, 42623, 38999, 24009, 34433, 17084, 25919, 36629, 37633, 22600, 30073, 20413, 35155, 38410, 44425, 15256, 41146, 13424, 13718, 2817, 11598, 22503, 43762, 31732, 32658, 37670, 26847, 41491, 1479, 23316, 201, 3100, 13678, 20294, 9927, 22064, 18607, 43962, 11942, 15658, 12519, 20407, 42332, 44377, 29132, 37189, 23989, 14641, 5279, 31407, 5352, 20081, 3548, 20984, 39176, 2321, 16074, 14572, 24303, 29067, 23725, 8177, 13597, 7768, 30278, 8114, 7765, 37138, 4300, 39932, 1618, 44719, 31839, 6369, 40427, 25321, 34473, 3097, 26174, 10787, 732, 25515, 9692, 37052, 32424, 26665, 23586, 16388, 22261, 31560, 42122, 13009, 3235, 8474, 23342, 27799, 29893, 32971, 38859, 18158, 30888, 9577, 1381, 11211, 25664, 30941, 22158, 153, 43065, 17279, 15138, 22640, 14330, 15176, 28488, 32744, 584, 15979, 24675, 32727, 22866, 44208, 9524, 4592, 13552, 13066, 3923, 21004, 21927, 1154, 3238, 9042, 14957, 21447, 3705, 21137, 36092, 23287, 6137, 29521, 26586, 6727, 38502, 32351, 10066, 23924, 3659, 24368, 10366, 15911, 30362, 40511, 11129, 4184, 38350, 31236, 1335, 13243, 5435, 28268, 40129, 37215, 13567, 41038, 17810, 38917, 40675, 8958, 42828, 30412, 31290, 7088, 32431, 14387, 44763, 14190, 18948, 24095, 28166, 25264, 26124, 26423, 23505, 12478, 42132, 16726, 38121, 16729, 3698, 20135, 2336, 41063, 9654, 22801, 4309, 28254, 29597, 12976, 5550, 3862, 37154, 31682, 20402, 22405, 8504, 9162, 30830, 20764, 6527, 37213, 24370, 992, 28090, 43101, 218, 10649, 13083, 4863, 13327, 32680, 44814, 44245, 4301, 8476, 25872, 35244, 2477, 8680, 16264, 42387, 23597, 14317, 35655, 17387, 15117, 5148, 29156, 41053, 32010, 3503, 21250, 23217, 42545, 37777, 42666, 17460, 41140, 25246, 12398, 43515, 27391, 42871, 13129, 5207, 1247, 27147, 28228, 42921, 7878, 36265, 4164, 10893, 20972, 21647, 41997, 5987, 20481, 37490, 13713, 27204, 33194, 12011, 21290, 11364, 22897, 40482, 42483, 24166, 17506, 36789, 16855, 23677, 1774, 42766, 14852, 29652, 15915, 23801, 3041, 14062, 25917, 2043, 44544, 42324, 23258, 157, 28542, 5655, 9170, 43593, 10469, 10546, 35097, 17033, 1598, 4052, 3860, 21941, 4797, 31101, 6184, 8724, 30207, 28173, 15316, 8625, 11471, 13362, 33740, 41226, 24324, 34960, 19654, 19178, 12979, 18289, 5091, 11773, 23569, 5192, 43513, 12900, 39985, 38206, 8617, 35486, 41714, 12878, 34305, 7767, 24609, 21134, 44261, 43714, 17240, 6083, 7348, 43026, 17123, 42076, 8682, 36146, 7585, 16774, 26689, 22835, 3121, 30173, 40491, 19600, 4589, 19494, 29211, 1710, 31704, 37560, 27413, 540, 14995, 25903, 33909, 5049, 35918, 3598, 16107, 42062, 37042, 2094, 39908, 22034, 30984, 17570, 33960, 37341, 20506, 36815, 26914, 7221, 27659, 25907, 18857, 33559, 29324, 27672, 25662, 10984, 39381, 37686, 44753, 3228, 41455, 42736, 29332, 31118, 27935, 18589, 15821, 3632, 43395, 27118, 3684, 1966, 25960, 10644, 39693, 41748, 10956, 1310, 22035, 6234, 41104, 24694, 8134, 11280, 20642, 38018, 35066, 18558, 18539, 38768, 17020, 12821, 8670, 17923, 8826, 35734, 18664, 2616, 1631, 9217, 11416, 7618, 29473, 1795, 13396, 30549, 27911, 24497, 12999, 18207, 35271, 18661, 26235, 33494, 42442, 29945, 33727, 19449, 29736, 24339, 42220, 14902, 31467, 10538, 8077, 21147, 42868, 22593, 18622, 36960, 25618, 36578, 35287, 31519, 37342, 35122, 23161, 31510, 15619, 41907, 6487, 12263, 44329, 19506, 3036, 27398, 14204, 26438, 31244, 40065, 40655, 2290, 3982, 9730, 40707, 34364, 24598, 39406, 34259, 5961, 6273, 18394, 29056, 19701, 11087, 18076, 8672, 24114, 44166, 7298, 28377, 13613, 19801, 27616, 31239, 18871, 9877, 32877, 38328, 28183, 26428, 25528, 35474, 29740, 18497, 9547, 36157, 35819, 44982, 18616, 16325, 11498, 3127, 42690, 14727, 12440, 13323, 23243, 37799, 20483, 17550, 38937, 40276, 17722, 10951, 25611, 4765, 4254, 17162, 15015, 34196, 3200, 39627, 39251, 22777, 31859, 11765, 30827, 34338, 7888, 30731, 3606, 32904, 17022, 12669, 25850, 10990, 23077, 44758, 19830, 38591, 36695, 8196, 38355, 8212, 43196, 34054, 16601, 7005, 27602, 29876, 22624, 30975, 37150, 11969, 2404, 35054, 9333, 24295, 33810, 33313, 30979, 25424, 3613, 16721, 8494, 35574, 41555, 44983, 33792, 38745, 4922, 14208, 38450, 35366, 39253, 36068, 7407, 20326, 6368, 17578, 10254, 3134, 34972, 16470, 32416, 21482, 10628, 32407, 11433, 34728, 4335, 6607, 19795, 1301, 24969, 1852, 37725, 3919, 40177, 39338, 25337, 10159, 12027, 32030, 11943, 43447, 13702, 20807, 26331, 35602, 21385, 527, 5115, 39223, 13173, 32032, 26087, 1488, 23676, 44148, 6687, 42375, 33286, 7930, 30033, 40333, 4402, 9570, 31200, 41729, 18863, 15593, 12782, 24577, 38270, 26108, 26430, 26166, 32295, 20337, 3407, 43989, 41776, 29384, 18881, 43652, 4053, 13468, 1225, 4212, 29206, 37646, 13648, 16986, 35294, 10838]], test_dataset='CIFAR-10 (Test)', train_augmentations=Sequential(\n",
       "  (0): RandomCrop(crop_size=(32, 32), padding=4, fill=0, pad_if_needed=False, padding_mode=constant, resample=BILINEAR, p=1.0, p_batch=1.0, same_on_batch=False, return_transform=False)\n",
       "  (1): RandomHorizontalFlip(p=0.5, p_batch=1.0, same_on_batch=False, return_transform=None)\n",
       "), initial_training_set_indices=[70932, 1050, 7741, 10854, 20307, 18195, 95343, 24004, 31784, 28745, 110483, 38085, 112486, 44284, 119930, 125950, 56637, 126614, 66426, 69929], evaluation_set_indices=[28964, 11411, 14886, 9609, 39292, 398, 3431, 21404, 44846, 11777, 6361, 36817, 5044, 37231, 14346, 24286, 4294, 28590, 16297, 12733, 19940, 27283, 27046, 17495, 4417, 40795, 10717, 3957, 14535, 20341, 27604, 43757, 26320, 40449, 10574, 12396, 14656, 21304, 44149, 12180, 27762, 22949, 32997, 11309, 29865, 36001, 20338, 24032, 34368, 9137, 23376, 13769, 44858, 15640, 40594, 407, 40764, 7166, 17277, 15347, 7175, 10233, 14617, 35065, 39662, 32385, 28273, 15891, 26145, 27266, 38700, 14319, 31039, 4596, 21831, 6428, 27461, 6582, 518, 20455, 6795, 21079, 30299, 33470, 38939, 27229, 22701, 33968, 19425, 6796, 5874, 32641, 32181, 5994, 43189, 38244, 32894, 18469, 34402, 20303, 20577, 32160, 36055, 40702, 27739, 32548, 34043, 37950, 485, 6804, 21241, 28762, 5895, 23667, 24825, 6571, 35106, 32930, 30491, 2144, 44711, 31990, 15621, 32067, 10979, 916, 12500, 37223, 2137, 5283, 19115, 5821, 42995, 29630, 3453, 13920, 43781, 28462, 6978, 5403, 95, 41092, 37595, 5074, 17779, 9361, 42814, 5915, 19029, 38211, 36126, 3585, 39096, 38059, 29091, 9536, 10188, 17837, 44226, 26950, 34699, 22029, 5367, 31753, 21825, 9641, 14769, 40708, 24651, 21536, 3733, 2481, 6508, 18527, 37142, 33274, 11940, 38604, 23653, 727, 16303, 1494, 32012, 29854, 2117, 7636, 21532, 3035, 5884, 17045, 20356, 42661, 8141, 13077, 16269, 41826, 3650, 43444, 8142, 27344, 9311, 4314, 25107, 12417, 21348, 15195, 39748, 7770, 34079, 4078, 16889, 20428, 8612, 32225, 44742, 32366, 27471, 11588, 19717, 39109, 17573, 21932, 38856, 801, 213, 34638, 7316, 34142, 26652, 39486, 10185, 42552, 2670, 23751, 39981, 18697, 35767, 16929, 17490, 12239, 31040, 22160, 1837, 6459, 35597, 43275, 29300, 2171, 10242, 27590, 22621, 27715, 9916, 32269, 24171, 13386, 12706, 4373, 10668, 22772, 5000, 25984, 41721, 14835, 6262, 17527, 35059, 32566, 19074, 44523, 40307, 27415, 7162, 21325, 12013, 40118, 4846, 42102, 15213, 21465, 6588, 23697, 29977, 33843, 25295, 2026, 21345, 1100, 36644, 1884, 41879, 27225, 35830, 44925, 22757, 41397, 24656, 1472, 32545, 37757, 40285, 32276, 30733, 988, 12852, 3505, 32891, 11600, 44626, 9843, 15515, 13337, 7960, 8046, 42623, 38999, 24009, 34433, 17084, 25919, 36629, 37633, 22600, 30073, 20413, 35155, 38410, 44425, 15256, 41146, 13424, 13718, 2817, 11598, 22503, 43762, 31732, 32658, 37670, 26847, 41491, 1479, 23316, 201, 3100, 13678, 20294, 9927, 22064, 18607, 43962, 11942, 15658, 12519, 20407, 42332, 44377, 29132, 37189, 23989, 14641, 5279, 31407, 5352, 20081, 3548, 20984, 39176, 2321, 16074, 14572, 24303, 29067, 23725, 8177, 13597, 7768, 30278, 8114, 7765, 37138, 4300, 39932, 1618, 44719, 31839, 6369, 40427, 25321, 34473, 3097, 26174, 10787, 732, 25515, 9692, 37052, 32424, 26665, 23586, 16388, 22261, 31560, 42122, 13009, 3235, 8474, 23342, 27799, 29893, 32971, 38859, 18158, 30888, 9577, 1381, 11211, 25664, 30941, 22158, 153, 43065, 17279, 15138, 22640, 14330, 15176, 28488, 32744, 584, 15979, 24675, 32727, 22866, 44208, 9524, 4592, 13552, 13066, 3923, 21004, 21927, 1154, 3238, 9042, 14957, 21447, 3705, 21137, 36092, 23287, 6137, 29521, 26586, 6727, 38502, 32351, 10066, 23924, 3659, 24368, 10366, 15911, 30362, 40511, 11129, 4184, 38350, 31236, 1335, 13243, 5435, 28268, 40129, 37215, 13567, 41038, 17810, 38917, 40675, 8958, 42828, 30412, 31290, 7088, 32431, 14387, 44763, 14190, 18948, 24095, 28166, 25264, 26124, 26423, 23505, 12478, 42132, 16726, 38121, 16729, 3698, 20135, 2336, 41063, 9654, 22801, 4309, 28254, 29597, 12976, 5550, 3862, 37154, 31682, 20402, 22405, 8504, 9162, 30830, 20764, 6527, 37213, 24370, 992, 28090, 43101, 218, 10649, 13083, 4863, 13327, 32680, 44814, 44245, 4301, 8476, 25872, 35244, 2477, 8680, 16264, 42387, 23597, 14317, 35655, 17387, 15117, 5148, 29156, 41053, 32010, 3503, 21250, 23217, 42545, 37777, 42666, 17460, 41140, 25246, 12398, 43515, 27391, 42871, 13129, 5207, 1247, 27147, 28228, 42921, 7878, 36265, 4164, 10893, 20972, 21647, 41997, 5987, 20481, 37490, 13713, 27204, 33194, 12011, 21290, 11364, 22897, 40482, 42483, 24166, 17506, 36789, 16855, 23677, 1774, 42766, 14852, 29652, 15915, 23801, 3041, 14062, 25917, 2043, 44544, 42324, 23258, 157, 28542, 5655, 9170, 43593, 10469, 10546, 35097, 17033, 1598, 4052, 3860, 21941, 4797, 31101, 6184, 8724, 30207, 28173, 15316, 8625, 11471, 13362, 33740, 41226, 24324, 34960, 19654, 19178, 12979, 18289, 5091, 11773, 23569, 5192, 43513, 12900, 39985, 38206, 8617, 35486, 41714, 12878, 34305, 7767, 24609, 21134, 44261, 43714, 17240, 6083, 7348, 43026, 17123, 42076, 8682, 36146, 7585, 16774, 26689, 22835, 3121, 30173, 40491, 19600, 4589, 19494, 29211, 1710, 31704, 37560, 27413, 540, 14995, 25903, 33909, 5049, 35918, 3598, 16107, 42062, 37042, 2094, 39908, 22034, 30984, 17570, 33960, 37341, 20506, 36815, 26914, 7221, 27659, 25907, 18857, 33559, 29324, 27672, 25662, 10984, 39381, 37686, 44753, 3228, 41455, 42736, 29332, 31118, 27935, 18589, 15821, 3632, 43395, 27118, 3684, 1966, 25960, 10644, 39693, 41748, 10956, 1310, 22035, 6234, 41104, 24694, 8134, 11280, 20642, 38018, 35066, 18558, 18539, 38768, 17020, 12821, 8670, 17923, 8826, 35734, 18664, 2616, 1631, 9217, 11416, 7618, 29473, 1795, 13396, 30549, 27911, 24497, 12999, 18207, 35271, 18661, 26235, 33494, 42442, 29945, 33727, 19449, 29736, 24339, 42220, 14902, 31467, 10538, 8077, 21147, 42868, 22593, 18622, 36960, 25618, 36578, 35287, 31519, 37342, 35122, 23161, 31510, 15619, 41907, 6487, 12263, 44329, 19506, 3036, 27398, 14204, 26438, 31244, 40065, 40655, 2290, 3982, 9730, 40707, 34364, 24598, 39406, 34259, 5961, 6273, 18394, 29056, 19701, 11087, 18076, 8672, 24114, 44166, 7298, 28377, 13613, 19801, 27616, 31239, 18871, 9877, 32877, 38328, 28183, 26428, 25528, 35474, 29740, 18497, 9547, 36157, 35819, 44982, 18616, 16325, 11498, 3127, 42690, 14727, 12440, 13323, 23243, 37799, 20483, 17550, 38937, 40276, 17722, 10951, 25611, 4765, 4254, 17162, 15015, 34196, 3200, 39627, 39251, 22777, 31859, 11765, 30827, 34338, 7888, 30731, 3606, 32904, 17022, 12669, 25850, 10990, 23077, 44758, 19830, 38591, 36695, 8196, 38355, 8212, 43196, 34054, 16601, 7005, 27602, 29876, 22624, 30975, 37150, 11969, 2404, 35054, 9333, 24295, 33810, 33313, 30979, 25424, 3613, 16721, 8494, 35574, 41555, 44983, 33792, 38745, 4922, 14208, 38450, 35366, 39253, 36068, 7407, 20326, 6368, 17578, 10254, 3134, 34972, 16470, 32416, 21482, 10628, 32407, 11433, 34728, 4335, 6607, 19795, 1301, 24969, 1852, 37725, 3919, 40177, 39338, 25337, 10159, 12027, 32030, 11943, 43447, 13702, 20807, 26331, 35602, 21385, 527, 5115, 39223, 13173, 32032, 26087, 1488, 23676, 44148, 6687, 42375, 33286, 7930, 30033, 40333, 4402, 9570, 31200, 41729, 18863, 15593, 12782, 24577, 38270, 26108, 26430, 26166, 32295, 20337, 3407, 43989, 41776, 29384, 18881, 43652, 4053, 13468, 1225, 4212, 29206, 37646, 13648, 16986, 35294, 10838], ood_dataset=None, ood_exposure=False, device='cpu')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "load_cinic_cifar_shift_experiment_data(\n",
    "    train_imagenet_only=True,\n",
    "    initial_training_set_size=20,\n",
    "    validation_set_size=5000,\n",
    "    validation_split_random_state=0,\n",
    "    evaluation_set_size=1000,\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:active_learning]",
   "language": "python",
   "name": "conda-env-active_learning-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
