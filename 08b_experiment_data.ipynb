{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "north-fleet",
   "metadata": {},
   "source": [
    "# Experiment Data (Setup)\n",
    "> No empirical experiments without data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp experiment_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-values",
   "metadata": {},
   "source": [
    "Import modules and functions were are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-bolivia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from batchbald_redux.active_learning import ActiveLearningData\n",
    "from batchbald_redux.dataset_challenges import (\n",
    "    AdditiveGaussianNoise,\n",
    "    AliasDataset,\n",
    "    NamedDataset,\n",
    "    get_balanced_sample_indices_by_class,\n",
    ")\n",
    "from batchbald_redux.datasets import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ExperimentData:\n",
    "    active_learning: ActiveLearningData\n",
    "    validation_dataset: Dataset\n",
    "    evaluation_dataset: Dataset\n",
    "    test_dataset: Dataset\n",
    "\n",
    "    train_augmentations: nn.Module\n",
    "\n",
    "    initial_training_set_indices: List[int]\n",
    "    evaluation_set_indices: List[int]\n",
    "\n",
    "    ood_dataset: NamedDataset\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class OoDDatasetConfig:\n",
    "    ood_dataset_name: str\n",
    "    ood_repetitions: float\n",
    "    ood_exposure: bool\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ExperimentDataConfig:\n",
    "    id_dataset_name: str\n",
    "    id_repetitions: float\n",
    "\n",
    "    initial_training_set_size: int\n",
    "\n",
    "    validation_set_size: int\n",
    "    validation_split_random_state: int\n",
    "\n",
    "    evaluation_set_size: int\n",
    "\n",
    "    add_dataset_noise: bool\n",
    "\n",
    "    ood_dataset_config: Optional[OoDDatasetConfig]\n",
    "\n",
    "    device: str\n",
    "\n",
    "    def load(self) -> ExperimentData:\n",
    "        return load_experiment_data(\n",
    "            id_dataset_name=self.id_dataset_name,\n",
    "            id_repetitions=self.id_repetitions,\n",
    "            initial_training_set_size=self.initial_training_set_size,\n",
    "            validation_set_size=self.validation_set_size,\n",
    "            validation_split_random_state=self.validation_split_random_state,\n",
    "            evaluation_set_size=self.evaluation_set_size,\n",
    "            add_dataset_noise=self.add_dataset_noise,\n",
    "            ood_dataset_config=self.ood_dataset_config,\n",
    "            device=self.device,\n",
    "        )\n",
    "\n",
    "\n",
    "def load_experiment_data(\n",
    "    *,\n",
    "    id_dataset_name: str,\n",
    "    id_repetitions: float,\n",
    "    initial_training_set_size: int,\n",
    "    validation_set_size: int,\n",
    "    validation_split_random_state: int,\n",
    "    evaluation_set_size: int,\n",
    "    add_dataset_noise: bool,\n",
    "    ood_dataset_config: Optional[OoDDatasetConfig],\n",
    "    device: str,\n",
    ") -> ExperimentData:\n",
    "    split_dataset = get_dataset(\n",
    "        id_dataset_name,\n",
    "        root=\"data\",\n",
    "        validation_set_size=validation_set_size,\n",
    "        validation_split_random_state=validation_split_random_state,\n",
    "        normalize_like_cifar10=True,\n",
    "        device_hint=device,\n",
    "    )\n",
    "\n",
    "    train_dataset = split_dataset.train\n",
    "\n",
    "    # TODO: add hook here to further process the train dataset?\n",
    "\n",
    "    # If we reduce the train set, we need to do so before picking the initial train set.\n",
    "    if id_repetitions < 1:\n",
    "        train_dataset = train_dataset * id_repetitions\n",
    "\n",
    "    num_classes = train_dataset.get_num_classes()\n",
    "    initial_samples_per_class = initial_training_set_size // num_classes\n",
    "    evaluation_set_samples_per_class = evaluation_set_size // num_classes\n",
    "    samples_per_class = initial_samples_per_class + evaluation_set_samples_per_class\n",
    "    balanced_samples_indices = get_balanced_sample_indices_by_class(\n",
    "        train_dataset,\n",
    "        num_classes=num_classes,\n",
    "        samples_per_class=samples_per_class,\n",
    "        seed=validation_split_random_state,\n",
    "    )\n",
    "\n",
    "    initial_training_set_indices = [\n",
    "        idx for by_class in balanced_samples_indices.values() for idx in by_class[:initial_samples_per_class]\n",
    "    ]\n",
    "    evaluation_set_indices = [\n",
    "        idx for by_class in balanced_samples_indices.values() for idx in by_class[initial_samples_per_class:]\n",
    "    ]\n",
    "\n",
    "    # If we over-sample the train set, we do so after picking the initial train set to avoid duplicates.\n",
    "    if id_repetitions > 1:\n",
    "        train_dataset = train_dataset * id_repetitions\n",
    "\n",
    "    if ood_dataset_config:\n",
    "        original_ood_dataset = get_dataset(ood_dataset_config.ood_dataset_name, root=\"data\", normalize_like_cifar10=True).train\n",
    "        if ood_dataset_config.ood_exposure:\n",
    "            train_dataset = train_dataset.one_hot(device=device)\n",
    "            ood_dataset = original_ood_dataset.uniform_target(device=device, num_classes=train_dataset.get_num_classes())\n",
    "        else:\n",
    "            ood_dataset = original_ood_dataset.constant_target(\n",
    "                target=torch.tensor(-1, device=device), num_classes=train_dataset.get_num_classes()\n",
    "            )\n",
    "\n",
    "        if ood_dataset_config.ood_repetitions != 1:\n",
    "            ood_dataset = ood_dataset * ood_dataset_config.ood_repetitions\n",
    "\n",
    "        train_dataset = train_dataset + ood_dataset\n",
    "    else:\n",
    "        original_ood_dataset = None\n",
    "\n",
    "    if add_dataset_noise:\n",
    "        train_dataset = AdditiveGaussianNoise(train_dataset, 0.1)\n",
    "\n",
    "    active_learning_data = ActiveLearningData(train_dataset)\n",
    "\n",
    "    active_learning_data.acquire_base_indices(initial_training_set_indices)\n",
    "\n",
    "    evaluation_dataset = AliasDataset(\n",
    "        active_learning_data.extract_dataset_from_base_indices(evaluation_set_indices),\n",
    "        f\"Evaluation Set ({len(evaluation_set_indices)} samples)\",\n",
    "    )\n",
    "\n",
    "    return ExperimentData(\n",
    "        active_learning=active_learning_data,\n",
    "        validation_dataset=split_dataset.validation,\n",
    "        test_dataset=split_dataset.test,\n",
    "        evaluation_dataset=evaluation_dataset,\n",
    "        train_augmentations=split_dataset.train_augmentations,\n",
    "        initial_training_set_indices=initial_training_set_indices,\n",
    "        evaluation_set_indices=evaluation_set_indices,\n",
    "        ood_dataset=original_ood_dataset,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-gates",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExperimentData(active_learning=<batchbald_redux.active_learning.ActiveLearningData object at 0x7f4340dc5850>, validation_dataset='MNIST (Validation, seed=0, 32 samples)', evaluation_dataset=Evaluation Set (10 samples), test_dataset='MNIST (Test)', train_augmentations=Sequential(), initial_training_set_indices=[46413, 55726, 25576, 55469, 39617, 35783, 36962, 56698, 4436, 24251, 27760, 7593, 15110, 21413, 31797, 42500, 34791, 46864, 47424, 57533], evaluation_set_indices=[43895, 47051, 56807, 13452, 39664, 38002, 53721, 37072, 18635, 52360], ood_dataset=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "load_experiment_data(\n",
    "    id_dataset_name=\"MNIST\",\n",
    "    initial_training_set_size=20,\n",
    "    validation_set_size=32,\n",
    "    evaluation_set_size=16,\n",
    "    id_repetitions=1.0,\n",
    "    add_dataset_noise=False,\n",
    "    validation_split_random_state=0,\n",
    "    ood_dataset_config=None,\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-advertising",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExperimentData(active_learning=<batchbald_redux.active_learning.ActiveLearningData object at 0x7f434caea280>, validation_dataset='CIFAR-10 (Validation, seed=0, 32 samples)', evaluation_dataset=Evaluation Set (10 samples), test_dataset='CIFAR-10 (Test)', train_augmentations=Sequential(\n",
       "  (0): RandomCrop(crop_size=(32, 32), padding=4, fill=0, pad_if_needed=False, padding_mode=constant, resample=BILINEAR, p=1.0, p_batch=1.0, same_on_batch=False, return_transform=False)\n",
       "  (1): RandomHorizontalFlip(p=0.5, p_batch=1.0, same_on_batch=False, return_transform=None)\n",
       "), initial_training_set_indices=[5618, 30732, 1910, 25225, 6409, 17895, 49063, 49577, 41071, 10377, 27423, 811, 27285, 22836, 26253, 5916, 49126, 40676, 31804, 13474], evaluation_set_indices=[36153, 11586, 36207, 16977, 1000, 10548, 11403, 2005, 41796, 25579], ood_dataset=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "load_experiment_data(\n",
    "    id_dataset_name=\"CIFAR-10\",\n",
    "    initial_training_set_size=20,\n",
    "    validation_set_size=32,\n",
    "    evaluation_set_size=16,\n",
    "    id_repetitions=1.0,\n",
    "    add_dataset_noise=False,\n",
    "    validation_split_random_state=0,\n",
    "    ood_dataset_config=None,\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-guest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExperimentData(active_learning=<batchbald_redux.active_learning.ActiveLearningData object at 0x7f434cd5ca90>, validation_dataset='CIFAR-10 (Validation, seed=0, 32 samples)', evaluation_dataset=Evaluation Set (10 samples), test_dataset='CIFAR-10 (Test)', train_augmentations=Sequential(\n",
       "  (0): RandomCrop(crop_size=(32, 32), padding=4, fill=0, pad_if_needed=False, padding_mode=constant, resample=BILINEAR, p=1.0, p_batch=1.0, same_on_batch=False, return_transform=False)\n",
       "  (1): RandomHorizontalFlip(p=0.5, p_batch=1.0, same_on_batch=False, return_transform=None)\n",
       "), initial_training_set_indices=[5618, 30732, 1910, 25225, 6409, 17895, 49063, 49577, 41071, 10377, 27423, 811, 27285, 22836, 26253, 5916, 49126, 40676, 31804, 13474], evaluation_set_indices=[36153, 11586, 36207, 16977, 1000, 10548, 11403, 2005, 41796, 25579], ood_dataset='CIFAR-100 (Train, seed=0, 50000 samples)')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "load_experiment_data(\n",
    "    id_dataset_name=\"CIFAR-10\",\n",
    "    initial_training_set_size=20,\n",
    "    validation_set_size=32,\n",
    "    evaluation_set_size=16,\n",
    "    id_repetitions=1.0,\n",
    "    add_dataset_noise=False,\n",
    "    validation_split_random_state=0,\n",
    "    ood_dataset_config=OoDDatasetConfig(ood_dataset_name=\"CIFAR-100\", ood_repetitions=1., ood_exposure=False),\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-maker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExperimentData(active_learning=<batchbald_redux.active_learning.ActiveLearningData object at 0x7f434db5f2e0>, validation_dataset='CIFAR-10 (Validation, seed=0, 32 samples)', evaluation_dataset=Evaluation Set (10 samples), test_dataset='CIFAR-10 (Test)', train_augmentations=Sequential(\n",
       "  (0): RandomCrop(crop_size=(32, 32), padding=4, fill=0, pad_if_needed=False, padding_mode=constant, resample=BILINEAR, p=1.0, p_batch=1.0, same_on_batch=False, return_transform=False)\n",
       "  (1): RandomHorizontalFlip(p=0.5, p_batch=1.0, same_on_batch=False, return_transform=None)\n",
       "), initial_training_set_indices=[5618, 30732, 1910, 25225, 6409, 17895, 49063, 49577, 41071, 10377, 27423, 811, 27285, 22836, 26253, 5916, 49126, 40676, 31804, 13474], evaluation_set_indices=[36153, 11586, 36207, 16977, 1000, 10548, 11403, 2005, 41796, 25579], ood_dataset='CIFAR-100 (Train, seed=0, 50000 samples)')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "load_experiment_data(\n",
    "    id_dataset_name=\"CIFAR-10\",\n",
    "    initial_training_set_size=20,\n",
    "    validation_set_size=32,\n",
    "    evaluation_set_size=16,\n",
    "    id_repetitions=1.0,\n",
    "    add_dataset_noise=False,\n",
    "    validation_split_random_state=0,\n",
    "    ood_dataset_config=OoDDatasetConfig(ood_dataset_name=\"CIFAR-100\", ood_repetitions=1., ood_exposure=True),\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-morrison",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:active_learning]",
   "language": "python",
   "name": "conda-env-active_learning-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
