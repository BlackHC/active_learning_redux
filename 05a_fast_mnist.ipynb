{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp fast_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import blackhc.project.script\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastMNIST\n",
    "> What the name says..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "from typing import Optional, Callable\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To speed up experiments, we are going to use Joost's FastMNIST (https://tinyurl.com/pytorch-fast-mnist), which preloads the dataset onto the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports fast_mnist\n",
    "from torchvision.datasets import MNIST, FashionMNIST\n",
    "\n",
    "\n",
    "# From https://tinyurl.com/pytorch-fast-mnist\n",
    "class FastMNIST(MNIST):\n",
    "    def __init__(self, root: str,\n",
    "                 train: bool = True,\n",
    "                 transform: Optional[Callable] = None,\n",
    "                 target_transform: Optional[Callable] = None,\n",
    "                 download: bool = False,\n",
    "                 *args, device, **kwargs):\n",
    "        super().__init__(root, train, transform, target_transform, download, *args, **kwargs)\n",
    "\n",
    "        # Scale data to [0,1]\n",
    "        self.data = self.data.unsqueeze(1).float().div(255)\n",
    "\n",
    "        # Normalize it with the usual MNIST mean and std\n",
    "        self.data = self.data.sub_(0.1307).div_(0.3081)\n",
    "\n",
    "        # Put both data and targets on GPU in advance\n",
    "        self.data, self.targets = self.data.to(device), self.targets.to(device)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        return img, target\n",
    "\n",
    "\n",
    "class FastFashionMNIST(FashionMNIST):\n",
    "    def __init__(self, root: str,\n",
    "            train: bool = True,\n",
    "            transform: Optional[Callable] = None,\n",
    "            target_transform: Optional[Callable] = None,\n",
    "            download: bool = False,\n",
    "            *args, device, **kwargs):\n",
    "        super().__init__(root, train, transform, target_transform, download, *args, **kwargs)\n",
    "\n",
    "        # Scale data to [0,1]\n",
    "        self.data = self.data.unsqueeze(1).float().div(255)\n",
    "\n",
    "        # Normalize it with the usual FashionMNIST mean and std\n",
    "        self.data = self.data.sub_(0.2861).div_(0.3530)\n",
    "\n",
    "        # Put both data and targets on GPU in advance\n",
    "        self.data, self.targets = self.data.to(device), self.targets.to(device)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        return img, target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
