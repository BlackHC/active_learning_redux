{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended /home/blackhc/PycharmProjects/bald-ical/src to paths\n",
      "Switched to directory /home/blackhc/PycharmProjects/bald-ical\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "import blackhc.project.script\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquisition Function: EPIG\n",
    "> Greedy algorithm and score computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will implement two helper classes to compute conditional entropies $H[y_i|w]$ and entropies $H[y_i]$. \n",
    "Then, we will implement BatchBALD and BALD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from blackhc.progress_bar import create_progress_bar\n",
    "from toma import toma\n",
    "\n",
    "from batchbald_redux.acquisition_functions.epig import * \n",
    "from batchbald_redux.joint_entropy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to define a couple of sampled distributions to use for our testing our code.\n",
    "\n",
    "$K=20$ means 20 inference samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mixture_prob_dist(p1, p2, m):\n",
    "    return (1.0 - m) * np.asarray(p1) + m * np.asarray(p2)\n",
    "\n",
    "\n",
    "p1 = [0.7, 0.1, 0.1, 0.1]\n",
    "p2 = [0.3, 0.3, 0.2, 0.2]\n",
    "y1_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "p1 = [0.1, 0.7, 0.1, 0.1]\n",
    "p2 = [0.2, 0.3, 0.3, 0.2]\n",
    "y2_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "p1 = [0.1, 0.1, 0.7, 0.1]\n",
    "p2 = [0.2, 0.2, 0.3, 0.3]\n",
    "y3_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "p1 = [0.1, 0.1, 0.1, 0.7]\n",
    "p2 = [0.3, 0.2, 0.2, 0.3]\n",
    "y4_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "\n",
    "def nested_to_tensor(l):\n",
    "    return torch.stack(list(map(torch.as_tensor, l)))\n",
    "\n",
    "\n",
    "ys_ws = nested_to_tensor([y1_ws, y2_ws, y3_ws, y4_ws])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "\n",
    "p = [0.25, 0.25, 0.25, 0.25]\n",
    "yu_ws = [p for m in range(K)]\n",
    "yus_ws = nested_to_tensor([yu_ws] * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 20, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_ws.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, our neural networks usually use a `log_softmax` as final layer. To avoid having to call `.exp_()`, which is easy to miss and annoying to debug, we will instead use a version that uses `log_probs` instead of `probs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "# Make sure everything is computed correctly.\n",
    "assert np.allclose(compute_conditional_entropy(yus_ws.log()), [1.3863, 1.3863, 1.3863, 1.3863], atol=0.1)\n",
    "assert np.allclose(compute_entropy(yus_ws.log()), [1.3863, 1.3863, 1.3863, 1.3863], atol=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2069, 1.2069, 1.2069, 1.2069], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "conditional_entropies = compute_conditional_entropy(ys_ws.log())\n",
    "\n",
    "print(conditional_entropies)\n",
    "\n",
    "assert np.allclose(conditional_entropies, [1.2069, 1.2069, 1.2069, 1.2069], atol=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2376, 1.2376, 1.2376, 1.2376], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "entropies = compute_entropy(ys_ws.log())\n",
    "\n",
    "print(entropies)\n",
    "\n",
    "assert np.allclose(entropies, [1.2376, 1.2376, 1.2376, 1.2376], atol=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EPIG-BALD\n",
    "\n",
    "The computation for EPIG-BALD is simple. We need to keep track of two separate (Batch)BALD terms:\n",
    "\n",
    "$$\\mathrm{I}\\left[(y)_{B} ; \\omega \\mid(x)_{B}, D_{T}\\right]-\\mathrm{I}\\left[(y)_{B} ; \\omega \\mid(x)_{B}, D_{U} \\cup D_{T}\\right].$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pleasing example of the case when predictions match (full overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BatchBALD:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.0, 0.0, 0.0, 0.0], indices=[0, 1, 2, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch_eval_bald_batch(\n",
    "    ys_ws.log().double(), ys_ws.log().double(), batch_size=4, num_samples=1000, dtype=torch.double\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BatchBALD:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.030715639666234917, 0.05961958627158248, 0.0869107051474467, 0.11275304532467878], indices=[1, 0, 2, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch_eval_bald_batch(\n",
    "    ys_ws.log().double(), torch.zeros_like(ys_ws).double(), batch_size=4, num_samples=1000, dtype=torch.double\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional EPIG-BALD variants\n",
    "\n",
    "Instead of using BatchBALD, let's compute BALD directly and use either the top-k, TopRandom or Thomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.0, 0.0, 0.0, 0.0], indices=[2, 3, 0, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_eval_bald_batch(ys_ws.log().double(), ys_ws.log().double(), batch_size=4, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.0, 0.0, 0.0, 0.0], indices=[1, 0, 3, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_random_eval_bald_batch(\n",
    "    ys_ws.log().double(), ys_ws.log().double(), batch_size=4, num_classes=10, dtype=torch.double\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EPIG\n",
    "\n",
    "As part of an ablation (and to see how it performs), we can also compute the ICAL score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_eig_scores(ys_ws.log().double(), ys_ws.log().double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BatchBALD:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.0, 0.0, 0.0, 0.0], indices=[0, 1, 2, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch_eig_batch(ys_ws.log().double(), ys_ws.log().double(), batch_size=4, num_samples=1000, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real EPIG\n",
    "\n",
    "Implement $I[Y_{acq} ; Y_{eval} \\mid x_{acq} ; X_{eval},  D_{train}]$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_joint_probs_N_C_C_old(pool_probs_N_K_C: torch.Tensor, single_eval_probs_K_C: torch.Tensor):\n",
    "    K = single_eval_probs_K_C.shape[0]\n",
    "\n",
    "    pool_log_probs_N_C_K = pool_probs_N_K_C.transpose(1, 2)\n",
    "    joint_probs_N_C_C = pool_log_probs_N_C_K @ single_eval_probs_K_C / K\n",
    "    return joint_probs_N_C_C\n",
    "\n",
    "\n",
    "def get_real_naive_epig_scores_old(\n",
    "    *, pool_log_probs_N_K_C: torch.Tensor, eval_log_probs_E_K_C: torch.Tensor, dtype=None, device=None\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Implements naive EPIG: I[Y_acq; Y_eval | x_acq, X_eval].\"\"\"\n",
    "    N, K, C = pool_log_probs_N_K_C.shape\n",
    "    E, _, _ = eval_log_probs_E_K_C.shape\n",
    "    assert (\n",
    "        pool_log_probs_N_K_C.shape[1:] == pool_log_probs_N_K_C.shape[1:]\n",
    "    ), \"{pool_log_probs_N_K_C.shape[1:]} != {pool_log_probs_N_K_C.shape[1:]}\"\n",
    "\n",
    "    pool_probs_N_K_C = pool_log_probs_N_K_C.to(dtype=dtype, device=device).exp()\n",
    "    eval_probs_E_K_C = eval_log_probs_E_K_C.to(dtype=dtype, device=device).exp()\n",
    "\n",
    "    pool_probs_N_C = torch.mean(pool_probs_N_K_C, dim=1, keepdim=False)\n",
    "\n",
    "    total_scores_N = torch.zeros((N,), dtype=dtype, device=\"cpu\")\n",
    "    for i_e in with_progress_bar(range(E), tqdm_args=dict(desc=\"Evaluation Set\", leave=False)):\n",
    "        single_eval_probs_K_C = eval_probs_E_K_C[i_e]\n",
    "\n",
    "        joint_probs_N_C_C = get_joint_probs_N_C_C_old(pool_probs_N_K_C, single_eval_probs_K_C)\n",
    "\n",
    "        single_eval_probs_C = torch.mean(single_eval_probs_K_C, dim=0, keepdim=False)\n",
    "\n",
    "        nats_N_C_C = (\n",
    "            -torch.log(single_eval_probs_C)[None, None, :]\n",
    "            - torch.log(pool_probs_N_C)[:, :, None]\n",
    "            + torch.log(joint_probs_N_C_C)\n",
    "        )\n",
    "\n",
    "        weighted_nats_N_C_C = nats_N_C_C * joint_probs_N_C_C\n",
    "        weighted_nats_N_C_C[torch.isnan(weighted_nats_N_C_C)] = 0.0\n",
    "        scores_N = weighted_nats_N_C_C.sum((1, 2), keepdim=False)\n",
    "\n",
    "        total_scores_N += scores_N.to(device=\"cpu\", non_blocking=True)\n",
    "\n",
    "    total_scores_N /= E\n",
    "\n",
    "    return total_scores_N"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# This is not working at the moment sadly :(((\n",
    "\n",
    "\n",
    "def simple_compute_entropy(log_probs_N_K_C: torch.Tensor) -> torch.Tensor:\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "\n",
    "    mean_log_probs_N_C = torch.logsumexp(log_probs_N_K_C.to(dtype=torch.double), dim=1) - math.log(K)\n",
    "    nats_N_C = mean_log_probs_N_C * torch.exp(mean_log_probs_N_C)\n",
    "\n",
    "    entropies_N = -torch.sum(nats_N_C, dim=1)\n",
    "\n",
    "    return entropies_N\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "@torch.jit.script\n",
    "def _get_real_naive_epig_scores(\n",
    "    bootstrap_type: int,\n",
    "    bootstrap_factor: float,\n",
    "    pool_log_probs_N_K_C: torch.Tensor,\n",
    "    eval_log_probs_E_K_C: torch.Tensor,\n",
    "    dtype: int,\n",
    "    device: torch.device,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Implements naive EPIG: I[Y_acq; Y_eval | x_acq, X_eval].\"\"\"\n",
    "    # I[Y_acq; Y_eval | x_acq, X_eval] = H[Y_acq | x_acq] + E_p(x_eval)[H[Y_eval | x_eval] - H[Y_acq, Y_eval | x_acq, x_eval]]\n",
    "    N, K, C = pool_log_probs_N_K_C.shape\n",
    "    E, _, _ = eval_log_probs_E_K_C.shape\n",
    "    assert (\n",
    "        pool_log_probs_N_K_C.shape[1:] == pool_log_probs_N_K_C.shape[1:]\n",
    "    ), \"{pool_log_probs_N_K_C.shape[1:]} != {pool_log_probs_N_K_C.shape[1:]}\"\n",
    "\n",
    "    pool_entropies_N = simple_compute_entropy(pool_log_probs_N_K_C)\n",
    "\n",
    "    pool_probs_N_K_C = pool_log_probs_N_K_C.to(dtype=dtype, device=device).exp()\n",
    "    eval_probs_E_K_C = eval_log_probs_E_K_C.to(dtype=dtype, device=device).exp()\n",
    "\n",
    "    total_joint_entropies_N = torch.zeros((N,), dtype=dtype, device=\"cpu\")\n",
    "\n",
    "    if bootstrap_type != 2:\n",
    "        eval_label_uncertainty = simple_compute_entropy(eval_log_probs_E_K_C).mean(dim=0, keepdim=False)\n",
    "\n",
    "        if bootstrap_type == 0:\n",
    "            eval_range = torch.arange(E)\n",
    "        elif bootstrap_type == 1:\n",
    "            num_eval_samples = int(E * bootstrap_factor)\n",
    "            eval_range = torch.multinomial(torch.tensor(1.0).expand(E), num_samples=num_eval_samples, replacement=True)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown bootstrap {bootstrap_type}\")\n",
    "\n",
    "        for i_e in eval_range:\n",
    "            single_eval_probs_K_C = eval_probs_E_K_C[i_e]\n",
    "\n",
    "            joint_probs_N_C_C = get_joint_probs_N_C_C(pool_probs_N_K_C, single_eval_probs_K_C)\n",
    "            weighted_nats_N_C_C = joint_probs_N_C_C * -torch.log(joint_probs_N_C_C)\n",
    "            joint_entropy_N = weighted_nats_N_C_C.sum((1, 2), keepdim=False)\n",
    "            # del weighted_nats_N_C_C\n",
    "\n",
    "            total_joint_entropies_N += joint_entropy_N.to(device=\"cpu\", non_blocking=True)\n",
    "\n",
    "        total_scores_N = pool_entropies_N - total_joint_entropies_N / E + eval_label_uncertainty\n",
    "    else:\n",
    "        eval_label_uncertainty_E = simple_compute_entropy(eval_log_probs_E_K_C)\n",
    "\n",
    "        total_scores_N = pool_entropies_N\n",
    "\n",
    "        for i_n in range(N):\n",
    "            single_pool_probs_K_C = pool_probs_N_K_C[i_n]\n",
    "\n",
    "            num_eval_samples = int(E * bootstrap_factor)\n",
    "            eval_indices = torch.multinomial(\n",
    "                torch.tensor(1.0).expand(E), num_samples=num_eval_samples, replacement=True\n",
    "            )\n",
    "            # For debugging:\n",
    "            # num_eval_samples = E\n",
    "            # eval_indices = torch.tensor(list(range(E)))\n",
    "\n",
    "            sampled_eval_probs_F_K_C = eval_probs_E_K_C[eval_indices]\n",
    "\n",
    "            joint_probs_F_C_C = get_joint_probs_N_C_C(sampled_eval_probs_F_K_C, single_pool_probs_K_C)\n",
    "            weighted_nats_F_C_C = joint_probs_F_C_C * -torch.log(joint_probs_F_C_C)\n",
    "            avg_joint_entropy = weighted_nats_F_C_C.sum().to(device=\"cpu\", non_blocking=True) / num_eval_samples\n",
    "            # del weighted_nats_F_C_C\n",
    "\n",
    "            eval_label_uncertainty = eval_label_uncertainty_E[eval_indices].mean(dim=0, keepdim=False)\n",
    "            total_scores_N[i_n] += eval_label_uncertainty - avg_joint_entropy\n",
    "\n",
    "    return total_scores_N\n",
    "\n",
    "\n",
    "def get_real_naive_epig_scores(\n",
    "    *,\n",
    "    bootstrap_type=BootstrapType.NO_BOOTSTRAP,\n",
    "    bootstrap_factor=1.0,\n",
    "    pool_log_probs_N_K_C: torch.Tensor,\n",
    "    eval_log_probs_E_K_C: torch.Tensor,\n",
    "    dtype=torch.float,\n",
    "    device=None,\n",
    ") -> torch.Tensor:\n",
    "    return _get_real_naive_epig_scores(\n",
    "        bootstrap_type.value, bootstrap_factor, pool_log_probs_N_K_C, eval_log_probs_E_K_C, dtype, device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "# def logmatmulexp(log_A: torch.Tensor, log_B: torch.Tensor) -> torch.Tensor:\n",
    "#     \"\"\"Given matrix log_A of shape (batch...) ϴ×R and matrix log_B of shape R×I, calculates\n",
    "#     (log_A.exp() @ log_B.exp()).log() and its backward in a numerically stable way.\"\"\"\n",
    "#     batch_shape = list(log_A.shape[:-2])\n",
    "#     ϴ, R = log_A.shape[-2:]\n",
    "#     I = log_B.shape[-1]\n",
    "#     assert log_B.shape == (R, I)\n",
    "#     log_A_expanded = log_A.unsqueeze(-1).expand(batch_shape + [ϴ, R, I])\n",
    "#     log_B_expanded = log_B.unsqueeze(-3).expand((ϴ, R, I))\n",
    "#     log_pairwise_products = log_A_expanded + log_B_expanded  # shape: (ϴ, R, I)\n",
    "#     return torch.logsumexp(log_pairwise_products, dim=-2)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def logmatmulexp(log_A: torch.Tensor, log_B: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Given matrix log_A of shape (batch...) ϴ×R and matrix log_B of shape R×I, calculates\n",
    "    (log_A.exp() @ log_B.exp()).log() and its backward in a numerically stable way.\"\"\"\n",
    "    max_A = torch.max(log_A, axis=-1, keepdim=True)[0]\n",
    "    max_B = torch.max(log_B, axis=-2, keepdim=True)[0]\n",
    "    C = torch.log((log_A - max_A).exp() @ (log_B - max_B).exp()) + max_A + max_B\n",
    "    return C\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_real_naive_epig_scores_stable(\n",
    "    *,\n",
    "    bootstrap_type=BootstrapType.NO_BOOTSTRAP,\n",
    "    bootstrap_factor=1.0,\n",
    "    pool_log_probs_N_K_C: torch.Tensor,\n",
    "    eval_log_probs_E_K_C: torch.Tensor,\n",
    "    dtype=None,\n",
    "    device=None,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Implements naive EPIG: I[Y_acq; Y_eval | x_acq, X_eval].\"\"\"\n",
    "    # I[Y_acq; Y_eval | x_acq, X_eval] = H[Y_acq | x_acq] + E_p(x_eval)[H[Y_eval | x_eval] - H[Y_acq, Y_eval | x_acq, x_eval]]\n",
    "    N, K, C = pool_log_probs_N_K_C.shape\n",
    "    E, _, _ = eval_log_probs_E_K_C.shape\n",
    "    assert (\n",
    "        pool_log_probs_N_K_C.shape[1:] == pool_log_probs_N_K_C.shape[1:]\n",
    "    ), \"{pool_log_probs_N_K_C.shape[1:]} != {pool_log_probs_N_K_C.shape[1:]}\"\n",
    "\n",
    "    pool_entropies_N = compute_entropy(pool_log_probs_N_K_C).to(device=device)\n",
    "\n",
    "    total_joint_entropies_N = torch.zeros((N,), dtype=dtype, device=device)\n",
    "\n",
    "    if bootstrap_type != BootstrapType.PER_POINT_BOOTSTRAP:\n",
    "        eval_label_uncertainty = compute_entropy(eval_log_probs_E_K_C).mean(dim=0, keepdim=False)\n",
    "\n",
    "        if bootstrap_type == BootstrapType.NO_BOOTSTRAP:\n",
    "            eval_range = range(E)\n",
    "        elif bootstrap_type == BootstrapType.SINGLE_BOOTSTRAP:\n",
    "            num_eval_samples = int(E * bootstrap_factor)\n",
    "            eval_range = torch.multinomial(torch.tensor(1.0).expand(E), num_samples=num_eval_samples, replacement=True)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown bootstrap {bootstrap_type}\")\n",
    "\n",
    "        pool_log_probs_N_C_K = pool_log_probs_N_K_C.transpose(1, 2).contiguous().to(dtype=dtype, device=device)\n",
    "        eval_log_probs_E_K_C = eval_log_probs_E_K_C.to(dtype=dtype, device=device)\n",
    "\n",
    "        for i_e in with_progress_bar(eval_range, tqdm_args=dict(desc=\"Evaluation Set\", leave=False)):\n",
    "            single_eval_log_probs_K_C = eval_log_probs_E_K_C[i_e]\n",
    "\n",
    "            joint_probs_N_C_C = logmatmulexp(pool_log_probs_N_C_K, single_eval_log_probs_K_C) - np.log(K)\n",
    "            weighted_nats_N_C_C = joint_probs_N_C_C * -torch.exp(joint_probs_N_C_C)\n",
    "            weighted_nats_N_C_C[torch.isnan(weighted_nats_N_C_C)] = 0.0\n",
    "            joint_entropy_N = weighted_nats_N_C_C.sum((1, 2), keepdim=False)\n",
    "            del weighted_nats_N_C_C\n",
    "\n",
    "            total_joint_entropies_N += joint_entropy_N\n",
    "\n",
    "        total_scores_N = pool_entropies_N - total_joint_entropies_N / E + eval_label_uncertainty\n",
    "    #     elif bootstrap_type == BootstrapType.PER_POINT_BOOTSTRAP:\n",
    "    #         eval_label_uncertainty_E = compute_entropy(eval_log_probs_E_K_C)\n",
    "\n",
    "    #         total_scores_N = pool_entropies_N\n",
    "\n",
    "    #         for i_n in with_progress_bar(range(N), tqdm_args=dict(desc=\"Pool Set\", leave=False)):\n",
    "    #             single_pool_probs_K_C = pool_probs_N_K_C[i_n]\n",
    "\n",
    "    #             num_eval_samples = int(E * bootstrap_factor)\n",
    "    #             eval_indices = torch.multinomial(\n",
    "    #                 torch.tensor(1.0).expand(E), num_samples=num_eval_samples, replacement=True\n",
    "    #             )\n",
    "    #             # For debugging:\n",
    "    #             # num_eval_samples = E\n",
    "    #             # eval_indices = torch.tensor(list(range(E)))\n",
    "\n",
    "    #             sampled_eval_probs_F_K_C = eval_probs_E_K_C[eval_indices]\n",
    "\n",
    "    #             joint_probs_F_C_C = get_joint_probs_N_C_C(sampled_eval_probs_F_K_C, single_pool_probs_K_C)\n",
    "    #             weighted_nats_F_C_C = joint_probs_F_C_C * -torch.log(joint_probs_F_C_C)\n",
    "    #             avg_joint_entropy = weighted_nats_F_C_C.sum() / num_eval_samples\n",
    "    #             del weighted_nats_F_C_C\n",
    "\n",
    "    #             eval_label_uncertainty = eval_label_uncertainty_E[eval_indices].mean(dim=0, keepdim=False)\n",
    "    #             total_scores_N[i_n] += eval_label_uncertainty - avg_joint_entropy\n",
    "\n",
    "    return total_scores_N.to(device=\"cpu\", non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_log_probs_N_K_C = torch.log_softmax(torch.randn(7, 13, 3) * 100, dim=2)\n",
    "eval_log_probs_E_K_C = torch.log_softmax(torch.randn(11, 13, 3) * 100, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation Set:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation Set:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2034, 0.2925, 0.2823, 0.2413, 0.1856, 0.1703, 0.1390],\n",
      "       dtype=torch.float64) tensor([0.2034, 0.2925, 0.2823, 0.2413, 0.1856, 0.1703, 0.1390],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation Set:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation Set:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2034, 0.2925, 0.2823, 0.2413, 0.1856, 0.1703, 0.1390],\n",
      "       dtype=torch.float64) tensor([0.2034, 0.2925, 0.2823, 0.2413, 0.1856, 0.1703, 0.1390],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for dtype in (torch.float32, torch.double):\n",
    "    print(\n",
    "        get_real_naive_epig_scores(\n",
    "            pool_log_probs_N_K_C=pool_log_probs_N_K_C,\n",
    "            eval_log_probs_E_K_C=eval_log_probs_E_K_C,\n",
    "            device=\"cuda\",\n",
    "            dtype=dtype,\n",
    "        ),\n",
    "        get_real_naive_epig_scores_stable(\n",
    "            pool_log_probs_N_K_C=pool_log_probs_N_K_C,\n",
    "            eval_log_probs_E_K_C=eval_log_probs_E_K_C,\n",
    "            device=\"cuda\",\n",
    "            dtype=dtype,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation Set:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation Set:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.2034, 0.2925, 0.2823, 0.2413, 0.1856, 0.1703, 0.1390],\n",
       "        dtype=torch.float64),\n",
       " tensor([0.2034, 0.2925, 0.2823, 0.2413, 0.1856, 0.1703, 0.1390]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_real_naive_epig_scores(\n",
    "    pool_log_probs_N_K_C=pool_log_probs_N_K_C, eval_log_probs_E_K_C=eval_log_probs_E_K_C, device=\"cuda\"\n",
    "), get_real_naive_epig_scores_old(\n",
    "    pool_log_probs_N_K_C=pool_log_probs_N_K_C, eval_log_probs_E_K_C=eval_log_probs_E_K_C, device=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pool Set:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.1770, 0.2326, 0.1526, 0.2323, 0.1525, 0.2118, 0.1741],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_real_naive_epig_scores(\n",
    "    bootstrap_type=BootstrapType.PER_POINT_BOOTSTRAP,\n",
    "    pool_log_probs_N_K_C=pool_log_probs_N_K_C,\n",
    "    eval_log_probs_E_K_C=eval_log_probs_E_K_C,\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation Set:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.1971, 0.1683, 0.1589, 0.1959, 0.1634, 0.2245, 0.1531],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_real_naive_epig_scores(\n",
    "    bootstrap_type=BootstrapType.SINGLE_BOOTSTRAP,\n",
    "    pool_log_probs_N_K_C=pool_log_probs_N_K_C,\n",
    "    eval_log_probs_E_K_C=eval_log_probs_E_K_C,\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575090b90187402e9d9204fb7fb46059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation Set:   0%|          | 0/60000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-9af49b935316>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     get_real_naive_epig_scores_old(\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mpool_log_probs_N_K_C\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0meval_log_probs_E_K_C\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-3282b1f8025e>\u001b[0m in \u001b[0;36mget_real_naive_epig_scores_old\u001b[0;34m(pool_log_probs_N_K_C, eval_log_probs_E_K_C, dtype, device)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mweighted_nats_N_C_C\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnats_N_C_C\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mjoint_probs_N_C_C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mweighted_nats_N_C_C\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweighted_nats_N_C_C\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mscores_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweighted_nats_N_C_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "num_samples = 60000\n",
    "\n",
    "with torch.no_grad():\n",
    "    X = torch.log_softmax(torch.randn(num_samples, 100, 10), dim=2)\n",
    "    Y = torch.log_softmax(torch.randn(num_samples, 100, 10), dim=2)\n",
    "    get_real_naive_epig_scores(\n",
    "        pool_log_probs_N_K_C=X,\n",
    "        eval_log_probs_E_K_C=Y,\n",
    "        dtype=torch.double,\n",
    "        device=\"cuda\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# slow\n",
    "\n",
    "num_samples = 6000\n",
    "\n",
    "with torch.no_grad():\n",
    "    get_real_naive_epig_scores_old(\n",
    "        pool_log_probs_N_K_C=X,\n",
    "        eval_log_probs_E_K_C=Y,\n",
    "        dtype=torch.float,\n",
    "        device=\"cuda\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "\n",
    "with torch.no_grad():\n",
    "    get_real_naive_epig_scores(\n",
    "        bootstrap_type=BootstrapType.PER_POINT_BOOTSTRAP,\n",
    "        bootstrap_factor=1,\n",
    "        pool_log_probs_N_K_C=torch.log_softmax(torch.randn(num_samples, 100, 10), dim=2),\n",
    "        eval_log_probs_E_K_C=torch.log_softmax(torch.randn(num_samples, 100, 10), dim=2),\n",
    "        device=\"cuda\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "\n",
    "with torch.no_grad():\n",
    "    get_real_naive_epig_scores(\n",
    "        bootstrap_type=BootstrapType.SINGLE_BOOTSTRAP,\n",
    "        bootstrap_factor=0.85,\n",
    "        pool_log_probs_N_K_C=torch.log_softmax(torch.randn(num_samples, 100, 10), dim=2),\n",
    "        eval_log_probs_E_K_C=torch.log_softmax(torch.randn(num_samples, 100, 10), dim=2),\n",
    "        device=\"cuda\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:active_learning]",
   "language": "python",
   "name": "conda-env-active_learning-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
