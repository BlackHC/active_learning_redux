{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp batchbald"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended /home/blackhc/PycharmProjects/bald-ical/src to paths\n",
      "Switched to directory /home/blackhc/PycharmProjects/bald-ical\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "import blackhc.project.script\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BatchBALD Algorithm\n",
    "> Greedy algorithm and score computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will implement two helper classes to compute conditional entropies $H[y_i|w]$ and entropies $H[y_i]$. \n",
    "Then, we will implement BatchBALD and BALD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from toma import toma\n",
    "from blackhc.progress_bar import with_progress_bar, create_progress_bar\n",
    "\n",
    "from batchbald_redux import joint_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to define a couple of sampled distributions to use for our testing our code.\n",
    "\n",
    "$K=20$ means 20 inference samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mixture_prob_dist(p1, p2, m):\n",
    "    return (1.0 - m) * np.asarray(p1) + m * np.asarray(p2)\n",
    "\n",
    "\n",
    "p1 = [0.7, 0.1, 0.1, 0.1]\n",
    "p2 = [0.3, 0.3, 0.2, 0.2]\n",
    "y1_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "p1 = [0.1, 0.7, 0.1, 0.1]\n",
    "p2 = [0.2, 0.3, 0.3, 0.2]\n",
    "y2_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "p1 = [0.1, 0.1, 0.7, 0.1]\n",
    "p2 = [0.2, 0.2, 0.3, 0.3]\n",
    "y3_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "p1 = [0.1, 0.1, 0.1, 0.7]\n",
    "p2 = [0.3, 0.2, 0.2, 0.3]\n",
    "y4_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "\n",
    "def nested_to_tensor(l):\n",
    "    return torch.stack(list(map(torch.as_tensor, l)))\n",
    "\n",
    "\n",
    "ys_ws = nested_to_tensor([y1_ws, y2_ws, y3_ws, y4_ws])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "\n",
    "p = [0.25, 0.25, 0.25, 0.25]\n",
    "yu_ws = [p for m in range(K)]\n",
    "yus_ws = nested_to_tensor([yu_ws] * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 20, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_ws.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Entropies and Batched Entropies\n",
    "\n",
    "To start with, we write two functions to compute the conditional entropy $H[y_i|w]$ and the entropy $H[y_i]$ for each input sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_conditional_entropy(probs_N_K_C: torch.Tensor) -> torch.Tensor:\n",
    "    N, K, C = probs_N_K_C.shape\n",
    "\n",
    "    entropies_N = torch.empty(N, dtype=torch.double)\n",
    "\n",
    "    pbar = create_progress_bar(N, tqdm_args=dict(desc=\"Conditional Entropy\", leave=False))\n",
    "    pbar.start()\n",
    "    \n",
    "    @toma.execute.chunked(probs_N_K_C, 1024)\n",
    "    def compute(probs_n_K_C, start: int, end: int):\n",
    "        nats_n_K_C = probs_n_K_C * torch.log(probs_n_K_C)\n",
    "        nats_n_K_C[probs_n_K_C == 0] = 0.0\n",
    "\n",
    "        entropies_N[start:end].copy_(-torch.sum(nats_n_K_C, dim=(1, 2)) / K)\n",
    "        pbar.update(end - start)\n",
    "\n",
    "    pbar.finish()\n",
    "\n",
    "    return entropies_N\n",
    "\n",
    "\n",
    "def compute_entropy(probs_N_K_C: torch.Tensor) -> torch.Tensor:\n",
    "    N, K, C = probs_N_K_C.shape\n",
    "\n",
    "    entropies_N = torch.empty(N, dtype=torch.double)\n",
    "\n",
    "    pbar = create_progress_bar(N, tqdm_args=dict(desc=\"Entropy\", leave=False))\n",
    "    pbar.start()\n",
    "\n",
    "    @toma.execute.chunked(probs_N_K_C, 1024)\n",
    "    def compute(probs_n_K_C, start: int, end: int):\n",
    "        mean_probs_n_C = probs_n_K_C.mean(dim=1)\n",
    "        nats_n_C = mean_probs_n_C * torch.log(mean_probs_n_C)\n",
    "        nats_n_C[mean_probs_n_C == 0] = 0.0\n",
    "\n",
    "        entropies_N[start:end].copy_(-torch.sum(nats_n_C, dim=1))\n",
    "        pbar.update(end - start)\n",
    "\n",
    "    pbar.finish()\n",
    "\n",
    "    return entropies_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make sure everything is computed correctly.\n",
    "\n",
    "assert np.allclose(compute_conditional_entropy(yus_ws), [1.3863, 1.3863, 1.3863, 1.3863], atol=0.1)\n",
    "assert np.allclose(compute_entropy(yus_ws), [1.3863, 1.3863, 1.3863, 1.3863], atol=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, our neural networks usually use a `log_softmax` as final layer. To avoid having to call `.exp_()`, which is easy to miss and annoying to debug, we will instead use a version that uses `log_probs` instead of `probs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "def compute_conditional_entropy(log_probs_N_K_C: torch.Tensor) -> torch.Tensor:\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "\n",
    "    entropies_N = torch.empty(N, dtype=torch.double)\n",
    "\n",
    "    pbar = create_progress_bar(N, tqdm_args=dict(desc=\"Conditional Entropy\", leave=False))\n",
    "    pbar.start()\n",
    "\n",
    "    @toma.execute.chunked(log_probs_N_K_C, 1024)\n",
    "    def compute(log_probs_n_K_C, start: int, end: int):\n",
    "        nats_n_K_C = log_probs_n_K_C * torch.exp(log_probs_n_K_C)\n",
    "\n",
    "        entropies_N[start:end].copy_(-torch.sum(nats_n_K_C, dim=(1, 2)) / K)\n",
    "        pbar.update(end - start)\n",
    "\n",
    "    pbar.finish()\n",
    "\n",
    "    return entropies_N\n",
    "\n",
    "\n",
    "def compute_entropy(log_probs_N_K_C: torch.Tensor) -> torch.Tensor:\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "\n",
    "    entropies_N = torch.empty(N, dtype=torch.double)\n",
    "\n",
    "    pbar = create_progress_bar(N, tqdm_args=dict(desc=\"Entropy\", leave=False))\n",
    "    pbar.start()\n",
    "\n",
    "    @toma.execute.chunked(log_probs_N_K_C, 1024)\n",
    "    def compute(log_probs_n_K_C, start: int, end: int):\n",
    "        mean_log_probs_n_C = torch.logsumexp(log_probs_n_K_C, dim=1) - math.log(K)\n",
    "        nats_n_C = mean_log_probs_n_C * torch.exp(mean_log_probs_n_C)\n",
    "\n",
    "        entropies_N[start:end].copy_(-torch.sum(nats_n_C, dim=1))\n",
    "        pbar.update(end - start)\n",
    "\n",
    "    pbar.finish()\n",
    "\n",
    "    return entropies_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "# Make sure everything is computed correctly.\n",
    "assert np.allclose(compute_conditional_entropy(yus_ws.log()), [1.3863, 1.3863, 1.3863, 1.3863], atol=0.1)\n",
    "assert np.allclose(compute_entropy(yus_ws.log()), [1.3863, 1.3863, 1.3863, 1.3863], atol=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2069, 1.2069, 1.2069, 1.2069], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "conditional_entropies = compute_conditional_entropy(ys_ws.log())\n",
    "\n",
    "print(conditional_entropies)\n",
    "\n",
    "assert np.allclose(conditional_entropies, [1.2069, 1.2069, 1.2069, 1.2069], atol=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2376, 1.2376, 1.2376, 1.2376], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "entropies = compute_entropy(ys_ws.log())\n",
    "\n",
    "print(entropies)\n",
    "\n",
    "assert np.allclose(entropies, [1.2376, 1.2376, 1.2376, 1.2376], atol=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BatchBALD\n",
    "\n",
    "To compute BatchBALD exactly for a candidate batch, we'd have to compute $I[(y_b)_B;w] = H[(y_b)_B] - H[(y_b)_B|w]$.\n",
    "\n",
    "As the $y_b$ are independent given $w$, we can simplify $H[(y_b)_B|w] = \\sum_b H[y_b|w]$.\n",
    "\n",
    "Furthermore, we use a greedy algorithm to build up the candidate batch, so $y_1,\\dots,y_{B-1}$ will stay fixed as we determine $y_{B}$. We compute\n",
    "$H[(y_b)_{B-1}, y_i] - H[y_i|w]$ for each pool element $y_i$ and add the highest scorer as $y_{B}$.\n",
    "\n",
    "We don't utilize the last optimization here in order to compute the actual scores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the Paper\n",
    "\n",
    "![BatchBALD algorithm in the paper](batchbald_algorithm.png)\n",
    "\n",
    "\n",
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CandidateBatch:\n",
    "    scores: List[float]\n",
    "    indices: List[int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "class BatchBALDScorer:\n",
    "    log_probs_N_K_C: torch.tensor\n",
    "    conditional_entropies_N: torch.Tensor\n",
    "    batch_joint_entropy: joint_entropy.JointEntropy\n",
    "    batch_conditional_entropies: torch.Tensor\n",
    "\n",
    "    def __init__(self, log_probs_N_K_C, *, max_size, num_samples: int, dtype=None, device=None):\n",
    "        N, K, C = log_probs_N_K_C.shape\n",
    "        self.log_probs_N_K_C = log_probs_N_K_C\n",
    "\n",
    "        self.conditional_entropies_N = compute_conditional_entropy(self.log_probs_N_K_C)\n",
    "        self.batch_conditional_entropies = 0\n",
    "\n",
    "        self.batch_joint_entropy = joint_entropy.DynamicJointEntropy(\n",
    "            num_samples, max_size, K, C, dtype=dtype, device=device\n",
    "        )\n",
    "\n",
    "    def append_to_batch(self, index: int):\n",
    "        self.batch_joint_entropy.add_variables(self.log_probs_N_K_C[index : index + 1])\n",
    "        self.batch_conditional_entropies += self.conditional_entropies_N[index].clone()\n",
    "\n",
    "    def alloc_scores(self) -> torch.Tensor:\n",
    "        # We always keep these on the CPU.\n",
    "        scores_N = torch.empty(\n",
    "            self.log_probs_N_K_C.shape[0],\n",
    "            dtype=torch.double,\n",
    "            pin_memory=torch.cuda.is_available(),\n",
    "        )\n",
    "        return scores_N\n",
    "\n",
    "    def compute_scores(self, out_scores_N: torch.Tensor):\n",
    "        self.batch_joint_entropy.compute_batch(self.log_probs_N_K_C, output_entropies_B=out_scores_N)\n",
    "\n",
    "        out_scores_N -= self.conditional_entropies_N + self.batch_conditional_entropies\n",
    "\n",
    "        return out_scores_N\n",
    "\n",
    "\n",
    "def get_batch_bald_batch(\n",
    "    log_probs_N_K_C: torch.Tensor, *, batch_size: int, num_samples: int, dtype=None, device=None\n",
    ") -> CandidateBatch:\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    candidate_indices = []\n",
    "    candidate_scores = []\n",
    "\n",
    "    if batch_size == 0:\n",
    "        return CandidateBatch(candidate_scores, candidate_indices)\n",
    "\n",
    "    batchbald_scorer = BatchBALDScorer(\n",
    "        log_probs_N_K_C,\n",
    "        max_size=batch_size - 1,\n",
    "        num_samples=num_samples,\n",
    "        dtype=dtype,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # We always keep these on the CPU.\n",
    "    scores_N = batchbald_scorer.alloc_scores()\n",
    "\n",
    "    for i in with_progress_bar(range(batch_size), tqdm_args=dict(desc=\"BatchBALD\", leave=False)):\n",
    "        if i > 0:\n",
    "            latest_index = candidate_indices[-1]\n",
    "            batchbald_scorer.append_to_batch(latest_index)\n",
    "\n",
    "        batchbald_scorer.compute_scores(scores_N)\n",
    "        scores_N[candidate_indices] = -float(\"inf\")\n",
    "\n",
    "        candidate_score, candidate_index = scores_N.max(dim=0)\n",
    "\n",
    "        candidate_indices.append(candidate_index.item())\n",
    "        candidate_scores.append(candidate_score.item())\n",
    "\n",
    "    return CandidateBatch(candidate_scores, candidate_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batchbald_batch_plain(\n",
    "    log_probs_N_K_C: torch.Tensor,\n",
    "    *,\n",
    "    batch_size: int,\n",
    "    num_samples: int,\n",
    "    dtype=None,\n",
    "    device=None,\n",
    ") -> CandidateBatch:\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    candidate_indices = []\n",
    "    candidate_scores = []\n",
    "\n",
    "    if batch_size == 0:\n",
    "        return CandidateBatch(candidate_scores, candidate_indices)\n",
    "\n",
    "    conditional_entropies_N = compute_conditional_entropy(log_probs_N_K_C)\n",
    "\n",
    "    batch_joint_entropy = joint_entropy.DynamicJointEntropy(\n",
    "        num_samples, batch_size - 1, K, C, dtype=dtype, device=device\n",
    "    )\n",
    "\n",
    "    # We always keep these on the CPU.\n",
    "    scores_N = torch.empty(N, dtype=torch.double, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "    for i in with_progress_bar(range(batch_size), tqdm_args=dict(desc=\"BatchBALD\", leave=False)):\n",
    "        if i > 0:\n",
    "            latest_index = candidate_indices[-1]\n",
    "            batch_joint_entropy.add_variables(log_probs_N_K_C[latest_index : latest_index + 1])\n",
    "\n",
    "        shared_conditional_entropies = conditional_entropies_N[candidate_indices].sum()\n",
    "\n",
    "        batch_joint_entropy.compute_batch(log_probs_N_K_C, output_entropies_B=scores_N)\n",
    "\n",
    "        scores_N -= conditional_entropies_N + shared_conditional_entropies\n",
    "        scores_N[candidate_indices] = -float(\"inf\")\n",
    "\n",
    "        candidate_score, candidate_index = scores_N.max(dim=0)\n",
    "\n",
    "        candidate_indices.append(candidate_index.item())\n",
    "        candidate_scores.append(candidate_score.item())\n",
    "\n",
    "    return CandidateBatch(candidate_scores, candidate_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BatchBALD:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.030715639666234917, 0.05961958627158248, 0.0869107051474467, 0.11275304532467878], indices=[1, 0, 2, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch_bald_batch(ys_ws.log().double(), batch_size=4, num_samples=1000, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BatchBALD:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.030715639666234917, 0.05961958627158248, 0.0869107051474467, 0.11275304532467878], indices=[1, 0, 2, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batchbald_batch_plain(ys_ws.log().double(), batch_size=4, num_samples=1000, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BALD\n",
    "\n",
    "BALD is the same as BatchBALD, except that we evaluate_old points individually, by computing $I[y_i;w]$ for each, and then take the top $B$ scorers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BALD scores\n",
    "\n",
    "Sometimes, we want to obtain BALD scores for all samples as measure of epistemic uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "# TODO: remove unused parameters!\n",
    "def get_bald_scores(log_probs_N_K_C: torch.Tensor, *, dtype=None, device=None) -> torch.Tensor:\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "\n",
    "    scores_N = -compute_conditional_entropy(log_probs_N_K_C)\n",
    "    scores_N += compute_entropy(log_probs_N_K_C)\n",
    "\n",
    "    return scores_N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining BALD batch is straighforward then given the scores:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding a BALD batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "def get_top_k_scorers(scores_N: torch.Tensor, *, batch_size: int) -> CandidateBatch:\n",
    "    N = len(scores_N)\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    candidate_scores, candidate_indices = torch.topk(scores_N, batch_size)\n",
    "\n",
    "    return CandidateBatch(candidate_scores.tolist(), candidate_indices.tolist())\n",
    "\n",
    "\n",
    "def get_bald_batch(log_probs_N_K_C: torch.Tensor, *, batch_size: int, dtype=None, device=None) -> CandidateBatch:\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "\n",
    "    scores_N = get_bald_scores(log_probs_N_K_C, dtype=dtype, device=device)\n",
    "\n",
    "    return get_top_k_scorers(scores_N, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.030715639666234917, 0.030715639666234917, 0.030715639666234917, 0.030715639666234695], indices=[1, 2, 0, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bald_batch(ys_ws.log().double(), batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EPIG-BALD\n",
    "\n",
    "The computation for EPIG-BALD is simple. We need to keep track of two separate (Batch)BALD terms:\n",
    "\n",
    "$$\\mathrm{I}\\left[(y)_{B} ; \\omega \\mid(x)_{B}, D_{T}\\right]-\\mathrm{I}\\left[(y)_{B} ; \\omega \\mid(x)_{B}, D_{U} \\cup D_{T}\\right].$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "def get_batch_eval_bald_batch(\n",
    "    training_log_probs_N_K_C: torch.Tensor,\n",
    "    eval_log_probs_N_K_C: torch.Tensor,\n",
    "    *,\n",
    "    batch_size: int,\n",
    "    num_samples: int,\n",
    "    dtype=None,\n",
    "    device=None,\n",
    ") -> CandidateBatch:\n",
    "    assert training_log_probs_N_K_C.shape == eval_log_probs_N_K_C.shape\n",
    "    N, K, C = training_log_probs_N_K_C.shape\n",
    "\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    candidate_indices = []\n",
    "    candidate_scores = []\n",
    "\n",
    "    if batch_size == 0:\n",
    "        return CandidateBatch(candidate_scores, candidate_indices)\n",
    "\n",
    "    training_batchbald_scorer = BatchBALDScorer(\n",
    "        training_log_probs_N_K_C,\n",
    "        max_size=batch_size - 1,\n",
    "        num_samples=num_samples,\n",
    "        dtype=dtype,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    pool_batchbald_scorer = BatchBALDScorer(\n",
    "        eval_log_probs_N_K_C,\n",
    "        max_size=batch_size - 1,\n",
    "        num_samples=num_samples,\n",
    "        dtype=dtype,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # We always keep these on the CPU.\n",
    "    training_scores_N = training_batchbald_scorer.alloc_scores()\n",
    "    pool_scores_N = pool_batchbald_scorer.alloc_scores()\n",
    "\n",
    "    for i in with_progress_bar(range(batch_size), tqdm_args=dict(desc=\"BatchBALD\", leave=False)):\n",
    "        if i > 0:\n",
    "            latest_index = candidate_indices[-1]\n",
    "            training_batchbald_scorer.append_to_batch(latest_index)\n",
    "            pool_batchbald_scorer.append_to_batch(latest_index)\n",
    "\n",
    "        training_batchbald_scorer.compute_scores(training_scores_N)\n",
    "        pool_batchbald_scorer.compute_scores(pool_scores_N)\n",
    "\n",
    "        scores_N = training_scores_N - pool_scores_N\n",
    "        scores_N[candidate_indices] = -float(\"inf\")\n",
    "\n",
    "        candidate_score, candidate_index = scores_N.max(dim=0)\n",
    "\n",
    "        candidate_indices.append(candidate_index.item())\n",
    "        candidate_scores.append(candidate_score.item())\n",
    "\n",
    "    return CandidateBatch(candidate_scores, candidate_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pleasing example of the case when predictions match (full overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BatchBALD:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.0, 0.0, 0.0, 0.0], indices=[0, 1, 2, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch_eval_bald_batch(ys_ws.log().double(), ys_ws.log().double(), batch_size=4, num_samples=1000, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BatchBALD:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.030715639666234917, 0.05961958627158248, 0.0869107051474467, 0.11275304532467878], indices=[1, 0, 2, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch_eval_bald_batch(\n",
    "    ys_ws.log().double(), torch.zeros_like(ys_ws).double(), batch_size=4, num_samples=1000, dtype=torch.double\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ThompsonBALD\n",
    "\n",
    "We compute the joint entropy as in BALD, but for the conditional entropy, we simply compute the entropy of a single $\\omega$ sample and then pick the highest scorer, before we another sample etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "def compute_each_conditional_entropy(log_probs_N_K_C: torch.Tensor) -> torch.Tensor:\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "\n",
    "    entropies_N_K = torch.empty((N, K), dtype=torch.double)\n",
    "\n",
    "    pbar = create_progress_bar(N, tqdm_args=dict(desc=\"Entropy\", leave=False))\n",
    "    pbar.start()\n",
    "\n",
    "    @toma.execute.chunked(log_probs_N_K_C, 1024)\n",
    "    def compute(log_probs_n_K_C, start: int, end: int):\n",
    "        nats_n_K_C = log_probs_n_K_C * torch.exp(log_probs_n_K_C)\n",
    "\n",
    "        entropies_N_K[start:end].copy_(-torch.sum(nats_n_K_C, dim=2))\n",
    "        pbar.update(end - start)\n",
    "\n",
    "    pbar.finish()\n",
    "\n",
    "    return entropies_N_K\n",
    "\n",
    "\n",
    "def get_thompson_bald_batch(\n",
    "    log_probs_N_K_C: torch.Tensor, *, batch_size: int, dtype=None, device=None\n",
    ") -> CandidateBatch:\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "    assert K >= batch_size\n",
    "\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    entropy_N = compute_entropy(log_probs_N_K_C)\n",
    "    all_conditional_entropies_N_K = compute_each_conditional_entropy(log_probs_N_K_C)\n",
    "\n",
    "    thompson_bald_scores_N_K = entropy_N[:, None] - all_conditional_entropies_N_K\n",
    "\n",
    "    candidate_scores, candidate_indices = [], []\n",
    "    for b in range(batch_size):\n",
    "        candidate_score, candidate_index = thompson_bald_scores_N_K[:, b].max(dim=0)\n",
    "\n",
    "        candidate_scores.append(candidate_score.item())\n",
    "        candidate_indices.append(candidate_index.item())\n",
    "\n",
    "        thompson_bald_scores_N_K[candidate_index] = -float(\"inf\")\n",
    "\n",
    "    return CandidateBatch(candidate_scores, candidate_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.29714917957723086, 0.25731026605631957, 0.21965481456439662, 0.18409109389668443], indices=[2, 0, 1, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_thompson_bald_batch(ys_ws.log().double(), batch_size=4, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomBALD Baseline\n",
    "\n",
    "We take the top $C \\times B$ and randomly pick $B$ candidates from that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "def get_top_random_scorers(scores_N: torch.Tensor, *, num_classes: int, batch_size: int) -> CandidateBatch:\n",
    "    N = len(scores_N)\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    L = min(batch_size * num_classes, N)\n",
    "\n",
    "    candidate_scores, candidate_indices = torch.topk(scores_N, L)\n",
    "\n",
    "    sub_indices = torch.randperm(L)[:batch_size]\n",
    "\n",
    "    return CandidateBatch(candidate_scores[sub_indices].tolist(), candidate_indices[sub_indices].tolist())\n",
    "\n",
    "\n",
    "def get_random_bald_batch(log_probs_N_K_C: torch.Tensor, *, batch_size: int, dtype=None, device=None) -> CandidateBatch:\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "\n",
    "    scores_N = get_bald_scores(log_probs_N_K_C, dtype=dtype, device=device)\n",
    "\n",
    "    return get_top_random_scorers(scores_N, num_classes=C, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.030715639666234695, 0.030715639666234917, 0.030715639666234917, 0.030715639666234917], indices=[3, 1, 0, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_bald_batch(ys_ws.log().double(), batch_size=4, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional EPIG-BALD variants\n",
    "\n",
    "Instead of using BatchBALD, let's compute BALD directly and use either the top-k, TopRandom or Thomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "def get_eval_bald_scores(\n",
    "    training_log_probs_N_K_C: torch.Tensor,\n",
    "    eval_log_probs_N_K_C: torch.Tensor,\n",
    "    *,\n",
    "    dtype=None,\n",
    "    device=None,\n",
    ") -> torch.Tensor:\n",
    "    assert training_log_probs_N_K_C.shape == eval_log_probs_N_K_C.shape\n",
    "\n",
    "    training_scores_N = get_bald_scores(training_log_probs_N_K_C, dtype=dtype, device=device)\n",
    "    pool_scores_N = get_bald_scores(eval_log_probs_N_K_C, dtype=dtype, device=device)\n",
    "\n",
    "    scores_N = training_scores_N - pool_scores_N\n",
    "\n",
    "    return scores_N\n",
    "\n",
    "\n",
    "def get_eval_bald_batch(\n",
    "    training_log_probs_N_K_C: torch.Tensor,\n",
    "    pool_log_probs_N_K_C: torch.Tensor,\n",
    "    *,\n",
    "    batch_size: int,\n",
    "    dtype=None,\n",
    "    device=None,\n",
    ") -> CandidateBatch:\n",
    "    return get_top_k_scorers(\n",
    "        get_eval_bald_scores(training_log_probs_N_K_C, pool_log_probs_N_K_C, dtype=dtype, device=device),\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_top_random_eval_bald_batch(\n",
    "    training_log_probs_N_K_C: torch.Tensor,\n",
    "    pool_log_probs_N_K_C: torch.Tensor,\n",
    "    *,\n",
    "    batch_size: int,\n",
    "    num_classes: int,\n",
    "    dtype=None,\n",
    "    device=None,\n",
    ") -> CandidateBatch:\n",
    "    return get_top_random_scorers(\n",
    "        get_eval_bald_scores(training_log_probs_N_K_C, pool_log_probs_N_K_C, dtype=dtype, device=device),\n",
    "        batch_size=batch_size,\n",
    "        num_classes=num_classes,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.0, 0.0, 0.0, 0.0], indices=[2, 3, 0, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_eval_bald_batch(ys_ws.log().double(), ys_ws.log().double(), batch_size=4, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.0, 0.0, 0.0, 0.0], indices=[3, 0, 2, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_random_eval_bald_batch(\n",
    "    ys_ws.log().double(), ys_ws.log().double(), batch_size=4, num_classes=10, dtype=torch.double\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TemperedBALD\n",
    "\n",
    "Use temperature-scaled BALD scores for importance sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "def get_sampled_tempered_scorers(exp_scores_N: torch.Tensor, *, temperature: float, batch_size: int) -> CandidateBatch:\n",
    "    N = len(exp_scores_N)\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    tempered_scores_N = exp_scores_N ** (1/temperature)\n",
    "    tempered_scores_N[exp_scores_N < 0] = 0.0\n",
    "    partition_constant = tempered_scores_N.sum()\n",
    "    p = tempered_scores_N / partition_constant\n",
    "\n",
    "    # TODO: change this to use PyTorch instead of numpy?\n",
    "    candidate_indices = np.random.choice(N, size=batch_size, replace=False, p=p.cpu().numpy())\n",
    "    candidate_scores = exp_scores_N[candidate_indices]\n",
    "\n",
    "    return CandidateBatch(candidate_scores.tolist(), candidate_indices.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.030715639666234917, 0.030715639666234917], indices=[1, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sampled_tempered_scorers(get_bald_scores(ys_ws.log().double()), temperature=10, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EPIG\n",
    "\n",
    "As part of an ablation (and to see how it performs), we can also compute the ICAL score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "def get_eig_scores(\n",
    "    training_log_probs_N_K_C: torch.Tensor,\n",
    "    pool_log_probs_N_K_C: torch.Tensor,\n",
    "    *,\n",
    "    dtype=None,\n",
    "    device=None,\n",
    ") -> torch.Tensor:\n",
    "    assert training_log_probs_N_K_C.shape == pool_log_probs_N_K_C.shape\n",
    "\n",
    "    N, K, C = training_log_probs_N_K_C.shape\n",
    "\n",
    "    scores_N = compute_entropy(training_log_probs_N_K_C) - compute_entropy(pool_log_probs_N_K_C)\n",
    "\n",
    "    return scores_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_eig_scores(ys_ws.log().double(), ys_ws.log().double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "# TODO: refactor the BatchBALDScorer to deduplicate some of this?\n",
    "def get_batch_eig_batch(\n",
    "    training_log_probs_N_K_C: torch.Tensor,\n",
    "    pool_log_probs_N_K_C: torch.Tensor,\n",
    "    *,\n",
    "    batch_size: int,\n",
    "    num_samples: int,\n",
    "    dtype=None,\n",
    "    device=None,\n",
    ") -> CandidateBatch:\n",
    "    assert training_log_probs_N_K_C.shape == pool_log_probs_N_K_C.shape\n",
    "    N, K, C = training_log_probs_N_K_C.shape\n",
    "\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    candidate_indices = []\n",
    "    candidate_scores = []\n",
    "\n",
    "    if batch_size == 0:\n",
    "        return CandidateBatch(candidate_scores, candidate_indices)\n",
    "\n",
    "    training_joint_entropy = joint_entropy.DynamicJointEntropy(\n",
    "        num_samples, batch_size, K, C, dtype=dtype, device=device\n",
    "    )\n",
    "\n",
    "    pool_joint_entropy = joint_entropy.DynamicJointEntropy(num_samples, batch_size, K, C, dtype=dtype, device=device)\n",
    "\n",
    "    # We always keep these on the CPU.\n",
    "    training_scores_N = torch.empty(\n",
    "        N,\n",
    "        dtype=torch.double,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "    )\n",
    "\n",
    "    pool_scores_N = torch.empty(\n",
    "        N,\n",
    "        dtype=torch.double,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "    )\n",
    "\n",
    "    for i in with_progress_bar(range(batch_size), tqdm_args=dict(desc=\"BatchBALD\", leave=False)):\n",
    "        if i > 0:\n",
    "            latest_index = candidate_indices[-1]\n",
    "            training_joint_entropy.add_variables(training_log_probs_N_K_C[latest_index : latest_index + 1])\n",
    "            pool_joint_entropy.add_variables(pool_log_probs_N_K_C[latest_index : latest_index + 1])\n",
    "\n",
    "        training_joint_entropy.compute_batch(training_log_probs_N_K_C, output_entropies_B=training_scores_N)\n",
    "        pool_joint_entropy.compute_batch(pool_log_probs_N_K_C, output_entropies_B=pool_scores_N)\n",
    "\n",
    "        scores_N = training_scores_N - pool_scores_N\n",
    "        scores_N[candidate_indices] = -float(\"inf\")\n",
    "\n",
    "        candidate_score, candidate_index = scores_N.max(dim=0)\n",
    "\n",
    "        candidate_indices.append(candidate_index.item())\n",
    "        candidate_scores.append(candidate_score.item())\n",
    "\n",
    "    return CandidateBatch(candidate_scores, candidate_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BatchBALD:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.0, 0.0, 0.0, 0.0], indices=[0, 1, 2, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch_eig_batch(ys_ws.log().double(), ys_ws.log().double(), batch_size=4, num_samples=1000, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Gain\n",
    "\n",
    "(Following the new notation.)\n",
    "\n",
    "Instead of computing $I[Y;\\omega|x]$, we use our knowledge of the labels and compute: $$I[y;\\omega|x]= H[y|x] - \\mathbb{E}_{p(\\omega|y,x)} H[y|x,\\omega].$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "def get_coreset_bald_scores_from_predictions(\n",
    "    log_probs_N_K_C: torch.Tensor, target_probs_N_C: torch.Tensor, *, dtype=None, device=None\n",
    ") -> torch.Tensor:\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "    assert target_probs_N_C.shape == (N, C)\n",
    "\n",
    "    log_probs_N_K_C = log_probs_N_K_C.to(dtype=dtype, device=device)\n",
    "    target_probs_N_C = target_probs_N_C.to(dtype=dtype, device=device)\n",
    "\n",
    "    log_prob_mean_N_C = torch.logsumexp(log_probs_N_K_C, dim=1) - np.log(K)\n",
    "\n",
    "    entropy_N_C = -log_prob_mean_N_C\n",
    "    conditional_entropy = -torch.mean(log_probs_N_K_C * log_probs_N_K_C.exp(), dim=1) / log_prob_mean_N_C.exp()\n",
    "    mutual_bits_N_C = entropy_N_C - conditional_entropy\n",
    "\n",
    "    cross_mutual_information = torch.sum(target_probs_N_C * mutual_bits_N_C, dim=1)\n",
    "\n",
    "    return cross_mutual_information\n",
    "\n",
    "\n",
    "def get_coreset_bald_scores(\n",
    "    log_probs_N_K_C: torch.Tensor, labels_N: torch.Tensor, *, dtype=None, device=None\n",
    ") -> torch.Tensor:\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "\n",
    "    labels_N_1_1 = labels_N[:, None, None]\n",
    "    log_probs_N_K = (\n",
    "        joint_entropy.gather_expand(log_probs_N_K_C, dim=2, index=labels_N_1_1)\n",
    "        .squeeze(2)\n",
    "        .to(dtype=dtype, device=device)\n",
    "    )\n",
    "\n",
    "    log_prob_mean_N = torch.logsumexp(log_probs_N_K, dim=1) - np.log(K)\n",
    "\n",
    "    lhs = -log_prob_mean_N\n",
    "    rhs = -torch.mean(log_probs_N_K * log_probs_N_K.exp(), dim=1) / log_prob_mean_N.exp()\n",
    "\n",
    "    coreset_infogain = lhs - rhs\n",
    "\n",
    "    return coreset_infogain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0300, 0.0300, 0.0300, 0.0300], dtype=torch.float64),\n",
       " [tensor([0.0300, 0.0207, 0.0207, 0.0474], dtype=torch.float64),\n",
       "  tensor([0.0474, 0.0300, 0.0207, 0.0207], dtype=torch.float64),\n",
       "  tensor([0.0207, 0.0474, 0.0300, 0.0207], dtype=torch.float64)])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_coreset_bald_scores(ys_ws.log().double(), torch.tensor([0, 1, 2, 3])), [get_coreset_bald_scores(ys_ws.log().double(), torch.tensor([i, i, i, i])) for i in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Information Gain\n",
    "\n",
    "(Following the new notation.)\n",
    "\n",
    "The batch version of this acquisition function can be computed more easily:\n",
    "\n",
    "$$ \\operatorname{I}[(y)_B;\\omega|(x)_B] = \\operatorname{H}[(y)_B|(x)_B] - \\mathbb{E}_{p(\\omega|(y)_B, (x)_B)} \\operatorname{H}[(y)_B|(x)_B, \\omega], $$\n",
    "\n",
    "where $p(\\omega|(y)_B, (x)_B) = \\frac{ p((y)_B| (x)_B, \\omega) p(\\omega) }{ p((y)_B| (x)_B) }$ as usual, and we make use of the independence of the $(y)_B$ given $\\omega$.\n",
    "\n",
    "We can make this efficient for computing scores in parallel by using:\n",
    "$$p((y)_B|(x)_B, \\omega) = p(y_B|x_B, \\omega) \\; p((y)_{B-1}|(x)_{B-1}, \\omega).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do we have sub-modularity?\n",
    "\n",
    "Unclear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "def get_batch_coreset_bald_batch(\n",
    "    log_probs_N_K_C: torch.Tensor, labels_N: torch.Tensor, *, batch_size: int, dtype=None, device=None\n",
    ") -> CandidateBatch:\n",
    "    # We want to compute (note this does not follow the notation from below):\n",
    "    # CoreSetBALD = H[y_1, ..., y_n ] - E_p(w) p(y_1, ..., y_n | w) / p(y_1, ..., y_n) H[y_1, ..., y_n | w]\n",
    "    # H[y_1, ..., y_n | w] = H[y_1, ..., y_{n-1} | w] + H[y_n | w] because y_i _||_ y_j | w\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    candidate_indices = []\n",
    "    candidate_scores = []\n",
    "\n",
    "    if batch_size == 0:\n",
    "        return CandidateBatch(candidate_scores, candidate_indices)\n",
    "\n",
    "    labels_N_1_1 = labels_N[:, None, None]\n",
    "    log_probs_N_K = (\n",
    "        joint_entropy.gather_expand(log_probs_N_K_C, dim=2, index=labels_N_1_1)\n",
    "        .squeeze(2)\n",
    "        .to(dtype=dtype, device=device)\n",
    "    )\n",
    "\n",
    "    # p((y)_{B-1}|(x)_{B-1}, \\omega)\n",
    "    log_probs_conditional_joint_batch_K = torch.zeros_like(log_probs_N_K[0], dtype=dtype, device=device)\n",
    "\n",
    "    for i in with_progress_bar(range(batch_size), tqdm_args=dict(desc=\"BatchCoreSetBALD\", leave=False)):\n",
    "        # p((y)_B|(x)_B, \\omega) = p(y_B|x_B, \\omega) * p((y)_{B-1}|(x)_{B-1}, \\omega)\n",
    "        log_prob_conditional_joint_N_K = log_probs_N_K + log_probs_conditional_joint_batch_K[None, :]\n",
    "\n",
    "        # Marginalize over w (but using sum not mean):\n",
    "        # p((y)_B|(x)_B) = E_p(\\omega) p((y)_B|(x)_B, \\omega)\n",
    "        # log_prob_joint_N_1 = log_prob_conditional_joint_N_K.logsumexp(dim=1, keepdim=True) - np.log(K)\n",
    "        log_prob_joint_pK_N_1 = log_prob_conditional_joint_N_K.logsumexp(dim=1, keepdim=True)\n",
    "        # \\frac{ p((y)_B| (x)_B, \\omega) }{ p((y)_B| (x)_B) }\n",
    "        # log_ratio_N_K = log_prob_conditional_joint_N_K - log_prob_joint_N_1\n",
    "        # log_ratio_N_K = log_prob_conditional_joint_N_K - log_prob_joint_pK_N_1 + np.log(K)\n",
    "        log_ratio_mK_N_K = log_prob_conditional_joint_N_K - log_prob_joint_pK_N_1\n",
    "        # conditional_entropy_joint_N = -torch.mean(log_ratio_N_K.exp() * log_prob_conditional_joint_N_K, dim=1)\n",
    "        # conditional_entropy_joint_N =\n",
    "        #       -torch.mean((log_ratio_mK_N_K + np.log(K)).exp() * log_prob_conditional_joint_N_K, dim=1)\n",
    "        conditional_entropy_joint_N = -torch.sum(log_ratio_mK_N_K.exp() * log_prob_conditional_joint_N_K, dim=1)\n",
    "        # entropy_joint_N = -log_prob_joint_N_1.squeeze(1)\n",
    "        # entropy_joint_N = -(log_prob_joint_pK_N_1 - np.log(K)).squeeze(1)\n",
    "        entropy_joint_N = -log_prob_joint_pK_N_1.squeeze(1) + np.log(K)\n",
    "        scores_N = entropy_joint_N - conditional_entropy_joint_N\n",
    "\n",
    "        # Select candidate\n",
    "        scores_N[candidate_indices] = -float(\"inf\")\n",
    "\n",
    "        candidate_score, candidate_index = scores_N.max(dim=0)\n",
    "\n",
    "        candidate_indices.append(candidate_index.item())\n",
    "        candidate_scores.append(candidate_score.item())\n",
    "\n",
    "        # Update log_probs_conditional_joint_batch_K\n",
    "        log_probs_conditional_joint_batch_K = log_prob_conditional_joint_N_K[candidate_index]\n",
    "\n",
    "    return CandidateBatch(candidate_scores, candidate_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_coreset_bald_batch_simpler(\n",
    "    log_probs_N_K_C: torch.Tensor, labels_N: torch.Tensor, *, batch_size: int, dtype=None, device=None\n",
    ") -> CandidateBatch:\n",
    "    # We want to compute (note this does not follow the notation from below):\n",
    "    # CoreSetBALD = H[y_1, ..., y_n ] - E_p(w) p(y_1, ..., y_n | w) / p(y_1, ..., y_n) H[y_1, ..., y_n | w]\n",
    "    # H[y_1, ..., y_n | w] = H[y_1, ..., y_{n-1} | w] + H[y_n | w] because y_i _||_ y_j | w\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    candidate_indices = []\n",
    "    candidate_scores = []\n",
    "\n",
    "    if batch_size == 0:\n",
    "        return CandidateBatch(candidate_scores, candidate_indices)\n",
    "\n",
    "    labels_N_1_1 = labels_N[:, None, None]\n",
    "    log_probs_N_K = (\n",
    "        joint_entropy.gather_expand(log_probs_N_K_C, dim=2, index=labels_N_1_1)\n",
    "        .squeeze(2)\n",
    "        .to(dtype=dtype, device=device)\n",
    "    )\n",
    "\n",
    "    # p((y)_{B-1}|(x)_{B-1}, \\omega)\n",
    "    log_probs_conditional_joint_batch_K = torch.zeros_like(log_probs_N_K[0], dtype=dtype, device=device)\n",
    "\n",
    "    for i in with_progress_bar(range(batch_size), tqdm_args=dict(desc=\"BatchCoreSetBALD\", leave=False)):\n",
    "        # p((y)_B|(x)_B, \\omega) = p(y_B|x_B, \\omega) * p((y)_{B-1}|(x)_{B-1}, \\omega)\n",
    "        log_prob_conditional_joint_N_K = log_probs_N_K + log_probs_conditional_joint_batch_K[None, :]\n",
    "\n",
    "        # Marginalize over w (but using sum not mean):\n",
    "        # p((y)_B|(x)_B) = E_p(\\omega) p((y)_B|(x)_B, \\omega)\n",
    "        log_prob_joint_N_1 = log_prob_conditional_joint_N_K.logsumexp(dim=1, keepdim=True) - np.log(K)\n",
    "       \n",
    "        # \\frac{ p((y)_B| (x)_B, \\omega) }{ p((y)_B| (x)_B) }\n",
    "        log_ratio_N_K = log_prob_conditional_joint_N_K - log_prob_joint_N_1\n",
    "        conditional_entropy_joint_N = -torch.mean(log_ratio_N_K.exp() * log_prob_conditional_joint_N_K, dim=1)\n",
    "        entropy_joint_N = -log_prob_joint_N_1.squeeze(1)\n",
    "        scores_N = entropy_joint_N - conditional_entropy_joint_N\n",
    "\n",
    "        # Select candidate\n",
    "        scores_N[candidate_indices] = -float(\"inf\")\n",
    "\n",
    "        candidate_score, candidate_index = scores_N.max(dim=0)\n",
    "\n",
    "        candidate_indices.append(candidate_index.item())\n",
    "        candidate_scores.append(candidate_score.item())\n",
    "\n",
    "        # Update log_probs_conditional_joint_batch_K\n",
    "        log_probs_conditional_joint_batch_K = log_prob_conditional_joint_N_K[candidate_index]\n",
    "\n",
    "    return CandidateBatch(candidate_scores, candidate_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.03002132, 0.03002132, 0.03002132, 0.03002132]),\n",
       " [tensor([0.0300, 0.0207, 0.0207, 0.0474], dtype=torch.float64),\n",
       "  tensor([0.0474, 0.0300, 0.0207, 0.0207], dtype=torch.float64),\n",
       "  tensor([0.0207, 0.0474, 0.0300, 0.0207], dtype=torch.float64)])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_coreset_bald_scores(ys_ws.log().double(), torch.tensor([0, 1, 2, 3])).numpy(), [get_coreset_bald_scores(ys_ws.log().double(), torch.tensor([i, i, i, i])) for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 20, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_ws.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BatchCoreSetBALD:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.030021323375763576, 0.10871562110954991, 0.2168431672489275, 0.3375447132429139], indices=[0, 1, 2, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch_coreset_bald_batch(ys_ws.log().double(), torch.tensor([0, 1, 2, 3]), batch_size=4, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BatchCoreSetBALD:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.030021323375763687, 0.10871562110954991, 0.2168431672489275, 0.3375447132429139], indices=[0, 1, 2, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch_coreset_bald_batch_simpler(ys_ws.log().double(), torch.tensor([0, 1, 2, 3]), batch_size=4, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoreSet-PIG & Coreset-PIG-BALD\n",
    "\n",
    "Combining EIG with CoreSets to use $I[y_{eval}; y_{batch} | x_{eval}; x_{batch}, D_{train}]$.\n",
    "\n",
    "This is really easy to compute as $H[y_{batch} | x_{batch}, D_{train}] - H[y_{batch} | y_{eval}, x_{eval}; x_{batch}, D_{train}]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "def get_coreset_eig_scores(\n",
    "        *,\n",
    "        training_log_probs_N_K_C: torch.Tensor,\n",
    "        eval_log_probs_N_K_C: torch.Tensor,\n",
    "        labels_N: torch.Tensor, dtype=None, device=None\n",
    ") -> torch.Tensor:\n",
    "    # We want to compute I[y_eval; y_batch].\n",
    "    # I[y_eval; y_train] = H[y_batch] - H[y_batch|y_eval]\n",
    "    N, K, C = training_log_probs_N_K_C.shape\n",
    "\n",
    "    labels_N_1_1 = labels_N[:, None, None]\n",
    "    training_log_probs_N_K = (\n",
    "        joint_entropy.gather_expand(training_log_probs_N_K_C, dim=2, index=labels_N_1_1)\n",
    "        .squeeze(2)\n",
    "        .to(dtype=dtype, device=device)\n",
    "    )\n",
    "    training_log_prob_mean_N = torch.logsumexp(training_log_probs_N_K, dim=1) - np.log(K)\n",
    "\n",
    "    eval_log_probs_N_K = (\n",
    "        joint_entropy.gather_expand(eval_log_probs_N_K_C, dim=2, index=labels_N_1_1)\n",
    "            .squeeze(2)\n",
    "            .to(dtype=dtype, device=device)\n",
    "    )\n",
    "    eval_log_prob_mean_N = torch.logsumexp(eval_log_probs_N_K, dim=1) - np.log(K)\n",
    "\n",
    "    pig = -training_log_prob_mean_N + eval_log_prob_mean_N\n",
    "\n",
    "    return pig\n",
    "\n",
    "\n",
    "def get_coreset_eig_bald_scores(\n",
    "        *,\n",
    "        training_log_probs_N_K_C: torch.Tensor,\n",
    "        eval_log_probs_N_K_C: torch.Tensor,\n",
    "        labels_N: torch.Tensor, dtype=None, device=None\n",
    ") -> torch.Tensor:\n",
    "    # We want to compute I[y_eval; y_batch; W].\n",
    "    # I[y_eval; y_batch; W] = I[y_batch; W] - I[y_batch; W|y_eval]\n",
    "    training_coreset = get_coreset_bald_scores(training_log_probs_N_K_C, labels_N=labels_N, dtype=dtype, device=device)\n",
    "    eval_coreset = get_coreset_bald_scores(eval_log_probs_N_K_C, labels_N=labels_N, dtype=dtype, device=device)\n",
    "    return training_coreset - eval_coreset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_coreset_eig_scores(training_log_probs_N_K_C=ys_ws.log().double(), eval_log_probs_N_K_C=ys_ws.log().double(), labels_N=torch.tensor([0, 1, 2, 3]), dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_coreset_eig_bald_scores(training_log_probs_N_K_C=ys_ws.log().double(), eval_log_probs_N_K_C=ys_ws.log().double(), labels_N=torch.tensor([0, 1, 2, 3]), dtype=torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SieveBALD\n",
    "\n",
    "This is the 2-BALD approximation (leaving out $ D_{train}$):\n",
    "$$I[Y_1, \\ldots, Y_n;\\Omega \\mid x_1, \\ldots,x_n] \\approx \\sum_i I[Y_i;\\Omega\\mid x_i] - \\sum_{i<j} I[Y_i;Y_j \\mid x_i,x_j].$$\n",
    "\n",
    "See also https://www.notion.so/SieveBALD-using-a-marginal-total-correlation-assumption-and-or-by-forcing-it-2e4a9548d4124b6bb8e0dcbba789887a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "def get_sieve_bald_batch(log_probs_N_K_C: torch.Tensor, *, batch_size: int, dtype=None, device=None) -> CandidateBatch:\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    candidate_scores = []\n",
    "    candidate_indices = []\n",
    "\n",
    "    entropies_N = compute_entropy(log_probs_N_K_C)\n",
    "\n",
    "    # we start with BALD scores\n",
    "    scores_N = entropies_N - compute_conditional_entropy(log_probs_N_K_C)\n",
    "\n",
    "    last_score = 0.\n",
    "    for _ in range(batch_size):\n",
    "        # Pick the highest scorer.\n",
    "        # This is amenable to lazy greedy and lazier than lazy greedy, though we do not implement this here. (Yet)\n",
    "        candidate_score, candidate_index = scores_N.max(dim=0)\n",
    "        candidate_score += last_score\n",
    "        last_score = candidate_score\n",
    "\n",
    "        candidate_indices.append(candidate_index.item())\n",
    "        candidate_scores.append(candidate_score.item())\n",
    "\n",
    "        # Update the acquired item's score so it is not picked again.\n",
    "        scores_N[candidate_index] = -float(\"inf\")\n",
    "\n",
    "        # Decrease scores for other items\n",
    "        joint_entropy_helper = joint_entropy.ExactJointEntropy.empty(K, device=device, dtype=dtype)\n",
    "        joint_entropy_helper.add_variables(log_probs_N_K_C[candidate_index: candidate_index+1])\n",
    "        joint_entropies_N = joint_entropy_helper.compute_batch(log_probs_N_K_C)\n",
    "        dual_mi_N = entropies_N + entropies_N[candidate_index] - joint_entropies_N\n",
    "\n",
    "        scores_N -= dual_mi_N\n",
    "\n",
    "    return CandidateBatch(candidate_scores, candidate_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.030715639666234917, 0.05961958627158248, 0.08671183981604269, 0.11199240029961577], indices=[0, 1, 2, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sieve_bald_batch(ys_ws.log().double(), batch_size=4, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BatchBALD:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.030715639666234917, 0.05961958627158248, 0.0869107051474467, 0.11275304532467878], indices=[1, 0, 2, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch_bald_batch(ys_ws.log().double(), batch_size=4, num_samples=1000, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real EPIG\n",
    "\n",
    "Implement $I[Y_{acq} ; Y_{eval} \\mid x_{acq} ; X_{eval},  D_{train}]$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_joint_probs_N_C_C(pool_probs_N_K_C: torch.Tensor, single_eval_probs_K_C: torch.Tensor):\n",
    "#     K = single_eval_probs_K_C.shape[0]\n",
    "    \n",
    "#     pool_log_probs_N_C_K = pool_probs_N_K_C.transpose(1,2)\n",
    "#     joint_probs_N_C_C = pool_log_probs_N_C_K @ single_eval_probs_K_C / K\n",
    "#     return joint_probs_N_C_C\n",
    "\n",
    "# def get_real_naive_epig_scores(*, pool_log_probs_N_K_C: torch.Tensor, eval_log_probs_E_K_C: torch.Tensor, dtype=None, device=None) -> torch.Tensor:\n",
    "#     \"\"\"Implements naive EPIG: I[Y_acq; Y_eval | x_acq, X_eval].\"\"\"\n",
    "#     N, K, C = pool_log_probs_N_K_C.shape\n",
    "#     E, _, _ = eval_log_probs_E_K_C.shape\n",
    "#     assert pool_log_probs_N_K_C.shape[1:] == pool_log_probs_N_K_C.shape[1:], \"{pool_log_probs_N_K_C.shape[1:]} != {pool_log_probs_N_K_C.shape[1:]}\"\n",
    "\n",
    "#     pool_probs_N_K_C = pool_log_probs_N_K_C.to(dtype=dtype).exp()\n",
    "#     eval_probs_E_K_C = eval_log_probs_E_K_C.to(dtype=dtype).exp()\n",
    "    \n",
    "#     #print(pool_probs_N_K_C, eval_probs_E_K_C)\n",
    "    \n",
    "#     pool_probs_N_C = torch.mean(pool_probs_N_K_C[:K//3], dim=1, keepdim=False)\n",
    "    \n",
    "#     # Split the MC dropout samples in 4 ranges.\n",
    "#     total_scores_N = torch.zeros((N,), dtype=dtype, device=\"cpu\")\n",
    "#     for i_e in with_progress_bar(range(E), tqdm_args=dict(desc=\"Evaluation Set\", leave=False)):\n",
    "#         single_eval_probs_K_C = eval_probs_E_K_C[i_e]\n",
    "        \n",
    "#         joint_probs_A__N_C_C = get_joint_probs_N_C_C(pool_probs_N_K_C[:, K//3:2*K//3, :], single_eval_probs_K_C[:K//3])\n",
    "#         joint_probs_B__N_C_C = get_joint_probs_N_C_C(pool_probs_N_K_C[:, 2*K//3:, :], single_eval_probs_K_C[K//3:2*K//3])\n",
    "         \n",
    "#         single_eval_probs_C = torch.mean(single_eval_probs_K_C[2*K//3:K], dim=0, keepdim=False)\n",
    "#         #print(single_eval_probs_C)\n",
    "        \n",
    "#         nats_N_C_C = -torch.log(single_eval_probs_C)[None, None, :] -torch.log(pool_probs_N_C)[:, :, None] + torch.log(joint_probs_B__N_C_C)\n",
    "        \n",
    "#         weighted_nats_N_C_C = nats_N_C_C * joint_probs_A__N_C_C\n",
    "#         scores_N = weighted_nats_N_C_C.sum((1,2), keepdim=False)\n",
    "        \n",
    "#         total_scores_N += scores_N\n",
    "        \n",
    "#     total_scores_N /= E\n",
    "    \n",
    "#     return total_scores_N\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "def get_joint_probs_N_C_C(pool_probs_N_K_C: torch.Tensor, single_eval_probs_K_C: torch.Tensor):\n",
    "    K = single_eval_probs_K_C.shape[0]\n",
    "\n",
    "    pool_log_probs_N_C_K = pool_probs_N_K_C.transpose(1,2)\n",
    "    joint_probs_N_C_C = pool_log_probs_N_C_K @ single_eval_probs_K_C / K\n",
    "    return joint_probs_N_C_C\n",
    "\n",
    "def get_real_naive_epig_scores(*, pool_log_probs_N_K_C: torch.Tensor, eval_log_probs_E_K_C: torch.Tensor, dtype=None, device=None) -> torch.Tensor:\n",
    "    \"\"\"Implements naive EPIG: I[Y_acq; Y_eval | x_acq, X_eval].\"\"\"\n",
    "    N, K, C = pool_log_probs_N_K_C.shape\n",
    "    E, _, _ = eval_log_probs_E_K_C.shape\n",
    "    assert pool_log_probs_N_K_C.shape[1:] == pool_log_probs_N_K_C.shape[1:], \"{pool_log_probs_N_K_C.shape[1:]} != {pool_log_probs_N_K_C.shape[1:]}\"\n",
    "\n",
    "    pool_probs_N_K_C = pool_log_probs_N_K_C.to(dtype=dtype, device=device).exp()\n",
    "    eval_probs_E_K_C = eval_log_probs_E_K_C.to(dtype=dtype, device=device).exp()\n",
    "\n",
    "    pool_probs_N_C = torch.mean(pool_probs_N_K_C, dim=1, keepdim=False)\n",
    "\n",
    "    total_scores_N = torch.zeros((N,), dtype=dtype, device=\"cpu\")\n",
    "    for i_e in with_progress_bar(range(E), tqdm_args=dict(desc=\"Evaluation Set\", leave=False)):\n",
    "        single_eval_probs_K_C = eval_probs_E_K_C[i_e]\n",
    "\n",
    "        joint_probs_N_C_C = get_joint_probs_N_C_C(pool_probs_N_K_C, single_eval_probs_K_C)\n",
    "\n",
    "        single_eval_probs_C = torch.mean(single_eval_probs_K_C, dim=0, keepdim=False)\n",
    "\n",
    "        nats_N_C_C = -torch.log(single_eval_probs_C)[None, None, :] -torch.log(pool_probs_N_C)[:, :, None] + torch.log(joint_probs_N_C_C)\n",
    "\n",
    "        weighted_nats_N_C_C = nats_N_C_C * joint_probs_N_C_C\n",
    "        scores_N = weighted_nats_N_C_C.sum((1,2), keepdim=False)\n",
    "\n",
    "        total_scores_N += scores_N.to(device=\"cpu\", non_blocking=True)\n",
    "\n",
    "    total_scores_N /= E\n",
    "\n",
    "    return total_scores_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation Set:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0194, 0.0080, 0.0129, 0.0102, 0.0125, 0.0094, 0.0164])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_real_naive_epig_scores(pool_log_probs_N_K_C=torch.log_softmax(torch.randn(7,13,5), dim=2), eval_log_probs_E_K_C=torch.log_softmax(torch.randn(11,13,5), dim=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation Set:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0051, 0.0048, 0.0043,  ..., 0.0044, 0.0048, 0.0047])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "get_real_naive_epig_scores(pool_log_probs_N_K_C=torch.log_softmax(torch.randn(6000,100,10), dim=2), eval_log_probs_E_K_C=torch.log_softmax(torch.randn(1000,100,10), dim=2), device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DirichletBALD (Unclear/TODO)\n",
    "\n",
    "This is enspired by Energy-Based Models and Dirichlet distributions. Instead of working with the probabilities after the Softmax layer, we use the logits directly and view them log concentrations of a Dirichlet distribution.\n",
    "\n",
    "We can combine this with MC Dropout to get different Dirichlet samples by averaging the log concentrations. This leads to the exact same computation as before (geometric averaging of the probabilities). \n",
    "\n",
    "This is different than fitting a Dirichlet distribution. Taking the log concentrations instead of probabilities does not throw away \"density\" information from the model.\n",
    "\n",
    "We could recover a mutual information term using the Dirichlet assumption then?\n",
    "\n",
    "(In general, it is not entirely clear to me how to combine them. One path could be to use a conjugate prior distribution and taking the mean/mode of that. The conjugate prior of a Dirichlet distribution is the Boojum distribution, which is quite complex and does not provide an analytical solution for computing its mean or mode.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_dirichlet_bald_scores(logits_N_K_C: torch.Tensor, *,\n",
    "#     dtype=None,\n",
    "#     device=None) -> torch.Tensor:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:active_learning]",
   "language": "python",
   "name": "conda-env-active_learning-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
