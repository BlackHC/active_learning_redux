{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp batchbald"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "\n",
    "import blackhc.project.script\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BatchBALD Algorithm\n",
    "> Greedy algorithm and score computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will implement two helper classes to compute conditional entropies $H[y_i|w]$ and entropies $H[y_i]$. \n",
    "Then, we will implement BatchBALD and BALD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import torch\n",
    "from blackhc.progress_bar import create_progress_bar, with_progress_bar\n",
    "from toma import toma\n",
    "\n",
    "from batchbald_redux import joint_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to define a couple of sampled distributions to use for our testing our code.\n",
    "\n",
    "$K=20$ means 20 inference samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-3d0d22441a54>:23: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068694/work/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  return torch.stack(list(map(torch.as_tensor, l)))\n"
     ]
    }
   ],
   "source": [
    "def get_mixture_prob_dist(p1, p2, m):\n",
    "    return (1.0 - m) * np.asarray(p1) + m * np.asarray(p2)\n",
    "\n",
    "\n",
    "p1 = [0.7, 0.1, 0.1, 0.1]\n",
    "p2 = [0.3, 0.3, 0.2, 0.2]\n",
    "y1_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "p1 = [0.1, 0.7, 0.1, 0.1]\n",
    "p2 = [0.2, 0.3, 0.3, 0.2]\n",
    "y2_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "p1 = [0.1, 0.1, 0.7, 0.1]\n",
    "p2 = [0.2, 0.2, 0.3, 0.3]\n",
    "y3_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "p1 = [0.1, 0.1, 0.1, 0.7]\n",
    "p2 = [0.3, 0.2, 0.2, 0.3]\n",
    "y4_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "\n",
    "def nested_to_tensor(l):\n",
    "    return torch.stack(list(map(torch.as_tensor, l)))\n",
    "\n",
    "\n",
    "ys_ws = nested_to_tensor([y1_ws, y2_ws, y3_ws, y4_ws])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "\n",
    "p = [0.25, 0.25, 0.25, 0.25]\n",
    "yu_ws = [p for m in range(K)]\n",
    "yus_ws = nested_to_tensor([yu_ws] * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 20, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_ws.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Entropies and Batched Entropies\n",
    "\n",
    "To start with, we write two functions to compute the conditional entropy $H[y_i|w]$ and the entropy $H[y_i]$ for each input sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_conditional_entropy(probs_N_K_C: torch.Tensor) -> torch.Tensor:\n",
    "    N, K, C = probs_N_K_C.shape\n",
    "\n",
    "    entropies_N = torch.empty(N, dtype=torch.double)\n",
    "\n",
    "    probs_N_K_C = probs_N_K_C.to(dtype=torch.double)\n",
    "\n",
    "    pbar = create_progress_bar(N, tqdm_args=dict(desc=\"Conditional Entropy\", leave=False))\n",
    "    pbar.start()\n",
    "\n",
    "    @toma.execute.chunked(probs_N_K_C, 1024)\n",
    "    def compute(probs_n_K_C, start: int, end: int):\n",
    "        nats_n_K_C = probs_n_K_C * torch.log(probs_n_K_C)\n",
    "        nats_n_K_C[torch.isnan(nats_n_K_C)] = 0.0\n",
    "\n",
    "        entropies_N[start:end].copy_(-torch.sum(nats_n_K_C, dim=(1, 2)) / K, non_blocking=True)\n",
    "        pbar.update(end - start)\n",
    "\n",
    "    pbar.finish()\n",
    "\n",
    "    return entropies_N\n",
    "\n",
    "\n",
    "def compute_entropy(probs_N_K_C: torch.Tensor) -> torch.Tensor:\n",
    "    N, K, C = probs_N_K_C.shape\n",
    "\n",
    "    entropies_N = torch.empty(N, dtype=torch.double)\n",
    "\n",
    "    probs_N_K_C = probs_N_K_C.to(dtype=torch.double)\n",
    "\n",
    "    pbar = create_progress_bar(N, tqdm_args=dict(desc=\"Entropy\", leave=False))\n",
    "    pbar.start()\n",
    "\n",
    "    @toma.execute.chunked(probs_N_K_C, 1024)\n",
    "    def compute(probs_n_K_C, start: int, end: int):\n",
    "        mean_probs_n_C = probs_n_K_C.mean(dim=1)\n",
    "        nats_n_C = mean_probs_n_C * torch.log(mean_probs_n_C)\n",
    "        nats_n_C[torch.isnan(nats_n_C)] = 0.0\n",
    "\n",
    "        entropies_N[start:end].copy_(-torch.sum(nats_n_C, dim=1), non_blocking=True)\n",
    "        pbar.update(end - start)\n",
    "\n",
    "    pbar.finish()\n",
    "\n",
    "    return entropies_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make sure everything is computed correctly.\n",
    "\n",
    "assert np.allclose(compute_conditional_entropy(yus_ws), [1.3863, 1.3863, 1.3863, 1.3863], atol=0.1)\n",
    "assert np.allclose(compute_entropy(yus_ws), [1.3863, 1.3863, 1.3863, 1.3863], atol=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, our neural networks usually use a `log_softmax` as final layer. To avoid having to call `.exp_()`, which is easy to miss and annoying to debug, we will instead use a version that uses `log_probs` instead of `probs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "def compute_conditional_entropy(log_probs_N_K_C: torch.Tensor) -> torch.Tensor:\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "\n",
    "    entropies_N = torch.empty(N, dtype=torch.double)\n",
    "\n",
    "    log_probs_N_K_C = log_probs_N_K_C.to(torch.double)\n",
    "\n",
    "    pbar = create_progress_bar(N, tqdm_args=dict(desc=\"Conditional Entropy\", leave=False))\n",
    "    pbar.start()\n",
    "\n",
    "    @toma.execute.chunked(log_probs_N_K_C, 65536)\n",
    "    def compute(log_probs_n_K_C, start: int, end: int):\n",
    "        nats_n_K_C = log_probs_n_K_C * torch.exp(log_probs_n_K_C)\n",
    "        nats_n_K_C[torch.isnan(nats_n_K_C)] = 0.0\n",
    "\n",
    "        entropies_N[start:end].copy_(-torch.sum(nats_n_K_C, dim=(1, 2)) / K)\n",
    "        pbar.update(end - start)\n",
    "\n",
    "    pbar.finish()\n",
    "\n",
    "    return entropies_N\n",
    "\n",
    "\n",
    "def compute_entropy(log_probs_N_K_C: torch.Tensor) -> torch.Tensor:\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "\n",
    "    entropies_N = torch.empty(N, dtype=torch.double)\n",
    "\n",
    "    log_probs_N_K_C = log_probs_N_K_C.to(torch.double)\n",
    "\n",
    "    pbar = create_progress_bar(N, tqdm_args=dict(desc=\"Entropy\", leave=False))\n",
    "    pbar.start()\n",
    "\n",
    "    @toma.execute.chunked(log_probs_N_K_C, 65536)\n",
    "    def compute(log_probs_n_K_C, start: int, end: int):\n",
    "        mean_log_probs_n_C = torch.logsumexp(log_probs_n_K_C, dim=1) - math.log(K)\n",
    "        nats_n_C = mean_log_probs_n_C * torch.exp(mean_log_probs_n_C)\n",
    "        nats_n_C[torch.isnan(nats_n_C)] = 0.0\n",
    "\n",
    "        entropies_N[start:end].copy_(-torch.sum(nats_n_C, dim=1))\n",
    "        pbar.update(end - start)\n",
    "\n",
    "    pbar.finish()\n",
    "\n",
    "    return entropies_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "# Make sure everything is computed correctly.\n",
    "assert np.allclose(compute_conditional_entropy(yus_ws.log()), [1.3863, 1.3863, 1.3863, 1.3863], atol=0.1)\n",
    "assert np.allclose(compute_entropy(yus_ws.log()), [1.3863, 1.3863, 1.3863, 1.3863], atol=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2069, 1.2069, 1.2069, 1.2069], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "conditional_entropies = compute_conditional_entropy(ys_ws.log())\n",
    "\n",
    "print(conditional_entropies)\n",
    "\n",
    "assert np.allclose(conditional_entropies, [1.2069, 1.2069, 1.2069, 1.2069], atol=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2376, 1.2376, 1.2376, 1.2376], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "entropies = compute_entropy(ys_ws.log())\n",
    "\n",
    "print(entropies)\n",
    "\n",
    "assert np.allclose(entropies, [1.2376, 1.2376, 1.2376, 1.2376], atol=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BatchBALD\n",
    "\n",
    "To compute BatchBALD exactly for a candidate batch, we'd have to compute $I[(y_b)_B;w] = H[(y_b)_B] - H[(y_b)_B|w]$.\n",
    "\n",
    "As the $y_b$ are independent given $w$, we can simplify $H[(y_b)_B|w] = \\sum_b H[y_b|w]$.\n",
    "\n",
    "Furthermore, we use a greedy algorithm to build up the candidate batch, so $y_1,\\dots,y_{B-1}$ will stay fixed as we determine $y_{B}$. We compute\n",
    "$H[(y_b)_{B-1}, y_i] - H[y_i|w]$ for each pool element $y_i$ and add the highest scorer as $y_{B}$.\n",
    "\n",
    "We don't utilize the last optimization here in order to compute the actual scores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the Paper\n",
    "\n",
    "![BatchBALD algorithm in the paper](batchbald_algorithm.png)\n",
    "\n",
    "\n",
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CandidateBatch:\n",
    "    scores: List[float]\n",
    "    indices: List[int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "class BatchBALDScorer:\n",
    "    log_probs_N_K_C: torch.tensor\n",
    "    conditional_entropies_N: torch.Tensor\n",
    "    batch_joint_entropy: joint_entropy.JointEntropy\n",
    "    batch_conditional_entropies: torch.Tensor\n",
    "\n",
    "    def __init__(self, log_probs_N_K_C, *, max_size, num_samples: int, dtype=None, device=None):\n",
    "        N, K, C = log_probs_N_K_C.shape\n",
    "        self.log_probs_N_K_C = log_probs_N_K_C\n",
    "\n",
    "        self.conditional_entropies_N = compute_conditional_entropy(self.log_probs_N_K_C)\n",
    "        self.batch_conditional_entropies = 0\n",
    "\n",
    "        self.batch_joint_entropy = joint_entropy.DynamicJointEntropy(\n",
    "            num_samples, max_size, K, C, dtype=dtype, device=device\n",
    "        )\n",
    "\n",
    "    def append_to_batch(self, index: int):\n",
    "        self.batch_joint_entropy.add_variables(self.log_probs_N_K_C[index : index + 1])\n",
    "        self.batch_conditional_entropies += self.conditional_entropies_N[index].clone()\n",
    "\n",
    "    def alloc_scores(self) -> torch.Tensor:\n",
    "        # We always keep these on the CPU.\n",
    "        scores_N = torch.empty(\n",
    "            self.log_probs_N_K_C.shape[0],\n",
    "            dtype=torch.double,\n",
    "            pin_memory=torch.cuda.is_available(),\n",
    "        )\n",
    "        return scores_N\n",
    "\n",
    "    def compute_scores(self, out_scores_N: torch.Tensor):\n",
    "        self.batch_joint_entropy.compute_batch(self.log_probs_N_K_C, output_entropies_B=out_scores_N)\n",
    "\n",
    "        out_scores_N -= self.conditional_entropies_N + self.batch_conditional_entropies\n",
    "\n",
    "        return out_scores_N\n",
    "\n",
    "\n",
    "def get_batch_bald_batch(\n",
    "    log_probs_N_K_C: torch.Tensor, *, batch_size: int, num_samples: int, dtype=None, device=None\n",
    ") -> CandidateBatch:\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    candidate_indices = []\n",
    "    candidate_scores = []\n",
    "\n",
    "    if batch_size == 0:\n",
    "        return CandidateBatch(candidate_scores, candidate_indices)\n",
    "\n",
    "    batchbald_scorer = BatchBALDScorer(\n",
    "        log_probs_N_K_C,\n",
    "        max_size=batch_size - 1,\n",
    "        num_samples=num_samples,\n",
    "        dtype=dtype,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # We always keep these on the CPU.\n",
    "    scores_N = batchbald_scorer.alloc_scores()\n",
    "\n",
    "    for i in with_progress_bar(range(batch_size), tqdm_args=dict(desc=\"BatchBALD\", leave=False)):\n",
    "        if i > 0:\n",
    "            latest_index = candidate_indices[-1]\n",
    "            batchbald_scorer.append_to_batch(latest_index)\n",
    "\n",
    "        batchbald_scorer.compute_scores(scores_N)\n",
    "        scores_N[candidate_indices] = -float(\"inf\")\n",
    "\n",
    "        candidate_score, candidate_index = scores_N.max(dim=0)\n",
    "\n",
    "        candidate_indices.append(candidate_index.item())\n",
    "        candidate_scores.append(candidate_score.item())\n",
    "\n",
    "    return CandidateBatch(candidate_scores, candidate_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batchbald_batch_plain(\n",
    "    log_probs_N_K_C: torch.Tensor,\n",
    "    *,\n",
    "    batch_size: int,\n",
    "    num_samples: int,\n",
    "    dtype=None,\n",
    "    device=None,\n",
    ") -> CandidateBatch:\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    candidate_indices = []\n",
    "    candidate_scores = []\n",
    "\n",
    "    if batch_size == 0:\n",
    "        return CandidateBatch(candidate_scores, candidate_indices)\n",
    "\n",
    "    conditional_entropies_N = compute_conditional_entropy(log_probs_N_K_C)\n",
    "\n",
    "    batch_joint_entropy = joint_entropy.DynamicJointEntropy(\n",
    "        num_samples, batch_size - 1, K, C, dtype=dtype, device=device\n",
    "    )\n",
    "\n",
    "    # We always keep these on the CPU.\n",
    "    scores_N = torch.empty(N, dtype=torch.double, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "    for i in with_progress_bar(range(batch_size), tqdm_args=dict(desc=\"BatchBALD\", leave=False)):\n",
    "        if i > 0:\n",
    "            latest_index = candidate_indices[-1]\n",
    "            batch_joint_entropy.add_variables(log_probs_N_K_C[latest_index : latest_index + 1])\n",
    "\n",
    "        shared_conditional_entropies = conditional_entropies_N[candidate_indices].sum()\n",
    "\n",
    "        batch_joint_entropy.compute_batch(log_probs_N_K_C, output_entropies_B=scores_N)\n",
    "\n",
    "        scores_N -= conditional_entropies_N + shared_conditional_entropies\n",
    "        scores_N[candidate_indices] = -float(\"inf\")\n",
    "\n",
    "        candidate_score, candidate_index = scores_N.max(dim=0)\n",
    "\n",
    "        candidate_indices.append(candidate_index.item())\n",
    "        candidate_scores.append(candidate_score.item())\n",
    "\n",
    "    return CandidateBatch(candidate_scores, candidate_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BatchBALD:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.030715639666234917, 0.05961958627158248, 0.0869107051474467, 0.11275304532467878], indices=[1, 0, 2, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch_bald_batch(ys_ws.log().double(), batch_size=4, num_samples=1000, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BatchBALD:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.030715639666234917, 0.05961958627158248, 0.0869107051474467, 0.11275304532467878], indices=[1, 0, 2, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batchbald_batch_plain(ys_ws.log().double(), batch_size=4, num_samples=1000, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BALD\n",
    "\n",
    "BALD is the same as BatchBALD, except that we evaluate_old points individually, by computing $I[y_i;w]$ for each, and then take the top $B$ scorers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BALD scores\n",
    "\n",
    "Sometimes, we want to obtain BALD scores for all samples as measure of epistemic uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "# TODO: remove unused parameters!\n",
    "def get_bald_scores(log_probs_N_K_C: torch.Tensor, *, dtype=None, device=None) -> torch.Tensor:\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "\n",
    "    scores_N = -compute_conditional_entropy(log_probs_N_K_C)\n",
    "    scores_N += compute_entropy(log_probs_N_K_C)\n",
    "\n",
    "    return scores_N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining BALD batch is straighforward then given the scores:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding a BALD batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "def get_top_k_scorers(scores_N: torch.Tensor, *, batch_size: int) -> CandidateBatch:\n",
    "    N = len(scores_N)\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    candidate_scores, candidate_indices = torch.topk(scores_N, batch_size)\n",
    "\n",
    "    return CandidateBatch(candidate_scores.tolist(), candidate_indices.tolist())\n",
    "\n",
    "\n",
    "def get_bald_batch(log_probs_N_K_C: torch.Tensor, *, batch_size: int, dtype=None, device=None) -> CandidateBatch:\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "\n",
    "    scores_N = get_bald_scores(log_probs_N_K_C, dtype=dtype, device=device)\n",
    "\n",
    "    return get_top_k_scorers(scores_N, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.030715639666234917, 0.030715639666234917, 0.030715639666234917, 0.030715639666234695], indices=[1, 2, 0, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bald_batch(ys_ws.log().double(), batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EPIG-BALD\n",
    "\n",
    "The computation for EPIG-BALD is simple. We need to keep track of two separate (Batch)BALD terms:\n",
    "\n",
    "$$\\mathrm{I}\\left[(y)_{B} ; \\omega \\mid(x)_{B}, D_{T}\\right]-\\mathrm{I}\\left[(y)_{B} ; \\omega \\mid(x)_{B}, D_{U} \\cup D_{T}\\right].$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "def get_batch_eval_bald_batch(\n",
    "    training_log_probs_N_K_C: torch.Tensor,\n",
    "    eval_log_probs_N_K_C: torch.Tensor,\n",
    "    *,\n",
    "    batch_size: int,\n",
    "    num_samples: int,\n",
    "    dtype=None,\n",
    "    device=None,\n",
    ") -> CandidateBatch:\n",
    "    assert training_log_probs_N_K_C.shape == eval_log_probs_N_K_C.shape\n",
    "    N, K, C = training_log_probs_N_K_C.shape\n",
    "\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    candidate_indices = []\n",
    "    candidate_scores = []\n",
    "\n",
    "    if batch_size == 0:\n",
    "        return CandidateBatch(candidate_scores, candidate_indices)\n",
    "\n",
    "    training_batchbald_scorer = BatchBALDScorer(\n",
    "        training_log_probs_N_K_C,\n",
    "        max_size=batch_size - 1,\n",
    "        num_samples=num_samples,\n",
    "        dtype=dtype,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    pool_batchbald_scorer = BatchBALDScorer(\n",
    "        eval_log_probs_N_K_C,\n",
    "        max_size=batch_size - 1,\n",
    "        num_samples=num_samples,\n",
    "        dtype=dtype,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # We always keep these on the CPU.\n",
    "    training_scores_N = training_batchbald_scorer.alloc_scores()\n",
    "    pool_scores_N = pool_batchbald_scorer.alloc_scores()\n",
    "\n",
    "    for i in with_progress_bar(range(batch_size), tqdm_args=dict(desc=\"BatchBALD\", leave=False)):\n",
    "        if i > 0:\n",
    "            latest_index = candidate_indices[-1]\n",
    "            training_batchbald_scorer.append_to_batch(latest_index)\n",
    "            pool_batchbald_scorer.append_to_batch(latest_index)\n",
    "\n",
    "        training_batchbald_scorer.compute_scores(training_scores_N)\n",
    "        pool_batchbald_scorer.compute_scores(pool_scores_N)\n",
    "\n",
    "        scores_N = training_scores_N - pool_scores_N\n",
    "        scores_N[candidate_indices] = -float(\"inf\")\n",
    "\n",
    "        candidate_score, candidate_index = scores_N.max(dim=0)\n",
    "\n",
    "        candidate_indices.append(candidate_index.item())\n",
    "        candidate_scores.append(candidate_score.item())\n",
    "\n",
    "    return CandidateBatch(candidate_scores, candidate_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pleasing example of the case when predictions match (full overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BatchBALD:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.0, 0.0, 0.0, 0.0], indices=[0, 1, 2, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch_eval_bald_batch(\n",
    "    ys_ws.log().double(), ys_ws.log().double(), batch_size=4, num_samples=1000, dtype=torch.double\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BatchBALD:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.030715639666234917, 0.05961958627158248, 0.0869107051474467, 0.11275304532467878], indices=[1, 0, 2, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch_eval_bald_batch(\n",
    "    ys_ws.log().double(), torch.zeros_like(ys_ws).double(), batch_size=4, num_samples=1000, dtype=torch.double\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ThompsonBALD\n",
    "\n",
    "We compute the joint entropy as in BALD, but for the conditional entropy, we simply compute the entropy of a single $\\omega$ sample and then pick the highest scorer, before we another sample etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "def compute_each_conditional_entropy(log_probs_N_K_C: torch.Tensor) -> torch.Tensor:\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "\n",
    "    entropies_N_K = torch.empty((N, K), dtype=torch.double)\n",
    "\n",
    "    pbar = create_progress_bar(N, tqdm_args=dict(desc=\"Entropy\", leave=False))\n",
    "    pbar.start()\n",
    "\n",
    "    @toma.execute.chunked(log_probs_N_K_C, 1024)\n",
    "    def compute(log_probs_n_K_C, start: int, end: int):\n",
    "        nats_n_K_C = log_probs_n_K_C * torch.exp(log_probs_n_K_C)\n",
    "\n",
    "        entropies_N_K[start:end].copy_(-torch.sum(nats_n_K_C, dim=2))\n",
    "        pbar.update(end - start)\n",
    "\n",
    "    pbar.finish()\n",
    "\n",
    "    return entropies_N_K\n",
    "\n",
    "\n",
    "def get_thompson_bald_batch(\n",
    "    log_probs_N_K_C: torch.Tensor, *, batch_size: int, dtype=None, device=None\n",
    ") -> CandidateBatch:\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "    assert K >= batch_size\n",
    "\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    entropy_N = compute_entropy(log_probs_N_K_C)\n",
    "    all_conditional_entropies_N_K = compute_each_conditional_entropy(log_probs_N_K_C)\n",
    "\n",
    "    thompson_bald_scores_N_K = entropy_N[:, None] - all_conditional_entropies_N_K\n",
    "\n",
    "    candidate_scores, candidate_indices = [], []\n",
    "    for b in range(batch_size):\n",
    "        candidate_score, candidate_index = thompson_bald_scores_N_K[:, b].max(dim=0)\n",
    "\n",
    "        candidate_scores.append(candidate_score.item())\n",
    "        candidate_indices.append(candidate_index.item())\n",
    "\n",
    "        thompson_bald_scores_N_K[candidate_index] = -float(\"inf\")\n",
    "\n",
    "    return CandidateBatch(candidate_scores, candidate_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.29714917957723086, 0.25731026605631957, 0.21965481456439662, 0.18409109389668443], indices=[2, 0, 1, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_thompson_bald_batch(ys_ws.log().double(), batch_size=4, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomBALD Baseline\n",
    "\n",
    "We take the top $C \\times B$ and randomly pick $B$ candidates from that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "def get_top_random_scorers(scores_N: torch.Tensor, *, num_classes: int, batch_size: int) -> CandidateBatch:\n",
    "    N = len(scores_N)\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    L = min(batch_size * num_classes, N)\n",
    "\n",
    "    candidate_scores, candidate_indices = torch.topk(scores_N, L)\n",
    "\n",
    "    sub_indices = torch.randperm(L)[:batch_size]\n",
    "\n",
    "    return CandidateBatch(candidate_scores[sub_indices].tolist(), candidate_indices[sub_indices].tolist())\n",
    "\n",
    "\n",
    "def get_random_bald_batch(log_probs_N_K_C: torch.Tensor, *, batch_size: int, dtype=None, device=None) -> CandidateBatch:\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "\n",
    "    scores_N = get_bald_scores(log_probs_N_K_C, dtype=dtype, device=device)\n",
    "\n",
    "    return get_top_random_scorers(scores_N, num_classes=C, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.030715639666234917, 0.030715639666234917, 0.030715639666234695, 0.030715639666234917], indices=[1, 2, 3, 0])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_bald_batch(ys_ws.log().double(), batch_size=4, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional EPIG-BALD variants\n",
    "\n",
    "Instead of using BatchBALD, let's compute BALD directly and use either the top-k, TopRandom or Thomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "def get_eval_bald_scores(\n",
    "    training_log_probs_N_K_C: torch.Tensor,\n",
    "    eval_log_probs_N_K_C: torch.Tensor,\n",
    "    *,\n",
    "    dtype=None,\n",
    "    device=None,\n",
    ") -> torch.Tensor:\n",
    "    assert training_log_probs_N_K_C.shape == eval_log_probs_N_K_C.shape\n",
    "\n",
    "    training_scores_N = get_bald_scores(training_log_probs_N_K_C, dtype=dtype, device=device)\n",
    "    pool_scores_N = get_bald_scores(eval_log_probs_N_K_C, dtype=dtype, device=device)\n",
    "\n",
    "    scores_N = training_scores_N - pool_scores_N\n",
    "\n",
    "    return scores_N\n",
    "\n",
    "\n",
    "def get_eval_bald_batch(\n",
    "    training_log_probs_N_K_C: torch.Tensor,\n",
    "    pool_log_probs_N_K_C: torch.Tensor,\n",
    "    *,\n",
    "    batch_size: int,\n",
    "    dtype=None,\n",
    "    device=None,\n",
    ") -> CandidateBatch:\n",
    "    return get_top_k_scorers(\n",
    "        get_eval_bald_scores(training_log_probs_N_K_C, pool_log_probs_N_K_C, dtype=dtype, device=device),\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_top_random_eval_bald_batch(\n",
    "    training_log_probs_N_K_C: torch.Tensor,\n",
    "    pool_log_probs_N_K_C: torch.Tensor,\n",
    "    *,\n",
    "    batch_size: int,\n",
    "    num_classes: int,\n",
    "    dtype=None,\n",
    "    device=None,\n",
    ") -> CandidateBatch:\n",
    "    return get_top_random_scorers(\n",
    "        get_eval_bald_scores(training_log_probs_N_K_C, pool_log_probs_N_K_C, dtype=dtype, device=device),\n",
    "        batch_size=batch_size,\n",
    "        num_classes=num_classes,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.0, 0.0, 0.0, 0.0], indices=[2, 3, 0, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_eval_bald_batch(ys_ws.log().double(), ys_ws.log().double(), batch_size=4, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.0, 0.0, 0.0, 0.0], indices=[3, 2, 1, 0])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_random_eval_bald_batch(\n",
    "    ys_ws.log().double(), ys_ws.log().double(), batch_size=4, num_classes=10, dtype=torch.double\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TemperedBALD\n",
    "\n",
    "Use temperature-scaled BALD scores for importance sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "def get_sampled_tempered_scorers(scores_N: torch.Tensor, *, temperature: float, batch_size: int) -> CandidateBatch:\n",
    "    N = len(scores_N)\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    # If we exponentiate scores_N beforehand, we obtain a softmax function here.\n",
    "    tempered_scores_N = scores_N ** (1 / temperature)\n",
    "    tempered_scores_N[scores_N < 0] = 0.0\n",
    "    partition_constant = tempered_scores_N.sum()\n",
    "    p = tempered_scores_N / partition_constant\n",
    "\n",
    "    # TODO: change this to use PyTorch instead of numpy?\n",
    "    candidate_indices = np.random.choice(N, size=batch_size, replace=False, p=p.cpu().numpy())\n",
    "    candidate_scores = scores_N[candidate_indices]\n",
    "\n",
    "    return CandidateBatch(candidate_scores.tolist(), candidate_indices.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.030715639666234695, 0.030715639666234917], indices=[3, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sampled_tempered_scorers(get_bald_scores(ys_ws.log().double()), temperature=10, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Acquisition\n",
    "\n",
    "Re-implementation for the final paper experiments (hopefully without bugs...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "def get_random_samples(scores_N: torch.Tensor, *, batch_size: int) -> CandidateBatch:\n",
    "    N = len(scores_N)\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    indices = np.random.choice(N, size=batch_size, replace=False)\n",
    "    candidate_batch = CandidateBatch([0.0] * batch_size, indices.tolist())\n",
    "    return candidate_batch\n",
    "\n",
    "\n",
    "def get_softmax_samples(scores_N: torch.Tensor, *, coldness: float, batch_size: int) -> CandidateBatch:\n",
    "    # As coldness -> 0, we obtain random sampling.\n",
    "    if coldness == 0.0:\n",
    "        return get_random_samples(scores_N, batch_size=batch_size)\n",
    "\n",
    "    N = len(scores_N)\n",
    "    noised_scores_N = scores_N + scipy.stats.gumbel_r.rvs(loc=0, scale=1 / coldness, size=N, random_state=None)\n",
    "\n",
    "    return get_top_k_scorers(noised_scores_N, batch_size=batch_size)\n",
    "\n",
    "\n",
    "def get_power_samples(scores_N: torch.Tensor, *, coldness: float, batch_size: int) -> CandidateBatch:\n",
    "    return get_softmax_samples(torch.log(scores_N), coldness=coldness, batch_size=batch_size)\n",
    "\n",
    "\n",
    "def get_softrank_samples(scores_N: torch.Tensor, *, coldness: float, batch_size: int) -> CandidateBatch:\n",
    "    N = len(scores_N)\n",
    "\n",
    "    sorted_indices_N = torch.argsort(scores_N, descending=True)\n",
    "    ranks_N = torch.argsort(sorted_indices_N) + 1\n",
    "\n",
    "    return get_power_samples(1 / ranks_N, coldness=coldness, batch_size=batch_size)\n",
    "\n",
    "\n",
    "def get_simulation_samples(scores_N: torch.Tensor, *, coldness: float, batch_size: int) -> CandidateBatch:\n",
    "    # As coldness -> 0, we obtain random sampling.\n",
    "    if coldness == 0.0:\n",
    "        return get_random_samples(scores_N, batch_size=batch_size)\n",
    "\n",
    "    N = len(scores_N)\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    indices = []\n",
    "    scores = []\n",
    "    current_scores_N = torch.clone(scores_N)\n",
    "    for i in range(batch_size):\n",
    "        score, index = torch.max(current_scores_N, dim=0)\n",
    "        scores += [score.item()]\n",
    "        indices += [index.item()]\n",
    "        current_scores_N = current_scores_N / (1+ scipy.stats.expon.rvs(loc=0, scale=1 / coldness, size=N, random_state=None))\n",
    "        current_scores_N[index] = float(\"-inf\")\n",
    "\n",
    "    return CandidateBatch(scores=scores, indices=indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_power_samples(torch.as_tensor([1, 0, 0]), coldness=1, batch_size=1).indices == [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.501, 0.266, 0.233])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(\n",
    "    sum(\n",
    "        (get_power_samples(torch.as_tensor([0.5, 0.25, 0.25]), coldness=1, batch_size=1).indices for _ in range(1000)),\n",
    "        [],\n",
    "    ),\n",
    "    return_counts=True,\n",
    ")[1] / 1000\n",
    "# should be around [0.5, 0.25, 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.487, 0.268, 0.245])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(\n",
    "    sum(\n",
    "        (\n",
    "            get_softmax_samples(torch.as_tensor([np.log(2), 0, 0]), coldness=1, batch_size=1).indices\n",
    "            for _ in range(1000)\n",
    "        ),\n",
    "        [],\n",
    "    ),\n",
    "    return_counts=True,\n",
    ")[1] / 1000\n",
    "# should be around [0.5, 0.25, 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.061, 2.959, 1.98 ])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(\n",
    "    sum((get_softrank_samples(torch.as_tensor([3, 2, 1]), coldness=1, batch_size=1).indices for _ in range(1000)), []),\n",
    "    return_counts=True,\n",
    ")[1] / 1000 * 11\n",
    "# p = [1, 1/2, 1/3] / ((6+3+2)/6) = [1, 1/2, 1/3] * 6 / 11 = [6/11, 3/11, 2/11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.967,  0.022,  0.011])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(\n",
    "    sum((get_softrank_samples(torch.as_tensor([3, 2, 1]), coldness=8, batch_size=1).indices for _ in range(1000)), []),\n",
    "    return_counts=True,\n",
    ")[1] / 1000 * 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.353, 0.313, 0.334])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(\n",
    "    sum((get_softmax_samples(torch.as_tensor([3, 2, 1]), coldness=0, batch_size=1).indices for _ in range(1000)), []),\n",
    "    return_counts=True,\n",
    ")[1] / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(\n",
    "    sum((get_softmax_samples(torch.as_tensor([3, 2, 1]), coldness=0, batch_size=1).indices for _ in range(1000)), []),\n",
    "    return_counts=True,\n",
    ")[1] / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5  , 0.442, 0.058])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(\n",
    "    sum((get_hypothesis_samples(torch.as_tensor([3, 2, 1]), coldness=1, batch_size=2).indices for _ in range(1000)), []),\n",
    "    return_counts=True,\n",
    ")[1] / 1000 / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "class StochasticMode(Enum):\n",
    "    Power = \"Power\"\n",
    "    Softmax = \"Softmax\"\n",
    "    Softrank = \"Softrank\"\n",
    "    Simulation = \"Simulation\"\n",
    "\n",
    "\n",
    "def get_stochastic_samples(\n",
    "    scores_N: torch.Tensor, *, coldness: float, batch_size: int, mode: StochasticMode\n",
    ") -> CandidateBatch:\n",
    "    if mode == StochasticMode.Power:\n",
    "        return get_power_samples(scores_N, coldness=coldness, batch_size=batch_size)\n",
    "    elif mode == StochasticMode.Softmax:\n",
    "        return get_softmax_samples(scores_N, coldness=coldness, batch_size=batch_size)\n",
    "    elif mode == StochasticMode.Softrank:\n",
    "        return get_softrank_samples(scores_N, coldness=coldness, batch_size=batch_size)\n",
    "    elif mode == StochasticMode.Simulation:\n",
    "        return get_simulation_samples(scores_N, coldness=coldness, batch_size=batch_size)\n",
    "    else:\n",
    "        return ValueError(f\"Unknown mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CandidateBatch(scores=[2.982371351302047, 1.8058588693740623], indices=[3, 0]),\n",
       " CandidateBatch(scores=[4.119388972071258, 2.457687553278123], indices=[0, 1]),\n",
       " CandidateBatch(scores=[0.47892253155902625, -0.7071420806250666], indices=[2, 0]),\n",
       " CandidateBatch(scores=[4.90777063369751, 0.32464359644716917], indices=[0, 2])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[get_stochastic_samples(torch.randn(size=(4,)).exp_(), coldness=1, batch_size=2, mode=mode) for mode in StochasticMode]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EPIG\n",
    "\n",
    "As part of an ablation (and to see how it performs), we can also compute the ICAL score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "def get_eig_scores(\n",
    "    training_log_probs_N_K_C: torch.Tensor,\n",
    "    pool_log_probs_N_K_C: torch.Tensor,\n",
    "    *,\n",
    "    dtype=None,\n",
    "    device=None,\n",
    ") -> torch.Tensor:\n",
    "    assert training_log_probs_N_K_C.shape == pool_log_probs_N_K_C.shape\n",
    "\n",
    "    N, K, C = training_log_probs_N_K_C.shape\n",
    "\n",
    "    scores_N = compute_entropy(training_log_probs_N_K_C) - compute_entropy(pool_log_probs_N_K_C)\n",
    "\n",
    "    return scores_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_eig_scores(ys_ws.log().double(), ys_ws.log().double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "# TODO: refactor the BatchBALDScorer to deduplicate some of this?\n",
    "def get_batch_eig_batch(\n",
    "    training_log_probs_N_K_C: torch.Tensor,\n",
    "    pool_log_probs_N_K_C: torch.Tensor,\n",
    "    *,\n",
    "    batch_size: int,\n",
    "    num_samples: int,\n",
    "    dtype=None,\n",
    "    device=None,\n",
    ") -> CandidateBatch:\n",
    "    assert training_log_probs_N_K_C.shape == pool_log_probs_N_K_C.shape\n",
    "    N, K, C = training_log_probs_N_K_C.shape\n",
    "\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    candidate_indices = []\n",
    "    candidate_scores = []\n",
    "\n",
    "    if batch_size == 0:\n",
    "        return CandidateBatch(candidate_scores, candidate_indices)\n",
    "\n",
    "    training_joint_entropy = joint_entropy.DynamicJointEntropy(\n",
    "        num_samples, batch_size, K, C, dtype=dtype, device=device\n",
    "    )\n",
    "\n",
    "    pool_joint_entropy = joint_entropy.DynamicJointEntropy(num_samples, batch_size, K, C, dtype=dtype, device=device)\n",
    "\n",
    "    # We always keep these on the CPU.\n",
    "    training_scores_N = torch.empty(\n",
    "        N,\n",
    "        dtype=torch.double,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "    )\n",
    "\n",
    "    pool_scores_N = torch.empty(\n",
    "        N,\n",
    "        dtype=torch.double,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "    )\n",
    "\n",
    "    for i in with_progress_bar(range(batch_size), tqdm_args=dict(desc=\"BatchBALD\", leave=False)):\n",
    "        if i > 0:\n",
    "            latest_index = candidate_indices[-1]\n",
    "            training_joint_entropy.add_variables(training_log_probs_N_K_C[latest_index : latest_index + 1])\n",
    "            pool_joint_entropy.add_variables(pool_log_probs_N_K_C[latest_index : latest_index + 1])\n",
    "\n",
    "        training_joint_entropy.compute_batch(training_log_probs_N_K_C, output_entropies_B=training_scores_N)\n",
    "        pool_joint_entropy.compute_batch(pool_log_probs_N_K_C, output_entropies_B=pool_scores_N)\n",
    "\n",
    "        scores_N = training_scores_N - pool_scores_N\n",
    "        scores_N[candidate_indices] = -float(\"inf\")\n",
    "\n",
    "        candidate_score, candidate_index = scores_N.max(dim=0)\n",
    "\n",
    "        candidate_indices.append(candidate_index.item())\n",
    "        candidate_scores.append(candidate_score.item())\n",
    "\n",
    "    return CandidateBatch(candidate_scores, candidate_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BatchBALD:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.0, 0.0, 0.0, 0.0], indices=[0, 1, 2, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch_eig_batch(ys_ws.log().double(), ys_ws.log().double(), batch_size=4, num_samples=1000, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Gain\n",
    "\n",
    "(Following the new notation.)\n",
    "\n",
    "Instead of computing $I[Y;\\omega|x]$, we use our knowledge of the labels and compute: $$I[y;\\omega|x]= H[y|x] - \\mathbb{E}_{p(\\omega|y,x)} H[y|x,\\omega].$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "def get_coreset_bald_scores_from_predictions(\n",
    "    log_probs_N_K_C: torch.Tensor, target_probs_N_C: torch.Tensor, *, dtype=None, device=None\n",
    ") -> torch.Tensor:\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "    assert target_probs_N_C.shape == (N, C)\n",
    "\n",
    "    log_probs_N_K_C = log_probs_N_K_C.to(dtype=dtype, device=device)\n",
    "    target_probs_N_C = target_probs_N_C.to(dtype=dtype, device=device)\n",
    "\n",
    "    log_prob_mean_N_C = torch.logsumexp(log_probs_N_K_C, dim=1) - np.log(K)\n",
    "\n",
    "    entropy_N_C = -log_prob_mean_N_C\n",
    "    conditional_entropy = -torch.mean(log_probs_N_K_C * log_probs_N_K_C.exp(), dim=1) / log_prob_mean_N_C.exp()\n",
    "    mutual_bits_N_C = entropy_N_C - conditional_entropy\n",
    "\n",
    "    cross_mutual_information = torch.sum(target_probs_N_C * mutual_bits_N_C, dim=1)\n",
    "\n",
    "    return cross_mutual_information\n",
    "\n",
    "\n",
    "def get_coreset_bald_scores(\n",
    "    log_probs_N_K_C: torch.Tensor, labels_N: torch.Tensor, *, dtype=None, device=None\n",
    ") -> torch.Tensor:\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "\n",
    "    labels_N_1_1 = labels_N[:, None, None]\n",
    "    log_probs_N_K = (\n",
    "        joint_entropy.gather_expand(log_probs_N_K_C, dim=2, index=labels_N_1_1)\n",
    "        .squeeze(2)\n",
    "        .to(dtype=dtype, device=device)\n",
    "    )\n",
    "\n",
    "    log_prob_mean_N = torch.logsumexp(log_probs_N_K, dim=1) - np.log(K)\n",
    "\n",
    "    lhs = -log_prob_mean_N\n",
    "    rhs = -torch.mean(log_probs_N_K * log_probs_N_K.exp(), dim=1) / log_prob_mean_N.exp()\n",
    "\n",
    "    coreset_infogain = lhs - rhs\n",
    "\n",
    "    return coreset_infogain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0300, 0.0300, 0.0300, 0.0300], dtype=torch.float64),\n",
       " [tensor([0.0300, 0.0207, 0.0207, 0.0474], dtype=torch.float64),\n",
       "  tensor([0.0474, 0.0300, 0.0207, 0.0207], dtype=torch.float64),\n",
       "  tensor([0.0207, 0.0474, 0.0300, 0.0207], dtype=torch.float64)])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_coreset_bald_scores(ys_ws.log().double(), torch.tensor([0, 1, 2, 3])), [\n",
    "    get_coreset_bald_scores(ys_ws.log().double(), torch.tensor([i, i, i, i])) for i in range(3)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Information Gain\n",
    "\n",
    "(Following the new notation.)\n",
    "\n",
    "The batch version of this acquisition function can be computed more easily:\n",
    "\n",
    "$$ \\operatorname{I}[(y)_B;\\omega|(x)_B] = \\operatorname{H}[(y)_B|(x)_B] - \\mathbb{E}_{p(\\omega|(y)_B, (x)_B)} \\operatorname{H}[(y)_B|(x)_B, \\omega], $$\n",
    "\n",
    "where $p(\\omega|(y)_B, (x)_B) = \\frac{ p((y)_B| (x)_B, \\omega) p(\\omega) }{ p((y)_B| (x)_B) }$ as usual, and we make use of the independence of the $(y)_B$ given $\\omega$.\n",
    "\n",
    "We can make this efficient for computing scores in parallel by using:\n",
    "$$p((y)_B|(x)_B, \\omega) = p(y_B|x_B, \\omega) \\; p((y)_{B-1}|(x)_{B-1}, \\omega).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do we have sub-modularity?\n",
    "\n",
    "Unclear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "def get_batch_coreset_bald_batch(\n",
    "    log_probs_N_K_C: torch.Tensor, labels_N: torch.Tensor, *, batch_size: int, dtype=None, device=None\n",
    ") -> CandidateBatch:\n",
    "    # We want to compute (note this does not follow the notation from below):\n",
    "    # CoreSetBALD = H[y_1, ..., y_n ] - E_p(w) p(y_1, ..., y_n | w) / p(y_1, ..., y_n) H[y_1, ..., y_n | w]\n",
    "    # H[y_1, ..., y_n | w] = H[y_1, ..., y_{n-1} | w] + H[y_n | w] because y_i _||_ y_j | w\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    candidate_indices = []\n",
    "    candidate_scores = []\n",
    "\n",
    "    if batch_size == 0:\n",
    "        return CandidateBatch(candidate_scores, candidate_indices)\n",
    "\n",
    "    labels_N_1_1 = labels_N[:, None, None]\n",
    "    log_probs_N_K = (\n",
    "        joint_entropy.gather_expand(log_probs_N_K_C, dim=2, index=labels_N_1_1)\n",
    "        .squeeze(2)\n",
    "        .to(dtype=dtype, device=device)\n",
    "    )\n",
    "\n",
    "    # p((y)_{B-1}|(x)_{B-1}, \\omega)\n",
    "    log_probs_conditional_joint_batch_K = torch.zeros_like(log_probs_N_K[0], dtype=dtype, device=device)\n",
    "\n",
    "    for i in with_progress_bar(range(batch_size), tqdm_args=dict(desc=\"BatchCoreSetBALD\", leave=False)):\n",
    "        # p((y)_B|(x)_B, \\omega) = p(y_B|x_B, \\omega) * p((y)_{B-1}|(x)_{B-1}, \\omega)\n",
    "        log_prob_conditional_joint_N_K = log_probs_N_K + log_probs_conditional_joint_batch_K[None, :]\n",
    "\n",
    "        # Marginalize over w (but using sum not mean):\n",
    "        # p((y)_B|(x)_B) = E_p(\\omega) p((y)_B|(x)_B, \\omega)\n",
    "        # log_prob_joint_N_1 = log_prob_conditional_joint_N_K.logsumexp(dim=1, keepdim=True) - np.log(K)\n",
    "        log_prob_joint_pK_N_1 = log_prob_conditional_joint_N_K.logsumexp(dim=1, keepdim=True)\n",
    "        # \\frac{ p((y)_B| (x)_B, \\omega) }{ p((y)_B| (x)_B) }\n",
    "        # log_ratio_N_K = log_prob_conditional_joint_N_K - log_prob_joint_N_1\n",
    "        # log_ratio_N_K = log_prob_conditional_joint_N_K - log_prob_joint_pK_N_1 + np.log(K)\n",
    "        log_ratio_mK_N_K = log_prob_conditional_joint_N_K - log_prob_joint_pK_N_1\n",
    "        # conditional_entropy_joint_N = -torch.mean(log_ratio_N_K.exp() * log_prob_conditional_joint_N_K, dim=1)\n",
    "        # conditional_entropy_joint_N =\n",
    "        #       -torch.mean((log_ratio_mK_N_K + np.log(K)).exp() * log_prob_conditional_joint_N_K, dim=1)\n",
    "        conditional_entropy_joint_N = -torch.sum(log_ratio_mK_N_K.exp() * log_prob_conditional_joint_N_K, dim=1)\n",
    "        # entropy_joint_N = -log_prob_joint_N_1.squeeze(1)\n",
    "        # entropy_joint_N = -(log_prob_joint_pK_N_1 - np.log(K)).squeeze(1)\n",
    "        entropy_joint_N = -log_prob_joint_pK_N_1.squeeze(1) + np.log(K)\n",
    "        scores_N = entropy_joint_N - conditional_entropy_joint_N\n",
    "\n",
    "        # Select candidate\n",
    "        scores_N[candidate_indices] = -float(\"inf\")\n",
    "\n",
    "        candidate_score, candidate_index = scores_N.max(dim=0)\n",
    "\n",
    "        candidate_indices.append(candidate_index.item())\n",
    "        candidate_scores.append(candidate_score.item())\n",
    "\n",
    "        # Update log_probs_conditional_joint_batch_K\n",
    "        log_probs_conditional_joint_batch_K = log_prob_conditional_joint_N_K[candidate_index]\n",
    "\n",
    "    return CandidateBatch(candidate_scores, candidate_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_coreset_bald_batch_simpler(\n",
    "    log_probs_N_K_C: torch.Tensor, labels_N: torch.Tensor, *, batch_size: int, dtype=None, device=None\n",
    ") -> CandidateBatch:\n",
    "    # We want to compute (note this does not follow the notation from below):\n",
    "    # CoreSetBALD = H[y_1, ..., y_n ] - E_p(w) p(y_1, ..., y_n | w) / p(y_1, ..., y_n) H[y_1, ..., y_n | w]\n",
    "    # H[y_1, ..., y_n | w] = H[y_1, ..., y_{n-1} | w] + H[y_n | w] because y_i _||_ y_j | w\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    candidate_indices = []\n",
    "    candidate_scores = []\n",
    "\n",
    "    if batch_size == 0:\n",
    "        return CandidateBatch(candidate_scores, candidate_indices)\n",
    "\n",
    "    labels_N_1_1 = labels_N[:, None, None]\n",
    "    log_probs_N_K = (\n",
    "        joint_entropy.gather_expand(log_probs_N_K_C, dim=2, index=labels_N_1_1)\n",
    "        .squeeze(2)\n",
    "        .to(dtype=dtype, device=device)\n",
    "    )\n",
    "\n",
    "    # p((y)_{B-1}|(x)_{B-1}, \\omega)\n",
    "    log_probs_conditional_joint_batch_K = torch.zeros_like(log_probs_N_K[0], dtype=dtype, device=device)\n",
    "\n",
    "    for i in with_progress_bar(range(batch_size), tqdm_args=dict(desc=\"BatchCoreSetBALD\", leave=False)):\n",
    "        # p((y)_B|(x)_B, \\omega) = p(y_B|x_B, \\omega) * p((y)_{B-1}|(x)_{B-1}, \\omega)\n",
    "        log_prob_conditional_joint_N_K = log_probs_N_K + log_probs_conditional_joint_batch_K[None, :]\n",
    "\n",
    "        # Marginalize over w (but using sum not mean):\n",
    "        # p((y)_B|(x)_B) = E_p(\\omega) p((y)_B|(x)_B, \\omega)\n",
    "        log_prob_joint_N_1 = log_prob_conditional_joint_N_K.logsumexp(dim=1, keepdim=True) - np.log(K)\n",
    "\n",
    "        # \\frac{ p((y)_B| (x)_B, \\omega) }{ p((y)_B| (x)_B) }\n",
    "        log_ratio_N_K = log_prob_conditional_joint_N_K - log_prob_joint_N_1\n",
    "        conditional_entropy_joint_N = -torch.mean(log_ratio_N_K.exp() * log_prob_conditional_joint_N_K, dim=1)\n",
    "        entropy_joint_N = -log_prob_joint_N_1.squeeze(1)\n",
    "        scores_N = entropy_joint_N - conditional_entropy_joint_N\n",
    "\n",
    "        # Select candidate\n",
    "        scores_N[candidate_indices] = -float(\"inf\")\n",
    "\n",
    "        candidate_score, candidate_index = scores_N.max(dim=0)\n",
    "\n",
    "        candidate_indices.append(candidate_index.item())\n",
    "        candidate_scores.append(candidate_score.item())\n",
    "\n",
    "        # Update log_probs_conditional_joint_batch_K\n",
    "        log_probs_conditional_joint_batch_K = log_prob_conditional_joint_N_K[candidate_index]\n",
    "\n",
    "    return CandidateBatch(candidate_scores, candidate_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.03002132, 0.03002132, 0.03002132, 0.03002132]),\n",
       " [tensor([0.0300, 0.0207, 0.0207, 0.0474], dtype=torch.float64),\n",
       "  tensor([0.0474, 0.0300, 0.0207, 0.0207], dtype=torch.float64),\n",
       "  tensor([0.0207, 0.0474, 0.0300, 0.0207], dtype=torch.float64)])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_coreset_bald_scores(ys_ws.log().double(), torch.tensor([0, 1, 2, 3])).numpy(), [\n",
    "    get_coreset_bald_scores(ys_ws.log().double(), torch.tensor([i, i, i, i])) for i in range(3)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 20, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_ws.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BatchCoreSetBALD:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.030021323375763576, 0.10871562110954991, 0.2168431672489275, 0.3375447132429139], indices=[0, 1, 2, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch_coreset_bald_batch(ys_ws.log().double(), torch.tensor([0, 1, 2, 3]), batch_size=4, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BatchCoreSetBALD:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.030021323375763687, 0.10871562110954991, 0.2168431672489275, 0.3375447132429139], indices=[0, 1, 2, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch_coreset_bald_batch_simpler(ys_ws.log().double(), torch.tensor([0, 1, 2, 3]), batch_size=4, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoreSet-PIG & Coreset-PIG-BALD\n",
    "\n",
    "Combining EIG with CoreSets to use $I[y_{eval}; y_{batch} | x_{eval}; x_{batch}, D_{train}]$.\n",
    "\n",
    "This is really easy to compute as $H[y_{batch} | x_{batch}, D_{train}] - H[y_{batch} | y_{eval}, x_{eval}; x_{batch}, D_{train}]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "def get_coreset_eig_scores(\n",
    "    *,\n",
    "    training_log_probs_N_K_C: torch.Tensor,\n",
    "    eval_log_probs_N_K_C: torch.Tensor,\n",
    "    labels_N: torch.Tensor,\n",
    "    dtype=None,\n",
    "    device=None\n",
    ") -> torch.Tensor:\n",
    "    # We want to compute I[y_eval; y_batch].\n",
    "    # I[y_eval; y_train] = H[y_batch] - H[y_batch|y_eval]\n",
    "    N, K, C = training_log_probs_N_K_C.shape\n",
    "\n",
    "    labels_N_1_1 = labels_N[:, None, None]\n",
    "    training_log_probs_N_K = (\n",
    "        joint_entropy.gather_expand(training_log_probs_N_K_C, dim=2, index=labels_N_1_1)\n",
    "        .squeeze(2)\n",
    "        .to(dtype=dtype, device=device)\n",
    "    )\n",
    "    training_log_prob_mean_N = torch.logsumexp(training_log_probs_N_K, dim=1) - np.log(K)\n",
    "\n",
    "    eval_log_probs_N_K = (\n",
    "        joint_entropy.gather_expand(eval_log_probs_N_K_C, dim=2, index=labels_N_1_1)\n",
    "        .squeeze(2)\n",
    "        .to(dtype=dtype, device=device)\n",
    "    )\n",
    "    eval_log_prob_mean_N = torch.logsumexp(eval_log_probs_N_K, dim=1) - np.log(K)\n",
    "\n",
    "    pig = -training_log_prob_mean_N + eval_log_prob_mean_N\n",
    "\n",
    "    return pig\n",
    "\n",
    "\n",
    "def get_coreset_eig_bald_scores(\n",
    "    *,\n",
    "    training_log_probs_N_K_C: torch.Tensor,\n",
    "    eval_log_probs_N_K_C: torch.Tensor,\n",
    "    labels_N: torch.Tensor,\n",
    "    dtype=None,\n",
    "    device=None\n",
    ") -> torch.Tensor:\n",
    "    # We want to compute I[y_eval; y_batch; W].\n",
    "    # I[y_eval; y_batch; W] = I[y_batch; W] - I[y_batch; W|y_eval]\n",
    "    training_coreset = get_coreset_bald_scores(training_log_probs_N_K_C, labels_N=labels_N, dtype=dtype, device=device)\n",
    "    eval_coreset = get_coreset_bald_scores(eval_log_probs_N_K_C, labels_N=labels_N, dtype=dtype, device=device)\n",
    "    return training_coreset - eval_coreset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_coreset_eig_scores(\n",
    "    training_log_probs_N_K_C=ys_ws.log().double(),\n",
    "    eval_log_probs_N_K_C=ys_ws.log().double(),\n",
    "    labels_N=torch.tensor([0, 1, 2, 3]),\n",
    "    dtype=torch.double,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_coreset_eig_bald_scores(\n",
    "    training_log_probs_N_K_C=ys_ws.log().double(),\n",
    "    eval_log_probs_N_K_C=ys_ws.log().double(),\n",
    "    labels_N=torch.tensor([0, 1, 2, 3]),\n",
    "    dtype=torch.double,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SieveBALD\n",
    "\n",
    "This is the 2-BALD approximation (leaving out $ D_{train}$):\n",
    "$$I[Y_1, \\ldots, Y_n;\\Omega \\mid x_1, \\ldots,x_n] \\approx \\sum_i I[Y_i;\\Omega\\mid x_i] - \\sum_{i<j} I[Y_i;Y_j \\mid x_i,x_j].$$\n",
    "\n",
    "See also https://www.notion.so/SieveBALD-using-a-marginal-total-correlation-assumption-and-or-by-forcing-it-2e4a9548d4124b6bb8e0dcbba789887a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "def get_sieve_bald_batch(log_probs_N_K_C: torch.Tensor, *, batch_size: int, dtype=None, device=None) -> CandidateBatch:\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    candidate_scores = []\n",
    "    candidate_indices = []\n",
    "\n",
    "    entropies_N = compute_entropy(log_probs_N_K_C)\n",
    "\n",
    "    # we start with BALD scores\n",
    "    scores_N = entropies_N - compute_conditional_entropy(log_probs_N_K_C)\n",
    "\n",
    "    last_score = 0.0\n",
    "    for _ in range(batch_size):\n",
    "        # Pick the highest scorer.\n",
    "        # This is amenable to lazy greedy and lazier than lazy greedy, though we do not implement this here. (Yet)\n",
    "        candidate_score, candidate_index = scores_N.max(dim=0)\n",
    "\n",
    "        # TODO: break here if candidate_score < 0 at this point!\n",
    "\n",
    "        candidate_score += last_score\n",
    "        last_score = candidate_score\n",
    "\n",
    "        candidate_indices.append(candidate_index.item())\n",
    "        candidate_scores.append(candidate_score.item())\n",
    "\n",
    "        # Update the acquired item's score so it is not picked again.\n",
    "        scores_N[candidate_index] = -float(\"inf\")\n",
    "\n",
    "        # Decrease scores for other items\n",
    "        joint_entropy_helper = joint_entropy.ExactJointEntropy.empty(K, device=device, dtype=dtype)\n",
    "        joint_entropy_helper.add_variables(log_probs_N_K_C[candidate_index : candidate_index + 1])\n",
    "        joint_entropies_N = joint_entropy_helper.compute_batch(log_probs_N_K_C)\n",
    "        dual_mi_N = entropies_N + entropies_N[candidate_index] - joint_entropies_N\n",
    "\n",
    "        scores_N -= dual_mi_N\n",
    "\n",
    "    return CandidateBatch(candidate_scores, candidate_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.030715639666234917, 0.05961958627158248, 0.08671183981604269, 0.11199240029961555, 0.13546126772230105, 0.15711844208409942, 0.17696392338501088, 0.1949977116250352], indices=[0, 1, 2, 3, 4, 6, 7, 5])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sieve_bald_batch(np.repeat(ys_ws, 2, axis=0).log().double(), batch_size=8, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 20, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_ws.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BatchBALD:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ExactJointEntropy.compute_batch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.030715639666234917, 0.05961958627158248, 0.0869107051474467, 0.11275304532467878, 0.1372853331853925, 0.16062670985153638, 0.18288066309757767, 0.2041378763246513], indices=[2, 0, 1, 4, 3, 5, 6, 7])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch_bald_batch(np.repeat(ys_ws, 2, axis=0).log().double(), batch_size=8, num_samples=1000000, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real EPIG\n",
    "\n",
    "Implement $I[Y_{acq} ; Y_{eval} \\mid x_{acq} ; X_{eval},  D_{train}]$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_joint_probs_N_C_C_old(pool_probs_N_K_C: torch.Tensor, single_eval_probs_K_C: torch.Tensor):\n",
    "    K = single_eval_probs_K_C.shape[0]\n",
    "\n",
    "    pool_log_probs_N_C_K = pool_probs_N_K_C.transpose(1, 2)\n",
    "    joint_probs_N_C_C = pool_log_probs_N_C_K @ single_eval_probs_K_C / K\n",
    "    return joint_probs_N_C_C\n",
    "\n",
    "\n",
    "def get_real_naive_epig_scores_old(\n",
    "    *, pool_log_probs_N_K_C: torch.Tensor, eval_log_probs_E_K_C: torch.Tensor, dtype=None, device=None\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Implements naive EPIG: I[Y_acq; Y_eval | x_acq, X_eval].\"\"\"\n",
    "    N, K, C = pool_log_probs_N_K_C.shape\n",
    "    E, _, _ = eval_log_probs_E_K_C.shape\n",
    "    assert (\n",
    "        pool_log_probs_N_K_C.shape[1:] == pool_log_probs_N_K_C.shape[1:]\n",
    "    ), \"{pool_log_probs_N_K_C.shape[1:]} != {pool_log_probs_N_K_C.shape[1:]}\"\n",
    "\n",
    "    pool_probs_N_K_C = pool_log_probs_N_K_C.to(dtype=dtype, device=device).exp()\n",
    "    eval_probs_E_K_C = eval_log_probs_E_K_C.to(dtype=dtype, device=device).exp()\n",
    "\n",
    "    pool_probs_N_C = torch.mean(pool_probs_N_K_C, dim=1, keepdim=False)\n",
    "\n",
    "    total_scores_N = torch.zeros((N,), dtype=dtype, device=\"cpu\")\n",
    "    for i_e in with_progress_bar(range(E), tqdm_args=dict(desc=\"Evaluation Set\", leave=False)):\n",
    "        single_eval_probs_K_C = eval_probs_E_K_C[i_e]\n",
    "\n",
    "        joint_probs_N_C_C = get_joint_probs_N_C_C_old(pool_probs_N_K_C, single_eval_probs_K_C)\n",
    "\n",
    "        single_eval_probs_C = torch.mean(single_eval_probs_K_C, dim=0, keepdim=False)\n",
    "\n",
    "        nats_N_C_C = (\n",
    "            -torch.log(single_eval_probs_C)[None, None, :]\n",
    "            - torch.log(pool_probs_N_C)[:, :, None]\n",
    "            + torch.log(joint_probs_N_C_C)\n",
    "        )\n",
    "\n",
    "        weighted_nats_N_C_C = nats_N_C_C * joint_probs_N_C_C\n",
    "        weighted_nats_N_C_C[torch.isnan(weighted_nats_N_C_C)] = 0.0\n",
    "        scores_N = weighted_nats_N_C_C.sum((1, 2), keepdim=False)\n",
    "\n",
    "        total_scores_N += scores_N.to(device=\"cpu\", non_blocking=True)\n",
    "\n",
    "    total_scores_N /= E\n",
    "\n",
    "    return total_scores_N"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# This is not working at the moment sadly :(((\n",
    "\n",
    "\n",
    "def simple_compute_entropy(log_probs_N_K_C: torch.Tensor) -> torch.Tensor:\n",
    "    N, K, C = log_probs_N_K_C.shape\n",
    "\n",
    "    mean_log_probs_N_C = torch.logsumexp(log_probs_N_K_C.to(dtype=torch.double), dim=1) - math.log(K)\n",
    "    nats_N_C = mean_log_probs_N_C * torch.exp(mean_log_probs_N_C)\n",
    "\n",
    "    entropies_N = -torch.sum(nats_N_C, dim=1)\n",
    "\n",
    "    return entropies_N\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "@torch.jit.script\n",
    "def _get_real_naive_epig_scores(\n",
    "    bootstrap_type: int,\n",
    "    bootstrap_factor: float,\n",
    "    pool_log_probs_N_K_C: torch.Tensor,\n",
    "    eval_log_probs_E_K_C: torch.Tensor,\n",
    "    dtype: int,\n",
    "    device: torch.device,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Implements naive EPIG: I[Y_acq; Y_eval | x_acq, X_eval].\"\"\"\n",
    "    # I[Y_acq; Y_eval | x_acq, X_eval] = H[Y_acq | x_acq] + E_p(x_eval)[H[Y_eval | x_eval] - H[Y_acq, Y_eval | x_acq, x_eval]]\n",
    "    N, K, C = pool_log_probs_N_K_C.shape\n",
    "    E, _, _ = eval_log_probs_E_K_C.shape\n",
    "    assert (\n",
    "        pool_log_probs_N_K_C.shape[1:] == pool_log_probs_N_K_C.shape[1:]\n",
    "    ), \"{pool_log_probs_N_K_C.shape[1:]} != {pool_log_probs_N_K_C.shape[1:]}\"\n",
    "\n",
    "    pool_entropies_N = simple_compute_entropy(pool_log_probs_N_K_C)\n",
    "\n",
    "    pool_probs_N_K_C = pool_log_probs_N_K_C.to(dtype=dtype, device=device).exp()\n",
    "    eval_probs_E_K_C = eval_log_probs_E_K_C.to(dtype=dtype, device=device).exp()\n",
    "\n",
    "    total_joint_entropies_N = torch.zeros((N,), dtype=dtype, device=\"cpu\")\n",
    "\n",
    "    if bootstrap_type != 2:\n",
    "        eval_label_uncertainty = simple_compute_entropy(eval_log_probs_E_K_C).mean(dim=0, keepdim=False)\n",
    "\n",
    "        if bootstrap_type == 0:\n",
    "            eval_range = torch.arange(E)\n",
    "        elif bootstrap_type == 1:\n",
    "            num_eval_samples = int(E * bootstrap_factor)\n",
    "            eval_range = torch.multinomial(torch.tensor(1.0).expand(E), num_samples=num_eval_samples, replacement=True)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown bootstrap {bootstrap_type}\")\n",
    "\n",
    "        for i_e in eval_range:\n",
    "            single_eval_probs_K_C = eval_probs_E_K_C[i_e]\n",
    "\n",
    "            joint_probs_N_C_C = get_joint_probs_N_C_C(pool_probs_N_K_C, single_eval_probs_K_C)\n",
    "            weighted_nats_N_C_C = joint_probs_N_C_C * -torch.log(joint_probs_N_C_C)\n",
    "            joint_entropy_N = weighted_nats_N_C_C.sum((1, 2), keepdim=False)\n",
    "            # del weighted_nats_N_C_C\n",
    "\n",
    "            total_joint_entropies_N += joint_entropy_N.to(device=\"cpu\", non_blocking=True)\n",
    "\n",
    "        total_scores_N = pool_entropies_N - total_joint_entropies_N / E + eval_label_uncertainty\n",
    "    else:\n",
    "        eval_label_uncertainty_E = simple_compute_entropy(eval_log_probs_E_K_C)\n",
    "\n",
    "        total_scores_N = pool_entropies_N\n",
    "\n",
    "        for i_n in range(N):\n",
    "            single_pool_probs_K_C = pool_probs_N_K_C[i_n]\n",
    "\n",
    "            num_eval_samples = int(E * bootstrap_factor)\n",
    "            eval_indices = torch.multinomial(\n",
    "                torch.tensor(1.0).expand(E), num_samples=num_eval_samples, replacement=True\n",
    "            )\n",
    "            # For debugging:\n",
    "            # num_eval_samples = E\n",
    "            # eval_indices = torch.tensor(list(range(E)))\n",
    "\n",
    "            sampled_eval_probs_F_K_C = eval_probs_E_K_C[eval_indices]\n",
    "\n",
    "            joint_probs_F_C_C = get_joint_probs_N_C_C(sampled_eval_probs_F_K_C, single_pool_probs_K_C)\n",
    "            weighted_nats_F_C_C = joint_probs_F_C_C * -torch.log(joint_probs_F_C_C)\n",
    "            avg_joint_entropy = weighted_nats_F_C_C.sum().to(device=\"cpu\", non_blocking=True) / num_eval_samples\n",
    "            # del weighted_nats_F_C_C\n",
    "\n",
    "            eval_label_uncertainty = eval_label_uncertainty_E[eval_indices].mean(dim=0, keepdim=False)\n",
    "            total_scores_N[i_n] += eval_label_uncertainty - avg_joint_entropy\n",
    "\n",
    "    return total_scores_N\n",
    "\n",
    "\n",
    "def get_real_naive_epig_scores(\n",
    "    *,\n",
    "    bootstrap_type=BootstrapType.NO_BOOTSTRAP,\n",
    "    bootstrap_factor=1.0,\n",
    "    pool_log_probs_N_K_C: torch.Tensor,\n",
    "    eval_log_probs_E_K_C: torch.Tensor,\n",
    "    dtype=torch.float,\n",
    "    device=None,\n",
    ") -> torch.Tensor:\n",
    "    return _get_real_naive_epig_scores(\n",
    "        bootstrap_type.value, bootstrap_factor, pool_log_probs_N_K_C, eval_log_probs_E_K_C, dtype, device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "class BootstrapType(Enum):\n",
    "    NO_BOOTSTRAP = 0\n",
    "    SINGLE_BOOTSTRAP = 1\n",
    "    PER_POINT_BOOTSTRAP = 2\n",
    "    FAST_PER_POINT_BOOTSTRAP = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "# def logmatmulexp(log_A: torch.Tensor, log_B: torch.Tensor) -> torch.Tensor:\n",
    "#     \"\"\"Given matrix log_A of shape (batch...) R and matrix log_B of shape RI, calculates\n",
    "#     (log_A.exp() @ log_B.exp()).log() and its backward in a numerically stable way.\"\"\"\n",
    "#     batch_shape = list(log_A.shape[:-2])\n",
    "#     , R = log_A.shape[-2:]\n",
    "#     I = log_B.shape[-1]\n",
    "#     assert log_B.shape == (R, I)\n",
    "#     log_A_expanded = log_A.unsqueeze(-1).expand(batch_shape + [, R, I])\n",
    "#     log_B_expanded = log_B.unsqueeze(-3).expand((, R, I))\n",
    "#     log_pairwise_products = log_A_expanded + log_B_expanded  # shape: (, R, I)\n",
    "#     return torch.logsumexp(log_pairwise_products, dim=-2)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def logmatmulexp(log_A: torch.Tensor, log_B: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Given matrix log_A of shape (batch...) R and matrix log_B of shape RI, calculates\n",
    "    (log_A.exp() @ log_B.exp()).log() and its backward in a numerically stable way.\"\"\"\n",
    "    max_A = torch.max(log_A, axis=-1, keepdim=True)[0]\n",
    "    max_B = torch.max(log_B, axis=-2, keepdim=True)[0]\n",
    "    C = torch.log((log_A - max_A).exp() @ (log_B - max_B).exp()) + max_A + max_B\n",
    "    return C\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_real_naive_epig_scores_stable(\n",
    "    *,\n",
    "    bootstrap_type=BootstrapType.NO_BOOTSTRAP,\n",
    "    bootstrap_factor=1.0,\n",
    "    pool_log_probs_N_K_C: torch.Tensor,\n",
    "    eval_log_probs_E_K_C: torch.Tensor,\n",
    "    dtype=None,\n",
    "    device=None,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Implements naive EPIG: I[Y_acq; Y_eval | x_acq, X_eval].\"\"\"\n",
    "    # I[Y_acq; Y_eval | x_acq, X_eval] = H[Y_acq | x_acq] + E_p(x_eval)[H[Y_eval | x_eval] - H[Y_acq, Y_eval | x_acq, x_eval]]\n",
    "    N, K, C = pool_log_probs_N_K_C.shape\n",
    "    E, _, _ = eval_log_probs_E_K_C.shape\n",
    "    assert (\n",
    "        pool_log_probs_N_K_C.shape[1:] == pool_log_probs_N_K_C.shape[1:]\n",
    "    ), \"{pool_log_probs_N_K_C.shape[1:]} != {pool_log_probs_N_K_C.shape[1:]}\"\n",
    "\n",
    "    pool_entropies_N = compute_entropy(pool_log_probs_N_K_C).to(device=device)\n",
    "\n",
    "    total_joint_entropies_N = torch.zeros((N,), dtype=dtype, device=device)\n",
    "\n",
    "    if bootstrap_type != BootstrapType.PER_POINT_BOOTSTRAP:\n",
    "        eval_label_uncertainty = compute_entropy(eval_log_probs_E_K_C).mean(dim=0, keepdim=False)\n",
    "\n",
    "        if bootstrap_type == BootstrapType.NO_BOOTSTRAP:\n",
    "            eval_range = range(E)\n",
    "        elif bootstrap_type == BootstrapType.SINGLE_BOOTSTRAP:\n",
    "            num_eval_samples = int(E * bootstrap_factor)\n",
    "            eval_range = torch.multinomial(torch.tensor(1.0).expand(E), num_samples=num_eval_samples, replacement=True)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown bootstrap {bootstrap_type}\")\n",
    "\n",
    "        pool_log_probs_N_C_K = pool_log_probs_N_K_C.transpose(1, 2).contiguous().to(dtype=dtype, device=device)\n",
    "        eval_log_probs_E_K_C = eval_log_probs_E_K_C.to(dtype=dtype, device=device)\n",
    "\n",
    "        for i_e in with_progress_bar(eval_range, tqdm_args=dict(desc=\"Evaluation Set\", leave=False)):\n",
    "            single_eval_log_probs_K_C = eval_log_probs_E_K_C[i_e]\n",
    "\n",
    "            joint_probs_N_C_C = logmatmulexp(pool_log_probs_N_C_K, single_eval_log_probs_K_C) - np.log(K)\n",
    "            weighted_nats_N_C_C = joint_probs_N_C_C * -torch.exp(joint_probs_N_C_C)\n",
    "            weighted_nats_N_C_C[torch.isnan(weighted_nats_N_C_C)] = 0.0\n",
    "            joint_entropy_N = weighted_nats_N_C_C.sum((1, 2), keepdim=False)\n",
    "            del weighted_nats_N_C_C\n",
    "\n",
    "            total_joint_entropies_N += joint_entropy_N\n",
    "\n",
    "        total_scores_N = pool_entropies_N - total_joint_entropies_N / E + eval_label_uncertainty\n",
    "    #     elif bootstrap_type == BootstrapType.PER_POINT_BOOTSTRAP:\n",
    "    #         eval_label_uncertainty_E = compute_entropy(eval_log_probs_E_K_C)\n",
    "\n",
    "    #         total_scores_N = pool_entropies_N\n",
    "\n",
    "    #         for i_n in with_progress_bar(range(N), tqdm_args=dict(desc=\"Pool Set\", leave=False)):\n",
    "    #             single_pool_probs_K_C = pool_probs_N_K_C[i_n]\n",
    "\n",
    "    #             num_eval_samples = int(E * bootstrap_factor)\n",
    "    #             eval_indices = torch.multinomial(\n",
    "    #                 torch.tensor(1.0).expand(E), num_samples=num_eval_samples, replacement=True\n",
    "    #             )\n",
    "    #             # For debugging:\n",
    "    #             # num_eval_samples = E\n",
    "    #             # eval_indices = torch.tensor(list(range(E)))\n",
    "\n",
    "    #             sampled_eval_probs_F_K_C = eval_probs_E_K_C[eval_indices]\n",
    "\n",
    "    #             joint_probs_F_C_C = get_joint_probs_N_C_C(sampled_eval_probs_F_K_C, single_pool_probs_K_C)\n",
    "    #             weighted_nats_F_C_C = joint_probs_F_C_C * -torch.log(joint_probs_F_C_C)\n",
    "    #             avg_joint_entropy = weighted_nats_F_C_C.sum() / num_eval_samples\n",
    "    #             del weighted_nats_F_C_C\n",
    "\n",
    "    #             eval_label_uncertainty = eval_label_uncertainty_E[eval_indices].mean(dim=0, keepdim=False)\n",
    "    #             total_scores_N[i_n] += eval_label_uncertainty - avg_joint_entropy\n",
    "\n",
    "    return total_scores_N.to(device=\"cpu\", non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "def get_joint_probs_N_C_C(pool_probs_N_K_C: torch.Tensor, single_eval_probs_K_C: torch.Tensor):\n",
    "    K = single_eval_probs_K_C.shape[0]\n",
    "\n",
    "    pool_log_probs_N_C_K = pool_probs_N_K_C.transpose(1, 2).contiguous()\n",
    "    joint_probs_N_C_C = pool_log_probs_N_C_K @ single_eval_probs_K_C / K\n",
    "    return joint_probs_N_C_C\n",
    "\n",
    "\n",
    "def get_joint_probs_N_C_EC_transposed(pool_probs_N_C_K: torch.Tensor, eval_probs_E_K_C: torch.Tensor):\n",
    "    N, C, K = pool_probs_N_C_K.shape\n",
    "    E, K, C = eval_probs_E_K_C.shape\n",
    "    # joint_probs_N_C_C = torch.empty(N, C, C, dtype=pool_probs_N_C_K.dtype, device=pool_probs_N_C_K.device)\n",
    "    # for joint_probs_C_C, pool_probs_C_K in zip(joint_probs_N_C_C.split(4096), pool_probs_N_C_K.split(4096)):\n",
    "    #     joint_probs = pool_probs_C_K @ single_eval_probs_K_C / K\n",
    "    #     joint_probs_C_C.copy_(joint_probs, non_blocking=True)\n",
    "    eval_probs_K_EC = eval_probs_E_K_C.transpose(0, 1).reshape(K, E * C)\n",
    "    # joint_probs_N_C_EC = pool_probs_N_C_K.contiguous() @ eval_probs_K_EC.contiguous() / K\n",
    "    joint_probs_N_C_EC = pool_probs_N_C_K @ eval_probs_K_EC / K\n",
    "    return joint_probs_N_C_EC\n",
    "\n",
    "\n",
    "def get_joint_probs_N_C_C_transposed(pool_probs_N_C_K: torch.Tensor, single_eval_probs_K_C: torch.Tensor):\n",
    "    K = single_eval_probs_K_C.shape[0]\n",
    "    joint_probs_N_C_C = pool_probs_N_C_K @ single_eval_probs_K_C / K\n",
    "    return joint_probs_N_C_C\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_real_naive_epig_scores(\n",
    "    *,\n",
    "    bootstrap_type=BootstrapType.NO_BOOTSTRAP,\n",
    "    bootstrap_factor=1.0,\n",
    "    pool_log_probs_N_K_C: torch.Tensor,\n",
    "    eval_log_probs_E_K_C: torch.Tensor,\n",
    "    dtype=None,\n",
    "    device=None,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Implements naive EPIG: I[Y_acq; Y_eval | x_acq, X_eval].\"\"\"\n",
    "    # I[Y_acq; Y_eval | x_acq, X_eval] = H[Y_acq | x_acq] + E_p(x_eval)[H[Y_eval | x_eval] - H[Y_acq, Y_eval | x_acq, x_eval]]\n",
    "    N, K, C = pool_log_probs_N_K_C.shape\n",
    "    E, _, _ = eval_log_probs_E_K_C.shape\n",
    "    assert (\n",
    "        pool_log_probs_N_K_C.shape[1:] == pool_log_probs_N_K_C.shape[1:]\n",
    "    ), \"{pool_log_probs_N_K_C.shape[1:]} != {pool_log_probs_N_K_C.shape[1:]}\"\n",
    "\n",
    "    pool_entropies_N = compute_entropy(pool_log_probs_N_K_C).to(device=device, non_blocking=True)\n",
    "\n",
    "    total_joint_entropies_N = torch.zeros((N,), dtype=dtype, device=device)\n",
    "\n",
    "    if bootstrap_type != BootstrapType.PER_POINT_BOOTSTRAP:\n",
    "        pool_probs_N_C_K = (\n",
    "            pool_log_probs_N_K_C.to(dtype=dtype, device=device, non_blocking=True).exp().transpose(1, 2).contiguous()\n",
    "        )\n",
    "        # eval_probs_E_K_C = eval_log_probs_E_K_C.to(device=device, non_blocking=True).exp()\n",
    "\n",
    "        eval_label_uncertainty = compute_entropy(eval_log_probs_E_K_C).mean(dim=0, keepdim=False)\n",
    "\n",
    "        if bootstrap_type == BootstrapType.NO_BOOTSTRAP:\n",
    "            num_eval_samples = E\n",
    "            eval_range = list(range(E))\n",
    "        elif bootstrap_type == BootstrapType.SINGLE_BOOTSTRAP:\n",
    "            num_eval_samples = int(E * bootstrap_factor)\n",
    "            eval_range = torch.multinomial(torch.tensor(1.0).expand(E), num_samples=num_eval_samples, replacement=True)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown bootstrap {bootstrap_type}\")\n",
    "\n",
    "        pbar = create_progress_bar(num_eval_samples, tqdm_args=dict(desc=\"Evaluation Set\", leave=False))\n",
    "        pbar.start()\n",
    "\n",
    "        @toma.execute.batch(1024)\n",
    "        def loop(batchsize: int):\n",
    "            pbar.reset()\n",
    "\n",
    "            nonlocal total_joint_entropies_N\n",
    "            for chunked_eval_log_probs_e_K_C in eval_log_probs_E_K_C[eval_range].split(batchsize):\n",
    "                chunked_eval_probs_e_K_C = chunked_eval_log_probs_e_K_C.to(\n",
    "                    dtype=dtype, device=device, non_blocking=True\n",
    "                ).exp()\n",
    "                joint_probs_N_E_EC = get_joint_probs_N_C_EC_transposed(pool_probs_N_C_K, chunked_eval_probs_e_K_C)\n",
    "                weighted_nats_N_C_EC = joint_probs_N_E_EC * -torch.log(joint_probs_N_E_EC)\n",
    "                weighted_nats_N_C_EC[torch.isnan(weighted_nats_N_C_EC)] = 0.0\n",
    "                joint_entropy_N = weighted_nats_N_C_EC.sum((1, 2), keepdim=False)\n",
    "                del weighted_nats_N_C_EC\n",
    "\n",
    "                total_joint_entropies_N += joint_entropy_N\n",
    "\n",
    "                pbar.update(len(chunked_eval_probs_e_K_C))\n",
    "\n",
    "        pbar.finish()\n",
    "\n",
    "        total_scores_N = pool_entropies_N - total_joint_entropies_N / E + eval_label_uncertainty\n",
    "    elif bootstrap_type == BootstrapType.PER_POINT_BOOTSTRAP:\n",
    "        pool_probs_N_K_C = pool_log_probs_N_K_C.to(dtype=dtype, device=device).exp()\n",
    "        eval_probs_E_C_K = eval_log_probs_E_K_C.to(dtype=dtype, device=device).exp().transpose(1, 2).contiguous()\n",
    "\n",
    "        eval_label_uncertainty_E = compute_entropy(eval_log_probs_E_K_C)\n",
    "\n",
    "        total_scores_N = pool_entropies_N\n",
    "\n",
    "        for i_n in with_progress_bar(range(N), tqdm_args=dict(desc=\"Pool Set\", leave=False)):\n",
    "            single_pool_probs_K_C = pool_probs_N_K_C[i_n]\n",
    "\n",
    "            num_eval_samples = int(E * bootstrap_factor)\n",
    "            eval_indices = torch.multinomial(\n",
    "                torch.tensor(1.0).expand(E), num_samples=num_eval_samples, replacement=True\n",
    "            )\n",
    "            # For debugging:\n",
    "            # num_eval_samples = E\n",
    "            # eval_indices = torch.tensor(list(range(E)))\n",
    "\n",
    "            sampled_eval_probs_F_C_K = eval_probs_E_C_K[eval_indices]\n",
    "\n",
    "            joint_probs_F_C_C = get_joint_probs_N_C_C_transposed(sampled_eval_probs_F_C_K, single_pool_probs_K_C)\n",
    "            weighted_nats_F_C_C = joint_probs_F_C_C * -torch.log(joint_probs_F_C_C)\n",
    "            weighted_nats_F_C_C[torch.isnan(weighted_nats_F_C_C)] = 0.0\n",
    "            avg_joint_entropy = weighted_nats_F_C_C.sum() / num_eval_samples\n",
    "            del weighted_nats_F_C_C\n",
    "\n",
    "            eval_label_uncertainty = eval_label_uncertainty_E[eval_indices].mean(dim=0, keepdim=False)\n",
    "            total_scores_N[i_n] += eval_label_uncertainty - avg_joint_entropy\n",
    "\n",
    "    return total_scores_N.to(device=\"cpu\", non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_log_probs_N_K_C = torch.log_softmax(torch.randn(7, 13, 3) * 100, dim=2)\n",
    "eval_log_probs_E_K_C = torch.log_softmax(torch.randn(11, 13, 3) * 100, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation Set:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation Set:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2072, 0.1844, 0.1629, 0.1929, 0.1682, 0.2395, 0.1918],\n",
      "       dtype=torch.float64) tensor([0.2072, 0.1844, 0.1629, 0.1929, 0.1682, 0.2395, 0.1918],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation Set:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation Set:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2072, 0.1844, 0.1629, 0.1929, 0.1682, 0.2395, 0.1918],\n",
      "       dtype=torch.float64) tensor([0.2072, 0.1844, 0.1629, 0.1929, 0.1682, 0.2395, 0.1918],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for dtype in (torch.float32, torch.double):\n",
    "    print(\n",
    "        get_real_naive_epig_scores(\n",
    "            pool_log_probs_N_K_C=pool_log_probs_N_K_C,\n",
    "            eval_log_probs_E_K_C=eval_log_probs_E_K_C,\n",
    "            device=\"cuda\",\n",
    "            dtype=dtype,\n",
    "        ),\n",
    "        get_real_naive_epig_scores_stable(\n",
    "            pool_log_probs_N_K_C=pool_log_probs_N_K_C,\n",
    "            eval_log_probs_E_K_C=eval_log_probs_E_K_C,\n",
    "            device=\"cuda\",\n",
    "            dtype=dtype,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation Set:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation Set:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.2072, 0.1844, 0.1629, 0.1929, 0.1682, 0.2395, 0.1918],\n",
       "        dtype=torch.float64),\n",
       " tensor([0.2072, 0.1844, 0.1629, 0.1929, 0.1682, 0.2395, 0.1918]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_real_naive_epig_scores(\n",
    "    pool_log_probs_N_K_C=pool_log_probs_N_K_C, eval_log_probs_E_K_C=eval_log_probs_E_K_C, device=\"cuda\"\n",
    "), get_real_naive_epig_scores_old(\n",
    "    pool_log_probs_N_K_C=pool_log_probs_N_K_C, eval_log_probs_E_K_C=eval_log_probs_E_K_C, device=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pool Set:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.1770, 0.2326, 0.1526, 0.2323, 0.1525, 0.2118, 0.1741],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_real_naive_epig_scores(\n",
    "    bootstrap_type=BootstrapType.PER_POINT_BOOTSTRAP,\n",
    "    pool_log_probs_N_K_C=pool_log_probs_N_K_C,\n",
    "    eval_log_probs_E_K_C=eval_log_probs_E_K_C,\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation Set:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.1971, 0.1683, 0.1589, 0.1959, 0.1634, 0.2245, 0.1531],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_real_naive_epig_scores(\n",
    "    bootstrap_type=BootstrapType.SINGLE_BOOTSTRAP,\n",
    "    pool_log_probs_N_K_C=pool_log_probs_N_K_C,\n",
    "    eval_log_probs_E_K_C=eval_log_probs_E_K_C,\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575090b90187402e9d9204fb7fb46059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation Set:   0%|          | 0/60000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-9af49b935316>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     get_real_naive_epig_scores_old(\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mpool_log_probs_N_K_C\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0meval_log_probs_E_K_C\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-3282b1f8025e>\u001b[0m in \u001b[0;36mget_real_naive_epig_scores_old\u001b[0;34m(pool_log_probs_N_K_C, eval_log_probs_E_K_C, dtype, device)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mweighted_nats_N_C_C\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnats_N_C_C\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mjoint_probs_N_C_C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mweighted_nats_N_C_C\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweighted_nats_N_C_C\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mscores_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweighted_nats_N_C_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "num_samples = 60000\n",
    "\n",
    "with torch.no_grad():\n",
    "    X = torch.log_softmax(torch.randn(num_samples, 100, 10), dim=2)\n",
    "    Y = torch.log_softmax(torch.randn(num_samples, 100, 10), dim=2)\n",
    "    get_real_naive_epig_scores(\n",
    "        pool_log_probs_N_K_C=X,\n",
    "        eval_log_probs_E_K_C=Y,\n",
    "        dtype=torch.double,\n",
    "        device=\"cuda\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# slow\n",
    "\n",
    "num_samples = 6000\n",
    "\n",
    "with torch.no_grad():\n",
    "    get_real_naive_epig_scores_old(\n",
    "        pool_log_probs_N_K_C=X,\n",
    "        eval_log_probs_E_K_C=Y,\n",
    "        dtype=torch.float,\n",
    "        device=\"cuda\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "\n",
    "with torch.no_grad():\n",
    "    get_real_naive_epig_scores(\n",
    "        bootstrap_type=BootstrapType.PER_POINT_BOOTSTRAP,\n",
    "        bootstrap_factor=1,\n",
    "        pool_log_probs_N_K_C=torch.log_softmax(torch.randn(num_samples, 100, 10), dim=2),\n",
    "        eval_log_probs_E_K_C=torch.log_softmax(torch.randn(num_samples, 100, 10), dim=2),\n",
    "        device=\"cuda\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "\n",
    "with torch.no_grad():\n",
    "    get_real_naive_epig_scores(\n",
    "        bootstrap_type=BootstrapType.SINGLE_BOOTSTRAP,\n",
    "        bootstrap_factor=0.85,\n",
    "        pool_log_probs_N_K_C=torch.log_softmax(torch.randn(num_samples, 100, 10), dim=2),\n",
    "        eval_log_probs_E_K_C=torch.log_softmax(torch.randn(num_samples, 100, 10), dim=2),\n",
    "        device=\"cuda\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DirichletBALD (Unclear/TODO)\n",
    "\n",
    "This is enspired by Energy-Based Models and Dirichlet distributions. Instead of working with the probabilities after the Softmax layer, we use the logits directly and view them log concentrations of a Dirichlet distribution.\n",
    "\n",
    "We can combine this with MC Dropout to get different Dirichlet samples by averaging the log concentrations. This leads to the exact same computation as before (geometric averaging of the probabilities). \n",
    "\n",
    "This is different than fitting a Dirichlet distribution. Taking the log concentrations instead of probabilities does not throw away \"density\" information from the model.\n",
    "\n",
    "We could recover a mutual information term using the Dirichlet assumption then?\n",
    "\n",
    "(In general, it is not entirely clear to me how to combine them. One path could be to use a conjugate prior distribution and taking the mean/mode of that. The conjugate prior of a Dirichlet distribution is the Boojum distribution, which is quite complex and does not provide an analytical solution for computing its mean or mode.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_dirichlet_bald_scores(logits_N_K_C: torch.Tensor, *,\n",
    "#     dtype=None,\n",
    "#     device=None) -> torch.Tensor:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:active_learning]",
   "language": "python",
   "name": "conda-env-active_learning-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
