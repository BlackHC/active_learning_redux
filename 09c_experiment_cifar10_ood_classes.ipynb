{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment CIFAR-10\n",
    "> Can we get better by training on our assumptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp experiment_cifar10_ood_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended /home/blackhc/PycharmProjects/bald-ical/src to paths\n",
      "Switched to directory /home/blackhc/PycharmProjects/bald-ical\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "import blackhc.project.script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules and functions were are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "import dataclasses\n",
    "import traceback\n",
    "\n",
    "from blackhc.project import is_run_from_ipython\n",
    "from blackhc.project.experiment import embedded_experiments\n",
    "\n",
    "from batchbald_redux import acquisition_functions\n",
    "from batchbald_redux import baseline_acquisition_functions\n",
    "from batchbald_redux.experiment_data import OODClassesDistributionExperimentDataConfig\n",
    "from batchbald_redux.unified_experiment import UnifiedExperiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "# (ID: air, automobile, ship and truck, OOD: bird, cat, deer, dog, frog and horse)\n",
    "# ood_classes={2, 3, 4, 5, 6, 7}\n",
    "\n",
    "configs = [\n",
    "    UnifiedExperiment(\n",
    "        experiment_data_config=OODClassesDistributionExperimentDataConfig(dataset_name=\"CIFAR-10\", repetitions=1,\n",
    "                                                                          initial_training_set_size=400,\n",
    "                                                                          validation_set_size=4096,\n",
    "                                                                          validation_split_random_state=0,\n",
    "                                                                          evaluation_set_size=0,\n",
    "                                                                          add_dataset_noise=False,\n",
    "                                                                          ood_exposure=ood_exposure, ood_repetitions=1,\n",
    "                                                                          ood_classes={2, 3, 4, 5, 6, 7}),\n",
    "        seed=seed + 4658,\n",
    "        acquisition_function=acquisition_function,\n",
    "        acquisition_size=acquisition_size,\n",
    "        num_pool_samples=num_pool_samples,\n",
    "        max_training_set=14000,\n",
    "    )\n",
    "    for seed in range(5)\n",
    "    for acquisition_function in [\n",
    "        acquisition_functions.BALD,\n",
    "        acquisition_functions.EPIG,\n",
    "        acquisition_functions.EvalBALD,\n",
    "        baseline_acquisition_functions.BADGE,\n",
    "        acquisition_functions.Random\n",
    "    ]\n",
    "    for acquisition_size in [1000]\n",
    "    for num_pool_samples in [50]\n",
    "    for ood_exposure in [False, True]\n",
    "]\n",
    "\n",
    "if not is_run_from_ipython() and __name__ == \"__main__\":\n",
    "    for job_id, store in embedded_experiments(__file__, len(configs)):\n",
    "        config = configs[job_id]\n",
    "        config.seed += job_id\n",
    "        print(config)\n",
    "        store[\"config\"] = dataclasses.asdict(config)\n",
    "        store[\"log\"] = {}\n",
    "\n",
    "        try:\n",
    "            config.run(store=store)\n",
    "        except Exception:\n",
    "            store[\"exception\"] = traceback.format_exc()\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8945,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=True\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8945,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=False\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8945,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=True\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EPIG\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8945,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=False\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EPIG\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8945,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=True\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8945,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=False\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8945,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=True\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8945,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=False\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8945,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=True\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.Random\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8945,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=False\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.Random\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8946,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=True\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8946,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=False\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8946,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=True\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EPIG\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8946,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=False\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EPIG\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8946,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=True\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8946,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=False\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8946,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=True\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8946,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=False\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8946,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=True\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.Random\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8946,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=False\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.Random\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8947,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=True\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8947,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=False\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8947,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=True\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EPIG\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8947,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=False\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EPIG\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8947,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=True\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8947,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=False\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8947,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=True\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8947,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=False\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8947,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=True\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.Random\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8947,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=False\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.Random\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8948,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=True\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8948,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=False\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8948,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=True\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EPIG\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8948,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=False\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EPIG\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8948,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=True\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8948,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=False\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8948,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=True\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8948,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=False\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8948,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=True\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.Random\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8948,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=False\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.Random\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8949,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=True\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8949,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=False\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8949,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=True\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EPIG\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8949,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=False\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EPIG\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8949,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=True\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8949,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=False\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8949,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=True\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8949,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=False\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8949,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=True\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.Random\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8949,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(\n",
      "            dataset_name='CIFAR-10',\n",
      "            repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_classes={2, 3, 4, 5, 6, 8},\n",
      "            ood_repetitions=1,\n",
      "            ood_exposure=False\n",
      "        ),\n",
      "        acquisition_size=1000,\n",
      "        max_training_set=15000,\n",
      "        num_pool_samples=50,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.Random\n",
      "    )\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import prettyprinter\n",
    "prettyprinter.install_extras({\"dataclasses\"})\n",
    "prettyprinter.pprint(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n",
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Initial Samples + Evaluation Set Class Counts: [4750, 4750, 0, 0, 0, 0, 0, 4750, 0, 4750]\n",
      "Creating: BALD(\n",
      "\tacquisition_size=1000,\n",
      "\tnum_pool_samples=5\n",
      ")\n",
      "Creating: Cifar10ModelTrainer(\n",
      "\tdevice=cuda,\n",
      "\tnum_training_samples=1,\n",
      "\tnum_validation_samples=20,\n",
      "\tmax_training_epochs=100\n",
      ")\n",
      "Creating: TrainSelfDistillationEvalModel(\n",
      "\tnum_pool_samples=5\n",
      ")\n",
      "Training set size 18361:\n",
      "Cosine Annealing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a315fcf06a17434abc4b30c504f26c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  1%|1         | 1/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/143]   1%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 metrics: {'accuracy': 0.5641809290953546, 'crossentropy': 1.0880740169790963}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/143]   1%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 metrics: {'accuracy': 0.7579462102689487, 'crossentropy': 0.6506049117132621}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/143]   1%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 metrics: {'accuracy': 0.8111246943765281, 'crossentropy': 0.5224523124601556}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/143]   1%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 metrics: {'accuracy': 0.7976772616136919, 'crossentropy': 0.6397940637429944}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de4b658c093b453ca8d017c1c4561b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/143]   1%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: .\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-14e34df1f161>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_training_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_pool_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/unified_experiment.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, store)\u001b[0m\n\u001b[1;32m    252\u001b[0m         )\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mactive_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/unified_experiment.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, log)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             trained_model = model_trainer.get_trained(\n\u001b[0m\u001b[1;32m    103\u001b[0m                 \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mtrain_augmentations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_augmentations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/resnet_models.py\u001b[0m in \u001b[0;36mget_trained\u001b[0;34m(self, train_loader, train_augmentations, validation_loader, log, loss, validation_loss)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cosine Annealing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             train_with_cosine_annealing(\n\u001b[0m\u001b[1;32m    403\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/black_box_model_training.py\u001b[0m in \u001b[0;36mtrain_with_cosine_annealing\u001b[0;34m(model, training_samples, validation_samples, train_loader, validation_loader, max_epochs, device, training_log, loss, validation_loss, optimizer, train_augmentations)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;31m# Kick everything off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0;31m# Return the optimizer in case we want to continue training.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Engine run is terminating due to exception: %s.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    728\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/__init__.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(engine, batch)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/kornia/augmentation/augmentation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, params, return_transform)\u001b[0m\n\u001b[1;32m   1135\u001b[0m             \u001b[0minput_pad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m             \u001b[0m_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecrop_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_pad\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1137\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m         \u001b[0;31m# Update the actual input size for inverse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/kornia/augmentation/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, params, return_transform)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_transform_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mori_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeepdim\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/kornia/augmentation/base.py\u001b[0m in \u001b[0;36mapply_func\u001b[0;34m(self, in_tensor, in_transform, params, return_transform)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# if all data needs to be augmented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_apply\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_apply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0mtrans_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_transformation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/kornia/augmentation/augmentation.py\u001b[0m in \u001b[0;36mcompute_transformation\u001b[0;34m(self, input, params)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_transformation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m         \u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_perspective_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'src'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dst'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/kornia/geometry/transform/imgwarp.py\u001b[0m in \u001b[0;36mget_perspective_transform\u001b[0;34m(src, dst)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_build_perspective_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_build_perspective_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# A is Bx8x8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/kornia/geometry/transform/imgwarp.py\u001b[0m in \u001b[0;36m_build_perspective_param\u001b[0;34m(p, q, axis)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         return torch.cat(\n\u001b[0m\u001b[1;32m    303\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "store={}\n",
    "\n",
    "configs[0].max_training_set=2000\n",
    "configs[0].experiment_data_config.initial_training_set_size = int(50000/10*4-1000)\n",
    "configs[0].max_training_epochs=100\n",
    "configs[0].num_pool_samples=5\n",
    "configs[0].run(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:active_learning]",
   "language": "python",
   "name": "conda-env-active_learning-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
