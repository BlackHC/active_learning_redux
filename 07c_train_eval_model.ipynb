{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trained Model Interface\n",
    "> \"Why simple, when you can use design patterns?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp train_eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended /home/blackhc/PycharmProjects/bald-ical/src to paths\n",
      "Switched to directory /home/blackhc/PycharmProjects/bald-ical\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "import blackhc.project.script\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "from dataclasses import dataclass\n",
    "from typing import Type\n",
    "\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.utils.data\n",
    "from torch import nn\n",
    "\n",
    "from batchbald_redux.active_learning import RandomFixedLengthSampler\n",
    "from batchbald_redux.consistent_mc_dropout import get_log_mean_probs\n",
    "from batchbald_redux.dataset_challenges import (\n",
    "    RandomLabelsDataset,\n",
    "    ReplaceTargetsDataset,\n",
    ")\n",
    "from batchbald_redux.trained_model import TrainedModel, ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "class TrainEvalModel:\n",
    "    def __call__(self, *, training_log, device) -> TrainedModel:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainSelfDistillationEvalModel(TrainEvalModel):\n",
    "    num_pool_samples: int\n",
    "    training_dataset: torch.utils.data.Dataset\n",
    "    eval_dataset: torch.utils.data.Dataset\n",
    "    validation_loader: torch.utils.data.DataLoader\n",
    "    trained_model: TrainedModel\n",
    "    model_trainer: ModelTrainer\n",
    "    dataset_device: object\n",
    "    # TODO: remove the default?\n",
    "    train_augmentations: nn.Module = None\n",
    "\n",
    "    def __call__(self, *, training_log, device):\n",
    "        train_eval_dataset = torch.utils.data.ConcatDataset([self.training_dataset, self.eval_dataset])\n",
    "        train_eval_loader = self.model_trainer.get_evaluation_dataloader(train_eval_dataset)\n",
    "\n",
    "        eval_log_probs_N_C = get_log_mean_probs(\n",
    "            self.trained_model.get_log_probs_N_K_C(train_eval_loader, num_samples=self.num_pool_samples, device=device, storage_device=self.dataset_device)\n",
    "        )\n",
    "\n",
    "        eval_self_distillation_dataset = ReplaceTargetsDataset(dataset=train_eval_dataset, targets=eval_log_probs_N_C)\n",
    "\n",
    "        train_eval_self_distillation_loader = self.model_trainer.get_train_dataloader(eval_self_distillation_dataset)\n",
    "\n",
    "        trained_model = self.model_trainer.get_distilled(\n",
    "            prediction_loader=train_eval_self_distillation_loader,\n",
    "            train_augmentations=self.train_augmentations,\n",
    "            validation_loader=self.validation_loader,\n",
    "            log=training_log\n",
    "        )\n",
    "\n",
    "        return trained_model\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainRandomLabelEvalModel(TrainEvalModel):\n",
    "    training_dataset: torch.utils.data.Dataset\n",
    "    eval_dataset: torch.utils.data.Dataset\n",
    "    validation_loader: torch.utils.data.DataLoader\n",
    "    model_trainer: ModelTrainer\n",
    "    dataset_device: object\n",
    "    # TODO: remove the default?\n",
    "    train_augmentations: nn.Module = None\n",
    "\n",
    "    def __call__(self, *, training_log, device):\n",
    "        # TODO: support one_hot!\n",
    "        # TODO: different seed needed!\n",
    "        train_eval_dataset = torch.utils.data.ConcatDataset(\n",
    "            [self.training_dataset, RandomLabelsDataset(self.eval_dataset, seed=0, device=self.dataset_device)]\n",
    "        )\n",
    "        train_eval_loader = self.model_trainer.get_train_dataloader(train_eval_dataset)\n",
    "\n",
    "        trained_model = self.model_trainer.get_trained(\n",
    "            prediction_loader=train_eval_loader,\n",
    "            train_augmentations=self.train_augmentations,\n",
    "            validation_loader=self.validation_loader,\n",
    "            log=training_log\n",
    "        )\n",
    "\n",
    "        return trained_model\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainExplicitEvalModel(TrainEvalModel):\n",
    "    training_dataset: torch.utils.data.Dataset\n",
    "    eval_dataset: torch.utils.data.Dataset\n",
    "    validation_loader: torch.utils.data.DataLoader\n",
    "    model_trainer: ModelTrainer\n",
    "    # TODO: remove the default?\n",
    "    train_augmentations: nn.Module = None\n",
    "\n",
    "    def __call__(self, *, training_log, device):\n",
    "        # TODO: support one_hot!? For this we need to change the eval_dataset to also have one_hot applied in ExperimentData?\n",
    "        train_eval_dataset = torch.utils.data.ConcatDataset([self.training_dataset, self.eval_dataset])\n",
    "        train_eval_loader = self.model_trainer.get_train_dataloader(train_eval_dataset)\n",
    "\n",
    "        trained_model = self.model_trainer.get_trained(train_loader=train_eval_loader,\n",
    "                                                       train_augmentations=self.train_augmentations,\n",
    "                                                       validation_loader=self.validation_loader, log=training_log)\n",
    "\n",
    "        return trained_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:active_learning]",
   "language": "python",
   "name": "conda-env-active_learning-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
