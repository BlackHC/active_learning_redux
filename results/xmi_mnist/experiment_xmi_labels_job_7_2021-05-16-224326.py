store = {}
store['timestamp']=1621201406
store['cmdline']=['/auto/users/andsch/github/active_learning_redux/batchbald_redux/experiment_xmi_labels.py', '--id=7']
store['commit']='e58e22f40eef16250bf8eae7794770660a6579a1'
store['github_url']='e58e22f40eef16250bf8eae7794770660a6579a1'
store['experiment']='/auto/users/andsch/github/active_learning_redux/batchbald_redux/experiment_xmi_labels.py'
store['job_id']=7
store['worker_id']=7
store['num_workers']=40
store['config']={'seed': 8, 'acquisition_size': 10, 'max_training_set': 300, 'num_pool_samples': 100, 'num_validation_samples': 20, 'num_training_samples': 1, 'num_patience_epochs': 20, 'max_training_epochs': 120, 'training_batch_size': 64, 'device': 'cuda', 'validation_set_size': 1024, 'initial_set_size': 20, 'min_samples_per_epoch': 1024, 'repeated_mnist_repetitions': 1, 'add_dataset_noise': False, 'acquisition_function': 'batchbald_redux.acquisition_functions.TemperedCoreSetBALD', 'train_eval_model': 'batchbald_redux.train_eval_model.TrainSelfDistillationEvalModel', 'model_optimizer_factory': 'batchbald_redux.models.MnistOptimizerFactory', 'acquisition_function_args': None, 'temperature': 8}
store['log']={}
store['initial_training_set_indices']=[38043, 40091, 17418, 2094, 39879, 3133, 5011, 40683, 54379, 24287, 9849, 59305, 39508, 39356, 8758, 52579, 13655, 7636, 21562, 41329]
store['dataset_info']={'training': "'FastMNIST (train)' | replace_targets{'targets': tensor([5, 0, 4,  ..., 5, 6, 8], device='cuda:0'), 'num_classes': 10}", 'test': "'FastMNIST (test, 10000 samples)'"}
store['active_learning_steps']=[]
store['active_learning_steps'].append({})
store['active_learning_steps'][0]['training']={}
store['active_learning_steps'][0]['training']['epochs']=[]
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.5087890625, 'crossentropy': 1.9896936416625977})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.6162109375, 'crossentropy': 1.9684631824493408})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.6103515625, 'crossentropy': 2.6208648681640625})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.6298828125, 'crossentropy': 2.6235902309417725})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.6123046875, 'crossentropy': 3.1568360328674316})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.6240234375, 'crossentropy': 3.1831490993499756})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.62890625, 'crossentropy': 3.02797269821167})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.6162109375, 'crossentropy': 3.297478675842285})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.6083984375, 'crossentropy': 3.3458752632141113})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.6396484375, 'crossentropy': 3.035590648651123})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.6337890625, 'crossentropy': 3.0463459491729736})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.630859375, 'crossentropy': 3.1441311836242676})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.6123046875, 'crossentropy': 3.452563762664795})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.6318359375, 'crossentropy': 3.3706860542297363})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.6376953125, 'crossentropy': 3.2109384536743164})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.6328125, 'crossentropy': 3.403789520263672})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.6240234375, 'crossentropy': 3.3532986640930176})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.6220703125, 'crossentropy': 3.703232526779175})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.626953125, 'crossentropy': 3.5091941356658936})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.619140625, 'crossentropy': 3.5918264389038086})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.640625, 'crossentropy': 3.40862774848938})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.625, 'crossentropy': 3.7794859409332275})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.6259765625, 'crossentropy': 3.6103196144104004})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.630859375, 'crossentropy': 3.7724454402923584})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.6181640625, 'crossentropy': 3.750530242919922})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.6396484375, 'crossentropy': 3.44107985496521})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.6142578125, 'crossentropy': 3.566243886947632})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.6279296875, 'crossentropy': 3.674622058868408})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.625, 'crossentropy': 3.7031188011169434})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.615234375, 'crossentropy': 3.839932918548584})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.6201171875, 'crossentropy': 3.9477806091308594})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.6103515625, 'crossentropy': 3.8849854469299316})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.6171875, 'crossentropy': 3.8213305473327637})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.630859375, 'crossentropy': 3.6927988529205322})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.6376953125, 'crossentropy': 3.768333911895752})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.6279296875, 'crossentropy': 3.9379308223724365})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.630859375, 'crossentropy': 4.087634086608887})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.6240234375, 'crossentropy': 4.039036750793457})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.62890625, 'crossentropy': 4.013267993927002})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.6220703125, 'crossentropy': 3.827446937561035})
store['active_learning_steps'][0]['training']['epochs'].append({'accuracy': 0.59765625, 'crossentropy': 3.9914698600769043})
store['active_learning_steps'][0]['training']['best_epoch']=21
store['active_learning_steps'][0]['evaluation_metrics']={'accuracy': 0.6424, 'crossentropy': 3.612100390625}
store['exception']='Traceback (most recent call last):\n  File "/auto/users/andsch/github/active_learning_redux/batchbald_redux/experiment_xmi_labels.py", line 295, in <module>\n    config.run(store=store)\n  File "/auto/users/andsch/github/active_learning_redux/batchbald_redux/experiment_xmi_labels.py", line 217, in run\n    candidate_batch = acquisition_function.compute_candidate_batch(trained_model, pool_loader, self.device)\n  File "/auto/users/andsch/github/active_learning_redux/batchbald_redux/acquisition_functions.py", line 156, in compute_candidate_batch\n    return self.get_candidate_batch(log_probs_N_K_C, labels_N, device)\n  File "/auto/users/andsch/github/active_learning_redux/batchbald_redux/acquisition_functions.py", line 172, in get_candidate_batch\n    candidate_batch = self.extract_candidates(scores_N)\n  File "/auto/users/andsch/github/active_learning_redux/batchbald_redux/acquisition_functions.py", line 191, in extract_candidates\n    return get_sampled_tempered_scorers(scores_N, batch_size=self.acquisition_size, temperature=self.temperature)\n  File "/auto/users/andsch/github/active_learning_redux/batchbald_redux/batchbald.py", line 376, in get_sampled_tempered_scorers\n    candidate_indices = np.random.choice(N, size=batch_size, replace=False, p=p)\n  File "mtrand.pyx", line 919, in numpy.random.mtrand.RandomState.choice\n  File "/scratch-ssd/andsch/tmp/conda_envs/job-6489/lib/python3.8/site-packages/torch/tensor.py", line 623, in __array__\n    return self.numpy().astype(dtype, copy=False)\nTypeError: can\'t convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n'
