{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Challenges\n",
    "> “Whoever fights monsters should see to it that in the process he does not become a monster. And if you gaze long enough into an abyss, the abyss will gaze back into you.”\n",
    ">\n",
    "> ― Friedrich Nietzsche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dataset_challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended /home/blackhc/PycharmProjects/bald-ical/src to paths\n",
      "Switched to directory /home/blackhc/PycharmProjects/bald-ical\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "import blackhc.project.script\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To model real-world use cases better, we need:\n",
    "* redundant/duplicated data;\n",
    "* noisy labels (emulating noisy oracles);\n",
    "* class imbalance;\n",
    "* out-of-distribution data/outliers included in the unlabelled data.\n",
    "\n",
    "RepeatedMNIST takes care of the first challenge.\n",
    "This chapter takes care of the second one.\n",
    "\n",
    "## Noisy Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "from batchbald_redux.repeated_mnist import TransformedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "def override_labels(dataset: data.Dataset, indices: list, new_labels: list):\n",
    "    indices_set = set(indices)\n",
    "    reverse_indices = {idx: rank for rank, idx in enumerate(indices)}\n",
    "\n",
    "    def override_label(idx, data):\n",
    "        if idx not in indices_set:\n",
    "            return data\n",
    "\n",
    "        x, y = data\n",
    "        ridx = reverse_indices[idx]\n",
    "        new_y = new_labels[ridx]\n",
    "        return x, new_y\n",
    "\n",
    "    return TransformedDataset(dataset, transformer=override_label)\n",
    "\n",
    "\n",
    "def corrupt_labels(\n",
    "    dataset: data.Dataset, *, percentage: int, num_classes: int, generator: np.random.Generator, device=None\n",
    "):\n",
    "    N = len(dataset)\n",
    "    num_corrupted = N * percentage // 100\n",
    "\n",
    "    indices = generator.choice(N, size=num_corrupted, replace=False)\n",
    "    new_labels = generator.choice(num_classes, size=num_corrupted, replace=True)\n",
    "\n",
    "    updated_dataset = override_labels(dataset, indices, torch.as_tensor(new_labels, device=device))\n",
    "\n",
    "    return updated_dataset\n",
    "\n",
    "\n",
    "def corrupt_all_labels(dataset: data.Dataset, *, num_classes: int, generator: np.random.Generator, device=None):\n",
    "    N = len(dataset)\n",
    "\n",
    "    new_labels = torch.as_tensor(generator.choice(num_classes, size=N, replace=True), device=device)\n",
    "\n",
    "    def override_label(idx, data):\n",
    "        x, _ = data\n",
    "        y = new_labels[idx]\n",
    "        return x, y\n",
    "\n",
    "    return TransformedDataset(dataset, transformer=override_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor(0.), tensor(7)),\n",
       " (tensor(0.), tensor(0.)),\n",
       " (tensor(0.), tensor(0.)),\n",
       " (tensor(0.), tensor(0.)),\n",
       " (tensor(0.), tensor(0)),\n",
       " (tensor(0.), tensor(0.)),\n",
       " (tensor(0.), tensor(0.)),\n",
       " (tensor(0.), tensor(8)),\n",
       " (tensor(0.), tensor(5)),\n",
       " (tensor(0.), tensor(4))]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_dataset = data.TensorDataset(torch.zeros(10), torch.zeros(10))\n",
    "\n",
    "noisy_dataset = corrupt_labels(zero_dataset, percentage=50, num_classes=10, generator=np.random.default_rng())\n",
    "\n",
    "list(noisy_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor(0.), tensor(5)),\n",
       " (tensor(0.), tensor(6)),\n",
       " (tensor(0.), tensor(2)),\n",
       " (tensor(0.), tensor(5)),\n",
       " (tensor(0.), tensor(3)),\n",
       " (tensor(0.), tensor(7)),\n",
       " (tensor(0.), tensor(7)),\n",
       " (tensor(0.), tensor(9)),\n",
       " (tensor(0.), tensor(0)),\n",
       " (tensor(0.), tensor(3))]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupted_dataset = corrupt_all_labels(zero_dataset, num_classes=10, generator=np.random.default_rng())\n",
    "\n",
    "list(corrupted_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "def get_class_indices(dataset: data.Dataset, *, class_counts: list, generator: np.random.Generator):\n",
    "    class_counts = list(class_counts)\n",
    "\n",
    "    subset_indices = []\n",
    "\n",
    "    remaining_samples = sum(class_counts)\n",
    "\n",
    "    indices = generator.choice(len(dataset), size=remaining_samples, replace=False)\n",
    "    for index in indices:\n",
    "        _, y = dataset[index]\n",
    "\n",
    "        if class_counts[y] > 0:\n",
    "            subset_indices.append(index)\n",
    "            class_counts[y] -= 1\n",
    "\n",
    "    return subset_indices\n",
    "\n",
    "\n",
    "def get_imbalanced_dataset(dataset: data.Dataset, *, class_counts: list, generator: np.random.Generator):\n",
    "    subset_indices = get_class_indices(dataset, class_counts=class_counts, generator=generator)\n",
    "\n",
    "    return data.Subset(dataset, subset_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor(0), tensor(0)), (tensor(1), tensor(1)), (tensor(2), tensor(2)), (tensor(3), tensor(0)), (tensor(4), tensor(1)), (tensor(5), tensor(2)), (tensor(6), tensor(0)), (tensor(7), tensor(1)), (tensor(8), tensor(2))]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([1, 3, 6, 0, 7, 5]), tensor([1, 0, 0, 0, 1, 2]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = data.TensorDataset(torch.arange(9), torch.as_tensor(list(range(3)) * 3))\n",
    "\n",
    "print(list(dataset))\n",
    "\n",
    "imbalanced_indices = get_class_indices(dataset, class_counts=[3, 2, 1], generator=np.random.default_rng())\n",
    "\n",
    "dataset[imbalanced_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixing in OOD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "def add_ood_dataset(\n",
    "    *,\n",
    "    dataset: data.Dataset,\n",
    "    ood_dataset: data.Dataset,\n",
    "    ood_percentage: int,\n",
    "    ood_random_labels: bool,\n",
    "    generator: np.random.Generator,\n",
    "    num_classes=None,\n",
    "    device=None\n",
    "):\n",
    "    subset_ood_N = len(dataset) * ood_percentage // 100\n",
    "\n",
    "    ood_N = len(ood_dataset)\n",
    "    assert subset_ood_N <= ood_N\n",
    "\n",
    "    ood_indices = generator.choice(ood_N, size=subset_ood_N, replace=False)\n",
    "\n",
    "    ood_subset = data.Subset(ood_dataset, torch.as_tensor(ood_indices, device=device))\n",
    "\n",
    "    if ood_random_labels:\n",
    "        assert num_classes\n",
    "        ood_subset = corrupt_all_labels(ood_subset, num_classes=num_classes, generator=generator, device=device)\n",
    "\n",
    "    return data.ConcatDataset((dataset, ood_subset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor(0.), tensor(0.)),\n",
       " (tensor(0.), tensor(0.)),\n",
       " (tensor(0.), tensor(0.)),\n",
       " (tensor(0.), tensor(0.)),\n",
       " (tensor(0.), tensor(0.)),\n",
       " (tensor(0.), tensor(0.)),\n",
       " (tensor(0.), tensor(0.)),\n",
       " (tensor(0.), tensor(0.)),\n",
       " (tensor(0.), tensor(0.)),\n",
       " (tensor(0.), tensor(0.)),\n",
       " (tensor(3), tensor(3)),\n",
       " (tensor(1), tensor(1)),\n",
       " (tensor(2), tensor(2)),\n",
       " (tensor(4), tensor(4)),\n",
       " (tensor(5), tensor(5))]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = data.TensorDataset(torch.zeros(10), torch.zeros(10))\n",
    "ood_dataset = data.TensorDataset(torch.arange(1, 6), torch.arange(1, 6))\n",
    "\n",
    "mixed_dataset = add_ood_dataset(\n",
    "    dataset=dataset,\n",
    "    ood_dataset=ood_dataset,\n",
    "    ood_percentage=50,\n",
    "    generator=np.random.default_rng(),\n",
    "    ood_random_labels=False,\n",
    ")\n",
    "\n",
    "list(mixed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor(0.), tensor(0.)),\n",
       " (tensor(0.), tensor(0.)),\n",
       " (tensor(0.), tensor(0.)),\n",
       " (tensor(0.), tensor(0.)),\n",
       " (tensor(0.), tensor(0.)),\n",
       " (tensor(0.), tensor(0.)),\n",
       " (tensor(0.), tensor(0.)),\n",
       " (tensor(0.), tensor(0.)),\n",
       " (tensor(0.), tensor(0.)),\n",
       " (tensor(0.), tensor(0.)),\n",
       " (tensor(3), tensor(74)),\n",
       " (tensor(5), tensor(56)),\n",
       " (tensor(4), tensor(49)),\n",
       " (tensor(2), tensor(58)),\n",
       " (tensor(1), tensor(31))]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_dataset2 = add_ood_dataset(\n",
    "    dataset=dataset,\n",
    "    ood_dataset=ood_dataset,\n",
    "    ood_percentage=50,\n",
    "    generator=np.random.default_rng(),\n",
    "    ood_random_labels=True,\n",
    "    num_classes=100,\n",
    ")\n",
    "\n",
    "list(mixed_dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:active_learning]",
   "language": "python",
   "name": "conda-env-active_learning-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
