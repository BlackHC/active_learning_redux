{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Models\n",
    "> To avoid copy-pasta #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp emnist_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import blackhc.project.script\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.optim\n",
    "from torch import nn as nn\n",
    "from torch.nn import functional as F, Module\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from batchbald_redux.active_learning import RandomFixedLengthSampler\n",
    "from batchbald_redux.black_box_model_training import train\n",
    "from batchbald_redux.consistent_mc_dropout import (\n",
    "    GradEmbeddingType,\n",
    "    BayesianModule,\n",
    "    ConsistentMCDropout,\n",
    "    ConsistentMCDropout2d,\n",
    "    freeze_encoder_context\n",
    ")\n",
    "\n",
    "from batchbald_redux.model_optimizer_factory import ModelOptimizer, ModelOptimizerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "from batchbald_redux.trained_model import ModelTrainer, TrainedModel, TrainedBayesianModel\n",
    "\n",
    "\n",
    "class BayesianEMNISTCNN(BayesianModule):\n",
    "    def __init__(self, num_classes=47):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv1_drop = ConsistentMCDropout2d()\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv2_drop = ConsistentMCDropout2d()\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3)\n",
    "        self.conv3_drop = ConsistentMCDropout2d()\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc1_drop = ConsistentMCDropout()\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def mc_forward_impl(self, input: torch.Tensor, freeze_encoder: bool):\n",
    "        with freeze_encoder_context(freeze_encoder):\n",
    "            input = F.relu(F.max_pool2d(self.conv1_drop(self.conv1(input)), 2))\n",
    "            input = F.relu(self.conv2_drop(self.conv2(input)))\n",
    "            input = F.relu(F.max_pool2d(self.conv3_drop(self.conv3(input)), 2))\n",
    "            input = input.view(-1, 128 * 4 * 4)\n",
    "        \n",
    "        embedding = input\n",
    "        input = F.relu(self.fc1_drop(self.fc1(input)))\n",
    "        input = self.fc2(input)\n",
    "        input = F.log_softmax(input, dim=1)\n",
    "        return input, embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BayesianEMNISTCNN(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv1_drop): ConsistentMCDropout2d(p=0.5)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2_drop): ConsistentMCDropout2d(p=0.5)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3_drop): ConsistentMCDropout2d(p=0.5)\n",
       "  (fc1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "  (fc1_drop): ConsistentMCDropout(p=0.5)\n",
       "  (fc2): Linear(in_features=512, out_features=47, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BayesianEMNISTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "class EMnistOptimizerFactory(ModelOptimizerFactory):\n",
    "    def create_model_optimizer(self) -> ModelOptimizer:\n",
    "        model = BayesianEMNISTCNN()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), weight_decay=5e-4)\n",
    "        return ModelOptimizer(model=model, optimizer=optimizer)\n",
    "\n",
    "    \n",
    "_dataloader_kwargs = dict(num_workers=4, pin_memory=True)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EMnistModelTrainer(ModelTrainer):\n",
    "    device: str\n",
    "\n",
    "    num_training_samples: int = 1\n",
    "    num_validation_samples: int = 20\n",
    "    num_patience_epochs: int = 20\n",
    "    max_training_epochs: int = 120\n",
    "\n",
    "    min_samples_per_epoch: int = 1024\n",
    "    num_training_batch_size: int = 64\n",
    "    num_evaluation_batch_size: int = 128\n",
    "\n",
    "    @staticmethod\n",
    "    def create_model_optimizer() -> ModelOptimizer:\n",
    "        model = BayesianEMNISTCNN()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), weight_decay=5e-4)\n",
    "        return ModelOptimizer(model=model, optimizer=optimizer)\n",
    "    \n",
    "    def get_train_dataloader(self, dataset: Dataset):\n",
    "        train_loader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=self.num_training_batch_size,\n",
    "            sampler=RandomFixedLengthSampler(dataset, self.min_samples_per_epoch),\n",
    "            drop_last=True,\n",
    "            **_dataloader_kwargs\n",
    "        )\n",
    "        return train_loader\n",
    "\n",
    "    def get_evaluation_dataloader(self, dataset: Dataset):\n",
    "        evaluation_loader = DataLoader(\n",
    "            dataset, batch_size=self.num_evaluation_batch_size, drop_last=False, shuffle=False, **_dataloader_kwargs\n",
    "        )\n",
    "        return evaluation_loader\n",
    "\n",
    "    def get_trained(self, *, train_loader: DataLoader, train_augmentations: Optional[Module],\n",
    "                    validation_loader: DataLoader, log, loss=None, validation_loss=None) -> TrainedModel:\n",
    "        model_optimizer = self.create_model_optimizer()\n",
    "\n",
    "        if loss is None:\n",
    "            loss = torch.nn.NLLLoss()\n",
    "        if validation_loss is None:\n",
    "            validation_loss = torch.nn.NLLLoss()\n",
    "\n",
    "        train(\n",
    "            model=model_optimizer.model,\n",
    "            optimizer=model_optimizer.optimizer,\n",
    "            training_samples=self.num_training_samples,\n",
    "            validation_samples=self.num_validation_samples,\n",
    "            train_loader=train_loader,\n",
    "            train_augmentations=train_augmentations,\n",
    "            validation_loader=validation_loader,\n",
    "            patience=self.num_patience_epochs,\n",
    "            max_epochs=self.max_training_epochs,\n",
    "            loss=loss,\n",
    "            validation_loss=validation_loss,\n",
    "            device=self.device,\n",
    "            training_log=log,\n",
    "        )\n",
    "\n",
    "        return TrainedBayesianModel(model_optimizer.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ef98458b0e4a3cb7e94794faf18360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/10905]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/909]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.865684344454665, 'crossentropy': 0.44169508072350266}\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: 0.865684344454665)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "from batchbald_redux import datasets\n",
    "\n",
    "emnist_dataset_split = datasets.get_dataset(\"EMNIST\", device_hint=\"cuda\")\n",
    "\n",
    "model_trainer = EMnistModelTrainer(\"cuda\", max_training_epochs=1)\n",
    "\n",
    "train_loader = model_trainer.get_train_dataloader(emnist_dataset_split.train)\n",
    "\n",
    "test_loader = model_trainer.get_evaluation_dataloader(emnist_dataset_split.test)\n",
    "\n",
    "log = {}\n",
    "trained_model = model_trainer.get_trained(train_loader=train_loader, train_augmentations=None, validation_loader=test_loader, log=log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('FastMNIST (Train)')~x0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c422225d0cd84d0c9eea96b5180a7e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/187]   1%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/79]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.9388, 'crossentropy': 0.36818689460754395}\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: 0.9388)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "from batchbald_redux import datasets\n",
    "\n",
    "emnist_dataset_split = datasets.get_dataset(\"EMNIST\", device_hint=\"cuda\")\n",
    "\n",
    "model_trainer = EMnistModelTrainer(\"cuda\", max_training_epochs=1)\n",
    "\n",
    "train_loader = model_trainer.get_train_dataloader(emnist_dataset_split.train * 0.1)\n",
    "\n",
    "test_loader = model_trainer.get_evaluation_dataloader(emnist_dataset_split.test)\n",
    "\n",
    "log = {}\n",
    "trained_model = model_trainer.get_trained(train_loader=train_loader, train_augmentations=None, validation_loader=test_loader, log=log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels: |          | 0/0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1, 1024])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "trained_model.model.get_embeddings(num_samples=0, loader=test_loader, device=\"cuda\", storage_device=\"cpu\").shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels: |          | 0/0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1, 10250])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slow\n",
    "\n",
    "trained_model.model.get_grad_embeddings(num_samples=0, loader=test_loader, loss=torch.nn.functional.nll_loss, grad_embedding_type=GradEmbeddingType.BIAS_LINEAR, model_labels=False, device=\"cuda\", storage_device=\"cpu\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels: |          | 0/0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1, 10250])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model.model.get_grad_embeddings(num_samples=0, loader=test_loader, loss=torch.nn.functional.nll_loss, grad_embedding_type=GradEmbeddingType.BIAS_LINEAR, model_labels=True, device=\"cuda\", storage_device=\"cpu\").shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:active_learning]",
   "language": "python",
   "name": "conda-env-active_learning-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
