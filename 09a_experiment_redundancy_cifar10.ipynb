{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment CIFAR-10\n",
    "> Can we get better by training on our assumptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp experiment_redundancy_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended /home/blackhc/PycharmProjects/bald-ical/src to paths\n",
      "Switched to directory /home/blackhc/PycharmProjects/bald-ical\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "import blackhc.project.script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules and functions were are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "import dataclasses\n",
    "import traceback\n",
    "\n",
    "from blackhc.project import is_run_from_ipython\n",
    "from blackhc.project.experiment import embedded_experiments\n",
    "\n",
    "from batchbald_redux import acquisition_functions\n",
    "from batchbald_redux import baseline_acquisition_functions\n",
    "from batchbald_redux.experiment_data import StandardExperimentDataConfig, OoDDatasetConfig\n",
    "from batchbald_redux.unified_experiment import UnifiedExperiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "configs = [\n",
    "        UnifiedExperiment(\n",
    "            experiment_data_config=StandardExperimentDataConfig(id_dataset_name=\"CIFAR-10\", id_repetitions=id_repetitions,\n",
    "                                                                  initial_training_set_size=1000,\n",
    "                                                                  validation_set_size=1024,\n",
    "                                                                  validation_split_random_state=0,\n",
    "                                                                  evaluation_set_size=0,\n",
    "                                                                  add_dataset_noise=True,\n",
    "                                                                  ood_dataset_config=None\n",
    "                                                                  ),\n",
    "            seed=seed + 8945,\n",
    "            acquisition_function=acquisition_function,\n",
    "            acquisition_size=acquisition_size,\n",
    "            num_pool_samples=num_pool_samples,\n",
    "            max_training_set=15000,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        for seed in range(5)\n",
    "        for acquisition_function in [\n",
    "            baseline_acquisition_functions.BADGE,\n",
    "        ]\n",
    "        for acquisition_size in [3000]\n",
    "        for num_pool_samples in [100]\n",
    "        for temperature in [0]\n",
    "        for id_repetitions in [1,5,10,20]\n",
    "    ]\n",
    "#     UnifiedExperiment(\n",
    "#         seed=seed + 8945,\n",
    "#         acquisition_function=acquisition_function,\n",
    "#         acquisition_size=acquisition_size,\n",
    "#         num_pool_samples=num_pool_samples,\n",
    "#         initial_training_set_size=1000,\n",
    "#         evaluation_set_size=0,\n",
    "#         max_training_set=15000,\n",
    "#         temperature=temperature,\n",
    "#         id_dataset_name=\"CIFAR-10\",\n",
    "#         ood_dataset_name=None,\n",
    "#         ood_exposure=False,\n",
    "#         id_repetitions=id_repetitions,\n",
    "#         add_dataset_noise=True\n",
    "\n",
    "#     )\n",
    "#     for seed in range(5)\n",
    "#     for acquisition_function in [\n",
    "#         acquisition_functions.SieveBALD,\n",
    "#     ]\n",
    "#     for acquisition_size in [3000]\n",
    "#     for num_pool_samples in [100]\n",
    "#     for temperature in [1/64]\n",
    "#     for id_repetitions in [1,5,10,20]\n",
    "# ]\n",
    "# +\n",
    "#     UnifiedExperiment(\n",
    "#         seed=seed + 8945,\n",
    "#         acquisition_function=acquisition_function,\n",
    "#         acquisition_size=acquisition_size,\n",
    "#         num_pool_samples=num_pool_samples,\n",
    "#         initial_training_set_size=1000,\n",
    "#         evaluation_set_size=0,\n",
    "#         max_training_set=15000,\n",
    "#         temperature=temperature,\n",
    "#         id_dataset_name=\"CIFAR-10\",\n",
    "#         ood_dataset_name=None,\n",
    "#         ood_exposure=False,\n",
    "#         id_repetitions=id_repetitions,\n",
    "#         add_dataset_noise=True\n",
    "\n",
    "#     )\n",
    "#     for seed in range(5)\n",
    "#     for acquisition_function in [\n",
    "#         acquisition_functions.SoftmaxBALD,\n",
    "#     ]\n",
    "#     for acquisition_size in [3000]\n",
    "#     for num_pool_samples in [100]\n",
    "#     for temperature in [1/64]\n",
    "#     for id_repetitions in [1,5,10,20]\n",
    "# ] + [\n",
    "#     UnifiedExperiment(\n",
    "#         seed=seed + 8945,\n",
    "#         acquisition_function=acquisition_function,\n",
    "#         acquisition_size=acquisition_size,\n",
    "#         num_pool_samples=num_pool_samples,\n",
    "#         initial_training_set_size=1000,\n",
    "#         evaluation_set_size=0,\n",
    "#         max_training_set=15000,\n",
    "#         temperature=temperature,\n",
    "#         id_repetitions=id_repetitions,\n",
    "#         add_dataset_noise=True,\n",
    "#         id_dataset_name=\"CIFAR-10\",\n",
    "#         ood_dataset_name=None,\n",
    "#         ood_exposure=False,\n",
    "#     )\n",
    "#     for seed in range(5)\n",
    "#     for acquisition_function in [\n",
    "#         acquisition_functions.BALD,\n",
    "#     ]\n",
    "#     for acquisition_size in [3000]\n",
    "#     for num_pool_samples in [100]\n",
    "#     for temperature in [0]\n",
    "#     for id_repetitions in [1,5,10,20]\n",
    "# ]\n",
    "\n",
    "if not is_run_from_ipython() and __name__ == \"__main__\":\n",
    "    for job_id, store in embedded_experiments(__file__, len(configs)):\n",
    "        config = configs[job_id]\n",
    "        config.seed += job_id\n",
    "        print(config)\n",
    "        store[\"config\"] = dataclasses.asdict(config)\n",
    "        store[\"log\"] = {}\n",
    "\n",
    "        try:\n",
    "            config.run(store=store)\n",
    "        except Exception:\n",
    "            store[\"exception\"] = traceback.format_exc()\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8945,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='CIFAR-10',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=1024,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=True,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=3000,\n",
      "        max_training_set=15000,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8945,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='CIFAR-10',\n",
      "            id_repetitions=5,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=1024,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=True,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=3000,\n",
      "        max_training_set=15000,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8945,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='CIFAR-10',\n",
      "            id_repetitions=10,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=1024,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=True,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=3000,\n",
      "        max_training_set=15000,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8945,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='CIFAR-10',\n",
      "            id_repetitions=20,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=1024,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=True,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=3000,\n",
      "        max_training_set=15000,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8946,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='CIFAR-10',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=1024,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=True,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=3000,\n",
      "        max_training_set=15000,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8946,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='CIFAR-10',\n",
      "            id_repetitions=5,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=1024,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=True,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=3000,\n",
      "        max_training_set=15000,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8946,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='CIFAR-10',\n",
      "            id_repetitions=10,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=1024,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=True,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=3000,\n",
      "        max_training_set=15000,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8946,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='CIFAR-10',\n",
      "            id_repetitions=20,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=1024,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=True,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=3000,\n",
      "        max_training_set=15000,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8947,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='CIFAR-10',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=1024,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=True,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=3000,\n",
      "        max_training_set=15000,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8947,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='CIFAR-10',\n",
      "            id_repetitions=5,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=1024,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=True,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=3000,\n",
      "        max_training_set=15000,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8947,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='CIFAR-10',\n",
      "            id_repetitions=10,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=1024,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=True,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=3000,\n",
      "        max_training_set=15000,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8947,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='CIFAR-10',\n",
      "            id_repetitions=20,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=1024,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=True,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=3000,\n",
      "        max_training_set=15000,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8948,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='CIFAR-10',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=1024,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=True,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=3000,\n",
      "        max_training_set=15000,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8948,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='CIFAR-10',\n",
      "            id_repetitions=5,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=1024,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=True,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=3000,\n",
      "        max_training_set=15000,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8948,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='CIFAR-10',\n",
      "            id_repetitions=10,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=1024,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=True,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=3000,\n",
      "        max_training_set=15000,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8948,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='CIFAR-10',\n",
      "            id_repetitions=20,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=1024,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=True,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=3000,\n",
      "        max_training_set=15000,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8949,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='CIFAR-10',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=1024,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=True,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=3000,\n",
      "        max_training_set=15000,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8949,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='CIFAR-10',\n",
      "            id_repetitions=5,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=1024,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=True,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=3000,\n",
      "        max_training_set=15000,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8949,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='CIFAR-10',\n",
      "            id_repetitions=10,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=1024,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=True,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=3000,\n",
      "        max_training_set=15000,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8949,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='CIFAR-10',\n",
      "            id_repetitions=20,\n",
      "            initial_training_set_size=1000,\n",
      "            validation_set_size=1024,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=True,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=3000,\n",
      "        max_training_set=15000,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE\n",
      "    )\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import prettyprinter\n",
    "prettyprinter.install_extras({\"dataclasses\"})\n",
    "prettyprinter.pprint(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n",
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Creating: BADGE(\n",
      "\tacquisition_size=3000\n",
      ")\n",
      "Creating: Cifar10ModelTrainer(\n",
      "\tdevice=cuda,\n",
      "\tnum_training_samples=1,\n",
      "\tnum_validation_samples=20,\n",
      "\tmax_training_epochs=1\n",
      ")\n",
      "Creating: TrainSelfDistillationEvalModel(\n",
      "\tnum_pool_samples=5\n",
      ")\n",
      "Training set size 1000:\n",
      "Cosine Annealing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e2e0c7920a947bf8f39d9eff3c41ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/39]   3%|2          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 metrics: {'accuracy': 0.18359375, 'crossentropy': 2.1889246702194214}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.1852, 'crossentropy': tensor(2.1773)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed22e3fa7394370bc2a1edde7249b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_grad_embeddings:   0%|          | 0/978520 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4bca5d112a01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_training_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_pool_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/unified_experiment.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, store)\u001b[0m\n\u001b[1;32m    252\u001b[0m         )\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mactive_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/unified_experiment.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, log)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macquisition_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCandidateBatchComputer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                 \u001b[0mcandidate_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macquisition_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_candidate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macquisition_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEvalDatasetBatchComputer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_dataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/baseline_acquisition_functions.py\u001b[0m in \u001b[0;36mcompute_candidate_batch\u001b[0;34m(self, model, pool_loader, device)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrainedModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_loader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     ) -> CandidateBatch:\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mgrad_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_grad_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_embedding_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGradEmbeddingType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLINEAR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mchosen_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_centers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquisition_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/trained_model.py\u001b[0m in \u001b[0;36mget_grad_embeddings\u001b[0;34m(self, loader, num_samples, loss, grad_embedding_type, model_labels, device, storage_device)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mstorage_device\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     ):\n\u001b[0;32m---> 72\u001b[0;31m         grad_embeddings_N_K_E = self.model.get_grad_embeddings(\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/consistent_mc_dropout.py\u001b[0m in \u001b[0;36mget_grad_embeddings\u001b[0;34m(self, num_samples, loader, loss, grad_embedding_type, model_labels, device, storage_device)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mstorage_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     ):\n\u001b[0;32m--> 184\u001b[0;31m         return bmodule_get_grad_embeddings(\n\u001b[0m\u001b[1;32m    185\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/consistent_mc_dropout.py\u001b[0m in \u001b[0;36mbmodule_get_grad_embeddings\u001b[0;34m(self, num_samples, loader, loss, grad_embedding_type, model_labels, device, storage_device)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtoma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_num_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mget_prediction_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mnonlocal\u001b[0m \u001b[0mgrad_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/toma/__init__.py\u001b[0m in \u001b[0;36mexecute_range\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mexecute_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mexplicit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoma_cache_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoma_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mexecute_range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/toma/__init__.py\u001b[0m in \u001b[0;36mrange\u001b[0;34m(func, start, end, initial_step, toma_context, toma_cache_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                 \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m                 \u001b[0mcurrent\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mgc_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/consistent_mc_dropout.py\u001b[0m in \u001b[0;36mget_prediction_batch\u001b[0;34m(start, end)\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             batch_predictions, batch_embeddings = self(\n\u001b[0m\u001b[1;32m    293\u001b[0m                 \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_sub_samples\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_embedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeze_encoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/consistent_mc_dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_B, num_samples, return_embedding, freeze_encoder)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;31m# No MC dropout (0 samples).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mfeatures_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeterministic_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeze_encoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreeze_encoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0moutput_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmc_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeze_encoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreeze_encoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0moutput_B_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBayesianModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/resnet_models.py\u001b[0m in \u001b[0;36mdeterministic_forward_impl\u001b[0;34m(self, x, freeze_encoder)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/resnet_models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    775\u001b[0m             \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_modules'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m    779\u001b[0m             type(self).__name__, name))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "store={}\n",
    "\n",
    "configs[3].max_training_epochs=1\n",
    "configs[3].num_pool_samples=5\n",
    "configs[3].run(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:active_learning]",
   "language": "python",
   "name": "conda-env-active_learning-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
