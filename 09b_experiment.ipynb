{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment\n",
    "> Can we get better by training on our assumptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended /home/blackhc/PycharmProjects/bald-ical/src to paths\n",
      "Switched to directory /home/blackhc/PycharmProjects/bald-ical\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "import blackhc.project.script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules and functions were are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "import dataclasses\n",
    "import traceback\n",
    "from dataclasses import dataclass\n",
    "from typing import Union, Type\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from blackhc.project import is_run_from_ipython\n",
    "from blackhc.project.experiment import embedded_experiments\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import batchbald_redux.acquisition_functions as acquisition_functions\n",
    "from batchbald_redux.acquisition_functions import CandidateBatchComputer, \\\n",
    "    EvalCandidateBatchComputer, CoreSetPoolPredictions, PoolPredictions\n",
    "from batchbald_redux.active_learning import ActiveLearningData, RandomFixedLengthSampler\n",
    "from batchbald_redux.black_box_model_training import (\n",
    "    evaluate,\n",
    "    train,\n",
    ")\n",
    "from batchbald_redux.dataset_challenges import (\n",
    "    create_repeated_MNIST_dataset,\n",
    "    get_base_dataset_index, get_target\n",
    ")\n",
    "from batchbald_redux.models import MnistOptimizerFactory, ModelOptimizerFactory\n",
    "\n",
    "from batchbald_redux.di import DependencyInjection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "# From the BatchBALD Repo\n",
    "from batchbald_redux.train_eval_model import TrainEvalModel, TrainSelfDistillationPoolModel\n",
    "from batchbald_redux.trained_model import TrainedMCDropoutModel\n",
    "\n",
    "mnist_initial_samples = [\n",
    "    38043,\n",
    "    40091,\n",
    "    17418,\n",
    "    2094,\n",
    "    39879,\n",
    "    3133,\n",
    "    5011,\n",
    "    40683,\n",
    "    54379,\n",
    "    24287,\n",
    "    9849,\n",
    "    59305,\n",
    "    39508,\n",
    "    39356,\n",
    "    8758,\n",
    "    52579,\n",
    "    13655,\n",
    "    7636,\n",
    "    21562,\n",
    "    41329,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Experiment:\n",
    "    seed: int = 1337\n",
    "    acquisition_size: int = 5\n",
    "    max_training_set: int = 300\n",
    "    num_pool_samples: int = 20\n",
    "    num_eval_samples: int = 20\n",
    "    num_training_samples: int = 1\n",
    "    num_patience_epochs: int = 3\n",
    "    max_training_epochs: int = 30\n",
    "    training_batch_size: int = 64\n",
    "    device = \"cuda\"\n",
    "    validation_set_size: int = 1024\n",
    "    initial_set_size: int = 20\n",
    "    samples_per_epoch: int = 5056\n",
    "    repeated_mnist_repetitions: int = 1\n",
    "    add_dataset_noise: bool = False\n",
    "    acquisition_function: Union[Type[CandidateBatchComputer], Type[EvalCandidateBatchComputer]] = acquisition_functions.BALD\n",
    "    train_eval_model: TrainEvalModel = TrainSelfDistillationPoolModel\n",
    "    model_optimizer_factory: Type[ModelOptimizerFactory] = MnistOptimizerFactory\n",
    "    acquisition_function_args: dict = None\n",
    "    temperature: float = 0.0\n",
    "\n",
    "\n",
    "    def load_dataset(self, initial_training_set_indices) -> (ActiveLearningData, Dataset, Dataset):\n",
    "        train_dataset, test_dataset = create_repeated_MNIST_dataset(\n",
    "            num_repetitions=self.repeated_mnist_repetitions, add_noise=self.add_dataset_noise\n",
    "        )\n",
    "        active_learning_data = ActiveLearningData(train_dataset)\n",
    "\n",
    "        active_learning_data.acquire(initial_training_set_indices)\n",
    "\n",
    "        validation_dataset = active_learning_data.extract_dataset_from_pool(self.validation_set_size)\n",
    "\n",
    "        return active_learning_data, validation_dataset, test_dataset\n",
    "\n",
    "    # Simple Dependency Injection\n",
    "    def create_acquisition_function(self):\n",
    "        di = DependencyInjection(vars(self), [PoolPredictions, CoreSetPoolPredictions])\n",
    "        return di.create_dataclass_type(self.acquisition_function)\n",
    "\n",
    "    def create_train_eval_model(self, runtime_config) -> TrainEvalModel:\n",
    "        config = {**vars(self), **runtime_config}\n",
    "        di = DependencyInjection(config, [])\n",
    "        return di.create_dataclass_type(self.train_eval_model)\n",
    "\n",
    "    def run(self, store):\n",
    "        torch.manual_seed(self.seed)\n",
    "\n",
    "        initial_training_set_indices = mnist_initial_samples\n",
    "        store[\"initial_training_set_indices\"] = initial_training_set_indices\n",
    "\n",
    "        # Active Learning setup\n",
    "        active_learning_data, validation_dataset, test_dataset = self.load_dataset(initial_training_set_indices)\n",
    "        store[\"dataset_info\"] = dict(training=repr(active_learning_data.dataset), test=repr(test_dataset))\n",
    "\n",
    "        # initial_training_set_indices = active_learning_data.get_random_pool_indices(self.initial_set_size)\n",
    "        # initial_training_set_indices = get_balanced_sample_indices(\n",
    "        #     active_learning_data.pool_dataset, 10, self.initial_set_size // 10\n",
    "        # )\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            active_learning_data.training_dataset,\n",
    "            batch_size=64,\n",
    "            sampler=RandomFixedLengthSampler(active_learning_data.training_dataset, self.samples_per_epoch),\n",
    "            drop_last=True,\n",
    "        )\n",
    "        pool_loader = torch.utils.data.DataLoader(\n",
    "            active_learning_data.pool_dataset, batch_size=128, drop_last=False, shuffle=False\n",
    "        )\n",
    "\n",
    "        validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=128, drop_last=False)\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, drop_last=False)\n",
    "\n",
    "        store[\"active_learning_steps\"] = []\n",
    "        active_learning_steps = store[\"active_learning_steps\"]\n",
    "\n",
    "        acquisition_function = self.create_acquisition_function()\n",
    "\n",
    "        # Active Training Loop\n",
    "        while True:\n",
    "            training_set_size = len(active_learning_data.training_dataset)\n",
    "            print(f\"Training set size {training_set_size}:\")\n",
    "\n",
    "            # iteration_log = dict(training={}, pool_training={}, evaluation_metrics=None, acquisition=None)\n",
    "            active_learning_steps.append({})\n",
    "            iteration_log = active_learning_steps[-1]\n",
    "\n",
    "            iteration_log[\"training\"] = {}\n",
    "\n",
    "            model_optimizer = self.model_optimizer_factory().create_model_optimizer()\n",
    "\n",
    "            train(\n",
    "                model=model_optimizer.model,\n",
    "                optimizer=model_optimizer.optimizer,\n",
    "                training_samples=self.num_training_samples,\n",
    "                validation_samples=self.num_eval_samples,\n",
    "                train_loader=train_loader,\n",
    "                validation_loader=validation_loader,\n",
    "                patience=self.num_patience_epochs,\n",
    "                max_epochs=self.max_training_epochs,\n",
    "                device=self.device,\n",
    "                training_log=iteration_log[\"training\"],\n",
    "            )\n",
    "\n",
    "            evaluation_metrics = evaluate(\n",
    "                model=model_optimizer.model, num_samples=self.num_eval_samples, loader=test_loader, device=self.device\n",
    "            )\n",
    "            iteration_log[\"evaluation_metrics\"] = evaluation_metrics\n",
    "            print(f\"Perf after training {evaluation_metrics}\")\n",
    "\n",
    "            if training_set_size >= self.max_training_set:\n",
    "                print(\"Done.\")\n",
    "                break\n",
    "\n",
    "            trained_model = TrainedMCDropoutModel(num_pool_samples=self.num_pool_samples, model=model_optimizer.model)\n",
    "\n",
    "            if isinstance(acquisition_function, CandidateBatchComputer):\n",
    "                candidate_batch = acquisition_function.compute_candidate_batch(trained_model, pool_loader, self.device)\n",
    "            elif isinstance(acquisition_function, EvalCandidateBatchComputer):\n",
    "                current_max_epochs = iteration_log[\"training\"][\"best_epoch\"]\n",
    "\n",
    "                train_eval_model = self.create_train_eval_model(dict(\n",
    "                    max_epochs=current_max_epochs,\n",
    "                    training_dataset=active_learning_data.training_dataset,\n",
    "                    pool_dataset=active_learning_data.pool_dataset,\n",
    "                    validation_loader=validation_loader,\n",
    "                    trained_model=trained_model,\n",
    "                ))\n",
    "\n",
    "                iteration_log[\"eval_training\"] = {}\n",
    "                trained_eval_model = train_eval_model(training_log=iteration_log[\"eval_training\"], device=self.device)\n",
    "\n",
    "                candidate_batch = acquisition_function.compute_candidate_batch(trained_model, trained_eval_model, pool_loader, device=self.device)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown acquisition function {acquisition_function}!\")\n",
    "\n",
    "\n",
    "            candidate_global_indices = [\n",
    "                get_base_dataset_index(active_learning_data.pool_dataset, index).index for index in candidate_batch.indices\n",
    "            ]\n",
    "            candidate_labels = [get_target(active_learning_data.dataset, index).item() for index in candidate_global_indices]\n",
    "\n",
    "            iteration_log[\"acquisition\"] = dict(\n",
    "                indices=candidate_global_indices, labels=candidate_labels, scores=candidate_batch.scores\n",
    "            )\n",
    "\n",
    "            active_learning_data.acquire(candidate_batch.indices)\n",
    "\n",
    "            ls = \", \".join(f\"{label} ({score:.4})\" for label, score in zip(candidate_labels, candidate_batch.scores))\n",
    "            print(f\"Acquiring (label, score)s: {ls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolved: PoolPredictions with {'num_pool_samples': 10}\n",
      "Creating: PoolPredictions(num_pool_samples=10)\n",
      "Resolved: EvalBALD with {'acquisition_size': 5, 'pool_scorer': PoolPredictions(num_pool_samples=10)}\n",
      "Creating: EvalBALD(acquisition_size=5,pool_scorer=PoolPredictions(num_pool_samples=10))\n",
      "Training set size 20:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6f7144532744c79798242497e22e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " 20%|##        | 1/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/79]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.6220703125, 'crossentropy': 2.689535826444626}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/79]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.638671875, 'crossentropy': 2.759561240673065}\n",
      "RestoringEarlyStopping: 1 / 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/79]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.6396484375, 'crossentropy': 3.0484785437583923}\n",
      "RestoringEarlyStopping: 2 / 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/79]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.6416015625, 'crossentropy': 3.127019852399826}\n",
      "RestoringEarlyStopping: 3 / 3\n",
      "RestoringEarlyStopping: Out of patience\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: -2.689535826444626)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/79]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.6312, 'crossentropy': 2.6634248794555666}\n",
      "Resolved: TrainSelfDistillationPoolModel with {'num_pool_samples': 10, 'num_training_samples': 1, 'num_eval_samples': 20, 'num_patience_epochs': 3, 'max_epochs': 1, 'training_dataset': <torch.utils.data.dataset.Subset object at 0x7f5e19c9ab50>, 'pool_dataset': <torch.utils.data.dataset.Subset object at 0x7f5e19c9ac70>, 'validation_loader': <torch.utils.data.dataloader.DataLoader object at 0x7f5e19c9ac40>, 'training_batch_size': 64, 'model_optimizer_factory': <class 'batchbald_redux.example_models.MnistOptimizerFactory'>, 'trained_model': TrainedMCDropoutModel(num_pool_samples=10, model=BayesianMNISTCNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv1_drop): ConsistentMCDropout2d(p=0.5)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): ConsistentMCDropout2d(p=0.5)\n",
      "  (fc1): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  (fc1_drop): ConsistentMCDropout(p=0.5)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      "))}\n",
      "Creating: TrainSelfDistillationPoolModel(num_pool_samples=10,num_training_samples=1,num_eval_samples=20,num_patience_epochs=3,max_epochs=1,training_dataset=<torch.utils.data.dataset.Subset object at 0x7f5e19c9ab50>,pool_dataset=<torch.utils.data.dataset.Subset object at 0x7f5e19c9ac70>,validation_loader=<torch.utils.data.dataloader.DataLoader object at 0x7f5e19c9ac40>,training_batch_size=64,model_optimizer_factory=<class 'batchbald_redux.example_models.MnistOptimizerFactory'>,trained_model=TrainedMCDropoutModel(num_pool_samples=10, model=BayesianMNISTCNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv1_drop): ConsistentMCDropout2d(p=0.5)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): ConsistentMCDropout2d(p=0.5)\n",
      "  (fc1): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  (fc1_drop): ConsistentMCDropout(p=0.5)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/589760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e37f8fa97e48edad4e387949b017e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/921]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.6494140625, 'crossentropy': 1.299349308013916}\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: -1.299349308013916)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/589560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/589560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/58956 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/58956 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/58956 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/58956 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquiring (label, score)s: 8 (1.097), 8 (1.075), 8 (1.06), 5 (1.046), 3 (1.035)\n",
      "Training set size 25:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831934d935b04d67bd95957c05f24d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " 20%|##        | 1/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/79]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.7138671875, 'crossentropy': 1.83877794444561}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/79]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.68359375, 'crossentropy': 2.499198794364929}\n",
      "RestoringEarlyStopping: 1 / 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/79]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.712890625, 'crossentropy': 2.2145942598581314}\n",
      "RestoringEarlyStopping: 2 / 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/79]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.7060546875, 'crossentropy': 2.710658013820648}\n",
      "RestoringEarlyStopping: 3 / 3\n",
      "RestoringEarlyStopping: Out of patience\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: -1.83877794444561)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/79]   1%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.716, 'crossentropy': 1.8976135944366455}\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(\n",
    "    seed=1120,\n",
    "    max_training_epochs=5,\n",
    "    max_training_set=25,\n",
    "    acquisition_function=acquisition_functions.EvalBALD,\n",
    "    acquisition_size=5,\n",
    "    num_pool_samples=10,\n",
    "    temperature=5,\n",
    ")\n",
    "\n",
    "results = {}\n",
    "experiment.run(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'initial_training_set_indices': [38043,\n",
       "  40091,\n",
       "  17418,\n",
       "  2094,\n",
       "  39879,\n",
       "  3133,\n",
       "  5011,\n",
       "  40683,\n",
       "  54379,\n",
       "  24287,\n",
       "  9849,\n",
       "  59305,\n",
       "  39508,\n",
       "  39356,\n",
       "  8758,\n",
       "  52579,\n",
       "  13655,\n",
       "  7636,\n",
       "  21562,\n",
       "  41329],\n",
       " 'dataset_info': {'training': \"'FastMNIST (Train)'\",\n",
       "  'test': \"'FastMNIST (Test)'\"},\n",
       " 'active_learning_steps': [{'training': {'epochs': [{'accuracy': 0.62109375,\n",
       "      'crossentropy': 2.6530187726020813},\n",
       "     {'accuracy': 0.6376953125, 'crossentropy': 2.762658029794693},\n",
       "     {'accuracy': 0.646484375, 'crossentropy': 3.056214064359665},\n",
       "     {'accuracy': 0.6416015625, 'crossentropy': 3.1257119178771973}],\n",
       "    'best_epoch': 1},\n",
       "   'evaluation_metrics': {'accuracy': 0.631,\n",
       "    'crossentropy': 2.6251225173950195}}]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size 20:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3fc327793734c0eb2f361164ad86451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/384]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/64]   2%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RestoringEarlyStopping: Restoring best parameters. (Score: -6.529030114412308)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/157]   1%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.5367, 'crossentropy': 6.438035237884521}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions:   0%|          | 0/463616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382711f4f7ad4ec7980c856e0f9d229e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1811]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/64]   2%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RestoringEarlyStopping: Restoring best parameters. (Score: -5.1637596152722836)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions:   0%|          | 0/2317680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions:   0%|          | 0/2317680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/115884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/115884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/115884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/115884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquiring (label, score)s: 8 (0.8711), 8 (0.8687), 3 (0.876), 3 (0.8465), 3 (0.8811)\n",
      "Training set size 25:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c326c4165e48eab908014b4064f795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/384]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/64]   2%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RestoringEarlyStopping: Restoring best parameters. (Score: -4.6851686127483845)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/157]   1%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.6256, 'crossentropy': 4.484497045135498}\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'initial_training_set_indices': [38043,\n",
       "  40091,\n",
       "  17418,\n",
       "  2094,\n",
       "  39879,\n",
       "  3133,\n",
       "  5011,\n",
       "  40683,\n",
       "  54379,\n",
       "  24287,\n",
       "  9849,\n",
       "  59305,\n",
       "  39508,\n",
       "  39356,\n",
       "  8758,\n",
       "  52579,\n",
       "  13655,\n",
       "  7636,\n",
       "  21562,\n",
       "  41329],\n",
       " 'active_learning_steps': [{'training': {'epochs': [{'accuracy': 0.538818359375,\n",
       "      'crossentropy': 6.529030114412308}],\n",
       "    'best_epoch': 1},\n",
       "   'evalution_metrics': {'accuracy': 0.5367,\n",
       "    'crossentropy': 6.438035237884521},\n",
       "   'pool_training': {'epochs': [{'accuracy': 0.531005859375,\n",
       "      'crossentropy': 5.1637596152722836}],\n",
       "    'best_epoch': 1},\n",
       "   'acquisition': {'indices': [63338, 10856, 63452, 81864, 109287],\n",
       "    'labels': [8, 8, 3, 3, 3],\n",
       "    'scores': [0.8710822958846325,\n",
       "     0.8687216999221631,\n",
       "     0.8759664372823723,\n",
       "     0.8464646732511746,\n",
       "     0.8810812784952251]}},\n",
       "  {'training': {'epochs': [{'accuracy': 0.62255859375,\n",
       "      'crossentropy': 4.6851686127483845}],\n",
       "    'best_epoch': 1},\n",
       "   'evalution_metrics': {'accuracy': 0.6256,\n",
       "    'crossentropy': 4.484497045135498}}]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment\n",
    "\n",
    "experiment = Experiment(\n",
    "    max_training_epochs=1, max_training_set=25, acquisition_function=AcquisitionFunction.randombaldical\n",
    ")\n",
    "\n",
    "results = {}\n",
    "experiment.run(results)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    configs = (\n",
    "        [\n",
    "            Experiment(\n",
    "                seed=seed + 120,\n",
    "                acquisition_function=acquisition_function,\n",
    "                acquisition_size=acquisition_size,\n",
    "                num_pool_samples=100,\n",
    "            )\n",
    "            for seed in range(5)\n",
    "            for acquisition_size in [5, 10]\n",
    "            for acquisition_function in [AcquisitionFunction.batchbald, AcquisitionFunction.batchbaldical]\n",
    "        ]\n",
    "        + [\n",
    "            Experiment(\n",
    "                seed=seed + 120,\n",
    "                acquisition_function=acquisition_function,\n",
    "                acquisition_size=acquisition_size,\n",
    "                num_pool_samples=max(20, acquisition_size),\n",
    "            )\n",
    "            for seed in range(5)\n",
    "            for acquisition_size in [5, 10, 20, 50]\n",
    "            for acquisition_function in [\n",
    "                AcquisitionFunction.bald,\n",
    "                AcquisitionFunction.thompsonbald,\n",
    "                AcquisitionFunction.randombald,\n",
    "            ]\n",
    "        ]\n",
    "        + [\n",
    "            Experiment(\n",
    "                seed=seed + 120,\n",
    "                acquisition_function=AcquisitionFunction.random,\n",
    "                acquisition_size=5,\n",
    "                num_pool_samples=20,\n",
    "            )\n",
    "            for seed in range(40)\n",
    "            for acquisition_size in [5]\n",
    "        ]\n",
    "    )\n",
    "if False:\n",
    "    configs = [\n",
    "        Experiment(\n",
    "            seed=seed + 240,\n",
    "            acquisition_function=acquisition_function,\n",
    "            acquisition_size=acquisition_size,\n",
    "            num_pool_samples=max(20, acquisition_size),\n",
    "        )\n",
    "        for seed in range(5)\n",
    "        for acquisition_size in [5, 10, 20, 50]\n",
    "        for acquisition_function in [\n",
    "            AcquisitionFunction.baldical,\n",
    "            AcquisitionFunction.randombaldical,\n",
    "        ]\n",
    "    ]\n",
    "if False:\n",
    "    configs = [\n",
    "        Experiment(\n",
    "            seed=seed + 340,\n",
    "            acquisition_function=acquisition_function,\n",
    "            acquisition_size=acquisition_size,\n",
    "            num_pool_samples=20,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        for seed in range(5)\n",
    "        for acquisition_size in [5, 10, 20, 50]\n",
    "        for acquisition_function in [\n",
    "            AcquisitionFunction.temperedbald,\n",
    "        ]\n",
    "        for temperature in [13, 15, 18]\n",
    "    ]\n",
    "if False:\n",
    "    configs = [\n",
    "        Experiment(\n",
    "            seed=seed + 340,\n",
    "            acquisition_function=acquisition_function,\n",
    "            acquisition_size=acquisition_size,\n",
    "            num_pool_samples=20,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        for seed in range(5)\n",
    "        for acquisition_size in [5, 10, 20, 50]\n",
    "        for acquisition_function in [\n",
    "            AcquisitionFunction.temperedbald,\n",
    "        ]\n",
    "        for temperature in [8, 10]\n",
    "    ] + [\n",
    "        Experiment(\n",
    "            seed=seed + 340,\n",
    "            acquisition_function=acquisition_function,\n",
    "            acquisition_size=acquisition_size,\n",
    "            num_pool_samples=20,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        for seed in range(5)\n",
    "        for acquisition_size in [5, 10, 20, 50]\n",
    "        for acquisition_function in [\n",
    "            AcquisitionFunction.temperedbaldical,\n",
    "        ]\n",
    "        for temperature in [8, 10, 13]\n",
    "    ]\n",
    "if False:\n",
    "    configs = [\n",
    "        Experiment(\n",
    "            seed=seed + 500,\n",
    "            acquisition_function=acquisition_function,\n",
    "            acquisition_size=acquisition_size,\n",
    "            num_pool_samples=20,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        for seed in range(5)\n",
    "        for acquisition_size in [5, 10, 20, 50]\n",
    "        for acquisition_function in [\n",
    "            AcquisitionFunction.temperedical,\n",
    "        ]\n",
    "        for temperature in [5, 8, 11]\n",
    "    ] + [\n",
    "        Experiment(\n",
    "            seed=seed + 600,\n",
    "            acquisition_function=acquisition_function,\n",
    "            acquisition_size=acquisition_size,\n",
    "            num_pool_samples=20,\n",
    "        )\n",
    "        for seed in range(5)\n",
    "        for acquisition_size in [5, 10, 20, 50]\n",
    "        for acquisition_function in [\n",
    "            AcquisitionFunction.ical,\n",
    "        ]\n",
    "    ]\n",
    "if False:\n",
    "    configs = (\n",
    "        [\n",
    "            Experiment(\n",
    "                seed=seed + 1000,\n",
    "                acquisition_function=acquisition_function,\n",
    "                acquisition_size=acquisition_size,\n",
    "                num_pool_samples=num_pool_samples,\n",
    "                temperature=temperature,\n",
    "            )\n",
    "            for seed in range(5)\n",
    "            for acquisition_size in [5, 10, 20, 50]\n",
    "            for num_pool_samples in [20, 100]\n",
    "            for acquisition_function in [\n",
    "                AcquisitionFunction.temperedical,\n",
    "                AcquisitionFunction.temperedbald,\n",
    "                AcquisitionFunction.temperedbaldical,\n",
    "            ]\n",
    "            for temperature in [2, 5, 8]\n",
    "        ]\n",
    "        + [\n",
    "            Experiment(\n",
    "                seed=seed + 2000,\n",
    "                acquisition_function=acquisition_function,\n",
    "                acquisition_size=acquisition_size,\n",
    "                num_pool_samples=num_pool_samples,\n",
    "            )\n",
    "            for seed in range(5)\n",
    "            for acquisition_size in [5, 10, 20, 50]\n",
    "            for num_pool_samples in [20, 100]\n",
    "            for acquisition_function in [\n",
    "                AcquisitionFunction.ical,\n",
    "                AcquisitionFunction.bald,\n",
    "                AcquisitionFunction.baldical,\n",
    "                AcquisitionFunction.randombald,\n",
    "            ]\n",
    "        ]\n",
    "        + [\n",
    "            Experiment(\n",
    "                seed=seed + 2000,\n",
    "                acquisition_function=acquisition_function,\n",
    "                acquisition_size=acquisition_size,\n",
    "                num_pool_samples=max(num_pool_samples, acquisition_size),\n",
    "            )\n",
    "            for seed in range(5)\n",
    "            for acquisition_size in [5, 10, 20, 50]\n",
    "            for num_pool_samples in [20, 100]\n",
    "            for acquisition_function in [\n",
    "                AcquisitionFunction.thompsonbald,\n",
    "            ]\n",
    "        ]\n",
    "        + [\n",
    "            Experiment(\n",
    "                seed=seed + 3000,\n",
    "                acquisition_function=acquisition_function,\n",
    "                acquisition_size=acquisition_size,\n",
    "                num_pool_samples=100,\n",
    "            )\n",
    "            for seed in range(5)\n",
    "            for acquisition_size in [5]\n",
    "            for acquisition_function in [\n",
    "                AcquisitionFunction.batchbaldical,\n",
    "                AcquisitionFunction.batchbald,\n",
    "            ]\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "configs = [\n",
    "    Experiment(\n",
    "        seed=seed,\n",
    "        acquisition_function=acquisition_functions.BALD,\n",
    "        acquisition_size=acquisition_size,\n",
    "        num_pool_samples=num_pool_samples,\n",
    "    )\n",
    "    for seed in range(5)\n",
    "    for acquisition_size in [5, 10, 20, 50]\n",
    "    for num_pool_samples in [10, 20, 50, 100]\n",
    "] + [\n",
    "    Experiment(\n",
    "        seed=seed,\n",
    "        acquisition_function=acquisition_functions.Random,\n",
    "        acquisition_size=5,\n",
    "        num_pool_samples=20,\n",
    "    )\n",
    "    for seed in range(20)\n",
    "]\n",
    "\n",
    "if not is_run_from_ipython() and __name__ == \"__main__\":\n",
    "    for job_id, store in embedded_experiments(__file__, len(configs)):\n",
    "        config = configs[job_id]\n",
    "        config.seed += job_id\n",
    "        print(config)\n",
    "        store[\"config\"] = dataclasses.asdict(config)\n",
    "        store[\"log\"] = {}\n",
    "\n",
    "        try:\n",
    "            config.run(store=store)\n",
    "        except Exception:\n",
    "            store[\"exception\"] = traceback.format_exc()\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:active_learning]",
   "language": "python",
   "name": "conda-env-active_learning-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
