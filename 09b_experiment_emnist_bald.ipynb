{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment EMNIST\n",
    "> Can we get better by training on our assumptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp experiment_emnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended /home/blackhc/PycharmProjects/bald-ical/src to paths\n",
      "Switched to directory /home/blackhc/PycharmProjects/bald-ical\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "import blackhc.project.script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules and functions were are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "import dataclasses\n",
    "import traceback\n",
    "\n",
    "from blackhc.project import is_run_from_ipython\n",
    "from blackhc.project.experiment import embedded_experiments\n",
    "\n",
    "from batchbald_redux import acquisition_functions, baseline_acquisition_functions\n",
    "from batchbald_redux.experiment_data import StandardExperimentDataConfig\n",
    "from batchbald_redux.emnist_models import EMnistModelTrainer\n",
    "from batchbald_redux.unified_experiment import UnifiedExperiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "configs = [\n",
    "    UnifiedExperiment(\n",
    "        experiment_data_config=StandardExperimentDataConfig(\n",
    "            id_dataset_name=\"EMNIST\",\n",
    "            id_repetitions=1,\n",
    "            initial_training_set_size=0,\n",
    "            validation_set_size=4096,\n",
    "            validation_split_random_state=0,\n",
    "            evaluation_set_size=0,\n",
    "            add_dataset_noise=False,\n",
    "            ood_dataset_config=None,\n",
    "        ),\n",
    "        seed=seed + 1765,\n",
    "        acquisition_function=acquisition_function,\n",
    "        acquisition_size=acquisition_size,\n",
    "        num_pool_samples=num_pool_samples,\n",
    "        max_training_set=300,\n",
    "        model_trainer_factory=EMnistModelTrainer,\n",
    "        stochastic_mode=stochastic_mode,\n",
    "        coldness=coldness,\n",
    "    )\n",
    "    for acquisition_function in [\n",
    "        acquisition_functions.StochasticBALD,\n",
    "    ]\n",
    "    for seed in range(5)\n",
    "    for acquisition_size in [10, 20, 40]\n",
    "    for num_pool_samples in [100]\n",
    "    for coldness in [8, 4, 1]\n",
    "    # Already ran Power\n",
    "    for stochastic_mode in [\n",
    "        acquisition_functions.StochasticMode.Power,\n",
    "        acquisition_functions.StochasticMode.Softmax,\n",
    "    ]\n",
    "] + [\n",
    "    UnifiedExperiment(\n",
    "        experiment_data_config=StandardExperimentDataConfig(\n",
    "            id_dataset_name=\"EMNIST\",\n",
    "            id_repetitions=1,\n",
    "            initial_training_set_size=0,\n",
    "            validation_set_size=4096,\n",
    "            validation_split_random_state=0,\n",
    "            evaluation_set_size=0,\n",
    "            add_dataset_noise=False,\n",
    "            ood_dataset_config=None,\n",
    "        ),\n",
    "        seed=seed + 1765,\n",
    "        acquisition_function=acquisition_function,\n",
    "        acquisition_size=acquisition_size,\n",
    "        num_pool_samples=num_pool_samples,\n",
    "        max_training_set=300,\n",
    "        model_trainer_factory=EMnistModelTrainer,\n",
    "        stochastic_mode=stochastic_mode,\n",
    "        coldness=coldness,\n",
    "    )\n",
    "    for acquisition_function in [\n",
    "        acquisition_functions.StochasticBALD,\n",
    "    ]\n",
    "    for seed in range(5)\n",
    "    for acquisition_size in [10, 20, 40]\n",
    "    for num_pool_samples in [100]\n",
    "    for coldness in [1]\n",
    "    # Already ran Power\n",
    "    for stochastic_mode in [\n",
    "        acquisition_functions.StochasticMode.Softrank,\n",
    "    ]\n",
    "] + [\n",
    "    UnifiedExperiment(\n",
    "        experiment_data_config=StandardExperimentDataConfig(\n",
    "            id_dataset_name=\"EMNIST\",\n",
    "            id_repetitions=1,\n",
    "            initial_training_set_size=0,\n",
    "            validation_set_size=4096,\n",
    "            validation_split_random_state=0,\n",
    "            evaluation_set_size=0,\n",
    "            add_dataset_noise=False,\n",
    "            ood_dataset_config=None,\n",
    "        ),\n",
    "        seed=seed + 1765,\n",
    "        acquisition_function=acquisition_function,\n",
    "        acquisition_size=acquisition_size,\n",
    "        num_pool_samples=num_pool_samples,\n",
    "        max_training_set=300,\n",
    "        model_trainer_factory=EMnistModelTrainer,\n",
    "    )\n",
    "    for acquisition_function in [\n",
    "        acquisition_functions.BALD,\n",
    "    ]\n",
    "    for seed in range(5)\n",
    "    for acquisition_size in [10, 20, 40]\n",
    "    for num_pool_samples in [10]\n",
    "] + [\n",
    "    UnifiedExperiment(\n",
    "        experiment_data_config=StandardExperimentDataConfig(\n",
    "            id_dataset_name=\"EMNIST\",\n",
    "            id_repetitions=1,\n",
    "            initial_training_set_size=0,\n",
    "            validation_set_size=4096, # Increase the validation set to reduce memory pressure\n",
    "            validation_split_random_state=0,\n",
    "            evaluation_set_size=0,\n",
    "            add_dataset_noise=False,\n",
    "            ood_dataset_config=None,\n",
    "        ),\n",
    "        seed=seed + 1765,\n",
    "        acquisition_function=acquisition_function,\n",
    "        acquisition_size=acquisition_size,\n",
    "        num_pool_samples=num_pool_samples,\n",
    "        max_training_set=300,\n",
    "        model_trainer_factory=EMnistModelTrainer,\n",
    "    )\n",
    "    for acquisition_function in [\n",
    "        baseline_acquisition_functions.BADGE,\n",
    "    ]\n",
    "    for seed in range(5)\n",
    "    for acquisition_size in [10, 20, 40]\n",
    "    for num_pool_samples in [10]\n",
    "] + [\n",
    "    UnifiedExperiment(\n",
    "        experiment_data_config=StandardExperimentDataConfig(\n",
    "            id_dataset_name=\"EMNIST\",\n",
    "            id_repetitions=1,\n",
    "            initial_training_set_size=0,\n",
    "            validation_set_size=4096,\n",
    "            validation_split_random_state=0,\n",
    "            evaluation_set_size=0,\n",
    "            add_dataset_noise=False,\n",
    "            ood_dataset_config=None,\n",
    "        ),\n",
    "        seed=seed + 1765,\n",
    "        acquisition_function=acquisition_function,\n",
    "        acquisition_size=acquisition_size,\n",
    "        num_pool_samples=num_pool_samples,\n",
    "        max_training_set=300,\n",
    "        model_trainer_factory=EMnistModelTrainer,\n",
    "    )\n",
    "    for acquisition_function in [\n",
    "        acquisition_functions.BatchBALD,\n",
    "    ]\n",
    "    for seed in range(5)\n",
    "    for acquisition_size in [5]\n",
    "    for num_pool_samples in [20]\n",
    "]\n",
    "\n",
    "if not is_run_from_ipython() and __name__ == \"__main__\":\n",
    "    for job_id, store in embedded_experiments(__file__, len(configs)):\n",
    "        config = configs[job_id]\n",
    "        config.seed += job_id\n",
    "        print(config)\n",
    "        store[\"config\"] = dataclasses.asdict(config)\n",
    "        store[\"log\"] = {}\n",
    "\n",
    "        try:\n",
    "            config.run(store=store)\n",
    "        except Exception:\n",
    "            store[\"exception\"] = traceback.format_exc()\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=1769,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='EMNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=0,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        acquisition_size=40,\n",
      "        max_training_set=300,\n",
      "        num_pool_samples=10,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE,\n",
      "        # class\n",
      "        train_eval_model=batchbald_redux.train_eval_model.TrainSelfDistillationEvalModel,\n",
      "        # class\n",
      "        model_trainer_factory=batchbald_redux.emnist_models.EMnistModelTrainer,\n",
      "        epig_bootstrap_type=batchbald_redux.batchbald.BootstrapType.NO_BOOTSTRAP\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=1765,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='EMNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=0,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        max_training_set=300,\n",
      "        num_pool_samples=10,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.BatchBALD,\n",
      "        # class\n",
      "        train_eval_model=batchbald_redux.train_eval_model.TrainSelfDistillationEvalModel,\n",
      "        # class\n",
      "        model_trainer_factory=batchbald_redux.emnist_models.EMnistModelTrainer,\n",
      "        epig_bootstrap_type=batchbald_redux.batchbald.BootstrapType.NO_BOOTSTRAP\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=1766,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='EMNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=0,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        max_training_set=300,\n",
      "        num_pool_samples=10,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.BatchBALD,\n",
      "        # class\n",
      "        train_eval_model=batchbald_redux.train_eval_model.TrainSelfDistillationEvalModel,\n",
      "        # class\n",
      "        model_trainer_factory=batchbald_redux.emnist_models.EMnistModelTrainer,\n",
      "        epig_bootstrap_type=batchbald_redux.batchbald.BootstrapType.NO_BOOTSTRAP\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=1767,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='EMNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=0,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        max_training_set=300,\n",
      "        num_pool_samples=10,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.BatchBALD,\n",
      "        # class\n",
      "        train_eval_model=batchbald_redux.train_eval_model.TrainSelfDistillationEvalModel,\n",
      "        # class\n",
      "        model_trainer_factory=batchbald_redux.emnist_models.EMnistModelTrainer,\n",
      "        epig_bootstrap_type=batchbald_redux.batchbald.BootstrapType.NO_BOOTSTRAP\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=1768,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='EMNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=0,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        max_training_set=300,\n",
      "        num_pool_samples=10,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.BatchBALD,\n",
      "        # class\n",
      "        train_eval_model=batchbald_redux.train_eval_model.TrainSelfDistillationEvalModel,\n",
      "        # class\n",
      "        model_trainer_factory=batchbald_redux.emnist_models.EMnistModelTrainer,\n",
      "        epig_bootstrap_type=batchbald_redux.batchbald.BootstrapType.NO_BOOTSTRAP\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=1769,\n",
      "        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(\n",
      "            id_dataset_name='EMNIST',\n",
      "            id_repetitions=1,\n",
      "            initial_training_set_size=0,\n",
      "            validation_set_size=4096,\n",
      "            validation_split_random_state=0,\n",
      "            evaluation_set_size=0,\n",
      "            add_dataset_noise=False,\n",
      "            ood_dataset_config=None\n",
      "        ),\n",
      "        max_training_set=300,\n",
      "        num_pool_samples=10,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.BatchBALD,\n",
      "        # class\n",
      "        train_eval_model=batchbald_redux.train_eval_model.TrainSelfDistillationEvalModel,\n",
      "        # class\n",
      "        model_trainer_factory=batchbald_redux.emnist_models.EMnistModelTrainer,\n",
      "        epig_bootstrap_type=batchbald_redux.batchbald.BootstrapType.NO_BOOTSTRAP\n",
      "    )\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import prettyprinter\n",
    "\n",
    "prettyprinter.install_extras({\"dataclasses\"})\n",
    "prettyprinter.pprint(configs[134:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardExperimentDataConfig(id_dataset_name='EMNIST', id_repetitions=1, initial_training_set_size=0, validation_set_size=4096, validation_split_random_state=0, evaluation_set_size=0, add_dataset_noise=False, ood_dataset_config=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n",
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating: BatchBALD(\n",
      "\tacquisition_size=5,\n",
      "\tnum_pool_samples=100\n",
      ")\n",
      "Creating: EMnistModelTrainer(\n",
      "\tdevice=cuda,\n",
      "\tnum_training_samples=1,\n",
      "\tnum_validation_samples=20,\n",
      "\tmax_training_epochs=300\n",
      ")\n",
      "Creating: TrainSelfDistillationEvalModel(\n",
      "\tnum_pool_samples=100\n",
      ")\n",
      "Training set size 0:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/2326460 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.00783164120595239, 'crossentropy': tensor(3.8564)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/69383600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-568184c2444e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# configs[0].num_pool_samples = 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# configs[0].evaluation_set_size = 1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m135\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/unified_experiment.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, store)\u001b[0m\n\u001b[1;32m    269\u001b[0m         )\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mactive_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/unified_experiment.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, log)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macquisition_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCandidateBatchComputer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0mcandidate_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macquisition_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_candidate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macquisition_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEvalDatasetBatchComputer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_dataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/acquisition_functions.py\u001b[0m in \u001b[0;36mcompute_candidate_batch\u001b[0;34m(self, model, pool_loader, device)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mlog_probs_N_K_C\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_log_probs_N_K_C\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_pool_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_candidate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs_N_K_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_candidate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs_N_K_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCandidateBatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/acquisition_functions.py\u001b[0m in \u001b[0;36mget_candidate_batch\u001b[0;34m(self, log_probs_N_K_C, device)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_candidate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs_N_K_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCandidateBatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# Evaluate BALD scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         candidate_batch = get_batch_bald_batch(\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0mlog_probs_N_K_C\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquisition_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/batchbald.py\u001b[0m in \u001b[0;36mget_batch_bald_batch\u001b[0;34m(log_probs_N_K_C, batch_size, num_samples, dtype, device)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mCandidateBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     batchbald_scorer = BatchBALDScorer(\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0mlog_probs_N_K_C\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mmax_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/batchbald.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, log_probs_N_K_C, max_size, num_samples, dtype, device)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_probs_N_K_C\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_probs_N_K_C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconditional_entropies_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_conditional_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_probs_N_K_C\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_conditional_entropies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/batchbald.py\u001b[0m in \u001b[0;36mcompute_conditional_entropy\u001b[0;34m(log_probs_N_K_C)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mentropies_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mlog_probs_N_K_C\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_probs_N_K_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_progress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtqdm_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Conditional Entropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "store = {}\n",
    "\n",
    "# configs[0].max_training_epochs = 1\n",
    "# configs[0].num_pool_samples = 5\n",
    "# configs[0].evaluation_set_size = 1024\n",
    "configs[135].run(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:active_learning]",
   "language": "python",
   "name": "conda-env-active_learning-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
