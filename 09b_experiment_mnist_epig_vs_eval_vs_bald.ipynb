{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment MNIST: (real EPIG) vs EvalBALD vs BALD\n",
    "> Can we get better by training on our assumptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp experiment_epig_vs_eval_vs_bald"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import blackhc.project.script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules and functions were are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "import dataclasses\n",
    "import traceback\n",
    "\n",
    "from blackhc.project import is_run_from_ipython\n",
    "from blackhc.project.experiment import embedded_experiments\n",
    "\n",
    "from batchbald_redux import acquisition_functions\n",
    "from batchbald_redux.unified_experiment import UnifiedExperiment\n",
    "\n",
    "from batchbald_redux.models import MnistModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "configs = [\n",
    "    UnifiedExperiment(\n",
    "        seed=seed + 8945,\n",
    "        acquisition_function=acquisition_function,\n",
    "        acquisition_size=acquisition_size,\n",
    "        num_pool_samples=num_pool_samples,\n",
    "        initial_training_set_size=20,\n",
    "        evaluation_set_size=0,\n",
    "        max_training_set=120,\n",
    "        id_dataset_name=\"MNIST\",\n",
    "        ood_dataset_name=None,\n",
    "        ood_exposure=False,\n",
    "        id_repetitions=id_repetitions,\n",
    "        add_dataset_noise=True,\n",
    "        model_trainer_factory=MnistModelTrainer\n",
    "    )\n",
    "    for seed in range(5)\n",
    "    for acquisition_function in [\n",
    "        acquisition_functions.EPIG,\n",
    "        acquisition_functions.EvalBALD,\n",
    "        acquisition_functions.BALD,\n",
    "    ]\n",
    "    for acquisition_size in [1]\n",
    "    for num_pool_samples in [100]\n",
    "    for id_repetitions in [1]\n",
    "]\n",
    "\n",
    "if not is_run_from_ipython() and __name__ == \"__main__\":\n",
    "    for job_id, store in embedded_experiments(__file__, len(configs)):\n",
    "        config = configs[job_id]\n",
    "        config.seed += job_id\n",
    "        print(config)\n",
    "        store[\"config\"] = dataclasses.asdict(config)\n",
    "        store[\"log\"] = {}\n",
    "\n",
    "        try:\n",
    "            config.run(store=store)\n",
    "        except Exception:\n",
    "            store[\"exception\"] = traceback.format_exc()\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8945,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=10000,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EPIG,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8945,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=10000,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8945,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=10000,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8946,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=10000,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EPIG,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8946,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=10000,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8946,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=10000,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8947,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=10000,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EPIG,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8947,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=10000,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8947,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=10000,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8948,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=10000,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EPIG,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8948,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=10000,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8948,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=10000,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8949,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=10000,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EPIG,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8949,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=10000,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8949,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=10000,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    )\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import prettyprinter\n",
    "prettyprinter.install_extras({\"dataclasses\"})\n",
    "prettyprinter.pprint(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating: ExperimentDataConfig(\n",
      "\tid_dataset_name=MNIST,\n",
      "\tid_repetitions=1,\n",
      "\tinitial_training_set_size=20,\n",
      "\tvalidation_set_size=1024,\n",
      "\tvalidation_split_random_state=0,\n",
      "\tevaluation_set_size=1024,\n",
      "\tadd_dataset_noise=True,\n",
      "\tdevice=cuda,\n",
      "\tood_dataset_config=None\n",
      ")\n",
      "Creating: EPIG(\n",
      "\tacquisition_size=1,\n",
      "\tnum_pool_samples=5\n",
      ")\n",
      "Creating: MnistModelTrainer(\n",
      "\tdevice=cuda,\n",
      "\tnum_training_samples=1,\n",
      "\tnum_validation_samples=20,\n",
      "\tmax_training_epochs=1\n",
      ")\n",
      "Creating: TrainSelfDistillationEvalModel(\n",
      "\tnum_pool_samples=5\n",
      ")\n",
      "Training set size 20:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n",
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b65751781cd4492ba0239e364c4d2343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.544921875, 'crossentropy': 1.815647765994072}\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: 0.544921875)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.5957, 'crossentropy': tensor(1.5099)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/289680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/5100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation Set:   0%|          | 0/1020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CandidateBatch(scores=[0.03721870894774071], indices=[8780])\n",
      "[('id', 8954)]\n",
      "Acquiring (label, score)s: 5 (0.03722)\n",
      "Training set size 21:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ed4a39795bb491d85875f6682fb0147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.5107421875, 'crossentropy': 1.9398711323738098}\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: 0.5107421875)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.5485, 'crossentropy': tensor(1.6474)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/289675 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/5100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation Set:   0%|          | 0/1020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CandidateBatch(scores=[0.027692629668440306], indices=[24815])\n",
      "[('id', 25256)]\n",
      "Acquiring (label, score)s: 0 (0.02769)\n",
      "Training set size 22:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6925eebb9a784b12a23d88f53346f371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.5166015625, 'crossentropy': 1.8856491297483444}\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: 0.5166015625)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.5543, 'crossentropy': tensor(1.5897)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/289670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/5100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation Set:   0%|          | 0/1020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CandidateBatch(scores=[0.09608910638074813], indices=[45233])\n",
      "[('id', 46047)]\n",
      "Acquiring (label, score)s: 2 (0.09609)\n",
      "Training set size 23:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c6381cade524f22b08460b09a93b92c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.494140625, 'crossentropy': 1.944316253066063}\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: 0.494140625)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.5487, 'crossentropy': tensor(1.7605)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/289665 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/5100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f14fc514406428fbd1f0cb4b81b6ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation Set:   0%|          | 0/1020 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-53ebc3871ad4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_pool_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_set_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/unified_experiment.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, store)\u001b[0m\n\u001b[1;32m    249\u001b[0m                                        model_trainer=model_trainer, data=data, device=self.device)\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mactive_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/unified_experiment.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, log)\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0meval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_evaluation_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                 candidate_batch = acquisition_function.compute_candidate_batch(model=trained_model,\n\u001b[0m\u001b[1;32m    123\u001b[0m                                                                                \u001b[0mpool_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                                                                                \u001b[0meval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/acquisition_functions.py\u001b[0m in \u001b[0;36mcompute_candidate_batch\u001b[0;34m(self, model, eval_loader, pool_loader, device)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0mlog_eval_probs_N_K_C\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_log_probs_N_K_C\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_pool_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         scores_N = get_real_naive_epig_scores(\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0mpool_log_probs_N_K_C\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_probs_N_K_C\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0meval_log_probs_E_K_C\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_eval_probs_N_K_C\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/batchbald.py\u001b[0m in \u001b[0;36mget_real_naive_epig_scores\u001b[0;34m(pool_log_probs_N_K_C, eval_log_probs_E_K_C, dtype, device)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0mscores_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweighted_nats_N_C_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0mtotal_scores_N\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mscores_N\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mtotal_scores_N\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "store={}\n",
    "\n",
    "configs[0].max_training_epochs=1\n",
    "configs[0].num_pool_samples=5\n",
    "configs[0].evaluation_set_size=1024\n",
    "configs[0].run(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:active_learning]",
   "language": "python",
   "name": "conda-env-active_learning-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
