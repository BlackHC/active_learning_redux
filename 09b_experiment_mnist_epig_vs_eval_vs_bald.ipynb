{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment MNIST: (real EPIG) vs EvalBALD vs BALD\n",
    "> Can we get better by training on our assumptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp experiment_epig_vs_eval_vs_bald_vs_sieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import blackhc.project.script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules and functions were are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "import dataclasses\n",
    "import traceback\n",
    "\n",
    "from blackhc.project import is_run_from_ipython\n",
    "from blackhc.project.experiment import embedded_experiments\n",
    "\n",
    "from batchbald_redux import acquisition_functions\n",
    "from batchbald_redux.unified_experiment import UnifiedExperiment\n",
    "\n",
    "from batchbald_redux.models import MnistModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "configs = [\n",
    "    UnifiedExperiment(\n",
    "        seed=seed + 8945,\n",
    "        acquisition_function=acquisition_function,\n",
    "        acquisition_size=acquisition_size,\n",
    "        num_pool_samples=num_pool_samples,\n",
    "        initial_training_set_size=20,\n",
    "        evaluation_set_size=0,\n",
    "        max_training_set=300,\n",
    "        id_dataset_name=\"MNIST\",\n",
    "        ood_dataset_name=None,\n",
    "        ood_exposure=False,\n",
    "        id_repetitions=id_repetitions,\n",
    "        add_dataset_noise=True,\n",
    "        model_trainer_factory=MnistModelTrainer\n",
    "    )\n",
    "    for seed in range(5)\n",
    "    for acquisition_function in [\n",
    "        acquisition_functions.EPIG,\n",
    "        acquisition_functions.EvalBALD,\n",
    "        acquisition_functions.BALD,\n",
    "    ]\n",
    "    for acquisition_size in [1]\n",
    "    for num_pool_samples in [100]\n",
    "    for id_repetitions in [1]\n",
    "]\n",
    "\n",
    "if not is_run_from_ipython() and __name__ == \"__main__\":\n",
    "    for job_id, store in embedded_experiments(__file__, len(configs)):\n",
    "        config = configs[job_id]\n",
    "        config.seed += job_id\n",
    "        print(config)\n",
    "        store[\"config\"] = dataclasses.asdict(config)\n",
    "        store[\"log\"] = {}\n",
    "\n",
    "        try:\n",
    "            config.run(store=store)\n",
    "        except Exception:\n",
    "            store[\"exception\"] = traceback.format_exc()\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8945,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=0,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EPIG,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8945,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=0,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8945,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=0,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8946,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=0,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EPIG,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8946,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=0,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8946,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=0,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8947,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=0,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EPIG,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8947,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=0,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8947,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=0,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8948,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=0,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EPIG,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8948,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=0,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8948,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=0,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8949,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=0,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EPIG,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8949,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=0,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    ),\n",
      "    batchbald_redux.unified_experiment.UnifiedExperiment(\n",
      "        seed=8949,\n",
      "        id_dataset_name='MNIST',\n",
      "        ood_dataset_name=None,\n",
      "        ood_exposure=False,\n",
      "        evaluation_set_size=0,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=1,\n",
      "        max_training_set=300,\n",
      "        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class\n",
      "    )\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import prettyprinter\n",
    "prettyprinter.install_extras({\"dataclasses\"})\n",
    "prettyprinter.pprint(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating: ExperimentDataConfig(\n",
      "\tid_dataset_name=MNIST,\n",
      "\tid_repetitions=1,\n",
      "\tinitial_training_set_size=20,\n",
      "\tvalidation_set_size=1024,\n",
      "\tvalidation_split_random_state=0,\n",
      "\tevaluation_set_size=1024,\n",
      "\tadd_dataset_noise=True,\n",
      "\tdevice=cuda,\n",
      "\tood_dataset_config=None\n",
      ")\n",
      "Creating: BALD(\n",
      "\tacquisition_size=1,\n",
      "\tnum_pool_samples=5\n",
      ")\n",
      "Creating: MnistModelTrainer(\n",
      "\tdevice=cuda,\n",
      "\tnum_training_samples=1,\n",
      "\tnum_validation_samples=20,\n",
      "\tmax_training_epochs=1\n",
      ")\n",
      "Creating: TrainSelfDistillationEvalModel(\n",
      "\tnum_pool_samples=5\n",
      ")\n",
      "Training set size 20:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n",
      "/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6970f110a93f452aa6366f5602b6e9aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.4921875, 'crossentropy': 1.9472027570009232}\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: 0.4921875)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.5215, 'crossentropy': tensor(1.6892)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/289680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/57936 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/57936 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CandidateBatch(scores=[0.3518548011779785], indices=[36700])\n",
      "[('id', 37367)]\n",
      "Acquiring (label, score)s: 8 (0.3519)\n",
      "Training set size 21:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa7b72d97154d4dac2a6f1940856eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/16]   6%|6          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.4736328125, 'crossentropy': 1.9298868030309677}\n",
      "RestoringEarlyStopping: Restoring best parameters. (Score: 0.4736328125)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.4307, 'crossentropy': tensor(1.6706)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/289675 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/57935 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "968cf0f851224dbba6bafb3974805a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/57935 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-788863a5dd9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_pool_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_set_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/unified_experiment.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, store)\u001b[0m\n\u001b[1;32m    249\u001b[0m                                        model_trainer=model_trainer, data=data, device=self.device)\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mactive_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/unified_experiment.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, log)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macquisition_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCandidateBatchComputer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                 \u001b[0mcandidate_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macquisition_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_candidate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macquisition_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEvalDatasetBatchComputer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_dataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/acquisition_functions.py\u001b[0m in \u001b[0;36mcompute_candidate_batch\u001b[0;34m(self, model, pool_loader, device)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mlog_probs_N_K_C\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_log_probs_N_K_C\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_pool_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_candidate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs_N_K_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_candidate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs_N_K_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCandidateBatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/acquisition_functions.py\u001b[0m in \u001b[0;36mget_candidate_batch\u001b[0;34m(self, log_probs_N_K_C, device)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_candidate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs_N_K_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCandidateBatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# Evaluate BALD scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mscores_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_bald_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs_N_K_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mcandidate_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_N\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/batchbald.py\u001b[0m in \u001b[0;36mget_bald_scores\u001b[0;34m(log_probs_N_K_C, dtype, device)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0mscores_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcompute_conditional_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs_N_K_C\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0mscores_N\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcompute_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs_N_K_C\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscores_N\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/bald-ical/batchbald_redux/batchbald.py\u001b[0m in \u001b[0;36mcompute_entropy\u001b[0;34m(log_probs_N_K_C)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtoma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs_N_K_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs_n_K_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mmean_log_probs_n_C\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs_n_K_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mnats_n_C\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_log_probs_n_C\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_log_probs_n_C\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/toma/__init__.py\u001b[0m in \u001b[0;36mexecute_chunked\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mexecute_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m                 return explicit.chunked(\n\u001b[0m\u001b[1;32m    202\u001b[0m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                     \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/toma/__init__.py\u001b[0m in \u001b[0;36mchunked\u001b[0;34m(func, tensor, initial_step, toma_dimension, toma_context, toma_cache_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoma_dimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         explicit.range(\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/toma/__init__.py\u001b[0m in \u001b[0;36mrange\u001b[0;34m(func, start, end, initial_step, toma_context, toma_cache_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mcurrent\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                 \u001b[0mgc_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mshould_reduce_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/active_learning/lib/python3.8/site-packages/toma/torch_cuda_memory.py\u001b[0m in \u001b[0;36mgc_cuda\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgc_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;34m\"\"\"Gargage collect Torch (CUDA) memory.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "store={}\n",
    "\n",
    "configs[2].max_training_epochs=1\n",
    "configs[2].num_pool_samples=5\n",
    "configs[2].evaluation_set_size=1024\n",
    "configs[2].run(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:active_learning]",
   "language": "python",
   "name": "conda-env-active_learning-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
