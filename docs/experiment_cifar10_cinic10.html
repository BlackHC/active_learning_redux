---

title: Experiment CIFAR-10


keywords: fastai
sidebar: home_sidebar

summary: "Can we get better by training on our assumptions?"
description: "Can we get better by training on our assumptions?"
nb_path: "09a_experiment_cifar10_cinic10.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 09a_experiment_cifar10_cinic10.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Appended /home/blackhc/PycharmProjects/bald-ical/src to paths
Switched to directory /home/blackhc/PycharmProjects/bald-ical
%load_ext autoreload
%autoreload 2
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Import modules and functions were are going to use.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">dataclasses</span>
<span class="kn">import</span> <span class="nn">traceback</span>

<span class="kn">from</span> <span class="nn">blackhc.project</span> <span class="kn">import</span> <span class="n">is_run_from_ipython</span>
<span class="kn">from</span> <span class="nn">blackhc.project.experiment</span> <span class="kn">import</span> <span class="n">embedded_experiments</span>

<span class="kn">import</span> <span class="nn">batchbald_redux.acquisition_functions.bald</span>
<span class="kn">from</span> <span class="nn">batchbald_redux</span> <span class="kn">import</span> <span class="n">acquisition_functions</span><span class="p">,</span> <span class="n">baseline_acquisition_functions</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.experiment_data</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">OoDDatasetConfig</span><span class="p">,</span>
    <span class="n">StandardExperimentDataConfig</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.resnet_models</span> <span class="kn">import</span> <span class="n">Cifar10ModelWorkshopPaperTrainer</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.unified_experiment</span> <span class="kn">import</span> <span class="n">UnifiedExperiment</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">shared_configs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="n">num_validation_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">num_pool_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">num_training_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">resnet18_dropout_head</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">ensemble_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">max_training_epochs</span><span class="o">=</span><span class="mi">105</span><span class="p">,</span>
    <span class="n">model_trainer_factory</span><span class="o">=</span><span class="n">Cifar10ModelWorkshopPaperTrainer</span><span class="p">,</span>
    <span class="n">max_training_set</span><span class="o">=</span><span class="mi">16000</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">configs</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="n">UnifiedExperiment</span><span class="p">(</span>
                <span class="n">experiment_data_config</span><span class="o">=</span><span class="n">StandardExperimentDataConfig</span><span class="p">(</span>
                    <span class="n">id_dataset_name</span><span class="o">=</span><span class="n">id_dataset_name</span><span class="p">,</span>
                    <span class="n">id_repetitions</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">initial_training_set_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                    <span class="n">validation_set_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
                    <span class="n">validation_split_random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                    <span class="n">evaluation_set_size</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                    <span class="n">add_dataset_noise</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">ood_dataset_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="n">seed</span><span class="o">=</span><span class="n">seed</span> <span class="o">+</span> <span class="mi">1456</span><span class="p">,</span>
                <span class="n">acquisition_function</span><span class="o">=</span><span class="n">acquisition_function</span><span class="p">,</span>
                <span class="n">acquisition_size</span><span class="o">=</span><span class="n">acquisition_size</span><span class="p">,</span>
                <span class="o">**</span><span class="n">shared_configs</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">acquisition_function</span> <span class="ow">in</span> <span class="p">[</span>
            <span class="n">batchbald_redux</span><span class="o">.</span><span class="n">acquisition_functions</span><span class="o">.</span><span class="n">bald</span><span class="o">.</span><span class="n">BALD</span><span class="p">,</span>
            <span class="p">]</span>
        <span class="p">]</span>
        <span class="o">+</span> <span class="p">[</span>
            <span class="n">UnifiedExperiment</span><span class="p">(</span>
                <span class="n">experiment_data_config</span><span class="o">=</span><span class="n">StandardExperimentDataConfig</span><span class="p">(</span>
                    <span class="n">id_dataset_name</span><span class="o">=</span><span class="n">id_dataset_name</span><span class="p">,</span>
                    <span class="n">id_repetitions</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">initial_training_set_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                    <span class="n">validation_set_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
                    <span class="n">validation_split_random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                    <span class="n">evaluation_set_size</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                    <span class="n">add_dataset_noise</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">ood_dataset_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="n">seed</span><span class="o">=</span><span class="n">seed</span> <span class="o">+</span> <span class="mi">8945</span><span class="p">,</span>
                <span class="n">acquisition_function</span><span class="o">=</span><span class="n">acquisition_function</span><span class="p">,</span>
                <span class="n">acquisition_size</span><span class="o">=</span><span class="n">acquisition_size</span><span class="p">,</span>
                <span class="n">coldness</span><span class="o">=</span><span class="n">coldness</span><span class="p">,</span>
                <span class="n">stochastic_mode</span><span class="o">=</span><span class="n">stochastic_mode</span><span class="p">,</span>
                <span class="o">**</span><span class="n">shared_configs</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">stochastic_mode</span> <span class="ow">in</span> <span class="p">[</span>
                <span class="n">acquisition_functions</span><span class="o">.</span><span class="n">StochasticMode</span><span class="o">.</span><span class="n">Power</span><span class="p">,</span>
                <span class="n">acquisition_functions</span><span class="o">.</span><span class="n">StochasticMode</span><span class="o">.</span><span class="n">Softmax</span><span class="p">,</span>
                <span class="n">acquisition_functions</span><span class="o">.</span><span class="n">StochasticMode</span><span class="o">.</span><span class="n">Softrank</span><span class="p">,</span>
            <span class="p">]</span>
            <span class="k">for</span> <span class="n">coldness</span> <span class="ow">in</span> <span class="p">([</span><span class="mi">1</span><span class="o">/</span><span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="n">stochastic_mode</span> <span class="o">!=</span> <span class="n">acquisition_functions</span><span class="o">.</span><span class="n">StochasticMode</span><span class="o">.</span><span class="n">Softrank</span> <span class="k">else</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">acquisition_function</span> <span class="ow">in</span> <span class="p">[</span>
                <span class="n">batchbald_redux</span><span class="o">.</span><span class="n">acquisition_functions</span><span class="o">.</span><span class="n">bald</span><span class="o">.</span><span class="n">StochasticBALD</span><span class="p">,</span>
            <span class="p">]</span>
        <span class="p">]</span>
        <span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">id_dataset_name</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;CINIC-10&quot;</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">acquisition_size</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">300</span><span class="p">]</span>
    <span class="p">],</span>
    <span class="p">[],</span>
<span class="p">)</span>
<span class="c1"># + [</span>
<span class="c1">#     UnifiedExperiment(</span>
<span class="c1">#         experiment_data_config=StandardExperimentDataConfig(</span>
<span class="c1">#             id_dataset_name=id_dataset_name,</span>
<span class="c1">#             id_repetitions=1,</span>
<span class="c1">#             initial_training_set_size=1000,</span>
<span class="c1">#             validation_set_size=1024,</span>
<span class="c1">#             validation_split_random_state=0,</span>
<span class="c1">#             evaluation_set_size=0,</span>
<span class="c1">#             add_dataset_noise=False,</span>
<span class="c1">#             ood_dataset_config=None,</span>
<span class="c1">#         ),</span>
<span class="c1">#         seed=seed + 1456,</span>
<span class="c1">#         acquisition_function=acquisition_function,</span>
<span class="c1">#         acquisition_size=acquisition_size,</span>
<span class="c1">#         num_validation_samples=1,</span>
<span class="c1">#         num_pool_samples=1,</span>
<span class="c1">#         num_training_samples=1,</span>
<span class="c1">#         resnet18_dropout_head=False,</span>
<span class="c1">#         ensemble_size=1,</span>
<span class="c1">#         max_training_epochs=105,</span>
<span class="c1">#         model_trainer_factory=Cifar10ModelWorkshopPaperTrainer,</span>
<span class="c1">#         max_training_set=16000,</span>
<span class="c1">#     )</span>
<span class="c1">#     for acquisition_function in [</span>
<span class="c1">#         baseline_acquisition_functions.BADGE,</span>
<span class="c1">#     ]</span>
<span class="c1">#     for seed in range(3)</span>
<span class="c1">#     for id_dataset_name in [&quot;CIFAR-10&quot;, &quot;CINIC-10&quot;]</span>
<span class="c1">#     for acquisition_size in [300, 900]</span>
<span class="c1"># ]</span>
<span class="c1">#     UnifiedExperiment(</span>
<span class="c1">#         seed=seed + 8945,</span>
<span class="c1">#         acquisition_function=acquisition_function,</span>
<span class="c1">#         acquisition_size=acquisition_size,</span>
<span class="c1">#         num_pool_samples=num_pool_samples,</span>
<span class="c1">#         initial_training_set_size=1000,</span>
<span class="c1">#         evaluation_set_size=0,</span>
<span class="c1">#         max_training_set=15000,</span>
<span class="c1">#         temperature=temperature,</span>
<span class="c1">#         id_dataset_name=&quot;CIFAR-10&quot;,</span>
<span class="c1">#         ood_dataset_name=None,</span>
<span class="c1">#         ood_exposure=False,</span>
<span class="c1">#         id_repetitions=id_repetitions,</span>
<span class="c1">#         add_dataset_noise=True</span>

<span class="c1">#     )</span>
<span class="c1">#     for seed in range(5)</span>
<span class="c1">#     for acquisition_function in [</span>
<span class="c1">#         acquisition_functions.SieveBALD,</span>
<span class="c1">#     ]</span>
<span class="c1">#     for acquisition_size in [3000]</span>
<span class="c1">#     for num_pool_samples in [100]</span>
<span class="c1">#     for temperature in [1/64]</span>
<span class="c1">#     for id_repetitions in [1,5,10,20]</span>
<span class="c1"># ]</span>
<span class="c1"># +</span>
<span class="c1">#     UnifiedExperiment(</span>
<span class="c1">#         seed=seed + 8945,</span>
<span class="c1">#         acquisition_function=acquisition_function,</span>
<span class="c1">#         acquisition_size=acquisition_size,</span>
<span class="c1">#         num_pool_samples=num_pool_samples,</span>
<span class="c1">#         initial_training_set_size=1000,</span>
<span class="c1">#         evaluation_set_size=0,</span>
<span class="c1">#         max_training_set=15000,</span>
<span class="c1">#         temperature=temperature,</span>
<span class="c1">#         id_dataset_name=&quot;CIFAR-10&quot;,</span>
<span class="c1">#         ood_dataset_name=None,</span>
<span class="c1">#         ood_exposure=False,</span>
<span class="c1">#         id_repetitions=id_repetitions,</span>
<span class="c1">#         add_dataset_noise=True</span>

<span class="c1">#     )</span>
<span class="c1">#     for seed in range(5)</span>
<span class="c1">#     for acquisition_function in [</span>
<span class="c1">#         acquisition_functions.SoftmaxBALD,</span>
<span class="c1">#     ]</span>
<span class="c1">#     for acquisition_size in [3000]</span>
<span class="c1">#     for num_pool_samples in [100]</span>
<span class="c1">#     for temperature in [1/64]</span>
<span class="c1">#     for id_repetitions in [1,5,10,20]</span>
<span class="c1"># ] + [</span>
<span class="c1">#     UnifiedExperiment(</span>
<span class="c1">#         seed=seed + 8945,</span>
<span class="c1">#         acquisition_function=acquisition_function,</span>
<span class="c1">#         acquisition_size=acquisition_size,</span>
<span class="c1">#         num_pool_samples=num_pool_samples,</span>
<span class="c1">#         initial_training_set_size=1000,</span>
<span class="c1">#         evaluation_set_size=0,</span>
<span class="c1">#         max_training_set=15000,</span>
<span class="c1">#         temperature=temperature,</span>
<span class="c1">#         id_repetitions=id_repetitions,</span>
<span class="c1">#         add_dataset_noise=True,</span>
<span class="c1">#         id_dataset_name=&quot;CIFAR-10&quot;,</span>
<span class="c1">#         ood_dataset_name=None,</span>
<span class="c1">#         ood_exposure=False,</span>
<span class="c1">#     )</span>
<span class="c1">#     for seed in range(5)</span>
<span class="c1">#     for acquisition_function in [</span>
<span class="c1">#         acquisition_functions.BALD,</span>
<span class="c1">#     ]</span>
<span class="c1">#     for acquisition_size in [3000]</span>
<span class="c1">#     for num_pool_samples in [100]</span>
<span class="c1">#     for temperature in [0]</span>
<span class="c1">#     for id_repetitions in [1,5,10,20]</span>
<span class="c1"># ]</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">is_run_from_ipython</span><span class="p">()</span> <span class="ow">and</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">job_id</span><span class="p">,</span> <span class="n">store</span> <span class="ow">in</span> <span class="n">embedded_experiments</span><span class="p">(</span><span class="vm">__file__</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">configs</span><span class="p">)):</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">configs</span><span class="p">[</span><span class="n">job_id</span><span class="p">]</span>
        <span class="n">config</span><span class="o">.</span><span class="n">seed</span> <span class="o">+=</span> <span class="n">job_id</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataclasses</span><span class="o">.</span><span class="n">asdict</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;log&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">config</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">store</span><span class="o">=</span><span class="n">store</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="n">store</span><span class="p">[</span><span class="s2">&quot;exception&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">traceback</span><span class="o">.</span><span class="n">format_exc</span><span class="p">()</span>
            <span class="k">raise</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">configs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>18</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">prettyprinter</span>

<span class="n">prettyprinter</span><span class="o">.</span><span class="n">install_extras</span><span class="p">({</span><span class="s2">&quot;dataclasses&quot;</span><span class="p">})</span>
<span class="n">prettyprinter</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">configs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=1456,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=1456,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.BALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8945,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Power,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8945,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        coldness=8,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Power,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8945,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softmax,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8945,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        coldness=8,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softmax,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8945,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softrank,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=1456,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=1456,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.BALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8945,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Power,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8945,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        coldness=8,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Power,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8945,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softmax,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8945,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        coldness=8,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softmax,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8945,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softrank,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=1456,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=1456,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.BALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8945,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Power,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8945,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        coldness=8,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Power,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8945,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softmax,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8945,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        coldness=8,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softmax,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8945,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softrank,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=1456,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=1456,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.BALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8945,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Power,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8945,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        coldness=8,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Power,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8945,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softmax,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8945,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        coldness=8,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softmax,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8945,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softrank,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=1457,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=1457,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.BALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8946,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Power,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8946,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        coldness=8,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Power,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8946,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softmax,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8946,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        coldness=8,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softmax,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8946,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softrank,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=1457,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=1457,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.BALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8946,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Power,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8946,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        coldness=8,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Power,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8946,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softmax,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8946,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        coldness=8,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softmax,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8946,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softrank,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=1457,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=1457,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.BALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8946,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Power,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8946,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        coldness=8,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Power,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8946,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softmax,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8946,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        coldness=8,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softmax,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8946,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softrank,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=1457,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=1457,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.BALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8946,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Power,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8946,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        coldness=8,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Power,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8946,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softmax,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8946,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        coldness=8,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softmax,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8946,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softrank,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=1458,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=1458,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.BALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8947,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Power,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8947,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        coldness=8,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Power,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8947,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softmax,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8947,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        coldness=8,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softmax,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8947,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softrank,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=1458,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=1458,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.BALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8947,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Power,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8947,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        coldness=8,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Power,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8947,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softmax,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8947,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        coldness=8,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softmax,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8947,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softrank,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=1458,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=1458,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.BALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8947,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Power,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8947,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        coldness=8,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Power,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8947,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softmax,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8947,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        coldness=8,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softmax,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8947,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=300,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softrank,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=1458,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=1458,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.BALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8947,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Power,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8947,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        coldness=8,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Power,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8947,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softmax,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8947,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        coldness=8,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softmax,
        resnet18_dropout_head=False
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8947,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CINIC-10&#39;,
            id_repetitions=1,
            initial_training_set_size=1000,
            validation_set_size=1024,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=900,
        max_training_set=16000,
        max_training_epochs=105,
        num_pool_samples=1,
        num_validation_samples=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.StochasticBALD,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        ensemble_size=3,
        stochastic_mode=batchbald_redux.batchbald.StochasticMode.Softrank,
        resnet18_dropout_head=False
    )
]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">store</span> <span class="o">=</span> <span class="p">{}</span>

<span class="n">configs</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">max_training_epochs</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">configs</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">num_pool_samples</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">configs</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">store</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>StandardExperimentDataConfig(id_dataset_name=&#39;CIFAR-10&#39;, id_repetitions=1, initial_training_set_size=1000, validation_set_size=1024, validation_split_random_state=0, evaluation_set_size=0, add_dataset_noise=False, ood_dataset_config=None)
Files already downloaded and verified
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  return floored.astype(np.int)
/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  return floored.astype(np.int)
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Files already downloaded and verified
Creating: StochasticBALD(
	acquisition_size=300,
	num_pool_samples=5,
	coldness=8,
	stochastic_mode=StochasticMode.Power
)
Creating: Cifar10ModelWorkshopPaperTrainer(
	device=cuda,
	num_training_samples=1,
	num_validation_samples=1,
	max_training_epochs=1,
	resnet18_dropout_head=False
)
Creating: TrainSelfDistillationEvalModel(
	num_pool_samples=5
)
Training set size 1000:
NeurIPS Workshop Style
Limit schedule/max epochs updated: [40, 60], 60
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/kornia/utils/helpers.py:96: UserWarning: torch.solve is deprecated in favor of torch.linalg.solveand will be removed in a future PyTorch release.
torch.linalg.solve has its arguments reversed and does not return the LU factorization.
To get the LU factorization see torch.lu, which can be used with torch.lu_solve or torch.lu_unpack.
X = torch.solve(B, A).solution
should be replaced with
X = torch.linalg.solve(A, B) (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068694/work/aten/src/ATen/native/BatchLinearAlgebra.cpp:766.)
  out1, out2 = torch.solve(input.to(dtype), A.to(dtype))
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch metrics: {&#39;accuracy&#39;: 0.140625, &#39;crossentropy&#39;: 2.479145050048828}
Epoch metrics: {&#39;accuracy&#39;: 0.2197265625, &#39;crossentropy&#39;: 2.094893455505371}
Epoch metrics: {&#39;accuracy&#39;: 0.2490234375, &#39;crossentropy&#39;: 1.9933443069458008}
Epoch metrics: {&#39;accuracy&#39;: 0.2890625, &#39;crossentropy&#39;: 2.018357753753662}
Epoch metrics: {&#39;accuracy&#39;: 0.302734375, &#39;crossentropy&#39;: 1.876763105392456}
Epoch metrics: {&#39;accuracy&#39;: 0.29296875, &#39;crossentropy&#39;: 1.9801175594329834}
Epoch 6: 0.29296875 worse than 0.302734375, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.357421875, &#39;crossentropy&#39;: 1.7292580604553223}
Epoch metrics: {&#39;accuracy&#39;: 0.3203125, &#39;crossentropy&#39;: 1.8108887672424316}
Epoch 8: 0.3203125 worse than 0.357421875, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.3720703125, &#39;crossentropy&#39;: 1.6613187789916992}
Epoch metrics: {&#39;accuracy&#39;: 0.3740234375, &#39;crossentropy&#39;: 1.760793924331665}
Epoch metrics: {&#39;accuracy&#39;: 0.3623046875, &#39;crossentropy&#39;: 1.9551172256469727}
Epoch 11: 0.3623046875 worse than 0.3740234375, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.3759765625, &#39;crossentropy&#39;: 1.9411952495574951}
Epoch metrics: {&#39;accuracy&#39;: 0.3994140625, &#39;crossentropy&#39;: 1.853234052658081}
Epoch metrics: {&#39;accuracy&#39;: 0.3408203125, &#39;crossentropy&#39;: 2.3708229064941406}
Epoch 14: 0.3408203125 worse than 0.3994140625, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.3955078125, &#39;crossentropy&#39;: 1.83982253074646}
Epoch 15: 0.3955078125 worse than 0.3994140625, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.3876953125, &#39;crossentropy&#39;: 1.762087106704712}
Epoch 16: 0.3876953125 worse than 0.3994140625, patience: 3/20!
Epoch metrics: {&#39;accuracy&#39;: 0.4052734375, &#39;crossentropy&#39;: 1.7708840370178223}
Epoch metrics: {&#39;accuracy&#39;: 0.3486328125, &#39;crossentropy&#39;: 2.088315010070801}
Epoch 18: 0.3486328125 worse than 0.4052734375, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.3955078125, &#39;crossentropy&#39;: 2.1869146823883057}
Epoch 19: 0.3955078125 worse than 0.4052734375, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.3525390625, &#39;crossentropy&#39;: 2.157532215118408}
Epoch 20: 0.3525390625 worse than 0.4052734375, patience: 3/20!
Epoch metrics: {&#39;accuracy&#39;: 0.4013671875, &#39;crossentropy&#39;: 2.183838367462158}
Epoch 21: 0.4013671875 worse than 0.4052734375, patience: 4/20!
Epoch metrics: {&#39;accuracy&#39;: 0.4296875, &#39;crossentropy&#39;: 1.7439382076263428}
Epoch metrics: {&#39;accuracy&#39;: 0.4052734375, &#39;crossentropy&#39;: 1.9809460639953613}
Epoch 23: 0.4052734375 worse than 0.4296875, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.392578125, &#39;crossentropy&#39;: 2.0482165813446045}
Epoch 24: 0.392578125 worse than 0.4296875, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.4365234375, &#39;crossentropy&#39;: 2.0709428787231445}
Epoch metrics: {&#39;accuracy&#39;: 0.4111328125, &#39;crossentropy&#39;: 1.9726386070251465}
Epoch 26: 0.4111328125 worse than 0.4365234375, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.3857421875, &#39;crossentropy&#39;: 2.676699161529541}
Epoch 27: 0.3857421875 worse than 0.4365234375, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.4228515625, &#39;crossentropy&#39;: 2.169896364212036}
Epoch 28: 0.4228515625 worse than 0.4365234375, patience: 3/20!
Epoch metrics: {&#39;accuracy&#39;: 0.345703125, &#39;crossentropy&#39;: 3.3966362476348877}
Epoch 29: 0.345703125 worse than 0.4365234375, patience: 4/20!
Epoch metrics: {&#39;accuracy&#39;: 0.408203125, &#39;crossentropy&#39;: 2.0707855224609375}
Epoch 30: 0.408203125 worse than 0.4365234375, patience: 5/20!
Epoch metrics: {&#39;accuracy&#39;: 0.4169921875, &#39;crossentropy&#39;: 1.9521968364715576}
Epoch 31: 0.4169921875 worse than 0.4365234375, patience: 6/20!
Epoch metrics: {&#39;accuracy&#39;: 0.435546875, &#39;crossentropy&#39;: 2.0135507583618164}
Epoch 32: 0.435546875 worse than 0.4365234375, patience: 7/20!
Epoch metrics: {&#39;accuracy&#39;: 0.4501953125, &#39;crossentropy&#39;: 1.9546098709106445}
Epoch metrics: {&#39;accuracy&#39;: 0.4365234375, &#39;crossentropy&#39;: 2.110567569732666}
Epoch 34: 0.4365234375 worse than 0.4501953125, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.4013671875, &#39;crossentropy&#39;: 2.5297391414642334}
Epoch 35: 0.4013671875 worse than 0.4501953125, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.443359375, &#39;crossentropy&#39;: 2.1002416610717773}
Epoch 36: 0.443359375 worse than 0.4501953125, patience: 3/20!
Epoch metrics: {&#39;accuracy&#39;: 0.396484375, &#39;crossentropy&#39;: 2.340847969055176}
Epoch 37: 0.396484375 worse than 0.4501953125, patience: 4/20!
Epoch metrics: {&#39;accuracy&#39;: 0.44140625, &#39;crossentropy&#39;: 2.1643896102905273}
Epoch 38: 0.44140625 worse than 0.4501953125, patience: 5/20!
Epoch metrics: {&#39;accuracy&#39;: 0.41796875, &#39;crossentropy&#39;: 2.752408504486084}
Epoch 39: 0.41796875 worse than 0.4501953125, patience: 6/20!
Epoch metrics: {&#39;accuracy&#39;: 0.39453125, &#39;crossentropy&#39;: 2.8070602416992188}
Epoch 40: 0.39453125 worse than 0.4501953125, patience: 7/20!
Restoring best snapshot: best_score: 0.4501953125 @ epoch 33
Epoch    40: reducing learning rate of group 0 to 1.0000e-03.
Epoch metrics: {&#39;accuracy&#39;: 0.458984375, &#39;crossentropy&#39;: 1.9254062175750732}
Epoch metrics: {&#39;accuracy&#39;: 0.46875, &#39;crossentropy&#39;: 1.8773713111877441}
Epoch metrics: {&#39;accuracy&#39;: 0.45703125, &#39;crossentropy&#39;: 1.8228464126586914}
Epoch 43: 0.45703125 worse than 0.46875, patience: 1/10!
Epoch metrics: {&#39;accuracy&#39;: 0.4482421875, &#39;crossentropy&#39;: 1.8531348705291748}
Epoch 44: 0.4482421875 worse than 0.46875, patience: 2/10!
Epoch metrics: {&#39;accuracy&#39;: 0.455078125, &#39;crossentropy&#39;: 1.8777580261230469}
Epoch 45: 0.455078125 worse than 0.46875, patience: 3/10!
Epoch metrics: {&#39;accuracy&#39;: 0.46484375, &#39;crossentropy&#39;: 1.850936770439148}
Epoch 46: 0.46484375 worse than 0.46875, patience: 4/10!
Epoch metrics: {&#39;accuracy&#39;: 0.4716796875, &#39;crossentropy&#39;: 1.8424134254455566}
Epoch metrics: {&#39;accuracy&#39;: 0.4638671875, &#39;crossentropy&#39;: 1.8579645156860352}
Epoch 48: 0.4638671875 worse than 0.4716796875, patience: 1/10!
Epoch metrics: {&#39;accuracy&#39;: 0.4658203125, &#39;crossentropy&#39;: 1.8713059425354004}
Epoch 49: 0.4658203125 worse than 0.4716796875, patience: 2/10!
Epoch metrics: {&#39;accuracy&#39;: 0.4619140625, &#39;crossentropy&#39;: 1.8749456405639648}
Epoch 50: 0.4619140625 worse than 0.4716796875, patience: 3/10!
Epoch metrics: {&#39;accuracy&#39;: 0.4658203125, &#39;crossentropy&#39;: 1.8763854503631592}
Epoch 51: 0.4658203125 worse than 0.4716796875, patience: 4/10!
Epoch metrics: {&#39;accuracy&#39;: 0.474609375, &#39;crossentropy&#39;: 1.8990215063095093}
Epoch metrics: {&#39;accuracy&#39;: 0.4697265625, &#39;crossentropy&#39;: 1.913280963897705}
Epoch 53: 0.4697265625 worse than 0.474609375, patience: 1/10!
Epoch metrics: {&#39;accuracy&#39;: 0.4697265625, &#39;crossentropy&#39;: 1.9096366167068481}
Epoch 54: 0.4697265625 worse than 0.474609375, patience: 2/10!
Epoch metrics: {&#39;accuracy&#39;: 0.45703125, &#39;crossentropy&#39;: 1.9259169101715088}
Epoch 55: 0.45703125 worse than 0.474609375, patience: 3/10!
Epoch metrics: {&#39;accuracy&#39;: 0.4638671875, &#39;crossentropy&#39;: 1.9375927448272705}
Epoch 56: 0.4638671875 worse than 0.474609375, patience: 4/10!
Epoch metrics: {&#39;accuracy&#39;: 0.4599609375, &#39;crossentropy&#39;: 1.916820764541626}
Epoch 57: 0.4599609375 worse than 0.474609375, patience: 5/10!
Epoch metrics: {&#39;accuracy&#39;: 0.4755859375, &#39;crossentropy&#39;: 1.9235997200012207}
Epoch metrics: {&#39;accuracy&#39;: 0.470703125, &#39;crossentropy&#39;: 1.944220781326294}
Epoch 59: 0.470703125 worse than 0.4755859375, patience: 1/10!
Epoch metrics: {&#39;accuracy&#39;: 0.4619140625, &#39;crossentropy&#39;: 1.955542802810669}
Epoch 60: 0.4619140625 worse than 0.4755859375, patience: 2/10!
Restoring best snapshot: best_score: 0.4755859375 @ epoch 58
NeurIPS Workshop Style
Limit schedule/max epochs updated: [40, 60], 60
Epoch metrics: {&#39;accuracy&#39;: 0.119140625, &#39;crossentropy&#39;: 2.3012704849243164}
Epoch metrics: {&#39;accuracy&#39;: 0.1884765625, &#39;crossentropy&#39;: 2.1952896118164062}
Epoch metrics: {&#39;accuracy&#39;: 0.2451171875, &#39;crossentropy&#39;: 1.9945433139801025}
Epoch metrics: {&#39;accuracy&#39;: 0.26171875, &#39;crossentropy&#39;: 1.9712258577346802}
Epoch metrics: {&#39;accuracy&#39;: 0.294921875, &#39;crossentropy&#39;: 1.8958768844604492}
Epoch metrics: {&#39;accuracy&#39;: 0.3251953125, &#39;crossentropy&#39;: 2.1190855503082275}
Epoch metrics: {&#39;accuracy&#39;: 0.3427734375, &#39;crossentropy&#39;: 1.7373878955841064}
Epoch metrics: {&#39;accuracy&#39;: 0.3359375, &#39;crossentropy&#39;: 1.7753663063049316}
Epoch 8: 0.3359375 worse than 0.3427734375, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.34765625, &#39;crossentropy&#39;: 1.8103389739990234}
Epoch metrics: {&#39;accuracy&#39;: 0.3232421875, &#39;crossentropy&#39;: 2.2755565643310547}
Epoch 10: 0.3232421875 worse than 0.34765625, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.3916015625, &#39;crossentropy&#39;: 1.7913551330566406}
Epoch metrics: {&#39;accuracy&#39;: 0.3486328125, &#39;crossentropy&#39;: 2.1044392585754395}
Epoch 12: 0.3486328125 worse than 0.3916015625, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.3544921875, &#39;crossentropy&#39;: 2.0263044834136963}
Epoch 13: 0.3544921875 worse than 0.3916015625, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.353515625, &#39;crossentropy&#39;: 2.3461270332336426}
Epoch 14: 0.353515625 worse than 0.3916015625, patience: 3/20!
Epoch metrics: {&#39;accuracy&#39;: 0.3642578125, &#39;crossentropy&#39;: 1.7959611415863037}
Epoch 15: 0.3642578125 worse than 0.3916015625, patience: 4/20!
Epoch metrics: {&#39;accuracy&#39;: 0.3544921875, &#39;crossentropy&#39;: 2.0480546951293945}
Epoch 16: 0.3544921875 worse than 0.3916015625, patience: 5/20!
Epoch metrics: {&#39;accuracy&#39;: 0.3623046875, &#39;crossentropy&#39;: 2.125328540802002}
Epoch 17: 0.3623046875 worse than 0.3916015625, patience: 6/20!
Epoch metrics: {&#39;accuracy&#39;: 0.42578125, &#39;crossentropy&#39;: 1.761115312576294}
Epoch metrics: {&#39;accuracy&#39;: 0.400390625, &#39;crossentropy&#39;: 1.8836984634399414}
Epoch 19: 0.400390625 worse than 0.42578125, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.4052734375, &#39;crossentropy&#39;: 1.9414761066436768}
Epoch 20: 0.4052734375 worse than 0.42578125, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.400390625, &#39;crossentropy&#39;: 1.9600749015808105}
Epoch 21: 0.400390625 worse than 0.42578125, patience: 3/20!
Epoch metrics: {&#39;accuracy&#39;: 0.4140625, &#39;crossentropy&#39;: 1.9491150379180908}
Epoch 22: 0.4140625 worse than 0.42578125, patience: 4/20!
Epoch metrics: {&#39;accuracy&#39;: 0.4365234375, &#39;crossentropy&#39;: 1.8223776817321777}
Epoch metrics: {&#39;accuracy&#39;: 0.4208984375, &#39;crossentropy&#39;: 1.879697561264038}
Epoch 24: 0.4208984375 worse than 0.4365234375, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.423828125, &#39;crossentropy&#39;: 2.2593374252319336}
Epoch 25: 0.423828125 worse than 0.4365234375, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.3984375, &#39;crossentropy&#39;: 1.9743627309799194}
Epoch 26: 0.3984375 worse than 0.4365234375, patience: 3/20!
Epoch metrics: {&#39;accuracy&#39;: 0.4599609375, &#39;crossentropy&#39;: 2.0620932579040527}
Epoch metrics: {&#39;accuracy&#39;: 0.4296875, &#39;crossentropy&#39;: 2.2803220748901367}
Epoch 28: 0.4296875 worse than 0.4599609375, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.4169921875, &#39;crossentropy&#39;: 2.111743927001953}
Epoch 29: 0.4169921875 worse than 0.4599609375, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.4072265625, &#39;crossentropy&#39;: 2.181873321533203}
Epoch 30: 0.4072265625 worse than 0.4599609375, patience: 3/20!
Epoch metrics: {&#39;accuracy&#39;: 0.42578125, &#39;crossentropy&#39;: 2.3784289360046387}
Epoch 31: 0.42578125 worse than 0.4599609375, patience: 4/20!
Epoch metrics: {&#39;accuracy&#39;: 0.4091796875, &#39;crossentropy&#39;: 2.1481378078460693}
Epoch 32: 0.4091796875 worse than 0.4599609375, patience: 5/20!
Epoch metrics: {&#39;accuracy&#39;: 0.43359375, &#39;crossentropy&#39;: 2.052018165588379}
Epoch 33: 0.43359375 worse than 0.4599609375, patience: 6/20!
Epoch metrics: {&#39;accuracy&#39;: 0.439453125, &#39;crossentropy&#39;: 2.166149854660034}
Epoch 34: 0.439453125 worse than 0.4599609375, patience: 7/20!
Epoch metrics: {&#39;accuracy&#39;: 0.4287109375, &#39;crossentropy&#39;: 2.3158931732177734}
Epoch 35: 0.4287109375 worse than 0.4599609375, patience: 8/20!
Epoch metrics: {&#39;accuracy&#39;: 0.451171875, &#39;crossentropy&#39;: 1.9303784370422363}
Epoch 36: 0.451171875 worse than 0.4599609375, patience: 9/20!
Epoch metrics: {&#39;accuracy&#39;: 0.4677734375, &#39;crossentropy&#39;: 2.0168795585632324}
Epoch metrics: {&#39;accuracy&#39;: 0.427734375, &#39;crossentropy&#39;: 2.620422840118408}
Epoch 38: 0.427734375 worse than 0.4677734375, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.412109375, &#39;crossentropy&#39;: 2.4242842197418213}
Epoch 39: 0.412109375 worse than 0.4677734375, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.412109375, &#39;crossentropy&#39;: 2.603012800216675}
Epoch 40: 0.412109375 worse than 0.4677734375, patience: 3/20!
Restoring best snapshot: best_score: 0.4677734375 @ epoch 37
Epoch    40: reducing learning rate of group 0 to 1.0000e-03.
Epoch metrics: {&#39;accuracy&#39;: 0.4853515625, &#39;crossentropy&#39;: 1.8233823776245117}
Epoch metrics: {&#39;accuracy&#39;: 0.4951171875, &#39;crossentropy&#39;: 1.8261725902557373}
Epoch metrics: {&#39;accuracy&#39;: 0.4931640625, &#39;crossentropy&#39;: 1.8644299507141113}
Epoch 43: 0.4931640625 worse than 0.4951171875, patience: 1/10!
Epoch metrics: {&#39;accuracy&#39;: 0.4990234375, &#39;crossentropy&#39;: 1.8875579833984375}
Epoch metrics: {&#39;accuracy&#39;: 0.4970703125, &#39;crossentropy&#39;: 1.8824461698532104}
Epoch 45: 0.4970703125 worse than 0.4990234375, patience: 1/10!
Epoch metrics: {&#39;accuracy&#39;: 0.494140625, &#39;crossentropy&#39;: 1.860888957977295}
Epoch 46: 0.494140625 worse than 0.4990234375, patience: 2/10!
Epoch metrics: {&#39;accuracy&#39;: 0.490234375, &#39;crossentropy&#39;: 1.8483492136001587}
Epoch 47: 0.490234375 worse than 0.4990234375, patience: 3/10!
Epoch metrics: {&#39;accuracy&#39;: 0.498046875, &#39;crossentropy&#39;: 1.855846643447876}
Epoch 48: 0.498046875 worse than 0.4990234375, patience: 4/10!
Epoch metrics: {&#39;accuracy&#39;: 0.501953125, &#39;crossentropy&#39;: 1.8568155765533447}
Epoch metrics: {&#39;accuracy&#39;: 0.498046875, &#39;crossentropy&#39;: 1.8720521926879883}
Epoch 50: 0.498046875 worse than 0.501953125, patience: 1/10!
Epoch metrics: {&#39;accuracy&#39;: 0.4912109375, &#39;crossentropy&#39;: 1.884466528892517}
Epoch 51: 0.4912109375 worse than 0.501953125, patience: 2/10!
Epoch metrics: {&#39;accuracy&#39;: 0.4921875, &#39;crossentropy&#39;: 1.9161241054534912}
Epoch 52: 0.4921875 worse than 0.501953125, patience: 3/10!
Epoch metrics: {&#39;accuracy&#39;: 0.498046875, &#39;crossentropy&#39;: 1.9108613729476929}
Epoch 53: 0.498046875 worse than 0.501953125, patience: 4/10!
Epoch metrics: {&#39;accuracy&#39;: 0.4912109375, &#39;crossentropy&#39;: 1.9222054481506348}
Epoch 54: 0.4912109375 worse than 0.501953125, patience: 5/10!
Epoch metrics: {&#39;accuracy&#39;: 0.494140625, &#39;crossentropy&#39;: 1.9441418647766113}
Epoch 55: 0.494140625 worse than 0.501953125, patience: 6/10!
Epoch metrics: {&#39;accuracy&#39;: 0.49609375, &#39;crossentropy&#39;: 1.9429115056991577}
Epoch 56: 0.49609375 worse than 0.501953125, patience: 7/10!
Epoch metrics: {&#39;accuracy&#39;: 0.494140625, &#39;crossentropy&#39;: 1.9341440200805664}
Epoch 57: 0.494140625 worse than 0.501953125, patience: 8/10!
Epoch metrics: {&#39;accuracy&#39;: 0.4931640625, &#39;crossentropy&#39;: 1.9487805366516113}
Epoch 58: 0.4931640625 worse than 0.501953125, patience: 9/10!
Epoch metrics: {&#39;accuracy&#39;: 0.4951171875, &#39;crossentropy&#39;: 1.9803202152252197}
Epoch 59: 0.4951171875 worse than 0.501953125, patience: 10/10!
Epoch metrics: {&#39;accuracy&#39;: 0.501953125, &#39;crossentropy&#39;: 1.9957759380340576}
Epoch 60: 0.501953125 worse than 0.501953125, patience: 11/10!
Restoring best snapshot: best_score: 0.501953125 @ epoch 49
NeurIPS Workshop Style
Limit schedule/max epochs updated: [40, 60], 60
Epoch metrics: {&#39;accuracy&#39;: 0.1318359375, &#39;crossentropy&#39;: 2.271721839904785}
Epoch metrics: {&#39;accuracy&#39;: 0.1923828125, &#39;crossentropy&#39;: 2.173743724822998}
Epoch metrics: {&#39;accuracy&#39;: 0.2412109375, &#39;crossentropy&#39;: 2.01741361618042}
Epoch metrics: {&#39;accuracy&#39;: 0.2529296875, &#39;crossentropy&#39;: 1.948512315750122}
Epoch metrics: {&#39;accuracy&#39;: 0.2158203125, &#39;crossentropy&#39;: 2.917454242706299}
Epoch 5: 0.2158203125 worse than 0.2529296875, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.2998046875, &#39;crossentropy&#39;: 1.8652114868164062}
Epoch metrics: {&#39;accuracy&#39;: 0.3046875, &#39;crossentropy&#39;: 1.8936755657196045}
Epoch metrics: {&#39;accuracy&#39;: 0.3408203125, &#39;crossentropy&#39;: 1.7680151462554932}
Epoch metrics: {&#39;accuracy&#39;: 0.3603515625, &#39;crossentropy&#39;: 1.7424509525299072}
Epoch metrics: {&#39;accuracy&#39;: 0.365234375, &#39;crossentropy&#39;: 1.7777519226074219}
Epoch metrics: {&#39;accuracy&#39;: 0.353515625, &#39;crossentropy&#39;: 1.7884161472320557}
Epoch 11: 0.353515625 worse than 0.365234375, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.3515625, &#39;crossentropy&#39;: 1.7184197902679443}
Epoch 12: 0.3515625 worse than 0.365234375, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.3955078125, &#39;crossentropy&#39;: 1.7181555032730103}
Epoch metrics: {&#39;accuracy&#39;: 0.3486328125, &#39;crossentropy&#39;: 2.0708694458007812}
Epoch 14: 0.3486328125 worse than 0.3955078125, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.392578125, &#39;crossentropy&#39;: 1.7636523246765137}
Epoch 15: 0.392578125 worse than 0.3955078125, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.40234375, &#39;crossentropy&#39;: 1.796265959739685}
Epoch metrics: {&#39;accuracy&#39;: 0.3427734375, &#39;crossentropy&#39;: 2.836376428604126}
Epoch 17: 0.3427734375 worse than 0.40234375, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.3779296875, &#39;crossentropy&#39;: 1.9393694400787354}
Epoch 18: 0.3779296875 worse than 0.40234375, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.4033203125, &#39;crossentropy&#39;: 1.8890727758407593}
Epoch metrics: {&#39;accuracy&#39;: 0.412109375, &#39;crossentropy&#39;: 1.8144328594207764}
Epoch metrics: {&#39;accuracy&#39;: 0.4296875, &#39;crossentropy&#39;: 1.735748529434204}
Epoch metrics: {&#39;accuracy&#39;: 0.4208984375, &#39;crossentropy&#39;: 2.085444927215576}
Epoch 22: 0.4208984375 worse than 0.4296875, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.4267578125, &#39;crossentropy&#39;: 1.8629573583602905}
Epoch 23: 0.4267578125 worse than 0.4296875, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.3994140625, &#39;crossentropy&#39;: 2.2250614166259766}
Epoch 24: 0.3994140625 worse than 0.4296875, patience: 3/20!
Epoch metrics: {&#39;accuracy&#39;: 0.4140625, &#39;crossentropy&#39;: 2.0015809535980225}
Epoch 25: 0.4140625 worse than 0.4296875, patience: 4/20!
Epoch metrics: {&#39;accuracy&#39;: 0.45703125, &#39;crossentropy&#39;: 2.0723748207092285}
Epoch metrics: {&#39;accuracy&#39;: 0.4072265625, &#39;crossentropy&#39;: 2.1009583473205566}
Epoch 27: 0.4072265625 worse than 0.45703125, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.40625, &#39;crossentropy&#39;: 2.00950288772583}
Epoch 28: 0.40625 worse than 0.45703125, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.4482421875, &#39;crossentropy&#39;: 2.2019996643066406}
Epoch 29: 0.4482421875 worse than 0.45703125, patience: 3/20!
Epoch metrics: {&#39;accuracy&#39;: 0.3916015625, &#39;crossentropy&#39;: 2.1107089519500732}
Epoch 30: 0.3916015625 worse than 0.45703125, patience: 4/20!
Epoch metrics: {&#39;accuracy&#39;: 0.4453125, &#39;crossentropy&#39;: 2.1417007446289062}
Epoch 31: 0.4453125 worse than 0.45703125, patience: 5/20!
Epoch metrics: {&#39;accuracy&#39;: 0.4267578125, &#39;crossentropy&#39;: 2.417229652404785}
Epoch 32: 0.4267578125 worse than 0.45703125, patience: 6/20!
Epoch metrics: {&#39;accuracy&#39;: 0.41796875, &#39;crossentropy&#39;: 2.119783401489258}
Epoch 33: 0.41796875 worse than 0.45703125, patience: 7/20!
Epoch metrics: {&#39;accuracy&#39;: 0.4345703125, &#39;crossentropy&#39;: 2.309903144836426}
Epoch 34: 0.4345703125 worse than 0.45703125, patience: 8/20!
Epoch metrics: {&#39;accuracy&#39;: 0.4716796875, &#39;crossentropy&#39;: 2.128251314163208}
Epoch metrics: {&#39;accuracy&#39;: 0.4091796875, &#39;crossentropy&#39;: 2.2573814392089844}
Epoch 36: 0.4091796875 worse than 0.4716796875, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.3916015625, &#39;crossentropy&#39;: 2.62845516204834}
Epoch 37: 0.3916015625 worse than 0.4716796875, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.44140625, &#39;crossentropy&#39;: 2.1764917373657227}
Epoch 38: 0.44140625 worse than 0.4716796875, patience: 3/20!
Epoch metrics: {&#39;accuracy&#39;: 0.4453125, &#39;crossentropy&#39;: 2.2685611248016357}
Epoch 39: 0.4453125 worse than 0.4716796875, patience: 4/20!
Epoch metrics: {&#39;accuracy&#39;: 0.37890625, &#39;crossentropy&#39;: 2.460073232650757}
Epoch 40: 0.37890625 worse than 0.4716796875, patience: 5/20!
Restoring best snapshot: best_score: 0.4716796875 @ epoch 35
Epoch    40: reducing learning rate of group 0 to 1.0000e-03.
Epoch metrics: {&#39;accuracy&#39;: 0.4765625, &#39;crossentropy&#39;: 1.9391651153564453}
Epoch metrics: {&#39;accuracy&#39;: 0.46875, &#39;crossentropy&#39;: 1.8957467079162598}
Epoch 42: 0.46875 worse than 0.4765625, patience: 1/10!
Epoch metrics: {&#39;accuracy&#39;: 0.4755859375, &#39;crossentropy&#39;: 1.877326250076294}
Epoch 43: 0.4755859375 worse than 0.4765625, patience: 2/10!
Epoch metrics: {&#39;accuracy&#39;: 0.482421875, &#39;crossentropy&#39;: 1.915670394897461}
Epoch metrics: {&#39;accuracy&#39;: 0.490234375, &#39;crossentropy&#39;: 1.9242346286773682}
Epoch metrics: {&#39;accuracy&#39;: 0.4912109375, &#39;crossentropy&#39;: 1.9122066497802734}
Epoch metrics: {&#39;accuracy&#39;: 0.4775390625, &#39;crossentropy&#39;: 1.912947177886963}
Epoch 47: 0.4775390625 worse than 0.4912109375, patience: 1/10!
Epoch metrics: {&#39;accuracy&#39;: 0.4736328125, &#39;crossentropy&#39;: 1.9354698657989502}
Epoch 48: 0.4736328125 worse than 0.4912109375, patience: 2/10!
Epoch metrics: {&#39;accuracy&#39;: 0.4853515625, &#39;crossentropy&#39;: 1.9456501007080078}
Epoch 49: 0.4853515625 worse than 0.4912109375, patience: 3/10!
Epoch metrics: {&#39;accuracy&#39;: 0.4873046875, &#39;crossentropy&#39;: 1.9420843124389648}
Epoch 50: 0.4873046875 worse than 0.4912109375, patience: 4/10!
Epoch metrics: {&#39;accuracy&#39;: 0.4892578125, &#39;crossentropy&#39;: 1.9611868858337402}
Epoch 51: 0.4892578125 worse than 0.4912109375, patience: 5/10!
Epoch metrics: {&#39;accuracy&#39;: 0.4921875, &#39;crossentropy&#39;: 1.942270040512085}
Epoch metrics: {&#39;accuracy&#39;: 0.48828125, &#39;crossentropy&#39;: 1.9460234642028809}
Epoch 53: 0.48828125 worse than 0.4921875, patience: 1/10!
Epoch metrics: {&#39;accuracy&#39;: 0.490234375, &#39;crossentropy&#39;: 1.9857553243637085}
Epoch 54: 0.490234375 worse than 0.4921875, patience: 2/10!
Epoch metrics: {&#39;accuracy&#39;: 0.48828125, &#39;crossentropy&#39;: 1.9796559810638428}
Epoch 55: 0.48828125 worse than 0.4921875, patience: 3/10!
Epoch metrics: {&#39;accuracy&#39;: 0.474609375, &#39;crossentropy&#39;: 1.979042410850525}
Epoch 56: 0.474609375 worse than 0.4921875, patience: 4/10!
Epoch metrics: {&#39;accuracy&#39;: 0.478515625, &#39;crossentropy&#39;: 1.9751605987548828}
Epoch 57: 0.478515625 worse than 0.4921875, patience: 5/10!
Epoch metrics: {&#39;accuracy&#39;: 0.48046875, &#39;crossentropy&#39;: 1.9913841485977173}
Epoch 58: 0.48046875 worse than 0.4921875, patience: 6/10!
Epoch metrics: {&#39;accuracy&#39;: 0.4892578125, &#39;crossentropy&#39;: 2.0270097255706787}
Epoch 59: 0.4892578125 worse than 0.4921875, patience: 7/10!
Epoch metrics: {&#39;accuracy&#39;: 0.4970703125, &#39;crossentropy&#39;: 2.0400729179382324}
Restoring best snapshot: best_score: 0.4970703125 @ epoch 60
Perf after training {&#39;accuracy&#39;: 0.5034, &#39;crossentropy&#39;: tensor(1.6824)}
CandidateBatch(scores=[0.29617753977740774, 0.14929386632449126, 0.14042188043822845, 0.13561701063934906, 0.12551198033788236, 0.11587380730878305, 0.1081785889516576, 0.10318522232910732, 0.10028609012837636, 0.07910100369259015, 0.0595642760746285, 0.056496623136499446, 0.0480974583513627, -0.0003344104814704263, -0.024483918028025405, -0.05868755287245064, -0.060729997998662744, -0.06483828993515683, -0.07266099279175536, -0.08303425078136822, -0.08493905198309115, -0.08826177952030845, -0.0917231456310107, -0.09322396681837897, -0.09349900755281104, -0.1085312087856567, -0.10880747194813978, -0.11035702823406313, -0.11373049969951132, -0.1284572549304118, -0.1369941620823329, -0.14414451338511716, -0.14638930275788886, -0.14709074744055906, -0.1544179604953905, -0.1718396815443063, -0.17193064279121323, -0.17433757495651808, -0.17493876712021292, -0.17793750532394587, -0.20004764783578136, -0.2047085608832342, -0.20785528881946924, -0.2126760937814199, -0.21795550007810643, -0.21854255992835558, -0.22375512548355175, -0.22821897951415104, -0.23081753358589896, -0.234552558420489, -0.23654412147374432, -0.23868492752525053, -0.23936193849792142, -0.23948581546398945, -0.24090250779725308, -0.24436573906718534, -0.24498798043854714, -0.25047486654500684, -0.25086789662747966, -0.25223379123728185, -0.25300603160378266, -0.2535722503628005, -0.25627488105340335, -0.2571039077439916, -0.2571323880393473, -0.2581345788913097, -0.25852047075469786, -0.25984682601623954, -0.2605125306329733, -0.26604510503814593, -0.26842628367418425, -0.2689608944143873, -0.27142159348898154, -0.2716202495232657, -0.2725370856601465, -0.27277114294881777, -0.272882899518596, -0.2746432822616215, -0.27475376736680157, -0.2747862738818379, -0.2787102389783494, -0.27878322594118177, -0.2799440079598173, -0.28053463957696523, -0.2832789355363545, -0.28628681074660906, -0.28636098372628815, -0.2864041874063044, -0.28681405980157704, -0.28695940484754145, -0.2874117431329296, -0.2876259871416516, -0.2883496122749491, -0.2899183102928764, -0.2916184667446343, -0.29320420380710155, -0.2942200635364417, -0.2944431093663251, -0.2966738541909059, -0.297017411323094, -0.29953332345032396, -0.29983150297606376, -0.3002000015119797, -0.3019102346504664, -0.3028038396797542, -0.3028627118081535, -0.3038174756319836, -0.306849925859872, -0.30820086116683587, -0.308965825301919, -0.30897690216943874, -0.30959008903917856, -0.3099016547172293, -0.31032215454158524, -0.31120895035679247, -0.3153142432505421, -0.31548377397124866, -0.31563967323632697, -0.31741590341198633, -0.3184705504455397, -0.3186296133000478, -0.3188583045728651, -0.31898546941660305, -0.31929041122606755, -0.3194115682999085, -0.32021299477095333, -0.3204498316628256, -0.3207799158954866, -0.3213031203079303, -0.32179618456249737, -0.3233233737207446, -0.32374891713521003, -0.3238423020704841, -0.3247656918989147, -0.32566961873345374, -0.33217372203353707, -0.3349474999600933, -0.3357192259877037, -0.33620567411464286, -0.3363011311948776, -0.3365677832300389, -0.3370698144629759, -0.3372166698970851, -0.33736364960582116, -0.33846277942686553, -0.33893716368329374, -0.34033803350888703, -0.34322883325797693, -0.3479661282946484, -0.3496217637763362, -0.3504955340097076, -0.35391144915546713, -0.3543950767299, -0.35530871090078564, -0.3557131845960627, -0.35621413902109283, -0.3572409967300617, -0.3576464756140218, -0.35814231199224156, -0.3594268818126217, -0.3603685044659176, -0.3612518765686598, -0.36141779072750346, -0.36149511305826776, -0.3637075418699047, -0.3647709883288704, -0.3651456187310086, -0.36549958773604746, -0.367867770082543, -0.36979487479146694, -0.36997330652615656, -0.37065781587321833, -0.37188363208508923, -0.3720712464649779, -0.3725246174791587, -0.3741113905857726, -0.37487541663214186, -0.3765130483936495, -0.3770045392571122, -0.37830993920155276, -0.37904312519700556, -0.37916669516105744, -0.3797246190040361, -0.3802248072692808, -0.3805829517214864, -0.38137434185811275, -0.38139966926843216, -0.38275453123783804, -0.3828721301448593, -0.38324830002303784, -0.3840574367068012, -0.3848752110497511, -0.38511278136715077, -0.38680337842145895, -0.3870088930739351, -0.38759071923778776, -0.3900058482648483, -0.39165746971073845, -0.393571533183396, -0.39386008406106676, -0.39640222058155206, -0.39725871294927645, -0.39762318984337786, -0.3995977204273729, -0.40058428696034654, -0.4008528334268859, -0.40115315785742417, -0.4031360172938938, -0.4037027197071569, -0.40599881537319915, -0.40608069510160916, -0.4075273271461095, -0.40771825158268993, -0.4083157579246251, -0.4092443713841649, -0.4101144843455635, -0.41013517432660673, -0.4103933504868254, -0.4106739336091622, -0.41105110475773526, -0.4149704261199883, -0.41520936086216265, -0.41668759267156763, -0.4173924823697352, -0.41834219413087625, -0.4208128608638036, -0.42144522437451576, -0.4215393126929983, -0.42269851335781516, -0.4241213854377994, -0.4248593061927449, -0.4271240783037835, -0.42766209765854246, -0.42767171119621483, -0.4285034119034359, -0.4294549770564495, -0.4306729306592306, -0.43267518564615803, -0.4329375258973172, -0.43329740747066264, -0.43348348496604033, -0.43377775257525875, -0.4372321714244561, -0.43914476597882834, -0.43934288154398643, -0.44179314758042154, -0.4421624819429151, -0.4443045549720485, -0.4443196451405673, -0.4444509061006758, -0.44448299587308526, -0.4448055747391292, -0.4448714057045422, -0.44491910446325866, -0.44539804753780626, -0.4462494431895739, -0.44834869684024936, -0.4487827383315519, -0.44893919474629707, -0.4495800342687628, -0.44995986731770204, -0.45010592529013005, -0.45038627300779654, -0.45100036518082676, -0.45122504740862956, -0.4518302312656539, -0.45367330019715135, -0.4548680094906636, -0.4573337192075583, -0.4577550355952673, -0.4580473118100618, -0.4588574475137798, -0.4590800872221339, -0.45995553986587245, -0.46061961841145027, -0.46070559205157857, -0.4619921595271598, -0.4622770064368557, -0.46299281719207847, -0.4630869780635737, -0.46321163177248537, -0.46339093198796383, -0.46502260069148205, -0.46703602944339245, -0.4672970777526009, -0.46750948448030616, -0.46878549079623066, -0.469115833001348, -0.46982044418763835, -0.4706509834900711, -0.47065273847105693, -0.4713936950953392, -0.47153453475637813, -0.47283527631143757, -0.4729532415689854, -0.47359199625134996, -0.47385549315704995, -0.4740639765908414, -0.4741059919057102, -0.4741773832163258], indices=[45959, 40218, 2136, 7337, 36514, 27826, 20723, 42523, 9059, 1924, 20562, 3942, 42054, 8158, 17715, 31528, 39334, 29999, 38597, 46350, 45747, 44368, 26299, 37672, 43483, 7047, 17859, 2783, 40833, 40045, 7766, 17673, 47292, 18243, 30327, 13691, 27010, 17437, 35942, 14592, 12088, 13135, 28104, 38709, 32031, 11686, 6861, 8354, 12274, 21669, 36287, 38691, 14012, 13709, 43433, 9249, 13743, 33130, 9900, 22314, 12976, 11433, 45476, 18117, 24328, 45116, 16243, 5782, 9473, 6737, 37623, 18404, 20916, 22250, 19125, 7892, 40551, 4844, 44318, 29482, 42022, 18994, 47529, 41009, 25134, 12245, 20197, 13418, 26460, 31189, 28794, 9589, 19319, 43210, 28326, 22447, 27235, 39886, 47800, 30085, 12777, 37238, 10250, 40046, 5796, 10259, 38706, 23487, 24430, 46863, 30012, 39914, 46485, 3393, 18811, 30490, 28922, 35408, 13991, 18192, 15909, 33871, 21657, 1990, 5693, 42824, 43244, 8153, 37902, 15475, 7639, 27583, 7825, 13605, 33694, 21164, 18645, 2435, 41681, 37004, 1249, 31393, 17920, 19759, 13016, 42670, 30857, 15496, 47198, 38282, 33041, 7333, 2567, 35694, 13453, 37884, 9684, 44957, 22303, 17471, 14140, 10958, 7839, 26054, 29764, 45368, 34490, 24825, 15910, 20320, 46640, 8028, 25085, 12279, 9901, 29752, 12615, 5670, 39050, 30764, 20654, 2208, 37288, 18992, 27375, 40398, 21783, 33667, 39958, 2690, 43889, 25621, 15163, 9416, 13335, 20270, 16984, 47360, 16252, 25053, 28652, 46669, 3402, 1250, 4818, 7082, 22138, 23208, 3555, 19543, 21373, 14969, 45728, 21581, 1114, 33165, 21821, 15946, 37820, 1539, 46962, 13227, 38121, 7266, 32273, 27559, 41917, 47960, 44290, 31368, 18131, 20510, 15104, 2323, 25887, 32835, 34807, 47209, 28606, 33688, 35543, 22684, 15875, 44539, 10243, 13912, 30777, 46271, 46966, 28327, 5606, 32153, 29605, 36142, 19103, 32807, 35478, 25660, 14237, 41325, 43163, 33631, 38801, 4447, 17121, 28185, 3283, 12005, 17946, 33456, 18398, 44464, 18253, 717, 2960, 43290, 6291, 33354, 28948, 31030, 6811, 46472, 44844, 33478, 17473, 10290, 327, 9063, 23472, 7432, 18622, 25021, 47423, 5541, 8261, 36502, 35005, 19908, 775, 1752])
[(&#39;id&#39;, 46917), (&#39;id&#39;, 41048), (&#39;id&#39;, 2179), (&#39;id&#39;, 7491), (&#39;id&#39;, 37258), (&#39;id&#39;, 28406), (&#39;id&#39;, 21160), (&#39;id&#39;, 43399), (&#39;id&#39;, 9254), (&#39;id&#39;, 1962), (&#39;id&#39;, 20997), (&#39;id&#39;, 4011), (&#39;id&#39;, 42923), (&#39;id&#39;, 8333), (&#39;id&#39;, 18098), (&#39;id&#39;, 32180), (&#39;id&#39;, 40151), (&#39;id&#39;, 30627), (&#39;id&#39;, 39397), (&#39;id&#39;, 47316), (&#39;id&#39;, 46702), (&#39;id&#39;, 45288), (&#39;id&#39;, 26845), (&#39;id&#39;, 38450), (&#39;id&#39;, 44381), (&#39;id&#39;, 7192), (&#39;id&#39;, 18246), (&#39;id&#39;, 2832), (&#39;id&#39;, 41681), (&#39;id&#39;, 40874), (&#39;id&#39;, 7929), (&#39;id&#39;, 18055), (&#39;id&#39;, 48281), (&#39;id&#39;, 18639), (&#39;id&#39;, 30958), (&#39;id&#39;, 13982), (&#39;id&#39;, 27571), (&#39;id&#39;, 17814), (&#39;id&#39;, 36675), (&#39;id&#39;, 14902), (&#39;id&#39;, 12349), (&#39;id&#39;, 13414), (&#39;id&#39;, 28692), (&#39;id&#39;, 39513), (&#39;id&#39;, 32692), (&#39;id&#39;, 11935), (&#39;id&#39;, 6999), (&#39;id&#39;, 8531), (&#39;id&#39;, 12535), (&#39;id&#39;, 22124), (&#39;id&#39;, 37025), (&#39;id&#39;, 39495), (&#39;id&#39;, 14309), (&#39;id&#39;, 14000), (&#39;id&#39;, 44330), (&#39;id&#39;, 9444), (&#39;id&#39;, 14034), (&#39;id&#39;, 33804), (&#39;id&#39;, 10108), (&#39;id&#39;, 22779), (&#39;id&#39;, 13249), (&#39;id&#39;, 11677), (&#39;id&#39;, 46426), (&#39;id&#39;, 18510), (&#39;id&#39;, 24831), (&#39;id&#39;, 46060), (&#39;id&#39;, 16586), (&#39;id&#39;, 5896), (&#39;id&#39;, 9672), (&#39;id&#39;, 6870), (&#39;id&#39;, 38400), (&#39;id&#39;, 18805), (&#39;id&#39;, 21357), (&#39;id&#39;, 22715), (&#39;id&#39;, 19540), (&#39;id&#39;, 8059), (&#39;id&#39;, 41396), (&#39;id&#39;, 4935), (&#39;id&#39;, 45236), (&#39;id&#39;, 30101), (&#39;id&#39;, 42890), (&#39;id&#39;, 19404), (&#39;id&#39;, 48522), (&#39;id&#39;, 41860), (&#39;id&#39;, 25657), (&#39;id&#39;, 12506), (&#39;id&#39;, 20628), (&#39;id&#39;, 13706), (&#39;id&#39;, 27011), (&#39;id&#39;, 31834), (&#39;id&#39;, 29396), (&#39;id&#39;, 9792), (&#39;id&#39;, 19737), (&#39;id&#39;, 44102), (&#39;id&#39;, 28920), (&#39;id&#39;, 22913), (&#39;id&#39;, 27798), (&#39;id&#39;, 40710), (&#39;id&#39;, 48795), (&#39;id&#39;, 30713), (&#39;id&#39;, 13049), (&#39;id&#39;, 38006), (&#39;id&#39;, 10466), (&#39;id&#39;, 40875), (&#39;id&#39;, 5910), (&#39;id&#39;, 10475), (&#39;id&#39;, 39510), (&#39;id&#39;, 23976), (&#39;id&#39;, 24934), (&#39;id&#39;, 47838), (&#39;id&#39;, 30640), (&#39;id&#39;, 40740), (&#39;id&#39;, 47453), (&#39;id&#39;, 3453), (&#39;id&#39;, 19220), (&#39;id&#39;, 31124), (&#39;id&#39;, 29526), (&#39;id&#39;, 36128), (&#39;id&#39;, 14286), (&#39;id&#39;, 18588), (&#39;id&#39;, 16245), (&#39;id&#39;, 34560), (&#39;id&#39;, 22111), (&#39;id&#39;, 2029), (&#39;id&#39;, 5806), (&#39;id&#39;, 43706), (&#39;id&#39;, 44138), (&#39;id&#39;, 8328), (&#39;id&#39;, 38683), (&#39;id&#39;, 15802), (&#39;id&#39;, 7797), (&#39;id&#39;, 28154), (&#39;id&#39;, 7991), (&#39;id&#39;, 13894), (&#39;id&#39;, 34380), (&#39;id&#39;, 21609), (&#39;id&#39;, 19051), (&#39;id&#39;, 2480), (&#39;id&#39;, 42542), (&#39;id&#39;, 37767), (&#39;id&#39;, 1271), (&#39;id&#39;, 32043), (&#39;id&#39;, 18309), (&#39;id&#39;, 20186), (&#39;id&#39;, 13290), (&#39;id&#39;, 43547), (&#39;id&#39;, 31499), (&#39;id&#39;, 15823), (&#39;id&#39;, 48184), (&#39;id&#39;, 39073), (&#39;id&#39;, 33714), (&#39;id&#39;, 7487), (&#39;id&#39;, 2614), (&#39;id&#39;, 36422), (&#39;id&#39;, 13741), (&#39;id&#39;, 38664), (&#39;id&#39;, 9887), (&#39;id&#39;, 45896), (&#39;id&#39;, 22768), (&#39;id&#39;, 17848), (&#39;id&#39;, 14440), (&#39;id&#39;, 11193), (&#39;id&#39;, 8005), (&#39;id&#39;, 26593), (&#39;id&#39;, 30388), (&#39;id&#39;, 46318), (&#39;id&#39;, 35191), (&#39;id&#39;, 25341), (&#39;id&#39;, 16246), (&#39;id&#39;, 20752), (&#39;id&#39;, 47612), (&#39;id&#39;, 8200), (&#39;id&#39;, 25607), (&#39;id&#39;, 12540), (&#39;id&#39;, 10109), (&#39;id&#39;, 30376), (&#39;id&#39;, 12882), (&#39;id&#39;, 5782), (&#39;id&#39;, 39857), (&#39;id&#39;, 31403), (&#39;id&#39;, 21089), (&#39;id&#39;, 2252), (&#39;id&#39;, 38058), (&#39;id&#39;, 19402), (&#39;id&#39;, 27941), (&#39;id&#39;, 41231), (&#39;id&#39;, 22240), (&#39;id&#39;, 34351), (&#39;id&#39;, 40784), (&#39;id&#39;, 2738), (&#39;id&#39;, 44795), (&#39;id&#39;, 26151), (&#39;id&#39;, 15484), (&#39;id&#39;, 9614), (&#39;id&#39;, 13620), (&#39;id&#39;, 20701), (&#39;id&#39;, 17350), (&#39;id&#39;, 48350), (&#39;id&#39;, 16596), (&#39;id&#39;, 25575), (&#39;id&#39;, 29251), (&#39;id&#39;, 47642), (&#39;id&#39;, 3462), (&#39;id&#39;, 1272), (&#39;id&#39;, 4909), (&#39;id&#39;, 7229), (&#39;id&#39;, 22601), (&#39;id&#39;, 23688), (&#39;id&#39;, 3616), (&#39;id&#39;, 19967), (&#39;id&#39;, 21823), (&#39;id&#39;, 15284), (&#39;id&#39;, 46682), (&#39;id&#39;, 22034), (&#39;id&#39;, 1131), (&#39;id&#39;, 33839), (&#39;id&#39;, 22279), (&#39;id&#39;, 16282), (&#39;id&#39;, 38598), (&#39;id&#39;, 1566), (&#39;id&#39;, 47938), (&#39;id&#39;, 13509), (&#39;id&#39;, 38909), (&#39;id&#39;, 7416), (&#39;id&#39;, 32936), (&#39;id&#39;, 28129), (&#39;id&#39;, 42784), (&#39;id&#39;, 48960), (&#39;id&#39;, 45208), (&#39;id&#39;, 32018), (&#39;id&#39;, 18525), (&#39;id&#39;, 20944), (&#39;id&#39;, 15423), (&#39;id&#39;, 2368), (&#39;id&#39;, 26422), (&#39;id&#39;, 33507), (&#39;id&#39;, 35515), (&#39;id&#39;, 48196), (&#39;id&#39;, 29205), (&#39;id&#39;, 34372), (&#39;id&#39;, 36268), (&#39;id&#39;, 23155), (&#39;id&#39;, 16210), (&#39;id&#39;, 45462), (&#39;id&#39;, 10459), (&#39;id&#39;, 14206), (&#39;id&#39;, 31416), (&#39;id&#39;, 47236), (&#39;id&#39;, 47942), (&#39;id&#39;, 28921), (&#39;id&#39;, 5717), (&#39;id&#39;, 32815), (&#39;id&#39;, 30227), (&#39;id&#39;, 36879), (&#39;id&#39;, 19518), (&#39;id&#39;, 33479), (&#39;id&#39;, 36201), (&#39;id&#39;, 26191), (&#39;id&#39;, 14540), (&#39;id&#39;, 42178), (&#39;id&#39;, 44054), (&#39;id&#39;, 34313), (&#39;id&#39;, 39606), (&#39;id&#39;, 4529), (&#39;id&#39;, 17490), (&#39;id&#39;, 28776), (&#39;id&#39;, 3339), (&#39;id&#39;, 12264), (&#39;id&#39;, 18335), (&#39;id&#39;, 34136), (&#39;id&#39;, 18799), (&#39;id&#39;, 45385), (&#39;id&#39;, 18649), (&#39;id&#39;, 729), (&#39;id&#39;, 3012), (&#39;id&#39;, 44186), (&#39;id&#39;, 6415), (&#39;id&#39;, 34032), (&#39;id&#39;, 29553), (&#39;id&#39;, 31673), (&#39;id&#39;, 6946), (&#39;id&#39;, 47440), (&#39;id&#39;, 45779), (&#39;id&#39;, 34158), (&#39;id&#39;, 17850), (&#39;id&#39;, 10506), (&#39;id&#39;, 332), (&#39;id&#39;, 9258), (&#39;id&#39;, 23960), (&#39;id&#39;, 7587), (&#39;id&#39;, 19027), (&#39;id&#39;, 25541), (&#39;id&#39;, 48413), (&#39;id&#39;, 5649), (&#39;id&#39;, 8437), (&#39;id&#39;, 37246), (&#39;id&#39;, 35717), (&#39;id&#39;, 20336), (&#39;id&#39;, 787), (&#39;id&#39;, 1784)]
Acquiring (label, score)s: 3 (0.2962), 6 (0.1493), 3 (0.1404), 1 (0.1356), 1 (0.1255), 6 (0.1159), 1 (0.1082), 3 (0.1032), 9 (0.1003), 6 (0.0791), 7 (0.05956), 8 (0.0565), 7 (0.0481), 0 (-0.0003344), 0 (-0.02448), 0 (-0.05869), 2 (-0.06073), 3 (-0.06484), 3 (-0.07266), 6 (-0.08303), 1 (-0.08494), 7 (-0.08826), 3 (-0.09172), 2 (-0.09322), 0 (-0.0935), 2 (-0.1085), 5 (-0.1088), 8 (-0.1104), 8 (-0.1137), 0 (-0.1285), 4 (-0.137), 4 (-0.1441), 8 (-0.1464), 5 (-0.1471), 2 (-0.1544), 8 (-0.1718), 3 (-0.1719), 8 (-0.1743), 6 (-0.1749), 3 (-0.1779), 0 (-0.2), 5 (-0.2047), 3 (-0.2079), 0 (-0.2127), 1 (-0.218), 1 (-0.2185), 1 (-0.2238), 8 (-0.2282), 3 (-0.2308), 4 (-0.2346), 9 (-0.2365), 0 (-0.2387), 2 (-0.2394), 8 (-0.2395), 9 (-0.2409), 5 (-0.2444), 9 (-0.245), 8 (-0.2505), 8 (-0.2509), 9 (-0.2522), 6 (-0.253), 8 (-0.2536), 5 (-0.2563), 1 (-0.2571), 3 (-0.2571), 0 (-0.2581), 3 (-0.2585), 0 (-0.2598), 1 (-0.2605), 2 (-0.266), 1 (-0.2684), 0 (-0.269), 2 (-0.2714), 0 (-0.2716), 7 (-0.2725), 0 (-0.2728), 4 (-0.2729), 3 (-0.2746), 0 (-0.2748), 8 (-0.2748), 5 (-0.2787), 3 (-0.2788), 5 (-0.2799), 0 (-0.2805), 4 (-0.2833), 5 (-0.2863), 7 (-0.2864), 8 (-0.2864), 0 (-0.2868), 1 (-0.287), 7 (-0.2874), 2 (-0.2876), 1 (-0.2883), 1 (-0.2899), 6 (-0.2916), 1 (-0.2932), 2 (-0.2942), 9 (-0.2944), 9 (-0.2967), 9 (-0.297), 5 (-0.2995), 4 (-0.2998), 5 (-0.3002), 2 (-0.3019), 2 (-0.3028), 1 (-0.3029), 2 (-0.3038), 8 (-0.3068), 4 (-0.3082), 8 (-0.309), 4 (-0.309), 8 (-0.3096), 2 (-0.3099), 5 (-0.3103), 4 (-0.3112), 1 (-0.3153), 9 (-0.3155), 0 (-0.3156), 7 (-0.3174), 2 (-0.3185), 9 (-0.3186), 3 (-0.3189), 5 (-0.319), 9 (-0.3193), 2 (-0.3194), 5 (-0.3202), 2 (-0.3204), 6 (-0.3208), 3 (-0.3213), 4 (-0.3218), 7 (-0.3233), 8 (-0.3237), 0 (-0.3238), 5 (-0.3248), 8 (-0.3257), 5 (-0.3322), 2 (-0.3349), 7 (-0.3357), 8 (-0.3362), 0 (-0.3363), 0 (-0.3366), 2 (-0.3371), 4 (-0.3372), 6 (-0.3374), 6 (-0.3385), 9 (-0.3389), 1 (-0.3403), 1 (-0.3432), 3 (-0.348), 8 (-0.3496), 1 (-0.3505), 2 (-0.3539), 7 (-0.3544), 8 (-0.3553), 6 (-0.3557), 2 (-0.3562), 2 (-0.3572), 7 (-0.3576), 1 (-0.3581), 0 (-0.3594), 5 (-0.3604), 6 (-0.3613), 0 (-0.3614), 7 (-0.3615), 9 (-0.3637), 2 (-0.3648), 1 (-0.3651), 4 (-0.3655), 2 (-0.3679), 6 (-0.3698), 7 (-0.37), 1 (-0.3707), 8 (-0.3719), 4 (-0.3721), 6 (-0.3725), 8 (-0.3741), 0 (-0.3749), 7 (-0.3765), 5 (-0.377), 4 (-0.3783), 4 (-0.379), 0 (-0.3792), 5 (-0.3797), 4 (-0.3802), 2 (-0.3806), 9 (-0.3814), 4 (-0.3814), 9 (-0.3828), 0 (-0.3829), 0 (-0.3832), 7 (-0.3841), 3 (-0.3849), 9 (-0.3851), 8 (-0.3868), 8 (-0.387), 1 (-0.3876), 9 (-0.39), 0 (-0.3917), 6 (-0.3936), 1 (-0.3939), 9 (-0.3964), 5 (-0.3973), 5 (-0.3976), 3 (-0.3996), 5 (-0.4006), 1 (-0.4009), 0 (-0.4012), 7 (-0.4031), 5 (-0.4037), 5 (-0.406), 1 (-0.4061), 2 (-0.4075), 3 (-0.4077), 5 (-0.4083), 3 (-0.4092), 2 (-0.4101), 2 (-0.4101), 0 (-0.4104), 1 (-0.4107), 5 (-0.4111), 1 (-0.415), 3 (-0.4152), 0 (-0.4167), 8 (-0.4174), 1 (-0.4183), 4 (-0.4208), 0 (-0.4214), 6 (-0.4215), 2 (-0.4227), 3 (-0.4241), 9 (-0.4249), 7 (-0.4271), 8 (-0.4277), 8 (-0.4277), 1 (-0.4285), 7 (-0.4295), 7 (-0.4307), 5 (-0.4327), 5 (-0.4329), 3 (-0.4333), 6 (-0.4335), 2 (-0.4338), 8 (-0.4372), 4 (-0.4391), 9 (-0.4393), 4 (-0.4418), 8 (-0.4422), 3 (-0.4443), 0 (-0.4443), 9 (-0.4445), 1 (-0.4445), 4 (-0.4448), 1 (-0.4449), 8 (-0.4449), 1 (-0.4454), 5 (-0.4462), 0 (-0.4483), 5 (-0.4488), 2 (-0.4489), 9 (-0.4496), 9 (-0.45), 4 (-0.4501), 9 (-0.4504), 9 (-0.451), 3 (-0.4512), 5 (-0.4518), 2 (-0.4537), 9 (-0.4549), 0 (-0.4573), 1 (-0.4578), 8 (-0.458), 9 (-0.4589), 6 (-0.4591), 6 (-0.46), 3 (-0.4606), 9 (-0.4607), 6 (-0.462), 9 (-0.4623), 2 (-0.463), 2 (-0.4631), 9 (-0.4632), 8 (-0.4634), 8 (-0.465), 5 (-0.467), 4 (-0.4673), 5 (-0.4675), 2 (-0.4688), 7 (-0.4691), 8 (-0.4698), 0 (-0.4707), 4 (-0.4707), 9 (-0.4714), 2 (-0.4715), 3 (-0.4728), 3 (-0.473), 0 (-0.4736), 7 (-0.4739), 7 (-0.4741), 3 (-0.4741), 7 (-0.4742)
Training set size 1300:
NeurIPS Workshop Style
Limit schedule/max epochs updated: [40, 60], 60
Epoch metrics: {&#39;accuracy&#39;: 0.146484375, &#39;crossentropy&#39;: 2.2959184646606445}
Epoch metrics: {&#39;accuracy&#39;: 0.2080078125, &#39;crossentropy&#39;: 2.1239328384399414}
Epoch metrics: {&#39;accuracy&#39;: 0.2490234375, &#39;crossentropy&#39;: 1.9910898208618164}
Epoch metrics: {&#39;accuracy&#39;: 0.2744140625, &#39;crossentropy&#39;: 1.8992671966552734}
Epoch metrics: {&#39;accuracy&#39;: 0.3076171875, &#39;crossentropy&#39;: 1.8491034507751465}
Epoch metrics: {&#39;accuracy&#39;: 0.2958984375, &#39;crossentropy&#39;: 2.0256447792053223}
Epoch 6: 0.2958984375 worse than 0.3076171875, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.33203125, &#39;crossentropy&#39;: 1.8950735330581665}
Epoch metrics: {&#39;accuracy&#39;: 0.3349609375, &#39;crossentropy&#39;: 1.7935713529586792}
Epoch metrics: {&#39;accuracy&#39;: 0.3544921875, &#39;crossentropy&#39;: 1.7524700164794922}
Epoch metrics: {&#39;accuracy&#39;: 0.3056640625, &#39;crossentropy&#39;: 1.8755322694778442}
Epoch 10: 0.3056640625 worse than 0.3544921875, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.35546875, &#39;crossentropy&#39;: 1.9226657152175903}
Epoch metrics: {&#39;accuracy&#39;: 0.3798828125, &#39;crossentropy&#39;: 1.6950584650039673}
Epoch metrics: {&#39;accuracy&#39;: 0.400390625, &#39;crossentropy&#39;: 1.6901555061340332}
Epoch metrics: {&#39;accuracy&#39;: 0.3671875, &#39;crossentropy&#39;: 1.81807541847229}
Epoch 14: 0.3671875 worse than 0.400390625, patience: 1/20!
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Exception ignored in: &lt;function _MultiProcessingDataLoaderIter.__del__ at 0x7f70d1c2b3a0&gt;
Traceback (most recent call last):
  File &#34;/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/utils/data/dataloader.py&#34;, line 1328, in __del__
    self._shutdown_workers()
  File &#34;/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/utils/data/dataloader.py&#34;, line 1301, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File &#34;/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/multiprocessing/process.py&#34;, line 149, in join
    res = self._popen.wait(timeout)
  File &#34;/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/multiprocessing/popen_fork.py&#34;, line 44, in wait
    if not wait([self.sentinel], timeout):
  File &#34;/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/multiprocessing/connection.py&#34;, line 931, in wait
    ready = selector.select(timeout)
  File &#34;/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/selectors.py&#34;, line 415, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt: 
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch metrics: {&#39;accuracy&#39;: 0.376953125, &#39;crossentropy&#39;: 1.8140383958816528}
Epoch 15: 0.376953125 worse than 0.400390625, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.4150390625, &#39;crossentropy&#39;: 1.6661734580993652}
Epoch metrics: {&#39;accuracy&#39;: 0.396484375, &#39;crossentropy&#39;: 1.8092057704925537}
Epoch 17: 0.396484375 worse than 0.4150390625, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.40625, &#39;crossentropy&#39;: 1.7282845973968506}
Epoch 18: 0.40625 worse than 0.4150390625, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.431640625, &#39;crossentropy&#39;: 1.7795724868774414}
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Engine run is terminating due to exception: 
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-6-b6f2f96a2e05&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">      3</span> configs<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">3</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>max_training_epochs <span class="ansi-blue-fg">=</span> <span class="ansi-cyan-fg">1</span>
<span class="ansi-green-intense-fg ansi-bold">      4</span> configs<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">3</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>num_pool_samples <span class="ansi-blue-fg">=</span> <span class="ansi-cyan-fg">5</span>
<span class="ansi-green-fg">----&gt; 5</span><span class="ansi-red-fg"> </span>configs<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">3</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>run<span class="ansi-blue-fg">(</span>store<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/unified_experiment.py</span> in <span class="ansi-cyan-fg">run</span><span class="ansi-blue-fg">(self, store)</span>
<span class="ansi-green-intense-fg ansi-bold">    269</span>         )
<span class="ansi-green-intense-fg ansi-bold">    270</span> 
<span class="ansi-green-fg">--&gt; 271</span><span class="ansi-red-fg">         </span>active_learner<span class="ansi-blue-fg">(</span>store<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    272</span> 
<span class="ansi-green-intense-fg ansi-bold">    273</span> <span class="ansi-red-fg"># Cell</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/unified_experiment.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, log)</span>
<span class="ansi-green-intense-fg ansi-bold">    104</span>                 loss <span class="ansi-blue-fg">=</span> validation_loss <span class="ansi-blue-fg">=</span> torch<span class="ansi-blue-fg">.</span>nn<span class="ansi-blue-fg">.</span>NLLLoss<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    105</span> 
<span class="ansi-green-fg">--&gt; 106</span><span class="ansi-red-fg">             trained_model = model_trainer.get_trained(
</span><span class="ansi-green-intense-fg ansi-bold">    107</span>                 train_loader<span class="ansi-blue-fg">=</span>train_loader<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    108</span>                 train_augmentations<span class="ansi-blue-fg">=</span>train_augmentations<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/trained_model.py</span> in <span class="ansi-cyan-fg">get_trained</span><span class="ansi-blue-fg">(self, train_loader, train_augmentations, validation_loader, log, loss, validation_loss)</span>
<span class="ansi-green-intense-fg ansi-bold">    252</span>         <span class="ansi-green-fg">for</span> i <span class="ansi-green-fg">in</span> range<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>ensemble_size<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    253</span>             log<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">&#34;ensemble&#34;</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>append<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">{</span><span class="ansi-blue-fg">}</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 254</span><span class="ansi-red-fg">             model = self.model_trainer.get_trained(
</span><span class="ansi-green-intense-fg ansi-bold">    255</span>                 train_loader<span class="ansi-blue-fg">=</span>train_loader<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    256</span>                 train_augmentations<span class="ansi-blue-fg">=</span>train_augmentations<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/resnet_models.py</span> in <span class="ansi-cyan-fg">get_trained</span><span class="ansi-blue-fg">(self, train_loader, train_augmentations, validation_loader, log, loss, validation_loss)</span>
<span class="ansi-green-intense-fg ansi-bold">    446</span> 
<span class="ansi-green-intense-fg ansi-bold">    447</span>         print<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#34;NeurIPS Workshop Style&#34;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 448</span><span class="ansi-red-fg">         train_with_schedule(
</span><span class="ansi-green-intense-fg ansi-bold">    449</span>             model<span class="ansi-blue-fg">=</span>model_optimizer<span class="ansi-blue-fg">.</span>model<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    450</span>             optimizer<span class="ansi-blue-fg">=</span>model_optimizer<span class="ansi-blue-fg">.</span>optimizer<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/black_box_model_training.py</span> in <span class="ansi-cyan-fg">train_with_schedule</span><span class="ansi-blue-fg">(model, training_samples, validation_samples, train_loader, validation_loader, patience_schedule, factor_schedule, max_epochs, device, training_log, loss, validation_loss, optimizer, prefer_accuracy, train_augmentations, limit_schedule)</span>
<span class="ansi-green-intense-fg ansi-bold">    267</span> 
<span class="ansi-green-intense-fg ansi-bold">    268</span>     <span class="ansi-red-fg"># Kick everything off</span>
<span class="ansi-green-fg">--&gt; 269</span><span class="ansi-red-fg">     </span>trainer<span class="ansi-blue-fg">.</span>run<span class="ansi-blue-fg">(</span>train_loader<span class="ansi-blue-fg">,</span> max_epochs<span class="ansi-blue-fg">=</span>max_epochs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    270</span> 
<span class="ansi-green-intense-fg ansi-bold">    271</span>     <span class="ansi-red-fg"># Return the optimizer in case we want to continue training.</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">run</span><span class="ansi-blue-fg">(self, data, max_epochs, epoch_length, seed)</span>
<span class="ansi-green-intense-fg ansi-bold">    696</span> 
<span class="ansi-green-intense-fg ansi-bold">    697</span>         self<span class="ansi-blue-fg">.</span>state<span class="ansi-blue-fg">.</span>dataloader <span class="ansi-blue-fg">=</span> data
<span class="ansi-green-fg">--&gt; 698</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_internal_run<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    699</span> 
<span class="ansi-green-intense-fg ansi-bold">    700</span>     <span class="ansi-blue-fg">@</span>staticmethod

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">_internal_run</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    769</span>             self<span class="ansi-blue-fg">.</span>_dataloader_iter <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span>
<span class="ansi-green-intense-fg ansi-bold">    770</span>             self<span class="ansi-blue-fg">.</span>logger<span class="ansi-blue-fg">.</span>error<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">f&#34;Engine run is terminating due to exception: {e}&#34;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 771</span><span class="ansi-red-fg">             </span>self<span class="ansi-blue-fg">.</span>_handle_exception<span class="ansi-blue-fg">(</span>e<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    772</span> 
<span class="ansi-green-intense-fg ansi-bold">    773</span>         self<span class="ansi-blue-fg">.</span>_dataloader_iter <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">_handle_exception</span><span class="ansi-blue-fg">(self, e)</span>
<span class="ansi-green-intense-fg ansi-bold">    464</span>             self<span class="ansi-blue-fg">.</span>_fire_event<span class="ansi-blue-fg">(</span>Events<span class="ansi-blue-fg">.</span>EXCEPTION_RAISED<span class="ansi-blue-fg">,</span> e<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    465</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 466</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">raise</span> e
<span class="ansi-green-intense-fg ansi-bold">    467</span> 
<span class="ansi-green-intense-fg ansi-bold">    468</span>     <span class="ansi-blue-fg">@</span>property

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">_internal_run</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    739</span>                     self<span class="ansi-blue-fg">.</span>_setup_engine<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    740</span> 
<span class="ansi-green-fg">--&gt; 741</span><span class="ansi-red-fg">                 </span>time_taken <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_run_once_on_dataset<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    742</span>                 <span class="ansi-red-fg"># time is available for handlers but must be update after fire</span>
<span class="ansi-green-intense-fg ansi-bold">    743</span>                 self<span class="ansi-blue-fg">.</span>state<span class="ansi-blue-fg">.</span>times<span class="ansi-blue-fg">[</span>Events<span class="ansi-blue-fg">.</span>EPOCH_COMPLETED<span class="ansi-blue-fg">.</span>name<span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> time_taken

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">_run_once_on_dataset</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    829</span>                 self<span class="ansi-blue-fg">.</span>state<span class="ansi-blue-fg">.</span>iteration <span class="ansi-blue-fg">+=</span> <span class="ansi-cyan-fg">1</span>
<span class="ansi-green-intense-fg ansi-bold">    830</span>                 self<span class="ansi-blue-fg">.</span>_fire_event<span class="ansi-blue-fg">(</span>Events<span class="ansi-blue-fg">.</span>ITERATION_STARTED<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 831</span><span class="ansi-red-fg">                 </span>self<span class="ansi-blue-fg">.</span>state<span class="ansi-blue-fg">.</span>output <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_process_function<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>state<span class="ansi-blue-fg">.</span>batch<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    832</span>                 self<span class="ansi-blue-fg">.</span>_fire_event<span class="ansi-blue-fg">(</span>Events<span class="ansi-blue-fg">.</span>ITERATION_COMPLETED<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    833</span> 

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/__init__.py</span> in <span class="ansi-cyan-fg">update</span><span class="ansi-blue-fg">(engine, batch)</span>
<span class="ansi-green-intense-fg ansi-bold">    108</span>             optimizer<span class="ansi-blue-fg">.</span>step<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    109</span>             optimizer<span class="ansi-blue-fg">.</span>zero_grad<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 110</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> output_transform<span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">,</span> y_pred<span class="ansi-blue-fg">,</span> loss<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    111</span> 
<span class="ansi-green-intense-fg ansi-bold">    112</span>     <span class="ansi-green-fg">return</span> update

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/__init__.py</span> in <span class="ansi-cyan-fg">&lt;lambda&gt;</span><span class="ansi-blue-fg">(x, y, y_pred, loss)</span>
<span class="ansi-green-intense-fg ansi-bold">    384</span>     non_blocking<span class="ansi-blue-fg">:</span> bool <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">False</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    385</span>     prepare_batch<span class="ansi-blue-fg">:</span> Callable <span class="ansi-blue-fg">=</span> _prepare_batch<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">--&gt; 386</span><span class="ansi-red-fg">     </span>output_transform<span class="ansi-blue-fg">:</span> Callable <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">lambda</span> x<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">,</span> y_pred<span class="ansi-blue-fg">,</span> loss<span class="ansi-blue-fg">:</span> loss<span class="ansi-blue-fg">.</span>item<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    387</span>     deterministic<span class="ansi-blue-fg">:</span> bool <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">False</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    388</span>     amp_mode<span class="ansi-blue-fg">:</span> Optional<span class="ansi-blue-fg">[</span>str<span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span>

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

