---

title: An experiment template


keywords: fastai
sidebar: home_sidebar

summary: "Modularity might not be the solution, but it's all we got."
description: "Modularity might not be the solution, but it's all we got."
nb_path: "09_experiment.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 09_experiment.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Import modules and functions were are going to use.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">dataclasses</span>
<span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.utils.data</span>
<span class="kn">from</span> <span class="nn">ignite.contrib.engines.common</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">add_early_stopping_by_val_score</span><span class="p">,</span>
    <span class="n">setup_common_training_handlers</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">ignite.contrib.handlers</span> <span class="kn">import</span> <span class="n">ProgressBar</span>
<span class="kn">from</span> <span class="nn">ignite.engine</span> <span class="kn">import</span> <span class="n">Events</span><span class="p">,</span> <span class="n">create_supervised_evaluator</span><span class="p">,</span> <span class="n">create_supervised_trainer</span>
<span class="kn">from</span> <span class="nn">ignite.metrics</span> <span class="kn">import</span> <span class="n">Accuracy</span><span class="p">,</span> <span class="n">Loss</span><span class="p">,</span> <span class="n">RunningAverage</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>

<span class="kn">from</span> <span class="nn">batchbald_redux.active_learning</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ActiveLearningData</span><span class="p">,</span>
    <span class="n">RandomFixedLengthSampler</span><span class="p">,</span>
    <span class="n">get_base_indices</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.batchbald</span> <span class="kn">import</span> <span class="n">get_bald_batch</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.black_box_model_training</span> <span class="kn">import</span> <span class="n">evaluate</span><span class="p">,</span> <span class="n">get_predictions</span><span class="p">,</span> <span class="n">train</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.consistent_mc_dropout</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">GeometricMeanPrediction</span><span class="p">,</span>
    <span class="n">SamplerModel</span><span class="p">,</span>
    <span class="n">geometric_mean_loss</span><span class="p">,</span>
    <span class="n">multi_sample_loss</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.example_models</span> <span class="kn">import</span> <span class="n">BayesianMNISTCNN</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.fast_mnist</span> <span class="kn">import</span> <span class="n">FastMNIST</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.repeated_mnist</span> <span class="kn">import</span> <span class="n">create_repeated_MNIST_dataset</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Experiment" class="doc_header"><code>class</code> <code>Experiment</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/experiment.py#L44" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Experiment</code>(<strong><code>acquisition_size</code></strong>:<code>int</code>=<em><code>10</code></em>, <strong><code>max_training_set</code></strong>:<code>int</code>=<em><code>300</code></em>, <strong><code>num_pool_samples</code></strong>:<code>int</code>=<em><code>20</code></em>, <strong><code>num_eval_samples</code></strong>:<code>int</code>=<em><code>4</code></em>, <strong><code>num_training_samples</code></strong>:<code>int</code>=<em><code>1</code></em>, <strong><code>num_patience_epochs</code></strong>:<code>int</code>=<em><code>3</code></em>, <strong><code>max_training_epochs</code></strong>:<code>int</code>=<em><code>10</code></em>, <strong><code>validation_set_size</code></strong>:<code>int</code>=<em><code>1024</code></em>, <strong><code>initial_set_size</code></strong>:<code>int</code>=<em><code>20</code></em>, <strong><code>samples_per_epoch</code></strong>:<code>int</code>=<em><code>32768</code></em>)</p>
</blockquote>
<p>Experiment(acquisition_size: int = 10, max_training_set: int = 300, num_pool_samples: int = 20, num_eval_samples: int = 4, num_training_samples: int = 1, num_patience_epochs: int = 3, max_training_epochs: int = 10, validation_set_size: int = 1024, initial_set_size: int = 20, samples_per_epoch: int = 32768)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">Experiment</span><span class="p">:</span>
    <span class="n">acquisition_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">max_training_set</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">300</span>
    <span class="n">num_pool_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="n">num_eval_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">num_training_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">num_patience_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">max_training_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span>
    <span class="n">validation_set_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span>
    <span class="n">initial_set_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="n">samples_per_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32768</span>

    <span class="k">def</span> <span class="nf">load_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">ActiveLearningData</span><span class="p">,</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">Dataset</span><span class="p">):</span>
        <span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">create_repeated_MNIST_dataset</span><span class="p">(</span><span class="n">num_repetitions</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">add_noise</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">active_learning_data</span> <span class="o">=</span> <span class="n">ActiveLearningData</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>

        <span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">active_learning_data</span><span class="o">.</span><span class="n">extract_dataset_from_pool</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">validation_set_size</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">active_learning_data</span><span class="p">,</span> <span class="n">validation_dataset</span><span class="p">,</span> <span class="n">test_dataset</span>

    <span class="k">def</span> <span class="nf">new_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">BayesianMNISTCNN</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">new_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_candidate_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">pool_loader</span><span class="p">):</span>
        <span class="c1"># Evaluate pool set</span>
        <span class="n">bald_model</span> <span class="o">=</span> <span class="n">SamplerModel</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_pool_samples</span><span class="p">)</span>
        <span class="n">pool_log_probs_N_K_C</span> <span class="o">=</span> <span class="n">get_predictions</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">bald_model</span><span class="p">,</span> <span class="n">loader</span><span class="o">=</span><span class="n">pool_loader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Evaluate BALD scores</span>
        <span class="n">candidate_batch</span> <span class="o">=</span> <span class="n">get_bald_batch</span><span class="p">(</span>
            <span class="n">pool_log_probs_N_K_C</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">acquisition_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">candidate_batch</span>

    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">results</span><span class="p">):</span>
        <span class="n">results</span><span class="p">[</span><span class="s2">&quot;hparams&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataclasses</span><span class="o">.</span><span class="n">asdict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="c1"># Active Learning setup</span>
        <span class="n">active_learning_data</span><span class="p">,</span> <span class="n">validation_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">()</span>

        <span class="n">initial_training_set_indices</span> <span class="o">=</span> <span class="n">active_learning_data</span><span class="o">.</span><span class="n">get_random_pool_indices</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">initial_set_size</span><span class="p">)</span>
        <span class="n">active_learning_data</span><span class="o">.</span><span class="n">acquire</span><span class="p">(</span><span class="n">initial_training_set_indices</span><span class="p">)</span>

        <span class="n">results</span><span class="p">[</span><span class="s2">&quot;initial_training_set_indices&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">initial_training_set_indices</span>

        <span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
            <span class="n">active_learning_data</span><span class="o">.</span><span class="n">training_dataset</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">RandomFixedLengthSampler</span><span class="p">(</span><span class="n">active_learning_data</span><span class="o">.</span><span class="n">training_dataset</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">samples_per_epoch</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="n">pool_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">active_learning_data</span><span class="o">.</span><span class="n">pool_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">validation_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">validation_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">results</span><span class="p">[</span><span class="s2">&quot;active_learning_steps&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">active_learning_steps</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s2">&quot;active_learning_steps&quot;</span><span class="p">]</span>

        <span class="c1"># Active Training Loop</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">training_set_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">active_learning_data</span><span class="o">.</span><span class="n">training_dataset</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training set size </span><span class="si">{</span><span class="n">training_set_size</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>

            <span class="n">iteration_log</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">training_log</span><span class="o">=</span><span class="p">[],</span> <span class="n">evalution_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">acquisition</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

            <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">new_model</span><span class="p">()</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">new_optimizer</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
            <span class="n">train</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
                <span class="n">training_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_training_samples</span><span class="p">,</span>
                <span class="n">validation_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_eval_samples</span><span class="p">,</span>
                <span class="n">train_loader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span>
                <span class="n">validation_loader</span><span class="o">=</span><span class="n">validation_loader</span><span class="p">,</span>
                <span class="n">patience</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_patience_epochs</span><span class="p">,</span>
                <span class="n">max_epochs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_training_epochs</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="n">epochs_log</span><span class="o">=</span><span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;training_log&quot;</span><span class="p">],</span>
            <span class="p">)</span>

            <span class="n">evaluation_metrics</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_eval_samples</span><span class="p">,</span> <span class="n">loader</span><span class="o">=</span><span class="n">test_loader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span>
            <span class="p">)</span>
            <span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;evalution_metrics&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">evaluation_metrics</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Perf after training </span><span class="si">{</span><span class="n">evaluation_metrics</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">training_set_size</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_training_set</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Done.&quot;</span><span class="p">)</span>
                <span class="k">break</span>

            <span class="n">candidate_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_candidate_batch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">pool_loader</span><span class="p">)</span>

            <span class="n">candidate_global_indices</span> <span class="o">=</span> <span class="n">get_base_indices</span><span class="p">(</span><span class="n">active_learning_data</span><span class="o">.</span><span class="n">pool_dataset</span><span class="p">,</span> <span class="n">candidate_batch</span><span class="o">.</span><span class="n">indices</span><span class="p">)</span>
            <span class="n">candidate_labels</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">active_learning_data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">targets</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">candidate_global_indices</span>
            <span class="p">]</span>

            <span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;acquisition&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
                <span class="n">indices</span><span class="o">=</span><span class="n">candidate_global_indices</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">candidate_labels</span><span class="p">,</span> <span class="n">scores</span><span class="o">=</span><span class="n">candidate_batch</span><span class="o">.</span><span class="n">scores</span>
            <span class="p">)</span>

            <span class="n">active_learning_data</span><span class="o">.</span><span class="n">acquire</span><span class="p">(</span><span class="n">candidate_batch</span><span class="o">.</span><span class="n">indices</span><span class="p">)</span>

            <span class="n">ls</span> <span class="o">=</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">score</span><span class="si">:</span><span class="s2">.4</span><span class="si">}</span><span class="s2">)&quot;</span> <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">candidate_labels</span><span class="p">,</span> <span class="n">candidate_batch</span><span class="o">.</span><span class="n">scores</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Acquiring (label, score)s: </span><span class="si">{</span><span class="n">ls</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="n">active_learning_steps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">iteration_log</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">active_learning_steps</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">experiment</span> <span class="o">=</span> <span class="n">Experiment</span><span class="p">(</span><span class="n">max_training_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_training_set</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">experiment</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>

<span class="n">results</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Training set size 20:

Perf after training {&#39;accuracy&#39;: 0.6184, &#39;crossentropy&#39;: 4.713012725067139}
Acquiring (label, score)s: 7 (1.314), 7 (1.303), 7 (1.237), 7 (1.215), 2 (1.21), 7 (1.207), 2 (1.198), 2 (1.196), 7 (1.196), 7 (1.196)
Training set size 30:

Perf after training {&#39;accuracy&#39;: 0.6501, &#39;crossentropy&#39;: 4.576156882095337}
Acquiring (label, score)s: 5 (1.403), 8 (1.331), 4 (1.303), 3 (1.3), 3 (1.265), 9 (1.25), 3 (1.249), 3 (1.241), 4 (1.222), 9 (1.22)
Training set size 40:

Perf after training {&#39;accuracy&#39;: 0.7086, &#39;crossentropy&#39;: 2.193311638832092}
Acquiring (label, score)s: 4 (1.297), 4 (1.232), 5 (1.232), 5 (1.231), 5 (1.219), 5 (1.206), 0 (1.195), 5 (1.189), 7 (1.173), 9 (1.17)
Training set size 50:

Perf after training {&#39;accuracy&#39;: 0.7608, &#39;crossentropy&#39;: 1.9754455966949462}
Acquiring (label, score)s: 0 (1.234), 6 (1.214), 2 (1.208), 3 (1.201), 0 (1.201), 9 (1.197), 1 (1.197), 2 (1.191), 3 (1.19), 2 (1.19)
Training set size 60:

Perf after training {&#39;accuracy&#39;: 0.7984, &#39;crossentropy&#39;: 1.5577151654243468}
Acquiring (label, score)s: 1 (1.261), 9 (1.249), 2 (1.248), 0 (1.217), 7 (1.206), 5 (1.198), 3 (1.195), 2 (1.192), 3 (1.191), 9 (1.183)
Training set size 70:

Perf after training {&#39;accuracy&#39;: 0.8284, &#39;crossentropy&#39;: 1.070880346775055}
Acquiring (label, score)s: 2 (1.203), 2 (1.198), 2 (1.189), 0 (1.166), 7 (1.162), 5 (1.143), 3 (1.137), 5 (1.135), 4 (1.133), 4 (1.127)
Training set size 80:

Perf after training {&#39;accuracy&#39;: 0.8569, &#39;crossentropy&#39;: 0.913114131975174}
Done.
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;hparams&#39;: {&#39;acquisition_size&#39;: 10,
  &#39;max_training_set&#39;: 80,
  &#39;num_pool_samples&#39;: 20,
  &#39;num_eval_samples&#39;: 4,
  &#39;num_training_samples&#39;: 1,
  &#39;num_patience_epochs&#39;: 3,
  &#39;max_training_epochs&#39;: 1,
  &#39;validation_set_size&#39;: 1024,
  &#39;initial_set_size&#39;: 20,
  &#39;samples_per_epoch&#39;: 32768},
 &#39;initial_training_set_indices&#39;: tensor([41376, 32395, 47549,  5049, 49034, 33411, 11929, 46723, 10032, 27715,
          4160, 37802, 13018, 18609, 30609, 25413, 26449,  1904, 48999, 40092]),
 &#39;active_learning_steps&#39;: [{&#39;training_log&#39;: [{&#39;accuracy&#39;: 0.6044921875,
     &#39;crossentropy&#39;: 4.612063035368919}],
   &#39;evalution_metrics&#39;: {&#39;accuracy&#39;: 0.6184,
    &#39;crossentropy&#39;: 4.713012725067139},
   &#39;acquisition&#39;: {&#39;indices&#39;: [17963,
     28675,
     25782,
     12819,
     43191,
     39687,
     19229,
     45077,
     25797,
     52443],
    &#39;labels&#39;: [7, 7, 7, 7, 2, 7, 2, 2, 7, 7],
    &#39;scores&#39;: [1.3138152360916138,
     1.3030644655227661,
     1.2367550432682037,
     1.2148968577384949,
     1.2101951837539673,
     1.206555187702179,
     1.1978866457939148,
     1.1956741213798523,
     1.195625126361847,
     1.1955157816410065]}},
  {&#39;training_log&#39;: [{&#39;accuracy&#39;: 0.64453125,
     &#39;crossentropy&#39;: 4.338195472955704}],
   &#39;evalution_metrics&#39;: {&#39;accuracy&#39;: 0.6501,
    &#39;crossentropy&#39;: 4.576156882095337},
   &#39;acquisition&#39;: {&#39;indices&#39;: [19959,
     44944,
     5293,
     42565,
     26311,
     11096,
     4138,
     40375,
     59300,
     21840],
    &#39;labels&#39;: [5, 8, 4, 3, 3, 9, 3, 3, 4, 9],
    &#39;scores&#39;: [1.4030729532241821,
     1.3311661779880524,
     1.3030898571014404,
     1.2996869385242462,
     1.2650838494300842,
     1.250482201576233,
     1.2488097548484802,
     1.2406066954135895,
     1.2218926548957825,
     1.2204528450965881]}},
  {&#39;training_log&#39;: [{&#39;accuracy&#39;: 0.697265625,
     &#39;crossentropy&#39;: 2.154685102403164}],
   &#39;evalution_metrics&#39;: {&#39;accuracy&#39;: 0.7086,
    &#39;crossentropy&#39;: 2.193311638832092},
   &#39;acquisition&#39;: {&#39;indices&#39;: [55073,
     52909,
     56306,
     15000,
     34829,
     43221,
     28102,
     14318,
     2574,
     52923],
    &#39;labels&#39;: [4, 4, 5, 5, 5, 5, 0, 5, 7, 9],
    &#39;scores&#39;: [1.2967806458473206,
     1.231921136379242,
     1.2319045662879944,
     1.2305855751037598,
     1.2188929319381714,
     1.2055236101150513,
     1.194618046283722,
     1.189286470413208,
     1.1734674870967865,
     1.1696651577949524]}},
  {&#39;training_log&#39;: [{&#39;accuracy&#39;: 0.75, &#39;crossentropy&#39;: 2.236232250928879}],
   &#39;evalution_metrics&#39;: {&#39;accuracy&#39;: 0.7608,
    &#39;crossentropy&#39;: 1.9754455966949462},
   &#39;acquisition&#39;: {&#39;indices&#39;: [37092,
     19276,
     8552,
     11693,
     32693,
     19934,
     49569,
     22269,
     8771,
     40279],
    &#39;labels&#39;: [0, 6, 2, 3, 0, 9, 1, 2, 3, 2],
    &#39;scores&#39;: [1.2335737347602844,
     1.213731288909912,
     1.2081089615821838,
     1.2011119425296783,
     1.2005239725112915,
     1.197088897228241,
     1.196723997592926,
     1.1913535296916962,
     1.190462052822113,
     1.190326601266861]}},
  {&#39;training_log&#39;: [{&#39;accuracy&#39;: 0.791015625,
     &#39;crossentropy&#39;: 1.5833088010549545}],
   &#39;evalution_metrics&#39;: {&#39;accuracy&#39;: 0.7984,
    &#39;crossentropy&#39;: 1.5577151654243468},
   &#39;acquisition&#39;: {&#39;indices&#39;: [8772,
     23463,
     35652,
     21308,
     51988,
     48260,
     1007,
     27537,
     33583,
     47540],
    &#39;labels&#39;: [1, 9, 2, 0, 7, 5, 3, 2, 3, 9],
    &#39;scores&#39;: [1.261091023683548,
     1.2491463422775269,
     1.2480011582374573,
     1.2168364822864532,
     1.2063267827033997,
     1.197663575410843,
     1.194612830877304,
     1.1920059323310852,
     1.1905683875083923,
     1.1833900809288025]}},
  {&#39;training_log&#39;: [{&#39;accuracy&#39;: 0.8134765625,
     &#39;crossentropy&#39;: 1.1898921206593513}],
   &#39;evalution_metrics&#39;: {&#39;accuracy&#39;: 0.8284,
    &#39;crossentropy&#39;: 1.070880346775055},
   &#39;acquisition&#39;: {&#39;indices&#39;: [5166,
     2184,
     48460,
     30127,
     54066,
     18326,
     670,
     36268,
     31114,
     20287],
    &#39;labels&#39;: [2, 2, 2, 0, 7, 5, 3, 5, 4, 4],
    &#39;scores&#39;: [1.2029272019863129,
     1.1984767317771912,
     1.1892695426940918,
     1.165510356426239,
     1.1616138815879822,
     1.142547845840454,
     1.1372374892234802,
     1.1345313787460327,
     1.1334386467933655,
     1.1267679929733276]}}]}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

