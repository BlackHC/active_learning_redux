---

title: FastMNIST


keywords: fastai
sidebar: home_sidebar

summary: "What the name says..."
description: "What the name says..."
nb_path: "05a_fast_mnist.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 05a_fast_mnist.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.utils.data</span> <span class="k">as</span> <span class="nn">data</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To speed up experiments, we are going to use Joost's FastMNIST (<a href="https://tinyurl.com/pytorch-fast-mnist">https://tinyurl.com/pytorch-fast-mnist</a>), which preloads the dataset onto the device.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="FastMNIST" class="doc_header"><code>class</code> <code>FastMNIST</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/fast_mnist.py#L17" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>FastMNIST</code>(<strong>*<code>args</code></strong>, <strong>**<code>kwds</code></strong>) :: <code>MNIST</code></p>
</blockquote>
<p><code>MNIST &lt;http://yann.lecun.com/exdb/mnist/&gt;</code>_ Dataset.</p>
<p>Args:
    root (string): Root directory of dataset where <code>MNIST/processed/training.pt</code>
        and  <code>MNIST/processed/test.pt</code> exist.
    train (bool, optional): If True, creates dataset from <code>training.pt</code>,
        otherwise from <code>test.pt</code>.
    download (bool, optional): If true, downloads the dataset from the internet and
        puts it in root directory. If dataset is already downloaded, it is not
        downloaded again.
    transform (callable, optional): A function/transform that  takes in an PIL image
        and returns a transformed version. E.g, <code>transforms.RandomCrop</code>
    target_transform (callable, optional): A function/transform that takes in the
        target and transforms it.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torchvision.datasets</span> <span class="kn">import</span> <span class="n">MNIST</span>


<span class="c1"># From https://tinyurl.com/pytorch-fast-mnist</span>
<span class="k">class</span> <span class="nc">FastMNIST</span><span class="p">(</span><span class="n">MNIST</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># Scale data to [0,1]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="mi">255</span><span class="p">)</span>

        <span class="c1"># Normalize it with the usual MNIST mean and std</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">sub_</span><span class="p">(</span><span class="mf">0.1307</span><span class="p">)</span><span class="o">.</span><span class="n">div_</span><span class="p">(</span><span class="mf">0.3081</span><span class="p">)</span>

        <span class="c1"># Put both data and targets on GPU in advance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">targets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            index (int): Index</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple: (image, target) where target is index of the target class.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">img</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">targets</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">img</span><span class="p">,</span> <span class="n">target</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

</div>
 

