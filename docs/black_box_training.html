---

title: Black Box Model Training


keywords: fastai
sidebar: home_sidebar

summary: ""Learning is not attained by chance, it must be sought for with ardor and attended to with diligence.” "
description: ""Learning is not attained by chance, it must be sought for with ardor and attended to with diligence.” "
nb_path: "07_black_box_training.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 07_black_box_training.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>After looking at a simple example experiment, it is worth looking at the big picture. The big picture requires us to train different models with differently-sized datasets.</p>
<p>We don't want to worry about fine-tuning training too much. Because we cannot.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Goals">Goals<a class="anchor-link" href="#Goals"> </a></h2><ul>
<li>Log as much as possible by default.</li>
<li>Avoid magic numbers. Magic numbers don't work very well when everything keeps changing.</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="train" class="doc_header"><code>train</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/black_box_model_training.py#L37" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>train</code>(<strong><code>model</code></strong>, <strong><code>training_samples</code></strong>, <strong><code>validation_samples</code></strong>, <strong><code>train_loader</code></strong>, <strong><code>validation_loader</code></strong>, <strong><code>patience</code></strong>:<code>Optional</code>[<code>int</code>], <strong><code>max_epochs</code></strong>:<code>int</code>, <strong><code>device</code></strong>:<code>str</code>, <strong><code>training_log</code></strong>:<code>dict</code>, <strong><code>loss</code></strong>=<em><code>None</code></em>, <strong><code>validation_loss</code></strong>=<em><code>None</code></em>, <strong><code>optimizer</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>:param model:
:param train_loader:
:param val_loader:
:param metric_loader: We compute metrics for debugging and introspection purposes with this data.
:param patience: How many epochs to wait for early-stopping.
:param max_epochs:
:param tb_log_dir:
:param device:
:return: Optimizer that was used for training.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="evaluate" class="doc_header"><code>evaluate</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/black_box_model_training.py#L134" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>evaluate</code>(<strong><code>model</code></strong>, <strong><code>num_samples</code></strong>, <strong><code>loader</code></strong>, <strong><code>device</code></strong>, <strong><code>loss</code></strong>=<em><code>None</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="create_metrics" class="doc_header"><code>create_metrics</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/black_box_model_training.py#L156" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>create_metrics</code>(<strong><code>loss</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">LOG_INTERVAL</span> <span class="o">=</span> <span class="mi">10</span>


<span class="k">def</span> <span class="nf">train</span><span class="p">(</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">training_samples</span><span class="p">,</span>
    <span class="n">validation_samples</span><span class="p">,</span>
    <span class="n">train_loader</span><span class="p">,</span>
    <span class="n">validation_loader</span><span class="p">,</span>
    <span class="n">patience</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">max_epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">training_log</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
    <span class="n">loss</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_loss</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    :param model:</span>
<span class="sd">    :param train_loader:</span>
<span class="sd">    :param val_loader:</span>
<span class="sd">    :param metric_loader: We compute metrics for debugging and introspection purposes with this data.</span>
<span class="sd">    :param patience: How many epochs to wait for early-stopping.</span>
<span class="sd">    :param max_epochs:</span>
<span class="sd">    :param tb_log_dir:</span>
<span class="sd">    :param device:</span>
<span class="sd">    :return: Optimizer that was used for training.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">validation_loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">validation_loss</span> <span class="o">=</span> <span class="n">loss</span>

    <span class="n">train_model</span> <span class="o">=</span> <span class="n">SamplerModel</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">training_samples</span><span class="p">)</span>
    <span class="n">validation_model</span> <span class="o">=</span> <span class="n">GeometricMeanPrediction</span><span class="p">(</span><span class="n">SamplerModel</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">validation_samples</span><span class="p">))</span>

    <span class="c1"># Move model to device before creating the optimizer</span>
    <span class="n">train_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">optimizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>

    <span class="n">trainer</span> <span class="o">=</span> <span class="n">create_supervised_trainer</span><span class="p">(</span><span class="n">train_model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">multi_sample_loss</span><span class="p">(</span><span class="n">loss</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

    <span class="n">metrics</span> <span class="o">=</span> <span class="n">create_metrics</span><span class="p">(</span><span class="n">validation_loss</span><span class="p">)</span>

    <span class="n">validation_evaluator</span> <span class="o">=</span> <span class="n">create_supervised_evaluator</span><span class="p">(</span><span class="n">validation_model</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

    <span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
        <span class="n">validation_evaluator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">validation_loader</span><span class="p">)</span>

    <span class="c1"># Only to look nicer.</span>
    <span class="n">RunningAverage</span><span class="p">(</span><span class="n">output_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="s2">&quot;crossentropy&quot;</span><span class="p">)</span>

    <span class="n">setup_common_training_handlers</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">with_gpu_stats</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">(),</span> <span class="n">log_every_iters</span><span class="o">=</span><span class="n">LOG_INTERVAL</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">is_run_from_ipython</span><span class="p">():</span>
        <span class="n">ProgressBar</span><span class="p">(</span><span class="n">persist</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
            <span class="n">validation_evaluator</span><span class="p">,</span>
            <span class="n">metric_names</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">,</span>
            <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">(</span><span class="n">every</span><span class="o">=</span><span class="n">LOG_INTERVAL</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="n">training_log</span><span class="p">[</span><span class="s2">&quot;epochs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">epochs_log</span> <span class="o">=</span> <span class="n">training_log</span><span class="p">[</span><span class="s2">&quot;epochs&quot;</span><span class="p">]</span>

    <span class="c1"># Logging</span>
    <span class="nd">@validation_evaluator</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">log_training_results</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">metrics</span><span class="p">)</span>
        <span class="n">epochs_log</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">is_run_from_ipython</span><span class="p">():</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch metrics: </span><span class="si">{</span><span class="n">metrics</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Add early stopping</span>
    <span class="k">if</span> <span class="n">patience</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">early_stopping</span> <span class="o">=</span> <span class="n">RestoringEarlyStopping</span><span class="p">(</span>
            <span class="n">patience</span><span class="o">=</span><span class="n">patience</span><span class="p">,</span>
            <span class="n">score_function</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="o">-</span><span class="n">validation_evaluator</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">metrics</span><span class="p">[</span><span class="s2">&quot;crossentropy&quot;</span><span class="p">]),</span>
            <span class="n">module</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
            <span class="n">training_engine</span><span class="o">=</span><span class="n">trainer</span><span class="p">,</span>
            <span class="n">validation_engine</span><span class="o">=</span><span class="n">validation_evaluator</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">early_stopping</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># Kick everything off</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="n">max_epochs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">early_stopping</span><span class="p">:</span>
        <span class="n">training_log</span><span class="p">[</span><span class="s2">&quot;best_epoch&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">early_stopping</span><span class="o">.</span><span class="n">best_epoch</span>

    <span class="c1"># Return the optimizer in case we want to continue training.</span>
    <span class="k">return</span> <span class="n">optimizer</span>


<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="n">loader</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">evaluation_model</span> <span class="o">=</span> <span class="n">GeometricMeanPrediction</span><span class="p">(</span><span class="n">SamplerModel</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>

    <span class="n">metrics</span> <span class="o">=</span> <span class="n">create_metrics</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

    <span class="n">evaluator</span> <span class="o">=</span> <span class="n">create_supervised_evaluator</span><span class="p">(</span><span class="n">evaluation_model</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

    <span class="n">ProgressBar</span><span class="p">(</span><span class="n">persist</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span>
        <span class="n">evaluator</span><span class="p">,</span>
        <span class="n">metric_names</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">,</span>
        <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">(</span><span class="n">every</span><span class="o">=</span><span class="n">LOG_INTERVAL</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="c1"># Kick everything off</span>
    <span class="n">evaluator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">loader</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">metrics</span>


<span class="k">def</span> <span class="nf">create_metrics</span><span class="p">(</span><span class="n">loss</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;accuracy&quot;</span><span class="p">:</span> <span class="n">Accuracy</span><span class="p">(),</span> <span class="s2">&quot;crossentropy&quot;</span><span class="p">:</span> <span class="n">Loss</span><span class="p">(</span><span class="n">loss</span><span class="p">)}</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We want to use metrics that allow us to capture the quality of the produced uncertainty during training.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch.utils.data</span>

<span class="kn">from</span> <span class="nn">batchbald_redux.consistent_mc_dropout</span> <span class="kn">import</span> <span class="n">GeometricMeanPrediction</span><span class="p">,</span> <span class="n">SamplerModel</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.dataset_challenges</span> <span class="kn">import</span> <span class="n">create_repeated_MNIST_dataset</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.example_models</span> <span class="kn">import</span> <span class="n">BayesianMNISTCNN</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.fast_mnist</span> <span class="kn">import</span> <span class="n">FastMNIST</span>

<span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">create_repeated_MNIST_dataset</span><span class="p">(</span><span class="n">num_repetitions</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">add_noise</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">BayesianMNISTCNN</span><span class="p">()</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">training_log</span> <span class="o">=</span> <span class="p">{}</span>

<span class="n">train</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">training_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">validation_samples</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">train_loader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span>
    <span class="n">validation_loader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span>
    <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">max_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span>
    <span class="n">training_log</span><span class="o">=</span><span class="n">training_log</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">training_log</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch metrics: {&#39;accuracy&#39;: 0.9739, &#39;crossentropy&#39;: 0.1600715060343345}
Epoch metrics: {&#39;accuracy&#39;: 0.9785833333333334, &#39;crossentropy&#39;: 0.13283825434496005}
Epoch metrics: {&#39;accuracy&#39;: 0.98225, &#39;crossentropy&#39;: 0.11636623338162899}
RestoringEarlyStopping: Restoring best parameters. (Score: -0.11636623338162899)
RestoringEarlyStopping: Restoring optimizer.
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;epochs&#39;: [{&#39;accuracy&#39;: 0.9739, &#39;crossentropy&#39;: 0.1600715060343345},
  {&#39;accuracy&#39;: 0.9785833333333334, &#39;crossentropy&#39;: 0.13283825434496005},
  {&#39;accuracy&#39;: 0.98225, &#39;crossentropy&#39;: 0.11636623338162899}],
 &#39;best_epoch&#39;: 3}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">loader</span><span class="o">=</span><span class="n">test_loader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;accuracy&#39;: 0.9715, &#39;crossentropy&#39;: 0.1681874878913164}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Obtaining-predictions">Obtaining predictions<a class="anchor-link" href="#Obtaining-predictions"> </a></h2><p>Sometimes, we want to obtain predictions from our models, instead of pure evaluation metrics... I know right?</p>
<p>The following helper method registers an event handler with an Ignite Engine that stores the predictions in a list:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_predictions_labels" class="doc_header"><code>get_predictions_labels</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/black_box_model_training.py#L162" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_predictions_labels</code>(<strong><code>model</code></strong>, <strong><code>num_samples</code></strong>, <strong><code>num_classes</code></strong>, <strong><code>loader</code></strong>, <strong><code>device</code></strong>:<code>str</code>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_predictions" class="doc_header"><code>get_predictions</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/black_box_model_training.py#L206" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_predictions</code>(<strong><code>model</code></strong>, <strong><code>num_samples</code></strong>, <strong><code>num_classes</code></strong>, <strong><code>loader</code></strong>, <strong><code>device</code></strong>:<code>str</code>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_log_mean_probs" class="doc_header"><code>get_log_mean_probs</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/black_box_model_training.py#L214" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_log_mean_probs</code>(<strong><code>model</code></strong>, <strong><code>num_samples</code></strong>, <strong><code>num_classes</code></strong>, <strong><code>loader</code></strong>, <strong><code>device</code></strong>:<code>str</code>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">get_predictions_labels</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">loader</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

    <span class="n">pbar</span> <span class="o">=</span> <span class="n">create_progress_bar</span><span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="n">num_samples</span><span class="p">,</span> <span class="n">tqdm_args</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">desc</span><span class="o">=</span><span class="s2">&quot;get_predictions_labels&quot;</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
    <span class="n">pbar</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

    <span class="nd">@toma</span><span class="o">.</span><span class="n">execute</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">get_prediction_batch</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">start</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

        <span class="n">prediction_model</span> <span class="o">=</span> <span class="n">SamplerModel</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>

        <span class="n">data_start</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_labels</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
            <span class="n">batch_x</span> <span class="o">=</span> <span class="n">batch_x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

            <span class="n">batch_predictions</span> <span class="o">=</span> <span class="n">prediction_model</span><span class="p">(</span><span class="n">batch_x</span><span class="p">)</span>

            <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_predictions</span><span class="p">)</span>
            <span class="n">data_end</span> <span class="o">=</span> <span class="n">data_start</span> <span class="o">+</span> <span class="n">batch_size</span>

            <span class="n">predictions</span><span class="p">[</span><span class="n">data_start</span><span class="p">:</span><span class="n">data_end</span><span class="p">,</span> <span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">batch_predictions</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">start</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">labels</span><span class="p">[</span><span class="n">data_start</span><span class="p">:</span><span class="n">data_end</span><span class="p">]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">batch_labels</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">assert</span> <span class="n">labels</span><span class="p">[</span><span class="n">data_start</span><span class="p">:</span><span class="n">data_end</span><span class="p">]</span> <span class="o">==</span> <span class="n">batch_labels</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>

            <span class="n">data_start</span> <span class="o">=</span> <span class="n">data_end</span>

            <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span>

    <span class="n">pbar</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span>


<span class="k">def</span> <span class="nf">get_predictions</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">loader</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="n">predictions</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">get_predictions_labels</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">loader</span><span class="o">=</span><span class="n">loader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">predictions</span>


<span class="k">def</span> <span class="nf">get_log_mean_probs</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">loader</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="n">log_probs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">get_predictions_labels</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">loader</span><span class="o">=</span><span class="n">loader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span>
    <span class="p">)</span>

    <span class="n">log_mean_probs</span> <span class="o">=</span> <span class="n">log_probs</span><span class="o">.</span><span class="n">logsumexp</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">log_probs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">log_mean_probs</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Example">Example<a class="anchor-link" href="#Example"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">get_predictions</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">loader</span><span class="o">=</span><span class="n">test_loader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="nb">len</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>10000</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">get_predictions_labels</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">loader</span><span class="o">=</span><span class="n">test_loader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span>
<span class="p">)</span>
<span class="n">predictions</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">labels</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([10000, 7, 10]), torch.Size([10000]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">predictions</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[[-2.8367e+01, -2.4773e+01, -1.6460e+01, -1.5410e+01, -2.6516e+01,
          -2.5284e+01, -4.4725e+01, -5.9605e-07, -1.9745e+01, -1.5331e+01],
         [-2.0561e+01, -2.3827e+01, -1.9392e+01, -2.4907e+01, -2.7014e+01,
          -2.3035e+01, -3.5366e+01, -1.6689e-06, -2.3001e+01, -1.3284e+01],
         [-2.8653e+01, -2.2573e+01, -1.1184e+01, -1.6494e+01, -3.4791e+01,
          -2.9149e+01, -4.1066e+01, -1.4067e-05, -2.3491e+01, -2.0259e+01],
         [-1.8519e+01, -1.0138e+01, -1.1501e+01, -9.9980e+00, -1.2409e+01,
          -1.5788e+01, -2.3412e+01, -6.1302e-04, -1.0140e+01, -7.6546e+00],
         [-2.5508e+01, -1.6356e+01, -1.3611e+01, -1.8889e+01, -2.4214e+01,
          -3.2515e+01, -4.0044e+01, -1.3113e-06, -2.1938e+01, -2.1855e+01],
         [-2.7792e+01, -2.1009e+01, -1.6808e+01, -2.0931e+01, -2.7830e+01,
          -2.6055e+01, -3.9284e+01, -9.5367e-07, -2.4812e+01, -1.3849e+01],
         [-2.9338e+01, -2.4237e+01, -2.1119e+01, -2.8949e+01, -3.0423e+01,
          -3.5695e+01, -5.0294e+01, -2.3842e-07, -2.9808e+01, -1.5091e+01]],

        [[-6.6202e+00, -1.5267e+01, -1.8708e-03, -1.4534e+01, -2.6040e+01,
          -1.8932e+01, -1.4454e+01, -2.0005e+01, -7.5338e+00, -1.9521e+01],
         [-6.9466e+00, -7.7664e-01, -6.2143e-01, -8.7233e+00, -9.3295e+00,
          -1.2793e+01, -8.8358e+00, -9.9763e+00, -6.5380e+00, -1.0822e+01],
         [-6.9954e+00, -1.8317e+01, -9.1654e-04, -1.7266e+01, -2.9420e+01,
          -2.9447e+01, -1.9204e+01, -2.7540e+01, -1.6756e+01, -2.5317e+01],
         [-8.7175e-01, -9.6184e+00, -5.6602e-01, -7.8070e+00, -1.5205e+01,
          -1.0090e+01, -5.0855e+00, -1.1524e+01, -4.9219e+00, -1.2727e+01],
         [-2.5550e+01, -1.5435e+01, -2.3842e-07, -1.8554e+01, -3.1748e+01,
          -3.8187e+01, -2.5995e+01, -2.3685e+01, -2.1000e+01, -3.7446e+01],
         [-9.5787e+00, -1.3928e+01, -2.0168e-04, -1.0935e+01, -2.4859e+01,
          -2.0220e+01, -1.4796e+01, -2.3907e+01, -9.0844e+00, -2.3881e+01],
         [-3.1086e+00, -7.6503e+00, -4.6193e-02, -2.3069e+01, -2.0763e+01,
          -2.4662e+01, -1.6486e+01, -2.1891e+01, -1.3556e+01, -2.4425e+01]],

        [[-1.0924e+01, -2.7033e-02, -7.5790e+00, -9.4438e+00, -4.4072e+00,
          -8.9046e+00, -4.4128e+00, -7.4897e+00, -7.4283e+00, -7.6774e+00],
         [-1.2271e+01, -5.3010e-04, -1.2919e+01, -1.5111e+01, -7.9624e+00,
          -1.0890e+01, -9.5858e+00, -9.9795e+00, -1.0626e+01, -1.1025e+01],
         [-1.6920e+01, -9.1832e-04, -1.1426e+01, -1.2194e+01, -9.2078e+00,
          -1.2397e+01, -1.2455e+01, -7.1480e+00, -1.2170e+01, -1.3161e+01],
         [-1.3441e+01, -4.2234e-03, -1.4484e+01, -1.2271e+01, -6.7756e+00,
          -1.0589e+01, -1.1132e+01, -6.1250e+00, -9.0457e+00, -7.2344e+00],
         [-2.5182e+01, -7.7486e-06, -1.6112e+01, -1.6870e+01, -1.4944e+01,
          -1.7934e+01, -1.6265e+01, -1.2391e+01, -1.2696e+01, -1.9349e+01],
         [-2.1247e+01, -1.3113e-06, -2.1583e+01, -1.9943e+01, -1.4988e+01,
          -1.5463e+01, -1.5930e+01, -1.5362e+01, -1.4699e+01, -1.9313e+01],
         [-2.7783e+01, -3.6716e-05, -2.6629e+01, -2.8167e+01, -1.0211e+01,
          -2.4403e+01, -2.3573e+01, -1.8405e+01, -2.1453e+01, -1.9456e+01]],

        [[-7.7543e-03, -1.5186e+01, -9.4181e+00, -1.1168e+01, -1.4532e+01,
          -7.6481e+00, -9.2738e+00, -1.0384e+01, -4.9611e+00, -1.0754e+01],
         [-4.5528e-04, -1.7889e+01, -1.7315e+01, -1.9002e+01, -1.5540e+01,
          -7.8443e+00, -1.1262e+01, -1.0303e+01, -1.2230e+01, -1.1351e+01],
         [-5.0495e-03, -1.8906e+01, -5.4178e+00, -1.2443e+01, -1.7726e+01,
          -1.2960e+01, -1.2100e+01, -1.3459e+01, -7.6330e+00, -9.1877e+00],
         [-5.7917e-03, -1.4555e+01, -1.0996e+01, -1.7610e+01, -1.6705e+01,
          -9.5658e+00, -5.2013e+00, -1.4351e+01, -8.6559e+00, -1.2529e+01],
         [-4.7684e-07, -2.5123e+01, -1.4947e+01, -2.5059e+01, -2.8786e+01,
          -2.0648e+01, -1.9444e+01, -1.9367e+01, -1.5966e+01, -2.4160e+01],
         [-8.3339e-03, -2.0464e+01, -1.6595e+01, -1.6657e+01, -1.7367e+01,
          -7.0197e+00, -4.9142e+00, -1.5997e+01, -1.0093e+01, -1.0712e+01],
         [ 0.0000e+00, -3.0200e+01, -2.3203e+01, -3.3509e+01, -4.2402e+01,
          -2.1398e+01, -2.4292e+01, -2.8858e+01, -1.7637e+01, -3.2227e+01]],

        [[-1.8499e+01, -2.4979e+01, -1.9336e+01, -1.8843e+01, -9.8768e-02,
          -1.4585e+01, -2.0720e+01, -1.3453e+01, -1.5895e+01, -2.3640e+00],
         [-1.4316e+01, -2.0806e+01, -1.5550e+01, -2.0495e+01, -3.6955e-06,
          -1.8439e+01, -1.3907e+01, -2.2486e+01, -2.0624e+01, -1.3141e+01],
         [-1.9121e+01, -2.1166e+01, -1.7532e+01, -1.7741e+01, -1.7498e-04,
          -2.2747e+01, -2.2131e+01, -1.9050e+01, -1.6993e+01, -8.6508e+00],
         [-1.9747e+01, -2.0353e+01, -1.4479e+01, -1.7232e+01, -1.5401e-04,
          -1.9031e+01, -1.6842e+01, -1.4703e+01, -1.8014e+01, -8.7855e+00],
         [-1.5684e+01, -1.5487e+01, -8.7441e+00, -1.4199e+01, -4.3466e-04,
          -1.9137e+01, -1.1640e+01, -8.2380e+00, -1.4705e+01, -1.4582e+01],
         [-1.5630e+01, -1.8462e+01, -1.4663e+01, -2.0053e+01, -3.1311e-04,
          -2.4119e+01, -1.5153e+01, -1.6353e+01, -1.5695e+01, -8.0728e+00],
         [-2.5900e+01, -2.1803e+01, -2.6461e+01, -3.0287e+01, -1.5497e-06,
          -2.7549e+01, -2.3879e+01, -2.6580e+01, -2.7880e+01, -1.3383e+01]],

        [[-1.2324e+01, -1.5824e-02, -8.2841e+00, -1.1531e+01, -5.1355e+00,
          -1.1042e+01, -4.6952e+00, -8.4596e+00, -8.9422e+00, -9.8938e+00],
         [-1.4428e+01, -8.3205e-05, -1.6124e+01, -1.8721e+01, -9.7820e+00,
          -1.3651e+01, -1.1106e+01, -1.2258e+01, -1.2351e+01, -1.4058e+01],
         [-2.0467e+01, -2.3493e-04, -1.3303e+01, -1.4561e+01, -1.1321e+01,
          -1.6175e+01, -1.6012e+01, -8.4230e+00, -1.4490e+01, -1.6359e+01],
         [-1.4916e+01, -2.1416e-03, -1.5921e+01, -1.3690e+01, -8.1365e+00,
          -1.2727e+01, -1.3083e+01, -6.3964e+00, -1.0302e+01, -8.8815e+00],
         [-2.3866e+01, -3.5405e-05, -1.3759e+01, -1.7127e+01, -1.5331e+01,
          -1.9535e+01, -1.6267e+01, -1.0684e+01, -1.1404e+01, -1.9767e+01],
         [-2.3413e+01, -2.3842e-07, -2.5266e+01, -2.3497e+01, -1.7425e+01,
          -1.8386e+01, -1.7727e+01, -1.7513e+01, -1.5505e+01, -2.2240e+01],
         [-2.7879e+01, -4.2915e-06, -2.7365e+01, -3.1678e+01, -1.2359e+01,
          -2.8105e+01, -2.4983e+01, -1.9962e+01, -2.1883e+01, -2.1608e+01]],

        [[-1.9733e+01, -2.5420e+01, -1.9939e+01, -1.8059e+01, -3.0303e-01,
          -9.2340e+00, -2.0749e+01, -1.2484e+01, -8.2243e+00, -1.3430e+00],
         [-1.3366e+01, -9.3194e+00, -1.2752e+01, -1.4943e+01, -2.8594e-04,
          -1.2928e+01, -1.2025e+01, -1.2327e+01, -9.6708e+00, -9.0674e+00],
         [-1.6692e+01, -1.3588e+01, -1.3212e+01, -1.4703e+01, -3.4616e-02,
          -1.4751e+01, -1.4533e+01, -1.3080e+01, -6.7268e+00, -3.4168e+00],
         [-3.1121e+01, -1.7317e+01, -2.1833e+01, -1.9458e+01, -6.1588e-04,
          -1.7771e+01, -2.4142e+01, -1.0984e+01, -1.3171e+01, -7.4240e+00],
         [-3.0571e+01, -2.7184e+01, -2.3067e+01, -2.1660e+01, -2.0266e-06,
          -2.2184e+01, -2.8647e+01, -1.4194e+01, -1.3545e+01, -1.7413e+01],
         [-2.0717e+01, -1.4666e+01, -1.8736e+01, -2.2005e+01, -2.6544e-04,
          -1.8455e+01, -1.5911e+01, -1.4565e+01, -8.5990e+00, -9.4319e+00],
         [-3.5859e+01, -2.0904e+01, -3.3990e+01, -2.8829e+01, -1.2517e-05,
          -1.8238e+01, -3.0454e+01, -2.0779e+01, -2.0958e+01, -1.1289e+01]],

        [[-2.7855e+01, -3.1768e+01, -2.5714e+01, -1.8389e+01, -8.6943e+00,
          -1.3262e+01, -3.0148e+01, -1.7637e+01, -1.4639e+01, -1.6974e-04],
         [-9.9251e+00, -1.2054e+01, -1.0521e+01, -8.4083e+00, -5.6589e+00,
          -6.8299e+00, -1.3738e+01, -8.6643e+00, -6.7774e+00, -6.2042e-03],
         [-1.5764e+01, -1.5791e+01, -1.2485e+01, -9.2081e+00, -5.8755e+00,
          -8.0630e+00, -1.5638e+01, -1.3784e+01, -5.2240e+00, -8.6508e-03],
         [-1.5507e+01, -1.3722e+01, -1.4377e+01, -8.1890e+00, -4.1146e+00,
          -4.7136e+00, -1.3800e+01, -9.7190e+00, -5.8427e+00, -2.8962e-02],
         [-1.5710e+01, -2.1056e+01, -1.5463e+01, -5.9697e+00, -1.0082e+01,
          -1.0693e+01, -2.1117e+01, -1.2028e+01, -3.5756e+00, -3.1104e-02],
         [-1.9268e+01, -2.6441e+01, -2.1147e+01, -1.3175e+01, -7.6129e+00,
          -9.4066e+00, -2.1952e+01, -1.5426e+01, -1.0856e+01, -5.9789e-04],
         [-2.0338e+01, -1.1768e+01, -1.8357e+01, -7.8905e+00, -6.3472e+00,
          -5.2227e+00, -2.0653e+01, -1.3608e+01, -7.5603e+00, -8.0809e-03]],

        [[-1.8418e+01, -2.9859e+01, -1.9532e+01, -2.0148e+01, -1.7572e+01,
          -5.1074e-02, -9.6074e+00, -2.0889e+01, -3.0080e+00, -7.9974e+00],
         [-1.1018e+01, -1.5769e+01, -1.8009e+01, -1.4769e+01, -8.6634e+00,
          -2.1326e-03, -9.6645e+00, -1.2161e+01, -8.2911e+00, -6.4246e+00],
         [-7.7984e+00, -1.5273e+01, -1.0723e+01, -1.1370e+01, -6.5486e+00,
          -1.7918e-01, -2.6650e+00, -1.4982e+01, -4.4559e+00, -2.5138e+00],
         [-6.2625e+00, -1.7464e+01, -1.0016e+01, -1.2694e+01, -1.0523e+01,
          -9.9680e-02, -2.5850e+00, -1.3946e+01, -5.0860e+00, -4.4819e+00],
         [-1.9125e+01, -3.7024e+01, -3.7909e+01, -3.1402e+01, -3.0102e+01,
          -1.7141e-01, -1.8483e+00, -4.0585e+01, -1.1336e+01, -2.6128e+01],
         [-5.8242e+00, -1.9773e+01, -1.6431e+01, -1.4472e+01, -1.2763e+01,
          -1.2837e-01, -4.0458e+00, -1.0770e+01, -2.3361e+00, -5.7160e+00],
         [-1.4145e+01, -1.6863e+01, -2.6579e+01, -1.9360e+01, -1.3682e+01,
          -6.9735e-05, -9.9623e+00, -2.1851e+01, -1.1306e+01, -1.1689e+01]],

        [[-3.3025e+01, -3.7300e+01, -2.9990e+01, -2.2606e+01, -1.1316e+01,
          -1.7137e+01, -3.8416e+01, -1.3299e+01, -1.4978e+01, -1.4186e-05],
         [-1.3933e+01, -1.7199e+01, -1.2314e+01, -1.2638e+01, -1.0085e+01,
          -1.0380e+01, -1.9811e+01, -2.8411e+00, -9.1330e+00, -6.0334e-02],
         [-2.1187e+01, -2.6215e+01, -1.9301e+01, -1.6299e+01, -1.0111e+01,
          -1.3128e+01, -2.0469e+01, -1.6457e+01, -7.5622e+00, -5.6263e-04],
         [-3.2213e+01, -2.3767e+01, -2.5504e+01, -1.8476e+01, -6.2695e+00,
          -1.7697e+01, -3.0409e+01, -1.0441e+01, -1.0757e+01, -1.9456e-03],
         [-2.8670e+01, -3.3934e+01, -2.7621e+01, -1.9474e+01, -1.0158e+01,
          -2.3465e+01, -4.0189e+01, -1.0862e+01, -9.1986e+00, -1.5913e-04],
         [-1.9840e+01, -2.4728e+01, -1.9644e+01, -1.5725e+01, -8.3183e+00,
          -1.3910e+01, -2.3886e+01, -8.1078e+00, -1.1086e+01, -5.6179e-04],
         [-3.3327e+01, -2.6882e+01, -3.1107e+01, -2.4077e+01, -1.2177e+01,
          -2.4243e+01, -4.2406e+01, -1.0158e+01, -1.7353e+01, -4.3868e-05]]])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

