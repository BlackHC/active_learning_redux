---

title: Experiment CIFAR-10


keywords: fastai
sidebar: home_sidebar

summary: "Can we get better by training on our assumptions?"
description: "Can we get better by training on our assumptions?"
nb_path: "09c_experiment_cifar10_missing_classes.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 09c_experiment_cifar10_missing_classes.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Appended /home/blackhc/PycharmProjects/bald-ical/src to paths
Switched to directory /home/blackhc/PycharmProjects/bald-ical
%load_ext autoreload
%autoreload 2
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Import modules and functions were are going to use.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">dataclasses</span>
<span class="kn">import</span> <span class="nn">traceback</span>

<span class="kn">from</span> <span class="nn">blackhc.project</span> <span class="kn">import</span> <span class="n">is_run_from_ipython</span>
<span class="kn">from</span> <span class="nn">blackhc.project.experiment</span> <span class="kn">import</span> <span class="n">embedded_experiments</span>

<span class="kn">import</span> <span class="nn">batchbald_redux.acquisition_functions.bald</span>
<span class="kn">import</span> <span class="nn">batchbald_redux.acquisition_functions.epig</span>
<span class="kn">from</span> <span class="nn">batchbald_redux</span> <span class="kn">import</span> <span class="n">acquisition_functions</span><span class="p">,</span> <span class="n">baseline_acquisition_functions</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.experiment_data</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ImbalancedTestDistributionExperimentDataConfig</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.unified_experiment</span> <span class="kn">import</span> <span class="n">UnifiedExperiment</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># (ID: air, automobile, ship and truck, OOD: bird, cat, deer, dog, frog and horse)</span>
<span class="c1"># ood_classes={2, 3, 4, 5, 6, 7}</span>



<span class="n">configs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">UnifiedExperiment</span><span class="p">(</span>
        <span class="n">experiment_data_config</span><span class="o">=</span><span class="n">ImbalancedTestDistributionExperimentDataConfig</span><span class="p">(</span>
            <span class="n">dataset_name</span><span class="o">=</span><span class="s2">&quot;CIFAR-10&quot;</span><span class="p">,</span>
            <span class="n">repetitions</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">initial_training_set_size</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">validation_set_size</span><span class="o">=</span><span class="mi">4000</span><span class="p">,</span>
            <span class="n">validation_split_random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">evaluation_set_size</span><span class="o">=</span><span class="mi">4000</span><span class="p">,</span>
            <span class="n">add_dataset_noise</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">minority_classes</span><span class="o">=</span><span class="p">{</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">},</span>
            <span class="n">minority_class_percentage</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">seed</span> <span class="o">+</span> <span class="mi">4658</span><span class="p">,</span>
        <span class="n">acquisition_function</span><span class="o">=</span><span class="n">acquisition_function</span><span class="p">,</span>
        <span class="n">acquisition_size</span><span class="o">=</span><span class="n">acquisition_size</span><span class="p">,</span>
        <span class="n">num_pool_samples</span><span class="o">=</span><span class="n">num_pool_samples</span><span class="p">,</span>
        <span class="n">max_training_set</span><span class="o">=</span><span class="mi">450</span><span class="p">,</span>
        <span class="n">ensemble_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">disable_training_augmentations</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
    <span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">acquisition_function</span> <span class="ow">in</span> <span class="p">[</span>
        <span class="n">batchbald_redux</span><span class="o">.</span><span class="n">acquisition_functions</span><span class="o">.</span><span class="n">bald</span><span class="o">.</span><span class="n">BALD</span><span class="p">,</span>
        <span class="n">batchbald_redux</span><span class="o">.</span><span class="n">acquisition_functions</span><span class="o">.</span><span class="n">epig</span><span class="o">.</span><span class="n">EPIG</span><span class="p">,</span>
        <span class="c1">#acquisition_functions.EvalBALD,</span>
        <span class="c1">#baseline_acquisition_functions.BADGE,</span>
        <span class="c1">#acquisition_functions.Random,</span>
    <span class="p">]</span>
    <span class="k">for</span> <span class="n">acquisition_size</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">10</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">num_pool_samples</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">100</span><span class="p">]</span>
<span class="p">]</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">is_run_from_ipython</span><span class="p">()</span> <span class="ow">and</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">job_id</span><span class="p">,</span> <span class="n">store</span> <span class="ow">in</span> <span class="n">embedded_experiments</span><span class="p">(</span><span class="vm">__file__</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">configs</span><span class="p">)):</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">configs</span><span class="p">[</span><span class="n">job_id</span><span class="p">]</span>
        <span class="n">config</span><span class="o">.</span><span class="n">seed</span> <span class="o">+=</span> <span class="n">job_id</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataclasses</span><span class="o">.</span><span class="n">asdict</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;log&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">config</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">store</span><span class="o">=</span><span class="n">store</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="n">store</span><span class="p">[</span><span class="s2">&quot;exception&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">traceback</span><span class="o">.</span><span class="n">format_exc</span><span class="p">()</span>
            <span class="k">raise</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">configs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>10</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">prettyprinter</span>

<span class="n">prettyprinter</span><span class="o">.</span><span class="n">install_extras</span><span class="p">({</span><span class="s2">&quot;dataclasses&quot;</span><span class="p">})</span>
<span class="n">prettyprinter</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">configs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4658,
        experiment_data_config=batchbald_redux.experiment_data.ImbalancedTestDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=0,
            validation_set_size=4000,
            validation_split_random_state=0,
            evaluation_set_size=4000,
            add_dataset_noise=False,
            minority_classes={2, 3, 4, 5, 6, 7},
            minority_class_percentage=0.0
        ),
        acquisition_size=10,
        max_training_set=450,
        num_pool_samples=20,
        ensemble_size=5,
        disable_training_augmentations=True
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4658,
        experiment_data_config=batchbald_redux.experiment_data.ImbalancedTestDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=0,
            validation_set_size=4000,
            validation_split_random_state=0,
            evaluation_set_size=4000,
            add_dataset_noise=False,
            minority_classes={2, 3, 4, 5, 6, 7},
            minority_class_percentage=0.0
        ),
        acquisition_size=10,
        max_training_set=450,
        num_pool_samples=20,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.EPIG,
        ensemble_size=5,
        disable_training_augmentations=True
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4659,
        experiment_data_config=batchbald_redux.experiment_data.ImbalancedTestDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=0,
            validation_set_size=4000,
            validation_split_random_state=0,
            evaluation_set_size=4000,
            add_dataset_noise=False,
            minority_classes={2, 3, 4, 5, 6, 7},
            minority_class_percentage=0.0
        ),
        acquisition_size=10,
        max_training_set=450,
        num_pool_samples=20,
        ensemble_size=5,
        disable_training_augmentations=True
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4659,
        experiment_data_config=batchbald_redux.experiment_data.ImbalancedTestDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=0,
            validation_set_size=4000,
            validation_split_random_state=0,
            evaluation_set_size=4000,
            add_dataset_noise=False,
            minority_classes={2, 3, 4, 5, 6, 7},
            minority_class_percentage=0.0
        ),
        acquisition_size=10,
        max_training_set=450,
        num_pool_samples=20,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.EPIG,
        ensemble_size=5,
        disable_training_augmentations=True
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4660,
        experiment_data_config=batchbald_redux.experiment_data.ImbalancedTestDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=0,
            validation_set_size=4000,
            validation_split_random_state=0,
            evaluation_set_size=4000,
            add_dataset_noise=False,
            minority_classes={2, 3, 4, 5, 6, 7},
            minority_class_percentage=0.0
        ),
        acquisition_size=10,
        max_training_set=450,
        num_pool_samples=20,
        ensemble_size=5,
        disable_training_augmentations=True
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4660,
        experiment_data_config=batchbald_redux.experiment_data.ImbalancedTestDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=0,
            validation_set_size=4000,
            validation_split_random_state=0,
            evaluation_set_size=4000,
            add_dataset_noise=False,
            minority_classes={2, 3, 4, 5, 6, 7},
            minority_class_percentage=0.0
        ),
        acquisition_size=10,
        max_training_set=450,
        num_pool_samples=20,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.EPIG,
        ensemble_size=5,
        disable_training_augmentations=True
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4661,
        experiment_data_config=batchbald_redux.experiment_data.ImbalancedTestDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=0,
            validation_set_size=4000,
            validation_split_random_state=0,
            evaluation_set_size=4000,
            add_dataset_noise=False,
            minority_classes={2, 3, 4, 5, 6, 7},
            minority_class_percentage=0.0
        ),
        acquisition_size=10,
        max_training_set=450,
        num_pool_samples=20,
        ensemble_size=5,
        disable_training_augmentations=True
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4661,
        experiment_data_config=batchbald_redux.experiment_data.ImbalancedTestDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=0,
            validation_set_size=4000,
            validation_split_random_state=0,
            evaluation_set_size=4000,
            add_dataset_noise=False,
            minority_classes={2, 3, 4, 5, 6, 7},
            minority_class_percentage=0.0
        ),
        acquisition_size=10,
        max_training_set=450,
        num_pool_samples=20,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.EPIG,
        ensemble_size=5,
        disable_training_augmentations=True
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4662,
        experiment_data_config=batchbald_redux.experiment_data.ImbalancedTestDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=0,
            validation_set_size=4000,
            validation_split_random_state=0,
            evaluation_set_size=4000,
            add_dataset_noise=False,
            minority_classes={2, 3, 4, 5, 6, 7},
            minority_class_percentage=0.0
        ),
        acquisition_size=10,
        max_training_set=450,
        num_pool_samples=20,
        ensemble_size=5,
        disable_training_augmentations=True
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4662,
        experiment_data_config=batchbald_redux.experiment_data.ImbalancedTestDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=0,
            validation_set_size=4000,
            validation_split_random_state=0,
            evaluation_set_size=4000,
            add_dataset_noise=False,
            minority_classes={2, 3, 4, 5, 6, 7},
            minority_class_percentage=0.0
        ),
        acquisition_size=10,
        max_training_set=450,
        num_pool_samples=20,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.EPIG,
        ensemble_size=5,
        disable_training_augmentations=True
    )
]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">store</span> <span class="o">=</span> <span class="p">{}</span>

<span class="n">config</span><span class="o">=</span><span class="n">configs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

<span class="n">config</span><span class="o">.</span><span class="n">max_training_set</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">config</span><span class="o">.</span><span class="n">experiment_data_config</span><span class="o">.</span><span class="n">initial_training_set_size</span> <span class="o">=</span> <span class="mi">400</span>  <span class="c1"># int(50000/10*4-1000)</span>
<span class="n">config</span><span class="o">.</span><span class="n">max_training_epochs</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">config</span><span class="o">.</span><span class="n">num_pool_samples</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">config</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">store</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>ImbalancedTestDistributionExperimentDataConfig(dataset_name=&#39;CIFAR-10&#39;, repetitions=1, initial_training_set_size=400, validation_set_size=4000, validation_split_random_state=0, evaluation_set_size=4000, add_dataset_noise=False, minority_classes={2, 3, 4, 5, 6, 7}, minority_class_percentage=0.0)
Files already downloaded and verified
Files already downloaded and verified
Evaluation Set Class Counts: [1000, 1000, 0, 0, 0, 0, 0, 0, 1000, 1000]
Creating: BALD(
	acquisition_size=10,
	num_pool_samples=5
)
Creating: Cifar10ModelTrainer(
	device=cuda,
	num_training_samples=1,
	num_validation_samples=20,
	max_training_epochs=1
)
Creating: TrainSelfDistillationEvalModel(
	num_pool_samples=5
)
Training set size 400:
Cosine Annealing
Epoch 1 metrics: {&#39;accuracy&#39;: 0.245625, &#39;crossentropy&#39;: 2.0901852226257325}
Cosine Annealing
Epoch 1 metrics: {&#39;accuracy&#39;: 0.33625, &#39;crossentropy&#39;: 1.932702169418335}
Cosine Annealing
Epoch 1 metrics: {&#39;accuracy&#39;: 0.2625, &#39;crossentropy&#39;: 1.965140504837036}
Cosine Annealing
Epoch 1 metrics: {&#39;accuracy&#39;: 0.34375, &#39;crossentropy&#39;: 1.9021611213684082}
Cosine Annealing
Epoch 1 metrics: {&#39;accuracy&#39;: 0.245, &#39;crossentropy&#39;: 2.1066539478302}
Perf after training {&#39;accuracy&#39;: 0.3355, &#39;crossentropy&#39;: tensor(1.9586)}
CandidateBatch(scores=[0.46315891719789504, 0.4231505304179928, 0.3833100349713272, 0.3782143635629611, 0.3764206563571689, 0.3669441361877186, 0.3640127074284958, 0.3546909277828616, 0.34928550656336643, 0.3473792822248405], indices=[28703, 3453, 36372, 5736, 30793, 1534, 18482, 25683, 39763, 36198])
[(&#39;id&#39;, 31742), (&#39;id&#39;, 3796), (&#39;id&#39;, 40189), (&#39;id&#39;, 6328), (&#39;id&#39;, 34030), (&#39;id&#39;, 1684), (&#39;id&#39;, 20388), (&#39;id&#39;, 28401), (&#39;id&#39;, 43950), (&#39;id&#39;, 39995)]
Acquiring (label, score)s: 2 (0.4632), 0 (0.4232), 0 (0.3833), 2 (0.3782), 4 (0.3764), 0 (0.3669), 0 (0.364), 0 (0.3547), 0 (0.3493), 5 (0.3474)
Training set size 410:
Cosine Annealing
Epoch 1 metrics: {&#39;accuracy&#39;: 0.31375, &#39;crossentropy&#39;: 2.0739346313476563}
Cosine Annealing
Epoch 1 metrics: {&#39;accuracy&#39;: 0.2775, &#39;crossentropy&#39;: 2.047981777191162}
Cosine Annealing
Epoch 1 metrics: {&#39;accuracy&#39;: 0.246875, &#39;crossentropy&#39;: 2.071867208480835}
Cosine Annealing
Epoch 1 metrics: {&#39;accuracy&#39;: 0.23875, &#39;crossentropy&#39;: 2.058145046234131}
Cosine Annealing
Epoch 1 metrics: {&#39;accuracy&#39;: 0.314375, &#39;crossentropy&#39;: 2.090928430557251}
Perf after training {&#39;accuracy&#39;: 0.32225, &#39;crossentropy&#39;: tensor(1.9943)}
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-20-debfac4d65fe&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">      7</span> config<span class="ansi-blue-fg">.</span>max_training_epochs <span class="ansi-blue-fg">=</span> <span class="ansi-cyan-fg">1</span>
<span class="ansi-green-intense-fg ansi-bold">      8</span> config<span class="ansi-blue-fg">.</span>num_pool_samples <span class="ansi-blue-fg">=</span> <span class="ansi-cyan-fg">5</span>
<span class="ansi-green-fg">----&gt; 9</span><span class="ansi-red-fg"> </span>config<span class="ansi-blue-fg">.</span>run<span class="ansi-blue-fg">(</span>store<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/unified_experiment.py</span> in <span class="ansi-cyan-fg">run</span><span class="ansi-blue-fg">(self, store)</span>
<span class="ansi-green-intense-fg ansi-bold">    265</span>         )
<span class="ansi-green-intense-fg ansi-bold">    266</span> 
<span class="ansi-green-fg">--&gt; 267</span><span class="ansi-red-fg">         </span>active_learner<span class="ansi-blue-fg">(</span>store<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    268</span> 
<span class="ansi-green-intense-fg ansi-bold">    269</span> <span class="ansi-red-fg"># Cell</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/unified_experiment.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, log)</span>
<span class="ansi-green-intense-fg ansi-bold">    128</span> 
<span class="ansi-green-intense-fg ansi-bold">    129</span>             <span class="ansi-green-fg">if</span> isinstance<span class="ansi-blue-fg">(</span>acquisition_function<span class="ansi-blue-fg">,</span> CandidateBatchComputer<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 130</span><span class="ansi-red-fg">                 </span>candidate_batch <span class="ansi-blue-fg">=</span> acquisition_function<span class="ansi-blue-fg">.</span>compute_candidate_batch<span class="ansi-blue-fg">(</span>trained_model<span class="ansi-blue-fg">,</span> pool_loader<span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>device<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    131</span>             <span class="ansi-green-fg">elif</span> isinstance<span class="ansi-blue-fg">(</span>acquisition_function<span class="ansi-blue-fg">,</span> EvalDatasetBatchComputer<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    132</span>                 <span class="ansi-green-fg">if</span> len<span class="ansi-blue-fg">(</span>data<span class="ansi-blue-fg">.</span>evaluation_dataset<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">&gt;</span> <span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/acquisition_functions.py</span> in <span class="ansi-cyan-fg">compute_candidate_batch</span><span class="ansi-blue-fg">(self, model, pool_loader, device)</span>
<span class="ansi-green-intense-fg ansi-bold">     75</span>         self<span class="ansi-blue-fg">,</span> model<span class="ansi-blue-fg">:</span> TrainedModel<span class="ansi-blue-fg">,</span> pool_loader<span class="ansi-blue-fg">:</span> torch<span class="ansi-blue-fg">.</span>utils<span class="ansi-blue-fg">.</span>data<span class="ansi-blue-fg">.</span>DataLoader<span class="ansi-blue-fg">,</span> device
<span class="ansi-green-intense-fg ansi-bold">     76</span>     ) -&gt; CandidateBatch:
<span class="ansi-green-fg">---&gt; 77</span><span class="ansi-red-fg">         </span>log_probs_N_K_C <span class="ansi-blue-fg">=</span> model<span class="ansi-blue-fg">.</span>get_log_probs_N_K_C<span class="ansi-blue-fg">(</span>pool_loader<span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>num_pool_samples<span class="ansi-blue-fg">,</span> device<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#34;cpu&#34;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     78</span> 
<span class="ansi-green-intense-fg ansi-bold">     79</span>         <span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>get_candidate_batch<span class="ansi-blue-fg">(</span>log_probs_N_K_C<span class="ansi-blue-fg">,</span> device<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/trained_model.py</span> in <span class="ansi-cyan-fg">get_log_probs_N_K_C</span><span class="ansi-blue-fg">(self, loader, num_samples, device, storage_device)</span>
<span class="ansi-green-intense-fg ansi-bold">     27</span> 
<span class="ansi-green-intense-fg ansi-bold">     28</span>     <span class="ansi-green-fg">def</span> get_log_probs_N_K_C<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> loader<span class="ansi-blue-fg">:</span> DataLoader<span class="ansi-blue-fg">,</span> num_samples<span class="ansi-blue-fg">:</span> int<span class="ansi-blue-fg">,</span> device<span class="ansi-blue-fg">:</span> object<span class="ansi-blue-fg">,</span> storage_device<span class="ansi-blue-fg">:</span> object<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">---&gt; 29</span><span class="ansi-red-fg">         </span>log_probs_N_K_C<span class="ansi-blue-fg">,</span> labels <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>get_log_probs_N_K_C_labels_N<span class="ansi-blue-fg">(</span>loader<span class="ansi-blue-fg">,</span> num_samples<span class="ansi-blue-fg">,</span> device<span class="ansi-blue-fg">,</span> storage_device<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     30</span>         <span class="ansi-green-fg">return</span> log_probs_N_K_C
<span class="ansi-green-intense-fg ansi-bold">     31</span> 

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/trained_model.py</span> in <span class="ansi-cyan-fg">get_log_probs_N_K_C_labels_N</span><span class="ansi-blue-fg">(self, loader, num_samples, device, storage_device)</span>
<span class="ansi-green-intense-fg ansi-bold">    110</span> 
<span class="ansi-green-intense-fg ansi-bold">    111</span>         <span class="ansi-green-fg">for</span> model <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">.</span>models<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 112</span><span class="ansi-red-fg">             log_probs_N_K_C, labels_B = model.get_log_probs_N_K_C_labels_N(
</span><span class="ansi-green-intense-fg ansi-bold">    113</span>                 loader<span class="ansi-blue-fg">=</span>loader<span class="ansi-blue-fg">,</span> num_samples<span class="ansi-blue-fg">=</span>member_num_samples<span class="ansi-blue-fg">,</span> device<span class="ansi-blue-fg">=</span>device<span class="ansi-blue-fg">,</span> storage_device<span class="ansi-blue-fg">=</span>storage_device
<span class="ansi-green-intense-fg ansi-bold">    114</span>             )

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/trained_model.py</span> in <span class="ansi-cyan-fg">get_log_probs_N_K_C_labels_N</span><span class="ansi-blue-fg">(self, loader, num_samples, device, storage_device)</span>
<span class="ansi-green-intense-fg ansi-bold">     50</span>         self<span class="ansi-blue-fg">,</span> loader<span class="ansi-blue-fg">:</span> DataLoader<span class="ansi-blue-fg">,</span> num_samples<span class="ansi-blue-fg">:</span> int<span class="ansi-blue-fg">,</span> device<span class="ansi-blue-fg">:</span> object<span class="ansi-blue-fg">,</span> storage_device<span class="ansi-blue-fg">:</span> object
<span class="ansi-green-intense-fg ansi-bold">     51</span>     ):
<span class="ansi-green-fg">---&gt; 52</span><span class="ansi-red-fg">         log_probs_N_K_C, labels_B = self.model.get_predictions_labels(
</span><span class="ansi-green-intense-fg ansi-bold">     53</span>             num_samples<span class="ansi-blue-fg">=</span>num_samples<span class="ansi-blue-fg">,</span> loader<span class="ansi-blue-fg">=</span>loader<span class="ansi-blue-fg">,</span> device<span class="ansi-blue-fg">=</span>device<span class="ansi-blue-fg">,</span> storage_device<span class="ansi-blue-fg">=</span>storage_device
<span class="ansi-green-intense-fg ansi-bold">     54</span>         )

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/consistent_mc_dropout.py</span> in <span class="ansi-cyan-fg">get_predictions_labels</span><span class="ansi-blue-fg">(self, num_samples, loader, device, storage_device)</span>
<span class="ansi-green-intense-fg ansi-bold">    147</span>         self<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span><span class="ansi-blue-fg">,</span> num_samples<span class="ansi-blue-fg">:</span> int<span class="ansi-blue-fg">,</span> loader<span class="ansi-blue-fg">:</span> data<span class="ansi-blue-fg">.</span>DataLoader<span class="ansi-blue-fg">,</span> device<span class="ansi-blue-fg">,</span> storage_device
<span class="ansi-green-intense-fg ansi-bold">    148</span>     ):
<span class="ansi-green-fg">--&gt; 149</span><span class="ansi-red-fg">         return bmodule_get_predictions_labels(
</span><span class="ansi-green-intense-fg ansi-bold">    150</span>             self<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    151</span>             num_samples<span class="ansi-blue-fg">=</span>num_samples<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/autograd/grad_mode.py</span> in <span class="ansi-cyan-fg">decorate_context</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">     24</span>         <span class="ansi-green-fg">def</span> decorate_context<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     25</span>             <span class="ansi-green-fg">with</span> self<span class="ansi-blue-fg">.</span>__class__<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">---&gt; 26</span><span class="ansi-red-fg">                 </span><span class="ansi-green-fg">return</span> func<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     27</span>         <span class="ansi-green-fg">return</span> cast<span class="ansi-blue-fg">(</span>F<span class="ansi-blue-fg">,</span> decorate_context<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     28</span> 

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/consistent_mc_dropout.py</span> in <span class="ansi-cyan-fg">bmodule_get_predictions_labels</span><span class="ansi-blue-fg">(self, num_samples, loader, device, storage_device)</span>
<span class="ansi-green-intense-fg ansi-bold">    391</span> 
<span class="ansi-green-intense-fg ansi-bold">    392</span>     <span class="ansi-blue-fg">@</span>toma<span class="ansi-blue-fg">.</span>execute<span class="ansi-blue-fg">.</span>range<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">,</span> num_samples<span class="ansi-blue-fg">,</span> <span class="ansi-cyan-fg">128</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 393</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">def</span> get_prediction_batch<span class="ansi-blue-fg">(</span>start<span class="ansi-blue-fg">,</span> end<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    394</span>         <span class="ansi-green-fg">nonlocal</span> predictions
<span class="ansi-green-intense-fg ansi-bold">    395</span>         <span class="ansi-green-fg">nonlocal</span> labels

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/toma/__init__.py</span> in <span class="ansi-cyan-fg">execute_range</span><span class="ansi-blue-fg">(func)</span>
<span class="ansi-green-intense-fg ansi-bold">    184</span> 
<span class="ansi-green-intense-fg ansi-bold">    185</span>             <span class="ansi-green-fg">def</span> execute_range<span class="ansi-blue-fg">(</span>func<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 186</span><span class="ansi-red-fg">                 </span><span class="ansi-green-fg">return</span> explicit<span class="ansi-blue-fg">.</span>range<span class="ansi-blue-fg">(</span>func<span class="ansi-blue-fg">,</span> start<span class="ansi-blue-fg">,</span> end<span class="ansi-blue-fg">,</span> initial_step<span class="ansi-blue-fg">,</span> toma_cache_type<span class="ansi-blue-fg">=</span>cache_type<span class="ansi-blue-fg">,</span> toma_context<span class="ansi-blue-fg">=</span>context<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    187</span> 
<span class="ansi-green-intense-fg ansi-bold">    188</span>             <span class="ansi-green-fg">return</span> execute_range

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/toma/__init__.py</span> in <span class="ansi-cyan-fg">range</span><span class="ansi-blue-fg">(func, start, end, initial_step, toma_context, toma_cache_type, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    267</span>         <span class="ansi-green-fg">while</span> current <span class="ansi-blue-fg">&lt;</span> end<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    268</span>             <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 269</span><span class="ansi-red-fg">                 </span>func<span class="ansi-blue-fg">(</span>current<span class="ansi-blue-fg">,</span> min<span class="ansi-blue-fg">(</span>current <span class="ansi-blue-fg">+</span> batchsize<span class="ansi-blue-fg">.</span>get<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> end<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    270</span>                 current <span class="ansi-blue-fg">+=</span> batchsize<span class="ansi-blue-fg">.</span>get<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    271</span>                 gc_cuda<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/consistent_mc_dropout.py</span> in <span class="ansi-cyan-fg">get_prediction_batch</span><span class="ansi-blue-fg">(start, end)</span>
<span class="ansi-green-intense-fg ansi-bold">    407</span>         <span class="ansi-green-fg">for</span> batch_x<span class="ansi-blue-fg">,</span> batch_labels <span class="ansi-green-fg">in</span> loader<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    408</span>             batch_x <span class="ansi-blue-fg">=</span> batch_x<span class="ansi-blue-fg">.</span>to<span class="ansi-blue-fg">(</span>device<span class="ansi-blue-fg">=</span>device<span class="ansi-blue-fg">,</span> non_blocking<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 409</span><span class="ansi-red-fg">             </span>batch_predictions <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">(</span>batch_x<span class="ansi-blue-fg">,</span> num_sub_samples<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    410</span> 
<span class="ansi-green-intense-fg ansi-bold">    411</span>             batch_size <span class="ansi-blue-fg">=</span> len<span class="ansi-blue-fg">(</span>batch_predictions<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_call_impl</span><span class="ansi-blue-fg">(self, *input, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    725</span>             result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_slow_forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    726</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 727</span><span class="ansi-red-fg">             </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    728</span>         for hook in itertools.chain(
<span class="ansi-green-intense-fg ansi-bold">    729</span>                 _global_forward_hooks<span class="ansi-blue-fg">.</span>values<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/consistent_mc_dropout.py</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">(self, input_B, num_samples, return_embedding, freeze_encoder)</span>
<span class="ansi-green-intense-fg ansi-bold">    106</span>             <span class="ansi-green-fg">return</span> output_B_1<span class="ansi-blue-fg">,</span> embedding_B_1
<span class="ansi-green-intense-fg ansi-bold">    107</span> 
<span class="ansi-green-fg">--&gt; 108</span><span class="ansi-red-fg">         </span>features_B <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>deterministic_forward_impl<span class="ansi-blue-fg">(</span>input_B<span class="ansi-blue-fg">,</span> freeze_encoder<span class="ansi-blue-fg">=</span>freeze_encoder<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    109</span>         mc_features_BK <span class="ansi-blue-fg">=</span> BayesianModule<span class="ansi-blue-fg">.</span>mc_tensor<span class="ansi-blue-fg">(</span>features_B<span class="ansi-blue-fg">,</span> num_samples<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    110</span>         mc_output_BK<span class="ansi-blue-fg">,</span> mc_embedding_BK <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>mc_forward_impl<span class="ansi-blue-fg">(</span>mc_features_BK<span class="ansi-blue-fg">,</span> freeze_encoder<span class="ansi-blue-fg">=</span>freeze_encoder<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/resnet_models.py</span> in <span class="ansi-cyan-fg">deterministic_forward_impl</span><span class="ansi-blue-fg">(self, x, freeze_encoder)</span>
<span class="ansi-green-intense-fg ansi-bold">    269</span>             x <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>maxpool<span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    270</span> 
<span class="ansi-green-fg">--&gt; 271</span><span class="ansi-red-fg">             </span>x <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>layer1<span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    272</span>             x <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>layer2<span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    273</span>             x <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>layer3<span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_call_impl</span><span class="ansi-blue-fg">(self, *input, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    725</span>             result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_slow_forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    726</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 727</span><span class="ansi-red-fg">             </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    728</span>         for hook in itertools.chain(
<span class="ansi-green-intense-fg ansi-bold">    729</span>                 _global_forward_hooks<span class="ansi-blue-fg">.</span>values<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/nn/modules/container.py</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">(self, input)</span>
<span class="ansi-green-intense-fg ansi-bold">    115</span>     <span class="ansi-green-fg">def</span> forward<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> input<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    116</span>         <span class="ansi-green-fg">for</span> module <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 117</span><span class="ansi-red-fg">             </span>input <span class="ansi-blue-fg">=</span> module<span class="ansi-blue-fg">(</span>input<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    118</span>         <span class="ansi-green-fg">return</span> input
<span class="ansi-green-intense-fg ansi-bold">    119</span> 

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_call_impl</span><span class="ansi-blue-fg">(self, *input, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    725</span>             result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_slow_forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    726</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 727</span><span class="ansi-red-fg">             </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    728</span>         for hook in itertools.chain(
<span class="ansi-green-intense-fg ansi-bold">    729</span>                 _global_forward_hooks<span class="ansi-blue-fg">.</span>values<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/resnet_models.py</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">(self, x)</span>
<span class="ansi-green-intense-fg ansi-bold">     87</span> 
<span class="ansi-green-intense-fg ansi-bold">     88</span>         out <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>conv1<span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 89</span><span class="ansi-red-fg">         </span>out <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>bn1<span class="ansi-blue-fg">(</span>out<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     90</span>         out <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>relu<span class="ansi-blue-fg">(</span>out<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     91</span> 

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_call_impl</span><span class="ansi-blue-fg">(self, *input, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    725</span>             result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_slow_forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    726</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 727</span><span class="ansi-red-fg">             </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    728</span>         for hook in itertools.chain(
<span class="ansi-green-intense-fg ansi-bold">    729</span>                 _global_forward_hooks<span class="ansi-blue-fg">.</span>values<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">(self, input)</span>
<span class="ansi-green-intense-fg ansi-bold">    132</span>             input<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    133</span>             <span class="ansi-red-fg"># If buffers are not to be tracked, ensure that they won&#39;t be updated</span>
<span class="ansi-green-fg">--&gt; 134</span><span class="ansi-red-fg">             </span>self<span class="ansi-blue-fg">.</span>running_mean <span class="ansi-green-fg">if</span> <span class="ansi-green-fg">not</span> self<span class="ansi-blue-fg">.</span>training <span class="ansi-green-fg">or</span> self<span class="ansi-blue-fg">.</span>track_running_stats <span class="ansi-green-fg">else</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    135</span>             self<span class="ansi-blue-fg">.</span>running_var <span class="ansi-green-fg">if</span> <span class="ansi-green-fg">not</span> self<span class="ansi-blue-fg">.</span>training <span class="ansi-green-fg">or</span> self<span class="ansi-blue-fg">.</span>track_running_stats <span class="ansi-green-fg">else</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    136</span>             self.weight, self.bias, bn_training, exponential_average_factor, self.eps)

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">__getattr__</span><span class="ansi-blue-fg">(self, name)</span>
<span class="ansi-green-intense-fg ansi-bold">    765</span>     <span class="ansi-green-fg">def</span> __getattr__<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> name<span class="ansi-blue-fg">:</span> str<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">-&gt;</span> Union<span class="ansi-blue-fg">[</span>Tensor<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#39;Module&#39;</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    766</span>         <span class="ansi-green-fg">if</span> <span class="ansi-blue-fg">&#39;_parameters&#39;</span> <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">.</span>__dict__<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 767</span><span class="ansi-red-fg">             </span>_parameters <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>__dict__<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">&#39;_parameters&#39;</span><span class="ansi-blue-fg">]</span>
<span class="ansi-green-intense-fg ansi-bold">    768</span>             <span class="ansi-green-fg">if</span> name <span class="ansi-green-fg">in</span> _parameters<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    769</span>                 <span class="ansi-green-fg">return</span> _parameters<span class="ansi-blue-fg">[</span>name<span class="ansi-blue-fg">]</span>

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

