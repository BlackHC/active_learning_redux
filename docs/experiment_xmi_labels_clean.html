---

title: Experiment XMI Labels Clean


keywords: fastai
sidebar: home_sidebar

summary: "Can we get better by training on our assumptions?"
description: "Can we get better by training on our assumptions?"
nb_path: "09g_experiment_xmi_labels_clean.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 09g_experiment_xmi_labels_clean.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Appended /home/blackhc/PycharmProjects/bald-ical/src to paths
Switched to directory /home/blackhc/PycharmProjects/bald-ical
%load_ext autoreload
%autoreload 2
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Import modules and functions were are going to use.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">dataclasses</span>
<span class="kn">import</span> <span class="nn">traceback</span>
<span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Type</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.utils.data</span>
<span class="kn">from</span> <span class="nn">blackhc.project</span> <span class="kn">import</span> <span class="n">is_run_from_ipython</span>
<span class="kn">from</span> <span class="nn">blackhc.project.experiment</span> <span class="kn">import</span> <span class="n">embedded_experiments</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>

<span class="kn">import</span> <span class="nn">batchbald_redux.acquisition_functions</span> <span class="k">as</span> <span class="nn">acquisition_functions</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.acquisition_functions</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">CandidateBatchComputer</span><span class="p">,</span>
    <span class="n">EvalCandidateBatchComputer</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.active_learning</span> <span class="kn">import</span> <span class="n">ActiveLearningData</span><span class="p">,</span> <span class="n">RandomFixedLengthSampler</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.black_box_model_training</span> <span class="kn">import</span> <span class="n">evaluate</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">train_double_snapshots</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.dataset_challenges</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">NamedDataset</span><span class="p">,</span>
    <span class="n">create_repeated_MNIST_dataset</span><span class="p">,</span>
    <span class="n">get_balanced_sample_indices</span><span class="p">,</span>
    <span class="n">get_base_dataset_index</span><span class="p">,</span>
    <span class="n">get_target</span><span class="p">,</span> <span class="n">AdditiveGaussianNoise</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.di</span> <span class="kn">import</span> <span class="n">DependencyInjection</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.fast_mnist</span> <span class="kn">import</span> <span class="n">FastMNIST</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.model_optimizer_factory</span> <span class="kn">import</span> <span class="n">ModelOptimizerFactory</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.models</span> <span class="kn">import</span> <span class="n">MnistOptimizerFactory</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># From the BatchBALD Repo</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.train_eval_model</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">TrainEvalModel</span><span class="p">,</span>
    <span class="n">TrainSelfDistillationEvalModel</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.trained_model</span> <span class="kn">import</span> <span class="n">TrainedMCDropoutModel</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="compute_entropy_from_probs" class="doc_header"><code>compute_entropy_from_probs</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/experiment_xmi_labels_clean.py#L52" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>compute_entropy_from_probs</code>(<strong><code>probs_N_K_C</code></strong>:<code>Tensor</code>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">blackhc.progress_bar</span> <span class="kn">import</span> <span class="n">create_progress_bar</span>
<span class="kn">from</span> <span class="nn">toma</span> <span class="kn">import</span> <span class="n">toma</span>


<span class="k">def</span> <span class="nf">compute_entropy_from_probs</span><span class="p">(</span><span class="n">probs_N_K_C</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="n">N</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="n">probs_N_K_C</span><span class="o">.</span><span class="n">shape</span>

    <span class="n">entropies_N</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>

    <span class="n">pbar</span> <span class="o">=</span> <span class="n">create_progress_bar</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">tqdm_args</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Entropy&quot;</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
    <span class="n">pbar</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

    <span class="nd">@toma</span><span class="o">.</span><span class="n">execute</span><span class="o">.</span><span class="n">chunked</span><span class="p">(</span><span class="n">probs_N_K_C</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="n">probs_n_K_C</span><span class="p">,</span> <span class="n">start</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">end</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">mean_probs_n_C</span> <span class="o">=</span> <span class="n">probs_n_K_C</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">nats_n_C</span> <span class="o">=</span> <span class="n">mean_probs_n_C</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">mean_probs_n_C</span><span class="p">)</span>
        <span class="n">nats_n_C</span><span class="p">[</span><span class="n">mean_probs_n_C</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="n">entropies_N</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">nats_n_C</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>

    <span class="n">pbar</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">entropies_N</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;./data/mnist_train_predictions.pt&quot;</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">train_entropies</span> <span class="o">=</span> <span class="n">compute_entropy_from_probs</span><span class="p">(</span><span class="n">train_predictions</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">train_entropies</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="nb">range</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(array([55951.,  1227.,   635.,   386.,   241.,   206.,   130.,   117.,
          118.,    74.]),
 array([0.  , 0.02, 0.04, 0.06, 0.08, 0.1 , 0.12, 0.14, 0.16, 0.18, 0.2 ]),
 &lt;BarContainer object of 10 artists&gt;)</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Experiment" class="doc_header"><code>class</code> <code>Experiment</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/experiment_xmi_labels_clean.py#L77" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Experiment</code>(<strong><code>seed</code></strong>:<code>int</code>=<em><code>1337</code></em>, <strong><code>acquisition_size</code></strong>:<code>int</code>=<em><code>5</code></em>, <strong><code>max_training_set</code></strong>:<code>int</code>=<em><code>300</code></em>, <strong><code>num_pool_samples</code></strong>:<code>int</code>=<em><code>20</code></em>, <strong><code>num_validation_samples</code></strong>:<code>int</code>=<em><code>20</code></em>, <strong><code>num_training_samples</code></strong>:<code>int</code>=<em><code>1</code></em>, <strong><code>num_patience_epochs</code></strong>:<code>int</code>=<em><code>20</code></em>, <strong><code>max_training_epochs</code></strong>:<code>int</code>=<em><code>120</code></em>, <strong><code>training_batch_size</code></strong>:<code>int</code>=<em><code>64</code></em>, <strong><code>device</code></strong>:<code>str</code>=<em><code>'cuda'</code></em>, <strong><code>validation_set_size</code></strong>:<code>int</code>=<em><code>1024</code></em>, <strong><code>initial_training_set_size</code></strong>:<code>int</code>=<em><code>20</code></em>, <strong><code>min_samples_per_epoch</code></strong>:<code>int</code>=<em><code>1024</code></em>, <strong><code>repeated_mnist_repetitions</code></strong>:<code>int</code>=<em><code>1</code></em>, <strong><code>add_dataset_noise</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>acquisition_function</code></strong>:<code>Union</code>[<code>Type</code>[<a href="/batchbald_redux/acquisition_functions.html#CandidateBatchComputer"><code>CandidateBatchComputer</code></a>], <code>Type</code>[<a href="/batchbald_redux/acquisition_functions.html#EvalCandidateBatchComputer"><code>EvalCandidateBatchComputer</code></a>]]=<em><code>BALD</code></em>, <strong><code>train_eval_model</code></strong>:<a href="/batchbald_redux/train_eval_model.html#TrainEvalModel"><code>TrainEvalModel</code></a>=<em><code>TrainSelfDistillationEvalModel</code></em>, <strong><code>model_optimizer_factory</code></strong>:<code>Type</code>[<a href="/batchbald_redux/model_optimizer_factory.html#ModelOptimizerFactory"><code>ModelOptimizerFactory</code></a>]=<em><code>MnistOptimizerFactory</code></em>, <strong><code>acquisition_function_args</code></strong>:<code>dict</code>=<em><code>None</code></em>, <strong><code>temperature</code></strong>:<code>float</code>=<em><code>0.0</code></em>)</p>
</blockquote>
<p>Experiment(seed: int = 1337, acquisition_size: int = 5, max_training_set: int = 300, num_pool_samples: int = 20, num_validation_samples: int = 20, num_training_samples: int = 1, num_patience_epochs: int = 20, max_training_epochs: int = 120, training_batch_size: int = 64, device: str = 'cuda', validation_set_size: int = 1024, initial_training_set_size: int = 20, min_samples_per_epoch: int = 1024, repeated_mnist_repetitions: int = 1, add_dataset_noise: bool = False, acquisition_function: Union[Type[batchbald_redux.acquisition_functions.CandidateBatchComputer], Type[batchbald_redux.acquisition_functions.EvalCandidateBatchComputer]] = &lt;class 'batchbald_redux.acquisition_functions.BALD'&gt;, train_eval_model: batchbald_redux.train_eval_model.TrainEvalModel = &lt;class 'batchbald_redux.train_eval_model.TrainSelfDistillationEvalModel'&gt;, model_optimizer_factory: Type[batchbald_redux.model_optimizer_factory.ModelOptimizerFactory] = &lt;class 'batchbald_redux.models.MnistOptimizerFactory'&gt;, acquisition_function_args: dict = None, temperature: float = 0.0)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">Experiment</span><span class="p">:</span>
    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1337</span>
    <span class="n">acquisition_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">max_training_set</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">300</span>
    <span class="n">num_pool_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="n">num_validation_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="n">num_training_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">num_patience_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">4</span>
    <span class="n">max_training_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">30</span> <span class="o">*</span> <span class="mi">4</span>
    <span class="n">training_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span>
    <span class="n">validation_set_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span>
    <span class="n">initial_training_set_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="n">min_samples_per_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span>
    <span class="n">repeated_mnist_repetitions</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">add_dataset_noise</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">acquisition_function</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
        <span class="n">Type</span><span class="p">[</span><span class="n">CandidateBatchComputer</span><span class="p">],</span> <span class="n">Type</span><span class="p">[</span><span class="n">EvalCandidateBatchComputer</span><span class="p">]</span>
    <span class="p">]</span> <span class="o">=</span> <span class="n">acquisition_functions</span><span class="o">.</span><span class="n">BALD</span>
    <span class="n">train_eval_model</span><span class="p">:</span> <span class="n">TrainEvalModel</span> <span class="o">=</span> <span class="n">TrainSelfDistillationEvalModel</span>
    <span class="n">model_optimizer_factory</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">ModelOptimizerFactory</span><span class="p">]</span> <span class="o">=</span> <span class="n">MnistOptimizerFactory</span>
    <span class="n">acquisition_function_args</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">def</span> <span class="nf">load_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">ActiveLearningData</span><span class="p">,</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">Dataset</span><span class="p">):</span>
        <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">NamedDataset</span><span class="p">(</span>
            <span class="n">FastMNIST</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="s2">&quot;FastMNIST (train)&quot;</span>
        <span class="p">)</span>
        <span class="n">train_predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;./data/mnist_train_predictions.pt&quot;</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">override_targets</span><span class="p">(</span><span class="n">targets</span><span class="o">=</span><span class="n">train_predictions</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

        <span class="n">train_entropies</span> <span class="o">=</span> <span class="n">compute_entropy_from_probs</span><span class="p">(</span><span class="n">train_predictions</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:])</span>

        <span class="n">allowed_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">train_entropies</span> <span class="o">&lt;</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">as_tuple</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Removing </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">allowed_indices</span><span class="p">)</span><span class="si">}</span><span class="s2"> training samples with entropy &gt;= 0.01.&quot;</span><span class="p">)</span>

        <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">subset</span><span class="p">(</span><span class="n">allowed_indices</span><span class="p">)</span>

        <span class="c1"># If we over-sample the train set, we do so after picking the initial train set to avoid duplicates.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">repeated_mnist_repetitions</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">repeated_mnist_repetitions</span>

        <span class="n">num_classes</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">get_num_classes</span><span class="p">()</span>
        <span class="n">initial_samples_per_class</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">initial_training_set_size</span> <span class="o">//</span> <span class="n">num_classes</span>
        <span class="n">initial_training_set_indices</span> <span class="o">=</span> <span class="n">get_balanced_sample_indices</span><span class="p">(</span>
            <span class="n">train_dataset</span><span class="p">,</span>
            <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span>
            <span class="n">samples_per_class</span><span class="o">=</span><span class="n">initial_samples_per_class</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># If we over-sample the train set, we do so after picking the initial train set to avoid duplicates.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">repeated_mnist_repetitions</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mnist_repetitions</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_dataset_noise</span><span class="p">:</span>
            <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">AdditiveGaussianNoise</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>

        <span class="n">active_learning_data</span> <span class="o">=</span> <span class="n">ActiveLearningData</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>

        <span class="n">active_learning_data</span><span class="o">.</span><span class="n">acquire</span><span class="p">(</span><span class="n">initial_training_set_indices</span><span class="p">)</span>

        <span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">active_learning_data</span><span class="o">.</span><span class="n">extract_dataset_from_pool</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">validation_set_size</span><span class="p">)</span>
        <span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">NamedDataset</span><span class="p">(</span>
            <span class="n">validation_dataset</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;FastMNIST (validation, </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">validation_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples)&quot;</span>
        <span class="p">)</span>

        <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">FastMNIST</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">NamedDataset</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;FastMNIST (test, </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples)&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">active_learning_data</span><span class="p">,</span> <span class="n">validation_dataset</span><span class="p">,</span> <span class="n">test_dataset</span><span class="p">,</span> <span class="n">initial_training_set_indices</span>

    <span class="c1"># Simple Dependency Injection</span>
    <span class="k">def</span> <span class="nf">create_acquisition_function</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">di</span> <span class="o">=</span> <span class="n">DependencyInjection</span><span class="p">(</span><span class="nb">vars</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">di</span><span class="o">.</span><span class="n">create_dataclass_type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">acquisition_function</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">create_train_eval_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">runtime_config</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TrainEvalModel</span><span class="p">:</span>
        <span class="n">config</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="nb">vars</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span> <span class="o">**</span><span class="n">runtime_config</span><span class="p">}</span>
        <span class="n">di</span> <span class="o">=</span> <span class="n">DependencyInjection</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="p">[])</span>
        <span class="k">return</span> <span class="n">di</span><span class="o">.</span><span class="n">create_dataclass_type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_eval_model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">store</span><span class="p">):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

        <span class="c1"># Active Learning setup</span>
        <span class="n">active_learning_data</span><span class="p">,</span> <span class="n">validation_dataset</span><span class="p">,</span> <span class="n">test_dataset</span><span class="p">,</span> <span class="n">initial_training_set_indices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">()</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;initial_training_set_indices&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">initial_training_set_indices</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;dataset_info&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">training</span><span class="o">=</span><span class="nb">repr</span><span class="p">(</span><span class="n">active_learning_data</span><span class="o">.</span><span class="n">base_dataset</span><span class="p">),</span> <span class="n">test</span><span class="o">=</span><span class="nb">repr</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">))</span>

        <span class="c1"># initial_training_set_indices = active_learning_data.get_random_pool_indices(self.initial_set_size)</span>
        <span class="c1"># initial_training_set_indices = get_balanced_sample_indices(</span>
        <span class="c1">#     active_learning_data.pool_dataset, 10, self.initial_set_size // 10</span>
        <span class="c1"># )</span>

        <span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
            <span class="n">active_learning_data</span><span class="o">.</span><span class="n">training_dataset</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">RandomFixedLengthSampler</span><span class="p">(</span><span class="n">active_learning_data</span><span class="o">.</span><span class="n">training_dataset</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_samples_per_epoch</span><span class="p">),</span>
            <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">pool_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
            <span class="n">active_learning_data</span><span class="o">.</span><span class="n">pool_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

        <span class="n">validation_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">validation_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;active_learning_steps&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">active_learning_steps</span> <span class="o">=</span> <span class="n">store</span><span class="p">[</span><span class="s2">&quot;active_learning_steps&quot;</span><span class="p">]</span>

        <span class="n">acquisition_function</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_acquisition_function</span><span class="p">()</span>

        <span class="c1"># Active Training Loop</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">training_set_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">active_learning_data</span><span class="o">.</span><span class="n">training_dataset</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training set size </span><span class="si">{</span><span class="n">training_set_size</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>

            <span class="c1"># iteration_log = dict(training={}, pool_training={}, evaluation_metrics=None, acquisition=None)</span>
            <span class="n">active_learning_steps</span><span class="o">.</span><span class="n">append</span><span class="p">({})</span>
            <span class="n">iteration_log</span> <span class="o">=</span> <span class="n">active_learning_steps</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

            <span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;training&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

            <span class="n">model_optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_optimizer_factory</span><span class="p">()</span><span class="o">.</span><span class="n">create_model_optimizer</span><span class="p">()</span>

            <span class="n">double_snapshots</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="n">training_set_size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">train</span><span class="p">(</span>
                    <span class="n">model</span><span class="o">=</span><span class="n">model_optimizer</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                    <span class="n">optimizer</span><span class="o">=</span><span class="n">model_optimizer</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span>
                    <span class="n">training_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_training_samples</span><span class="p">,</span>
                    <span class="n">validation_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_validation_samples</span><span class="p">,</span>
                    <span class="n">train_loader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span>
                    <span class="n">validation_loader</span><span class="o">=</span><span class="n">validation_loader</span><span class="p">,</span>
                    <span class="n">patience</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_patience_epochs</span><span class="p">,</span>
                    <span class="n">max_epochs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_training_epochs</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                    <span class="n">training_log</span><span class="o">=</span><span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;training&quot;</span><span class="p">],</span>
                <span class="p">)</span>

            <span class="n">evaluation_metrics</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">model_optimizer</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="n">num_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_validation_samples</span><span class="p">,</span>
                <span class="n">loader</span><span class="o">=</span><span class="n">test_loader</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;evaluation_metrics&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">evaluation_metrics</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Perf after training </span><span class="si">{</span><span class="n">evaluation_metrics</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">training_set_size</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_training_set</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Done.&quot;</span><span class="p">)</span>
                <span class="k">break</span>

            <span class="n">trained_model</span> <span class="o">=</span> <span class="n">TrainedMCDropoutModel</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_pool_samples</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model_optimizer</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">acquisition_function</span><span class="p">,</span> <span class="n">CandidateBatchComputer</span><span class="p">):</span>
                <span class="n">candidate_batch</span> <span class="o">=</span> <span class="n">acquisition_function</span><span class="o">.</span><span class="n">compute_candidate_batch</span><span class="p">(</span><span class="n">trained_model</span><span class="p">,</span> <span class="n">pool_loader</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">acquisition_function</span><span class="p">,</span> <span class="n">EvalCandidateBatchComputer</span><span class="p">):</span>
                <span class="n">current_max_epochs</span> <span class="o">=</span> <span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;training&quot;</span><span class="p">][</span><span class="s2">&quot;best_epoch&quot;</span><span class="p">]</span>

                <span class="n">train_eval_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_train_eval_model</span><span class="p">(</span>
                    <span class="nb">dict</span><span class="p">(</span>
                        <span class="n">max_epochs</span><span class="o">=</span><span class="n">current_max_epochs</span><span class="p">,</span>
                        <span class="n">training_dataset</span><span class="o">=</span><span class="n">active_learning_data</span><span class="o">.</span><span class="n">training_dataset</span><span class="p">,</span>
                        <span class="n">eval_dataset</span><span class="o">=</span><span class="n">active_learning_data</span><span class="o">.</span><span class="n">pool_dataset</span><span class="p">,</span>
                        <span class="n">validation_loader</span><span class="o">=</span><span class="n">validation_loader</span><span class="p">,</span>
                        <span class="n">trained_model</span><span class="o">=</span><span class="n">trained_model</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>

                <span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;eval_training&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="n">trained_eval_model</span> <span class="o">=</span> <span class="n">train_eval_model</span><span class="p">(</span><span class="n">training_log</span><span class="o">=</span><span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;eval_training&quot;</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

                <span class="n">candidate_batch</span> <span class="o">=</span> <span class="n">acquisition_function</span><span class="o">.</span><span class="n">compute_candidate_batch</span><span class="p">(</span>
                    <span class="n">trained_model</span><span class="p">,</span> <span class="n">trained_eval_model</span><span class="p">,</span> <span class="n">pool_loader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown acquisition function </span><span class="si">{</span><span class="n">acquisition_function</span><span class="si">}</span><span class="s2">!&quot;</span><span class="p">)</span>

            <span class="n">candidate_global_indices</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">get_base_dataset_index</span><span class="p">(</span><span class="n">active_learning_data</span><span class="o">.</span><span class="n">pool_dataset</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span><span class="o">.</span><span class="n">index</span>
                <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">candidate_batch</span><span class="o">.</span><span class="n">indices</span>
            <span class="p">]</span>
            <span class="n">candidate_labels</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">get_target</span><span class="p">(</span><span class="n">active_learning_data</span><span class="o">.</span><span class="n">pool_dataset</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">candidate_batch</span><span class="o">.</span><span class="n">indices</span>
            <span class="p">]</span>

            <span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;acquisition&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
                <span class="n">indices</span><span class="o">=</span><span class="n">candidate_global_indices</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">candidate_labels</span><span class="p">,</span> <span class="n">scores</span><span class="o">=</span><span class="n">candidate_batch</span><span class="o">.</span><span class="n">scores</span>
            <span class="p">)</span>

            <span class="n">active_learning_data</span><span class="o">.</span><span class="n">acquire</span><span class="p">(</span><span class="n">candidate_batch</span><span class="o">.</span><span class="n">indices</span><span class="p">)</span>

            <span class="n">ls</span> <span class="o">=</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">score</span><span class="si">:</span><span class="s2">.4</span><span class="si">}</span><span class="s2">)&quot;</span> <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">candidate_labels</span><span class="p">,</span> <span class="n">candidate_batch</span><span class="o">.</span><span class="n">scores</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Acquiring (label, score)s: </span><span class="si">{</span><span class="n">ls</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">experiment</span> <span class="o">=</span> <span class="n">Experiment</span><span class="p">(</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">1120</span><span class="p">,</span>
    <span class="n">max_training_epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">num_patience_epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">max_training_set</span><span class="o">=</span><span class="mi">130</span><span class="p">,</span>
    <span class="n">acquisition_function</span><span class="o">=</span><span class="n">acquisition_functions</span><span class="o">.</span><span class="n">CoreSetBALD</span><span class="p">,</span>
    <span class="n">acquisition_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">num_pool_samples</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">initial_training_set_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">min_samples_per_epoch</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">experiment</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Removing 5678 training samples with entropy &gt;= 0.01.
Resolved: CoreSetBALD with {&#39;acquisition_size&#39;: 1}
Creating: CoreSetBALD(acquisition_size=1)
Training set size 20:
Epoch metrics: {&#39;accuracy&#39;: 0.521484375, &#39;crossentropy&#39;: 1.889914259314537}
Epoch metrics: {&#39;accuracy&#39;: 0.57421875, &#39;crossentropy&#39;: 1.9272612035274506}
LowCrossEntropy-PatienceWithSnapshot: 1 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.5810546875, &#39;crossentropy&#39;: 2.288734942674637}
LowCrossEntropy-PatienceWithSnapshot: 2 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.607421875, &#39;crossentropy&#39;: 2.4602707028388977}
LowCrossEntropy-PatienceWithSnapshot: 3 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.6015625, &#39;crossentropy&#39;: 2.550099015235901}
LowCrossEntropy-PatienceWithSnapshot: 4 / 20
Accuracy-PatienceWithSnapshot: 1 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.6142578125, &#39;crossentropy&#39;: 2.5500193536281586}
LowCrossEntropy-PatienceWithSnapshot: 5 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.611328125, &#39;crossentropy&#39;: 2.8304773569107056}
LowCrossEntropy-PatienceWithSnapshot: 6 / 20
Accuracy-PatienceWithSnapshot: 1 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.5791015625, &#39;crossentropy&#39;: 3.0471464097499847}
LowCrossEntropy-PatienceWithSnapshot: 7 / 20
Accuracy-PatienceWithSnapshot: 2 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.611328125, &#39;crossentropy&#39;: 2.850183144211769}
LowCrossEntropy-PatienceWithSnapshot: 8 / 20
Accuracy-PatienceWithSnapshot: 3 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.60546875, &#39;crossentropy&#39;: 2.8832032084465027}
LowCrossEntropy-PatienceWithSnapshot: 9 / 20
Accuracy-PatienceWithSnapshot: 4 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.6005859375, &#39;crossentropy&#39;: 3.0551536083221436}
LowCrossEntropy-PatienceWithSnapshot: 10 / 20
Accuracy-PatienceWithSnapshot: 5 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.6220703125, &#39;crossentropy&#39;: 2.9148428440093994}
LowCrossEntropy-PatienceWithSnapshot: 11 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.61328125, &#39;crossentropy&#39;: 3.061246871948242}
LowCrossEntropy-PatienceWithSnapshot: 12 / 20
Accuracy-PatienceWithSnapshot: 1 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.6015625, &#39;crossentropy&#39;: 3.5231330692768097}
LowCrossEntropy-PatienceWithSnapshot: 13 / 20
Accuracy-PatienceWithSnapshot: 2 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.6015625, &#39;crossentropy&#39;: 3.413724660873413}
LowCrossEntropy-PatienceWithSnapshot: 14 / 20
Accuracy-PatienceWithSnapshot: 3 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.59375, &#39;crossentropy&#39;: 3.4970711767673492}
LowCrossEntropy-PatienceWithSnapshot: 15 / 20
Accuracy-PatienceWithSnapshot: 4 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.587890625, &#39;crossentropy&#39;: 3.449317991733551}
LowCrossEntropy-PatienceWithSnapshot: 16 / 20
Accuracy-PatienceWithSnapshot: 5 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.59375, &#39;crossentropy&#39;: 3.507500499486923}
LowCrossEntropy-PatienceWithSnapshot: 17 / 20
Accuracy-PatienceWithSnapshot: 6 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.5771484375, &#39;crossentropy&#39;: 3.6764039993286133}
LowCrossEntropy-PatienceWithSnapshot: 18 / 20
Accuracy-PatienceWithSnapshot: 7 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.5732421875, &#39;crossentropy&#39;: 3.9285079538822174}
LowCrossEntropy-PatienceWithSnapshot: 19 / 20
Accuracy-PatienceWithSnapshot: 8 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.6103515625, &#39;crossentropy&#39;: 3.660591959953308}
LowCrossEntropy-PatienceWithSnapshot: 20 / 20
LowCrossEntropy-PatienceWithSnapshot: Out of patience
LowCrossEntropy-PatienceWithSnapshot: Best score: -1.889914259314537)
Accuracy-PatienceWithSnapshot: 9 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.6171875, &#39;crossentropy&#39;: 3.4324305057525635}
LowCrossEntropy-PatienceWithSnapshot: 21 / 20
Accuracy-PatienceWithSnapshot: 10 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.6171875, &#39;crossentropy&#39;: 3.3927571177482605}
LowCrossEntropy-PatienceWithSnapshot: 22 / 20
Accuracy-PatienceWithSnapshot: 11 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.5966796875, &#39;crossentropy&#39;: 3.4646926820278168}
LowCrossEntropy-PatienceWithSnapshot: 23 / 20
Accuracy-PatienceWithSnapshot: 12 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.59375, &#39;crossentropy&#39;: 3.5257967710494995}
LowCrossEntropy-PatienceWithSnapshot: 24 / 20
Accuracy-PatienceWithSnapshot: 13 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.625, &#39;crossentropy&#39;: 3.3281938433647156}
LowCrossEntropy-PatienceWithSnapshot: 25 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.6240234375, &#39;crossentropy&#39;: 3.402111440896988}
LowCrossEntropy-PatienceWithSnapshot: 26 / 20
Accuracy-PatienceWithSnapshot: 1 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.611328125, &#39;crossentropy&#39;: 3.672366112470627}
LowCrossEntropy-PatienceWithSnapshot: 27 / 20
Accuracy-PatienceWithSnapshot: 2 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.58203125, &#39;crossentropy&#39;: 3.9365107119083405}
LowCrossEntropy-PatienceWithSnapshot: 28 / 20
Accuracy-PatienceWithSnapshot: 3 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.611328125, &#39;crossentropy&#39;: 3.514330804347992}
LowCrossEntropy-PatienceWithSnapshot: 29 / 20
Accuracy-PatienceWithSnapshot: 4 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.6005859375, &#39;crossentropy&#39;: 3.6969501674175262}
LowCrossEntropy-PatienceWithSnapshot: 30 / 20
Accuracy-PatienceWithSnapshot: 5 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.6064453125, &#39;crossentropy&#39;: 3.810693085193634}
LowCrossEntropy-PatienceWithSnapshot: 31 / 20
Accuracy-PatienceWithSnapshot: 6 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.6123046875, &#39;crossentropy&#39;: 3.6847313046455383}
LowCrossEntropy-PatienceWithSnapshot: 32 / 20
Accuracy-PatienceWithSnapshot: 7 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.611328125, &#39;crossentropy&#39;: 3.7691094875335693}
LowCrossEntropy-PatienceWithSnapshot: 33 / 20
Accuracy-PatienceWithSnapshot: 8 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.615234375, &#39;crossentropy&#39;: 3.5492989122867584}
LowCrossEntropy-PatienceWithSnapshot: 34 / 20
Accuracy-PatienceWithSnapshot: 9 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.62109375, &#39;crossentropy&#39;: 3.6144717037677765}
LowCrossEntropy-PatienceWithSnapshot: 35 / 20
Accuracy-PatienceWithSnapshot: 10 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.6142578125, &#39;crossentropy&#39;: 3.7552120089530945}
LowCrossEntropy-PatienceWithSnapshot: 36 / 20
Accuracy-PatienceWithSnapshot: 11 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.60546875, &#39;crossentropy&#39;: 3.9477584958076477}
LowCrossEntropy-PatienceWithSnapshot: 37 / 20
Accuracy-PatienceWithSnapshot: 12 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.615234375, &#39;crossentropy&#39;: 3.729003071784973}
LowCrossEntropy-PatienceWithSnapshot: 38 / 20
Accuracy-PatienceWithSnapshot: 13 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.580078125, &#39;crossentropy&#39;: 3.815106302499771}
LowCrossEntropy-PatienceWithSnapshot: 39 / 20
Accuracy-PatienceWithSnapshot: 14 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.5849609375, &#39;crossentropy&#39;: 3.988441675901413}
LowCrossEntropy-PatienceWithSnapshot: 40 / 20
Accuracy-PatienceWithSnapshot: 15 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.61328125, &#39;crossentropy&#39;: 3.6669183373451233}
LowCrossEntropy-PatienceWithSnapshot: 41 / 20
Accuracy-PatienceWithSnapshot: 16 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.580078125, &#39;crossentropy&#39;: 3.8236795365810394}
LowCrossEntropy-PatienceWithSnapshot: 42 / 20
Accuracy-PatienceWithSnapshot: 17 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.564453125, &#39;crossentropy&#39;: 3.914109319448471}
LowCrossEntropy-PatienceWithSnapshot: 43 / 20
Accuracy-PatienceWithSnapshot: 18 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.61328125, &#39;crossentropy&#39;: 3.178557902574539}
LowCrossEntropy-PatienceWithSnapshot: 44 / 20
Accuracy-PatienceWithSnapshot: 19 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.609375, &#39;crossentropy&#39;: 3.5299744606018066}
LowCrossEntropy-PatienceWithSnapshot: 45 / 20
Accuracy-PatienceWithSnapshot: 20 / 20
Accuracy-PatienceWithSnapshot: Out of patience
Accuracy-PatienceWithSnapshot: Best score: 0.625)
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Engine run is terminating due to exception: .
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-13-33f4812b3283&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">     16</span> 
<span class="ansi-green-intense-fg ansi-bold">     17</span> results <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">{</span><span class="ansi-blue-fg">}</span>
<span class="ansi-green-fg">---&gt; 18</span><span class="ansi-red-fg"> </span>experiment<span class="ansi-blue-fg">.</span>run<span class="ansi-blue-fg">(</span>results<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">&lt;ipython-input-12-32e7657b512c&gt;</span> in <span class="ansi-cyan-fg">run</span><span class="ansi-blue-fg">(self, store)</span>
<span class="ansi-green-intense-fg ansi-bold">    147</span>                 model_optimizer<span class="ansi-blue-fg">.</span>model<span class="ansi-blue-fg">.</span>load_state_dict<span class="ansi-blue-fg">(</span>double_snapshots<span class="ansi-blue-fg">.</span>high_accuracy<span class="ansi-blue-fg">.</span>model_state_dict<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    148</span> 
<span class="ansi-green-fg">--&gt; 149</span><span class="ansi-red-fg">             evaluation_metrics = evaluate(
</span><span class="ansi-green-intense-fg ansi-bold">    150</span>                 model<span class="ansi-blue-fg">=</span>model_optimizer<span class="ansi-blue-fg">.</span>model<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    151</span>                 num_samples<span class="ansi-blue-fg">=</span>self<span class="ansi-blue-fg">.</span>num_validation_samples<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/black_box_model_training.py</span> in <span class="ansi-cyan-fg">evaluate</span><span class="ansi-blue-fg">(model, num_samples, loader, device, loss)</span>
<span class="ansi-green-intense-fg ansi-bold">    317</span> 
<span class="ansi-green-intense-fg ansi-bold">    318</span>     <span class="ansi-red-fg"># Kick everything off</span>
<span class="ansi-green-fg">--&gt; 319</span><span class="ansi-red-fg">     </span>evaluator<span class="ansi-blue-fg">.</span>run<span class="ansi-blue-fg">(</span>loader<span class="ansi-blue-fg">,</span> max_epochs<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    320</span> 
<span class="ansi-green-intense-fg ansi-bold">    321</span>     <span class="ansi-green-fg">return</span> evaluator<span class="ansi-blue-fg">.</span>state<span class="ansi-blue-fg">.</span>metrics

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">run</span><span class="ansi-blue-fg">(self, data, max_epochs, epoch_length, seed)</span>
<span class="ansi-green-intense-fg ansi-bold">    689</span> 
<span class="ansi-green-intense-fg ansi-bold">    690</span>         self<span class="ansi-blue-fg">.</span>state<span class="ansi-blue-fg">.</span>dataloader <span class="ansi-blue-fg">=</span> data
<span class="ansi-green-fg">--&gt; 691</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_internal_run<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    692</span> 
<span class="ansi-green-intense-fg ansi-bold">    693</span>     <span class="ansi-blue-fg">@</span>staticmethod

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">_internal_run</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    760</span>             self<span class="ansi-blue-fg">.</span>_dataloader_iter <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span>
<span class="ansi-green-intense-fg ansi-bold">    761</span>             self<span class="ansi-blue-fg">.</span>logger<span class="ansi-blue-fg">.</span>error<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#34;Engine run is terminating due to exception: %s.&#34;</span><span class="ansi-blue-fg">,</span> str<span class="ansi-blue-fg">(</span>e<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 762</span><span class="ansi-red-fg">             </span>self<span class="ansi-blue-fg">.</span>_handle_exception<span class="ansi-blue-fg">(</span>e<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    763</span> 
<span class="ansi-green-intense-fg ansi-bold">    764</span>         self<span class="ansi-blue-fg">.</span>_dataloader_iter <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">_handle_exception</span><span class="ansi-blue-fg">(self, e)</span>
<span class="ansi-green-intense-fg ansi-bold">    465</span>             self<span class="ansi-blue-fg">.</span>_fire_event<span class="ansi-blue-fg">(</span>Events<span class="ansi-blue-fg">.</span>EXCEPTION_RAISED<span class="ansi-blue-fg">,</span> e<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    466</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 467</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">raise</span> e
<span class="ansi-green-intense-fg ansi-bold">    468</span> 
<span class="ansi-green-intense-fg ansi-bold">    469</span>     <span class="ansi-blue-fg">@</span>property

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">_internal_run</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    728</span>                     self<span class="ansi-blue-fg">.</span>_setup_engine<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    729</span> 
<span class="ansi-green-fg">--&gt; 730</span><span class="ansi-red-fg">                 </span>time_taken <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_run_once_on_dataset<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    731</span>                 <span class="ansi-red-fg"># time is available for handlers but must be update after fire</span>
<span class="ansi-green-intense-fg ansi-bold">    732</span>                 self<span class="ansi-blue-fg">.</span>state<span class="ansi-blue-fg">.</span>times<span class="ansi-blue-fg">[</span>Events<span class="ansi-blue-fg">.</span>EPOCH_COMPLETED<span class="ansi-blue-fg">.</span>name<span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> time_taken

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">_run_once_on_dataset</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    777</span>                     <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>last_event_name <span class="ansi-blue-fg">!=</span> Events<span class="ansi-blue-fg">.</span>DATALOADER_STOP_ITERATION<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    778</span>                         self<span class="ansi-blue-fg">.</span>_fire_event<span class="ansi-blue-fg">(</span>Events<span class="ansi-blue-fg">.</span>GET_BATCH_STARTED<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 779</span><span class="ansi-red-fg">                     </span>self<span class="ansi-blue-fg">.</span>state<span class="ansi-blue-fg">.</span>batch <span class="ansi-blue-fg">=</span> next<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>_dataloader_iter<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    780</span>                     self<span class="ansi-blue-fg">.</span>_fire_event<span class="ansi-blue-fg">(</span>Events<span class="ansi-blue-fg">.</span>GET_BATCH_COMPLETED<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    781</span>                     iter_counter <span class="ansi-blue-fg">+=</span> <span class="ansi-cyan-fg">1</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/utils/data/dataloader.py</span> in <span class="ansi-cyan-fg">__next__</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    433</span>         <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>_sampler_iter <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    434</span>             self<span class="ansi-blue-fg">.</span>_reset<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 435</span><span class="ansi-red-fg">         </span>data <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_next_data<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    436</span>         self<span class="ansi-blue-fg">.</span>_num_yielded <span class="ansi-blue-fg">+=</span> <span class="ansi-cyan-fg">1</span>
<span class="ansi-green-intense-fg ansi-bold">    437</span>         <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>_dataset_kind <span class="ansi-blue-fg">==</span> _DatasetKind<span class="ansi-blue-fg">.</span>Iterable <span class="ansi-green-fg">and</span><span class="ansi-red-fg"> </span><span class="ansi-red-fg">\</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/utils/data/dataloader.py</span> in <span class="ansi-cyan-fg">_next_data</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    473</span>     <span class="ansi-green-fg">def</span> _next_data<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    474</span>         index <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_next_index<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># may raise StopIteration</span>
<span class="ansi-green-fg">--&gt; 475</span><span class="ansi-red-fg">         </span>data <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_dataset_fetcher<span class="ansi-blue-fg">.</span>fetch<span class="ansi-blue-fg">(</span>index<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># may raise StopIteration</span>
<span class="ansi-green-intense-fg ansi-bold">    476</span>         <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>_pin_memory<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    477</span>             data <span class="ansi-blue-fg">=</span> _utils<span class="ansi-blue-fg">.</span>pin_memory<span class="ansi-blue-fg">.</span>pin_memory<span class="ansi-blue-fg">(</span>data<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py</span> in <span class="ansi-cyan-fg">fetch</span><span class="ansi-blue-fg">(self, possibly_batched_index)</span>
<span class="ansi-green-intense-fg ansi-bold">     42</span>     <span class="ansi-green-fg">def</span> fetch<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> possibly_batched_index<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     43</span>         <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>auto_collation<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">---&gt; 44</span><span class="ansi-red-fg">             </span>data <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">[</span>self<span class="ansi-blue-fg">.</span>dataset<span class="ansi-blue-fg">[</span>idx<span class="ansi-blue-fg">]</span> <span class="ansi-green-fg">for</span> idx <span class="ansi-green-fg">in</span> possibly_batched_index<span class="ansi-blue-fg">]</span>
<span class="ansi-green-intense-fg ansi-bold">     45</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     46</span>             data <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>dataset<span class="ansi-blue-fg">[</span>possibly_batched_index<span class="ansi-blue-fg">]</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py</span> in <span class="ansi-cyan-fg">&lt;listcomp&gt;</span><span class="ansi-blue-fg">(.0)</span>
<span class="ansi-green-intense-fg ansi-bold">     42</span>     <span class="ansi-green-fg">def</span> fetch<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> possibly_batched_index<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     43</span>         <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>auto_collation<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">---&gt; 44</span><span class="ansi-red-fg">             </span>data <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">[</span>self<span class="ansi-blue-fg">.</span>dataset<span class="ansi-blue-fg">[</span>idx<span class="ansi-blue-fg">]</span> <span class="ansi-green-fg">for</span> idx <span class="ansi-green-fg">in</span> possibly_batched_index<span class="ansi-blue-fg">]</span>
<span class="ansi-green-intense-fg ansi-bold">     45</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     46</span>             data <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>dataset<span class="ansi-blue-fg">[</span>possibly_batched_index<span class="ansi-blue-fg">]</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/dataset_challenges.py</span> in <span class="ansi-cyan-fg">__getitem__</span><span class="ansi-blue-fg">(self, idx)</span>
<span class="ansi-green-intense-fg ansi-bold">     48</span> 
<span class="ansi-green-intense-fg ansi-bold">     49</span>     <span class="ansi-green-fg">def</span> __getitem__<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> idx<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">---&gt; 50</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>dataset<span class="ansi-blue-fg">[</span>idx<span class="ansi-blue-fg">]</span>
<span class="ansi-green-intense-fg ansi-bold">     51</span> 
<span class="ansi-green-intense-fg ansi-bold">     52</span>     <span class="ansi-green-fg">def</span> __len__<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/fast_mnist.py</span> in <span class="ansi-cyan-fg">__getitem__</span><span class="ansi-blue-fg">(self, index)</span>
<span class="ansi-green-intense-fg ansi-bold">     36</span>             tuple<span class="ansi-blue-fg">:</span> <span class="ansi-blue-fg">(</span>image<span class="ansi-blue-fg">,</span> target<span class="ansi-blue-fg">)</span> where target <span class="ansi-green-fg">is</span> index of the target <span class="ansi-green-fg">class</span><span class="ansi-blue-fg">.</span>
<span class="ansi-green-intense-fg ansi-bold">     37</span>         &#34;&#34;&#34;
<span class="ansi-green-fg">---&gt; 38</span><span class="ansi-red-fg">         </span>img<span class="ansi-blue-fg">,</span> target <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>data<span class="ansi-blue-fg">[</span>index<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>targets<span class="ansi-blue-fg">[</span>index<span class="ansi-blue-fg">]</span>
<span class="ansi-green-intense-fg ansi-bold">     39</span> 
<span class="ansi-green-intense-fg ansi-bold">     40</span>         <span class="ansi-green-fg">return</span> img<span class="ansi-blue-fg">,</span> target

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">results</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;initial_training_set_indices&#39;: [38043,
  40091,
  17418,
  2094,
  39879,
  3133,
  5011,
  40683,
  54379,
  24287,
  9849,
  59305,
  39508,
  39356,
  8758,
  52579,
  13655,
  7636,
  21562,
  41329],
 &#39;dataset_info&#39;: {&#39;training&#39;: &#34;&#39;FastMNIST (Train)&#39;&#34;,
  &#39;test&#39;: &#34;&#39;FastMNIST (Test)&#39;&#34;},
 &#39;active_learning_steps&#39;: [{&#39;training&#39;: {&#39;epochs&#39;: [{&#39;accuracy&#39;: 0.62109375,
      &#39;crossentropy&#39;: 2.6530187726020813},
     {&#39;accuracy&#39;: 0.6376953125, &#39;crossentropy&#39;: 2.762658029794693},
     {&#39;accuracy&#39;: 0.646484375, &#39;crossentropy&#39;: 3.056214064359665},
     {&#39;accuracy&#39;: 0.6416015625, &#39;crossentropy&#39;: 3.1257119178771973}],
    &#39;best_epoch&#39;: 1},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.631,
    &#39;crossentropy&#39;: 2.6251225173950195}}]}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">experiment</span> <span class="o">=</span> <span class="n">Experiment</span><span class="p">(</span>
    <span class="n">max_training_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_training_set</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">acquisition_function</span><span class="o">=</span><span class="n">AcquisitionFunction</span><span class="o">.</span><span class="n">randombaldical</span>
<span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">experiment</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>

<span class="n">results</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Training set size 20:
RestoringEarlyStopping: Restoring best parameters. (Score: -6.529030114412308)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.5367, &#39;crossentropy&#39;: 6.438035237884521}
RestoringEarlyStopping: Restoring best parameters. (Score: -5.1637596152722836)
RestoringEarlyStopping: Restoring optimizer.
Acquiring (label, score)s: 8 (0.8711), 8 (0.8687), 3 (0.876), 3 (0.8465), 3 (0.8811)
Training set size 25:
RestoringEarlyStopping: Restoring best parameters. (Score: -4.6851686127483845)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.6256, &#39;crossentropy&#39;: 4.484497045135498}
Done.
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;initial_training_set_indices&#39;: [38043,
  40091,
  17418,
  2094,
  39879,
  3133,
  5011,
  40683,
  54379,
  24287,
  9849,
  59305,
  39508,
  39356,
  8758,
  52579,
  13655,
  7636,
  21562,
  41329],
 &#39;active_learning_steps&#39;: [{&#39;training&#39;: {&#39;epochs&#39;: [{&#39;accuracy&#39;: 0.538818359375,
      &#39;crossentropy&#39;: 6.529030114412308}],
    &#39;best_epoch&#39;: 1},
   &#39;evalution_metrics&#39;: {&#39;accuracy&#39;: 0.5367,
    &#39;crossentropy&#39;: 6.438035237884521},
   &#39;pool_training&#39;: {&#39;epochs&#39;: [{&#39;accuracy&#39;: 0.531005859375,
      &#39;crossentropy&#39;: 5.1637596152722836}],
    &#39;best_epoch&#39;: 1},
   &#39;acquisition&#39;: {&#39;indices&#39;: [63338, 10856, 63452, 81864, 109287],
    &#39;labels&#39;: [8, 8, 3, 3, 3],
    &#39;scores&#39;: [0.8710822958846325,
     0.8687216999221631,
     0.8759664372823723,
     0.8464646732511746,
     0.8810812784952251]}},
  {&#39;training&#39;: {&#39;epochs&#39;: [{&#39;accuracy&#39;: 0.62255859375,
      &#39;crossentropy&#39;: 4.6851686127483845}],
    &#39;best_epoch&#39;: 1},
   &#39;evalution_metrics&#39;: {&#39;accuracy&#39;: 0.6256,
    &#39;crossentropy&#39;: 4.484497045135498}}]}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">configs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">Experiment</span><span class="p">(</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
        <span class="n">acquisition_function</span><span class="o">=</span><span class="n">acquisition_function</span><span class="p">,</span>
        <span class="n">acquisition_size</span><span class="o">=</span><span class="n">acquisition_size</span><span class="p">,</span>
        <span class="n">num_pool_samples</span><span class="o">=</span><span class="n">num_pool_samples</span><span class="p">,</span>
        <span class="n">temperature</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">acquisition_function</span> <span class="ow">in</span> <span class="p">[</span>
        <span class="n">acquisition_functions</span><span class="o">.</span><span class="n">BALD</span><span class="p">,</span>
        <span class="n">acquisition_functions</span><span class="o">.</span><span class="n">CoreSetBALD</span><span class="p">,</span>
    <span class="p">]</span>
    <span class="k">for</span> <span class="n">acquisition_size</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">num_pool_samples</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">100</span><span class="p">]</span>
<span class="p">]</span> <span class="o">+</span> <span class="p">[</span>
    <span class="n">Experiment</span><span class="p">(</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
        <span class="n">acquisition_function</span><span class="o">=</span><span class="n">acquisition_functions</span><span class="o">.</span><span class="n">Random</span><span class="p">,</span>
        <span class="n">acquisition_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">num_pool_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">configs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">Experiment</span><span class="p">(</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
        <span class="n">acquisition_function</span><span class="o">=</span><span class="n">acquisition_function</span><span class="p">,</span>
        <span class="n">acquisition_size</span><span class="o">=</span><span class="n">acquisition_size</span><span class="p">,</span>
        <span class="n">num_pool_samples</span><span class="o">=</span><span class="n">num_pool_samples</span><span class="p">,</span>
        <span class="n">initial_training_set_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">max_training_set</span><span class="o">=</span><span class="mi">140</span><span class="p">,</span>
        <span class="n">temperature</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">acquisition_function</span> <span class="ow">in</span> <span class="p">[</span>
        <span class="n">acquisition_functions</span><span class="o">.</span><span class="n">BALD</span><span class="p">,</span>
        <span class="n">acquisition_functions</span><span class="o">.</span><span class="n">CoreSetBALD</span><span class="p">,</span>
    <span class="p">]</span>
    <span class="k">for</span> <span class="n">acquisition_size</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">num_pool_samples</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">100</span><span class="p">]</span>
<span class="p">]</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">is_run_from_ipython</span><span class="p">()</span> <span class="ow">and</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">job_id</span><span class="p">,</span> <span class="n">store</span> <span class="ow">in</span> <span class="n">embedded_experiments</span><span class="p">(</span><span class="vm">__file__</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">configs</span><span class="p">)):</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">configs</span><span class="p">[</span><span class="n">job_id</span><span class="p">]</span>
        <span class="n">config</span><span class="o">.</span><span class="n">seed</span> <span class="o">+=</span> <span class="n">job_id</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataclasses</span><span class="o">.</span><span class="n">asdict</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;log&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">config</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">store</span><span class="o">=</span><span class="n">store</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="n">store</span><span class="p">[</span><span class="s2">&quot;exception&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">traceback</span><span class="o">.</span><span class="n">format_exc</span><span class="p">()</span>
            <span class="k">raise</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">configs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>20</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

