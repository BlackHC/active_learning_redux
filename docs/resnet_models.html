---

title: Some Models


keywords: fastai
sidebar: home_sidebar

summary: "To avoid copy-pasta"
description: "To avoid copy-pasta"
nb_path: "06c_resnet_models.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 06c_resnet_models.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Type</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Any</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.optim</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">Module</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">Dataset</span>

<span class="kn">from</span> <span class="nn">batchbald_redux.active_learning</span> <span class="kn">import</span> <span class="n">RandomFixedLengthSampler</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.black_box_model_training</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">train</span><span class="p">,</span>
    <span class="n">train_with_cosine_annealing</span><span class="p">,</span>
    <span class="n">train_with_schedule</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.consistent_mc_dropout</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">BayesianModule</span><span class="p">,</span>
    <span class="n">ConsistentMCDropout</span><span class="p">,</span>
    <span class="n">freeze_encoder_context</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.model_optimizer_factory</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ModelOptimizer</span><span class="p">,</span>
    <span class="n">ModelOptimizerFactory</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="conv3x3" class="doc_header"><code>conv3x3</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/resnet_models.py#L56" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>conv3x3</code>(<strong><code>in_planes</code></strong>:<code>int</code>, <strong><code>out_planes</code></strong>:<code>int</code>, <strong><code>stride</code></strong>:<code>int</code>=<em><code>1</code></em>, <strong><code>groups</code></strong>:<code>int</code>=<em><code>1</code></em>, <strong><code>dilation</code></strong>:<code>int</code>=<em><code>1</code></em>)</p>
</blockquote>
<p>3x3 convolution with padding</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="conv1x1" class="doc_header"><code>conv1x1</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/resnet_models.py#L70" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>conv1x1</code>(<strong><code>in_planes</code></strong>:<code>int</code>, <strong><code>out_planes</code></strong>:<code>int</code>, <strong><code>stride</code></strong>:<code>int</code>=<em><code>1</code></em>)</p>
</blockquote>
<p>1x1 convolution</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BasicBlock" class="doc_header"><code>class</code> <code>BasicBlock</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/resnet_models.py#L75" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BasicBlock</code>(<strong><code>inplanes</code></strong>:<code>int</code>, <strong><code>planes</code></strong>:<code>int</code>, <strong><code>stride</code></strong>:<code>int</code>=<em><code>1</code></em>, <strong><code>downsample</code></strong>:<code>Optional</code>[<code>Module</code>]=<em><code>None</code></em>, <strong><code>groups</code></strong>:<code>int</code>=<em><code>1</code></em>, <strong><code>base_width</code></strong>:<code>int</code>=<em><code>64</code></em>, <strong><code>dilation</code></strong>:<code>int</code>=<em><code>1</code></em>, <strong><code>norm_layer</code></strong>:<code>Optional</code>[<code>Callable</code>[<code>Ellipsis</code>, <code>Module</code>]]=<em><code>None</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Bottleneck" class="doc_header"><code>class</code> <code>Bottleneck</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/resnet_models.py#L124" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Bottleneck</code>(<strong><code>inplanes</code></strong>:<code>int</code>, <strong><code>planes</code></strong>:<code>int</code>, <strong><code>stride</code></strong>:<code>int</code>=<em><code>1</code></em>, <strong><code>downsample</code></strong>:<code>Optional</code>[<code>Module</code>]=<em><code>None</code></em>, <strong><code>groups</code></strong>:<code>int</code>=<em><code>1</code></em>, <strong><code>base_width</code></strong>:<code>int</code>=<em><code>64</code></em>, <strong><code>dilation</code></strong>:<code>int</code>=<em><code>1</code></em>, <strong><code>norm_layer</code></strong>:<code>Optional</code>[<code>Callable</code>[<code>Ellipsis</code>, <code>Module</code>]]=<em><code>None</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BayesianResNet" class="doc_header"><code>class</code> <code>BayesianResNet</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/resnet_models.py#L176" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BayesianResNet</code>(<strong><code>block</code></strong>:<code>Type</code>[<code>Union</code>[<a href="/batchbald_redux/resnet_models.html#BasicBlock"><code>BasicBlock</code></a>, <a href="/batchbald_redux/resnet_models.html#Bottleneck"><code>Bottleneck</code></a>]], <strong><code>layers</code></strong>:<code>List</code>[<code>int</code>], <strong><code>dropout_head</code></strong>:<code>bool</code>, <strong><code>num_classes</code></strong>:<code>int</code>=<em><code>1000</code></em>, <strong><code>zero_init_residual</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>groups</code></strong>:<code>int</code>=<em><code>1</code></em>, <strong><code>width_per_group</code></strong>:<code>int</code>=<em><code>64</code></em>, <strong><code>replace_stride_with_dilation</code></strong>:<code>Optional</code>[<code>List</code>[<code>bool</code>]]=<em><code>None</code></em>, <strong><code>norm_layer</code></strong>:<code>Optional</code>[<code>Callable</code>[<code>Ellipsis</code>, <code>Module</code>]]=<em><code>None</code></em>) :: <a href="/batchbald_redux/consistent_mc_dropout.html#BayesianModule"><code>BayesianModule</code></a></p>
</blockquote>
<p>A module that we can sample multiple times from given a single input batch.</p>
<p>To be efficient, the module allows for a part of the forward pass to be deterministic.</p>
<p>If we sample with "0" samples, we do a single deterministic forward pass with disabled dropout during evaluation.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="bayesian_resnet18" class="doc_header"><code>bayesian_resnet18</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/resnet_models.py#L351" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>bayesian_resnet18</code>(<strong><code>cifar_mod</code></strong>=<em><code>False</code></em>, <strong><code>dropout_head</code></strong>=<em><code>False</code></em>, <strong><code>pretrained</code></strong>=<em><code>False</code></em>, <strong><code>progress</code></strong>=<em><code>True</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Constructs a ResNet-18 model.</p>
<p>Args:
    pretrained (bool): If True, returns a model pre-trained on ImageNet
    progress (bool): If True, displays a progress bar of the download to stderr</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="bayesian_resnet34" class="doc_header"><code>bayesian_resnet34</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/resnet_models.py#L361" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>bayesian_resnet34</code>(<strong><code>cifar_mod</code></strong>=<em><code>False</code></em>, <strong><code>dropout_head</code></strong>=<em><code>False</code></em>, <strong><code>pretrained</code></strong>=<em><code>False</code></em>, <strong><code>progress</code></strong>=<em><code>True</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Constructs a ResNet-34 model.</p>
<p>Args:
    pretrained (bool): If True, returns a model pre-trained on ImageNet
    progress (bool): If True, displays a progress bar of the download to stderr</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">torch.hub</span> <span class="kn">import</span> <span class="n">load_state_dict_from_url</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>

<span class="kn">from</span> <span class="nn">batchbald_redux.trained_model</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ModelTrainer</span><span class="p">,</span>
    <span class="n">TrainedBayesianModel</span><span class="p">,</span>
    <span class="n">TrainedModel</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model_urls</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;resnet18&quot;</span><span class="p">:</span> <span class="s2">&quot;https://download.pytorch.org/models/resnet18-5c106cde.pth&quot;</span><span class="p">,</span>
    <span class="s2">&quot;resnet34&quot;</span><span class="p">:</span> <span class="s2">&quot;https://download.pytorch.org/models/resnet34-333f7ec4.pth&quot;</span><span class="p">,</span>
    <span class="s2">&quot;resnet50&quot;</span><span class="p">:</span> <span class="s2">&quot;https://download.pytorch.org/models/resnet50-19c8e357.pth&quot;</span><span class="p">,</span>
    <span class="s2">&quot;resnet101&quot;</span><span class="p">:</span> <span class="s2">&quot;https://download.pytorch.org/models/resnet101-5d3b4d8f.pth&quot;</span><span class="p">,</span>
    <span class="s2">&quot;resnet152&quot;</span><span class="p">:</span> <span class="s2">&quot;https://download.pytorch.org/models/resnet152-b121ed2d.pth&quot;</span><span class="p">,</span>
    <span class="s2">&quot;resnext50_32x4d&quot;</span><span class="p">:</span> <span class="s2">&quot;https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth&quot;</span><span class="p">,</span>
    <span class="s2">&quot;resnext101_32x8d&quot;</span><span class="p">:</span> <span class="s2">&quot;https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth&quot;</span><span class="p">,</span>
<span class="p">}</span>


<span class="k">def</span> <span class="nf">conv3x3</span><span class="p">(</span><span class="n">in_planes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">out_planes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">groups</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dilation</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;3x3 convolution with padding&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
        <span class="n">in_planes</span><span class="p">,</span>
        <span class="n">out_planes</span><span class="p">,</span>
        <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span>
        <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">,</span>
        <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">conv1x1</span><span class="p">(</span><span class="n">in_planes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">out_planes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;1x1 convolution&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_planes</span><span class="p">,</span> <span class="n">out_planes</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">BasicBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="n">expansion</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inplanes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">planes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">downsample</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">groups</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">base_width</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span>
        <span class="n">dilation</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">norm_layer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BasicBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">norm_layer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">norm_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span>
        <span class="k">if</span> <span class="n">groups</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">base_width</span> <span class="o">!=</span> <span class="mi">64</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;BasicBlock only supports groups=1 and base_width=64&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dilation</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Dilation &gt; 1 not supported in BasicBlock&quot;</span><span class="p">)</span>
        <span class="c1"># Both self.conv1 and self.downsample layers downsample the input when stride != 1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv3x3</span><span class="p">(</span><span class="n">inplanes</span><span class="p">,</span> <span class="n">planes</span><span class="p">,</span> <span class="n">stride</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">norm_layer</span><span class="p">(</span><span class="n">planes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv3x3</span><span class="p">(</span><span class="n">planes</span><span class="p">,</span> <span class="n">planes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">norm_layer</span><span class="p">(</span><span class="n">planes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span> <span class="o">=</span> <span class="n">downsample</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="n">identity</span> <span class="o">=</span> <span class="n">x</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">identity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">+=</span> <span class="n">identity</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>


<span class="k">class</span> <span class="nc">Bottleneck</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="n">expansion</span> <span class="o">=</span> <span class="mi">4</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inplanes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">planes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">downsample</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">groups</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">base_width</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span>
        <span class="n">dilation</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">norm_layer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Bottleneck</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">norm_layer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">norm_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span>
        <span class="n">width</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">planes</span> <span class="o">*</span> <span class="p">(</span><span class="n">base_width</span> <span class="o">/</span> <span class="mf">64.0</span><span class="p">))</span> <span class="o">*</span> <span class="n">groups</span>
        <span class="c1"># Both self.conv2 and self.downsample layers downsample the input when stride != 1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv1x1</span><span class="p">(</span><span class="n">inplanes</span><span class="p">,</span> <span class="n">width</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">norm_layer</span><span class="p">(</span><span class="n">width</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv3x3</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">dilation</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">norm_layer</span><span class="p">(</span><span class="n">width</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">conv1x1</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">planes</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">expansion</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn3</span> <span class="o">=</span> <span class="n">norm_layer</span><span class="p">(</span><span class="n">planes</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">expansion</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span> <span class="o">=</span> <span class="n">downsample</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="n">identity</span> <span class="o">=</span> <span class="n">x</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">identity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">+=</span> <span class="n">identity</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>


<span class="k">class</span> <span class="nc">BayesianResNet</span><span class="p">(</span><span class="n">BayesianModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">block</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">BasicBlock</span><span class="p">,</span> <span class="n">Bottleneck</span><span class="p">]],</span>
        <span class="n">layers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
        <span class="n">dropout_head</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">zero_init_residual</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">groups</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">width_per_group</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span>
        <span class="n">replace_stride_with_dilation</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">bool</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">norm_layer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">norm_layer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">norm_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_norm_layer</span> <span class="o">=</span> <span class="n">norm_layer</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">inplanes</span> <span class="o">=</span> <span class="mi">64</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dilation</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">replace_stride_with_dilation</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># each element in the tuple indicates if we should replace</span>
            <span class="c1"># the 2x2 stride with a dilated convolution instead</span>
            <span class="n">replace_stride_with_dilation</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">replace_stride_with_dilation</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;replace_stride_with_dilation should be None &quot;</span>
                <span class="s2">&quot;or a 3-element tuple, got </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">replace_stride_with_dilation</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">groups</span> <span class="o">=</span> <span class="n">groups</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_width</span> <span class="o">=</span> <span class="n">width_per_group</span>

        <span class="c1"># This gets reset when cifar_mod=True below</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inplanes</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">norm_layer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inplanes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># This gets reset when cifar_mod=True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maxpool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_layer</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_layer</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">layers</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dilate</span><span class="o">=</span><span class="n">replace_stride_with_dilation</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_layer</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">layers</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dilate</span><span class="o">=</span><span class="n">replace_stride_with_dilation</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_layer</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">layers</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dilate</span><span class="o">=</span><span class="n">replace_stride_with_dilation</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">avgpool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">dropout_head</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span> <span class="o">*</span> <span class="n">block</span><span class="o">.</span><span class="n">expansion</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">ConsistentMCDropout</span><span class="p">(),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span> <span class="o">*</span> <span class="n">block</span><span class="o">.</span><span class="n">expansion</span><span class="p">,</span> <span class="mi">256</span> <span class="o">*</span> <span class="n">block</span><span class="o">.</span><span class="n">expansion</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">ConsistentMCDropout</span><span class="p">(),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span> <span class="o">*</span> <span class="n">block</span><span class="o">.</span><span class="n">expansion</span><span class="p">,</span> <span class="mi">256</span> <span class="o">*</span> <span class="n">block</span><span class="o">.</span><span class="n">expansion</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="c1"># self.fc = nn.Sequential(</span>
        <span class="c1">#     nn.ReLU(),</span>
        <span class="c1">#     nn.Linear(512 * block.expansion, 256 * block.expansion),</span>
        <span class="c1">#     ConsistentMCDropout(),</span>
        <span class="c1">#     nn.Linear(256 * block.expansion, 128 * block.expansion),</span>
        <span class="c1">#     ConsistentMCDropout(),</span>
        <span class="c1">#     nn.Linear(128 * block.expansion, 128 * block.expansion),</span>
        <span class="c1">#     nn.ReLU(),</span>
        <span class="c1">#     nn.Linear(128 * block.expansion, num_classes),</span>
        <span class="c1"># )</span>

        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;fan_out&quot;</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">)):</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Zero-initialize the last BN in each residual branch,</span>
        <span class="c1"># so that the residual branch starts with zeros, and each residual block behaves like an identity.</span>
        <span class="c1"># This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677</span>
        <span class="k">if</span> <span class="n">zero_init_residual</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">Bottleneck</span><span class="p">):</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bn3</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># type: ignore[arg-type]</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">BasicBlock</span><span class="p">):</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bn2</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># type: ignore[arg-type]</span>

    <span class="k">def</span> <span class="nf">_make_layer</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">block</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">BasicBlock</span><span class="p">,</span> <span class="n">Bottleneck</span><span class="p">]],</span>
        <span class="n">planes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">blocks</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">dilate</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">:</span>
        <span class="n">norm_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_norm_layer</span>
        <span class="n">downsample</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">previous_dilation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dilation</span>
        <span class="k">if</span> <span class="n">dilate</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dilation</span> <span class="o">*=</span> <span class="n">stride</span>
            <span class="n">stride</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">stride</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">inplanes</span> <span class="o">!=</span> <span class="n">planes</span> <span class="o">*</span> <span class="n">block</span><span class="o">.</span><span class="n">expansion</span><span class="p">:</span>
            <span class="n">downsample</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">conv1x1</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inplanes</span><span class="p">,</span> <span class="n">planes</span> <span class="o">*</span> <span class="n">block</span><span class="o">.</span><span class="n">expansion</span><span class="p">,</span> <span class="n">stride</span><span class="p">),</span>
                <span class="n">norm_layer</span><span class="p">(</span><span class="n">planes</span> <span class="o">*</span> <span class="n">block</span><span class="o">.</span><span class="n">expansion</span><span class="p">),</span>
            <span class="p">)</span>

        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">block</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">inplanes</span><span class="p">,</span> <span class="n">planes</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">downsample</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_width</span><span class="p">,</span> <span class="n">previous_dilation</span><span class="p">,</span> <span class="n">norm_layer</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inplanes</span> <span class="o">=</span> <span class="n">planes</span> <span class="o">*</span> <span class="n">block</span><span class="o">.</span><span class="n">expansion</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">blocks</span><span class="p">):</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">block</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">inplanes</span><span class="p">,</span>
                    <span class="n">planes</span><span class="p">,</span>
                    <span class="n">groups</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">,</span>
                    <span class="n">base_width</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">base_width</span><span class="p">,</span>
                    <span class="n">dilation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span>
                    <span class="n">norm_layer</span><span class="o">=</span><span class="n">norm_layer</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">deterministic_forward_impl</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">freeze_encoder</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">freeze_encoder_context</span><span class="p">(</span><span class="n">freeze_encoder</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxpool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer4</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">avgpool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">mc_forward_impl</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">freeze_encoder</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
        <span class="n">embedding</span> <span class="o">=</span> <span class="n">x</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">embedding</span>


<span class="k">def</span> <span class="nf">_bayesian_resnet</span><span class="p">(</span>
    <span class="n">arch</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">block</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">BasicBlock</span><span class="p">,</span> <span class="n">Bottleneck</span><span class="p">]],</span>
    <span class="n">layers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">cifar_mod</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">dropout_head</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">pretrained</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">progress</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">BayesianResNet</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">BayesianResNet</span><span class="p">(</span><span class="n">block</span><span class="o">=</span><span class="n">block</span><span class="p">,</span> <span class="n">layers</span><span class="o">=</span><span class="n">layers</span><span class="p">,</span> <span class="n">dropout_head</span><span class="o">=</span><span class="n">dropout_head</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">cifar_mod</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">maxpool</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">pretrained</span><span class="p">:</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">cifar_mod</span>
        <span class="n">state_dict</span> <span class="o">=</span> <span class="n">load_state_dict_from_url</span><span class="p">(</span><span class="n">model_urls</span><span class="p">[</span><span class="n">arch</span><span class="p">],</span> <span class="n">progress</span><span class="o">=</span><span class="n">progress</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">model</span>


<span class="k">def</span> <span class="nf">bayesian_resnet18</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> <span class="n">cifar_mod</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dropout_head</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">progress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructs a ResNet-18 model.</span>

<span class="sd">    Args:</span>
<span class="sd">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span>
<span class="sd">        progress (bool): If True, displays a progress bar of the download to stderr</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_bayesian_resnet</span><span class="p">(</span><span class="s2">&quot;resnet18&quot;</span><span class="p">,</span> <span class="n">BasicBlock</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">cifar_mod</span><span class="p">,</span> <span class="n">dropout_head</span><span class="p">,</span> <span class="n">pretrained</span><span class="p">,</span> <span class="n">progress</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">bayesian_resnet34</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> <span class="n">cifar_mod</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dropout_head</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">progress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructs a ResNet-34 model.</span>

<span class="sd">    Args:</span>
<span class="sd">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span>
<span class="sd">        progress (bool): If True, displays a progress bar of the download to stderr</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_bayesian_resnet</span><span class="p">(</span><span class="s2">&quot;resnet34&quot;</span><span class="p">,</span> <span class="n">BasicBlock</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">cifar_mod</span><span class="p">,</span> <span class="n">dropout_head</span><span class="p">,</span> <span class="n">pretrained</span><span class="p">,</span> <span class="n">progress</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Cifar10BayesianResnetFactory" class="doc_header"><code>class</code> <code>Cifar10BayesianResnetFactory</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/resnet_models.py#L373" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Cifar10BayesianResnetFactory</code>() :: <code>ModelOptimizerFactory</code></p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Cifar10DeterministicResnetFactory" class="doc_header"><code>class</code> <code>Cifar10DeterministicResnetFactory</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/resnet_models.py#L381" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Cifar10DeterministicResnetFactory</code>() :: <code>ModelOptimizerFactory</code></p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Cifar10ModelWorkshopPaperTrainer" class="doc_header"><code>class</code> <code>Cifar10ModelWorkshopPaperTrainer</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/resnet_models.py#L392" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Cifar10ModelWorkshopPaperTrainer</code>(<strong><code>device</code></strong>:<code>str</code>, <strong><code>num_training_samples</code></strong>:<code>int</code>=<em><code>1</code></em>, <strong><code>num_validation_samples</code></strong>:<code>int</code>=<em><code>20</code></em>, <strong><code>max_training_epochs</code></strong>:<code>int</code>=<em><code>105</code></em>, <strong><code>patience_schedule</code></strong>:<code>[&lt;class 'int'&gt;]</code>=<em><code>(20, 10)</code></em>, <strong><code>factor_schedule</code></strong>:<code>[&lt;class 'int'&gt;]</code>=<em><code>(0.1,)</code></em>, <strong><code>min_samples_per_epoch</code></strong>:<code>int</code>=<em><code>1024</code></em>, <strong><code>num_training_batch_size</code></strong>:<code>int</code>=<em><code>128</code></em>, <strong><code>num_evaluation_batch_size</code></strong>:<code>int</code>=<em><code>512</code></em>, <strong><code>resnet18_dropout_head</code></strong>:<code>bool</code>=<em><code>True</code></em>) :: <code>ModelTrainer</code></p>
</blockquote>
<p>Cifar10ModelWorkshopPaperTrainer(device: str, num_training_samples: int = 1, num_validation_samples: int = 20, max_training_epochs: int = 105, patience_schedule: [&lt;class 'int'&gt;] = (20, 10), factor_schedule: [&lt;class 'int'&gt;] = (0.1,), min_samples_per_epoch: int = 1024, num_training_batch_size: int = 128, num_evaluation_batch_size: int = 512, resnet18_dropout_head: bool = True)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Cifar10ModelTrainer" class="doc_header"><code>class</code> <code>Cifar10ModelTrainer</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/resnet_models.py#L471" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Cifar10ModelTrainer</code>(<strong><code>device</code></strong>:<code>str</code>, <strong><code>num_training_samples</code></strong>:<code>int</code>=<em><code>1</code></em>, <strong><code>num_validation_samples</code></strong>:<code>int</code>=<em><code>20</code></em>, <strong><code>max_training_epochs</code></strong>:<code>int</code>=<em><code>300</code></em>, <strong><code>patience_schedule</code></strong>:<code>[&lt;class 'int'&gt;]</code>=<em><code>(10, 10, 5)</code></em>, <strong><code>factor_schedule</code></strong>:<code>[&lt;class 'int'&gt;]</code>=<em><code>(0.1,)</code></em>, <strong><code>min_samples_per_epoch</code></strong>:<code>int</code>=<em><code>5056</code></em>, <strong><code>num_training_batch_size</code></strong>:<code>int</code>=<em><code>128</code></em>, <strong><code>num_evaluation_batch_size</code></strong>:<code>int</code>=<em><code>512</code></em>, <strong><code>resnet18_dropout_head</code></strong>:<code>bool</code>=<em><code>True</code></em>) :: <code>ModelTrainer</code></p>
</blockquote>
<p>Cifar10ModelTrainer(device: str, num_training_samples: int = 1, num_validation_samples: int = 20, max_training_epochs: int = 300, patience_schedule: [&lt;class 'int'&gt;] = (10, 10, 5), factor_schedule: [&lt;class 'int'&gt;] = (0.1,), min_samples_per_epoch: int = 5056, num_training_batch_size: int = 128, num_evaluation_batch_size: int = 512, resnet18_dropout_head: bool = True)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Cifar10BayesianResnetFactory</span><span class="p">(</span><span class="n">ModelOptimizerFactory</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">create_model_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelOptimizer</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">bayesian_resnet18</span><span class="p">(</span><span class="n">cifar_mod</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dropout_head</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ModelOptimizer</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>



<span class="k">class</span> <span class="nc">Cifar10DeterministicResnetFactory</span><span class="p">(</span><span class="n">ModelOptimizerFactory</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">create_model_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelOptimizer</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">bayesian_resnet18</span><span class="p">(</span><span class="n">cifar_mod</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dropout_head</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ModelOptimizer</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>


<span class="n">_dataloader_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">Cifar10ModelWorkshopPaperTrainer</span><span class="p">(</span><span class="n">ModelTrainer</span><span class="p">):</span>
    <span class="n">device</span><span class="p">:</span> <span class="nb">str</span>

    <span class="n">num_training_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">num_validation_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="n">max_training_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">105</span>
    <span class="c1">#patience_schedule: [int] = (20,)</span>
    <span class="c1"># Added</span>
    <span class="n">patience_schedule</span><span class="p">:</span> <span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">factor_schedule</span><span class="p">:</span> <span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.1</span><span class="p">,)</span>

    <span class="n">min_samples_per_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span>
    <span class="n">num_training_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span>
    <span class="n">num_evaluation_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">512</span>

    <span class="n">resnet18_dropout_head</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">create_model_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelOptimizer</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">bayesian_resnet18</span><span class="p">(</span><span class="n">cifar_mod</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dropout_head</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">resnet18_dropout_head</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ModelOptimizer</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">:</span> <span class="n">Dataset</span><span class="p">):</span>
        <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
            <span class="n">dataset</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_training_batch_size</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">RandomFixedLengthSampler</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_samples_per_epoch</span><span class="p">),</span>
            <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="o">**</span><span class="n">_dataloader_kwargs</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">train_loader</span>

    <span class="k">def</span> <span class="nf">get_evaluation_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">:</span> <span class="n">Dataset</span><span class="p">):</span>
        <span class="n">evaluation_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
            <span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_evaluation_batch_size</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">_dataloader_kwargs</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">evaluation_loader</span>

    <span class="k">def</span> <span class="nf">get_trained</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">train_loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
        <span class="n">train_augmentations</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Module</span><span class="p">],</span>
        <span class="n">validation_loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
        <span class="n">log</span><span class="p">,</span>
        <span class="n">wandb_key_path</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">loss</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">validation_loss</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TrainedModel</span><span class="p">:</span>
        <span class="n">model_optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_model_optimizer</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">validation_loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">validation_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;NeurIPS Workshop Style&quot;</span><span class="p">)</span>
        <span class="n">train_with_schedule</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model_optimizer</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">optimizer</span><span class="o">=</span><span class="n">model_optimizer</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span>
            <span class="n">training_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_training_samples</span><span class="p">,</span>
            <span class="n">validation_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_validation_samples</span><span class="p">,</span>
            <span class="n">train_loader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span>
            <span class="n">train_augmentations</span><span class="o">=</span><span class="n">train_augmentations</span><span class="p">,</span>
            <span class="n">validation_loader</span><span class="o">=</span><span class="n">validation_loader</span><span class="p">,</span>
            <span class="n">max_epochs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_training_epochs</span><span class="p">,</span>
            <span class="n">patience_schedule</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">patience_schedule</span><span class="p">,</span>
            <span class="n">factor_schedule</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">factor_schedule</span><span class="p">,</span>
            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
            <span class="n">validation_loss</span><span class="o">=</span><span class="n">validation_loss</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="n">training_log</span><span class="o">=</span><span class="n">log</span><span class="p">,</span>
            <span class="n">wandb_key_path</span><span class="o">=</span><span class="n">wandb_key_path</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">TrainedBayesianModel</span><span class="p">(</span><span class="n">model_optimizer</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>


<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">Cifar10ModelTrainer</span><span class="p">(</span><span class="n">ModelTrainer</span><span class="p">):</span>
    <span class="n">device</span><span class="p">:</span> <span class="nb">str</span>

    <span class="n">num_training_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">num_validation_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="n">max_training_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">300</span>
    <span class="n">patience_schedule</span><span class="p">:</span> <span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">factor_schedule</span><span class="p">:</span> <span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.1</span><span class="p">,)</span>

    <span class="n">min_samples_per_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5056</span>
    <span class="n">num_training_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span>
    <span class="n">num_evaluation_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">512</span>

    <span class="n">resnet18_dropout_head</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>


    <span class="k">def</span> <span class="nf">create_model_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelOptimizer</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">bayesian_resnet18</span><span class="p">(</span><span class="n">cifar_mod</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dropout_head</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">resnet18_dropout_head</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ModelOptimizer</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">:</span> <span class="n">Dataset</span><span class="p">):</span>
        <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
            <span class="n">dataset</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_training_batch_size</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">RandomFixedLengthSampler</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_samples_per_epoch</span><span class="p">),</span>
            <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="o">**</span><span class="n">_dataloader_kwargs</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">train_loader</span>

    <span class="k">def</span> <span class="nf">get_evaluation_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">:</span> <span class="n">Dataset</span><span class="p">):</span>
        <span class="n">evaluation_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
            <span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_evaluation_batch_size</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">_dataloader_kwargs</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">evaluation_loader</span>

    <span class="k">def</span> <span class="nf">get_trained</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">train_loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
        <span class="n">train_augmentations</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Module</span><span class="p">],</span>
        <span class="n">validation_loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
        <span class="n">log</span><span class="p">,</span>
        <span class="n">wandb_key_path</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">loss</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">validation_loss</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TrainedModel</span><span class="p">:</span>
        <span class="n">model_optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_model_optimizer</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">validation_loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">validation_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>

        <span class="k">if</span> <span class="kc">False</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;With Patience&quot;</span><span class="p">)</span>
            <span class="n">train_with_schedule</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">model_optimizer</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="n">model_optimizer</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span>
                <span class="n">training_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_training_samples</span><span class="p">,</span>
                <span class="n">validation_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_validation_samples</span><span class="p">,</span>
                <span class="n">train_loader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span>
                <span class="n">train_augmentations</span><span class="o">=</span><span class="n">train_augmentations</span><span class="p">,</span>
                <span class="n">validation_loader</span><span class="o">=</span><span class="n">validation_loader</span><span class="p">,</span>
                <span class="n">patience_schedule</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">patience_schedule</span><span class="p">,</span>
                <span class="n">factor_schedule</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">factor_schedule</span><span class="p">,</span>
                <span class="n">max_epochs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_training_epochs</span><span class="p">,</span>
                <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
                <span class="n">validation_loss</span><span class="o">=</span><span class="n">validation_loss</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="n">training_log</span><span class="o">=</span><span class="n">log</span><span class="p">,</span>
                <span class="n">wandb_key_path</span><span class="o">=</span><span class="n">wandb_key_path</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cosine Annealing&quot;</span><span class="p">)</span>
            <span class="n">train_with_cosine_annealing</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">model_optimizer</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="n">model_optimizer</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span>
                <span class="n">training_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_training_samples</span><span class="p">,</span>
                <span class="n">validation_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_validation_samples</span><span class="p">,</span>
                <span class="n">train_loader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span>
                <span class="n">train_augmentations</span><span class="o">=</span><span class="n">train_augmentations</span><span class="p">,</span>
                <span class="n">validation_loader</span><span class="o">=</span><span class="n">validation_loader</span><span class="p">,</span>
                <span class="n">max_epochs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_training_epochs</span><span class="p">,</span>
                <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
                <span class="n">validation_loss</span><span class="o">=</span><span class="n">validation_loss</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="n">training_log</span><span class="o">=</span><span class="n">log</span><span class="p">,</span>
                <span class="n">wandb_key_path</span><span class="o">=</span><span class="n">wandb_key_path</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">TrainedBayesianModel</span><span class="p">(</span><span class="n">model_optimizer</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="CIFAR-10-40%-baseline">CIFAR-10 40% baseline<a class="anchor-link" href="#CIFAR-10-40%-baseline"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">batchbald_redux.black_box_model_training</span> <span class="kn">import</span> <span class="n">evaluate</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.datasets</span> <span class="kn">import</span> <span class="n">get_dataset</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># split_dataset = get_dataset(&quot;CIFAR-10&quot;, root=&quot;data&quot;, normalize_like_cifar10=False, validation_set_size=5000)</span>
<span class="n">split_dataset</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span><span class="s2">&quot;CIFAR-10&quot;</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">normalize_like_cifar10</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">validation_set_size</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Files already downloaded and verified
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  return floored.astype(np.int)
/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  return floored.astype(np.int)
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Files already downloaded and verified
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils</span> <span class="kn">import</span> <span class="n">data</span>

<span class="n">model_trainer</span> <span class="o">=</span> <span class="n">Cifar10ModelWorkshopPaperTrainer</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">resnet18_dropout_head</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_validation_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_training_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_train_dataloader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">train</span> <span class="o">*</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">))</span>
<span class="n">validation_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_evaluation_dataloader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">validation</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_evaluation_dataloader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">test</span><span class="p">)</span>

<span class="n">log</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">trained_model</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_trained</span><span class="p">(</span>
    <span class="n">train_loader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span>
    <span class="n">train_augmentations</span><span class="o">=</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">train_augmentations</span><span class="p">,</span>
    <span class="n">validation_loader</span><span class="o">=</span><span class="n">validation_loader</span><span class="p">,</span>
    <span class="n">log</span><span class="o">=</span><span class="n">log</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">log</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>9000
NeurIPS Workshop Style
Limit schedule/max epochs updated: [40, 60], 60
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/kornia/utils/helpers.py:96: UserWarning: torch.solve is deprecated in favor of torch.linalg.solveand will be removed in a future PyTorch release.
torch.linalg.solve has its arguments reversed and does not return the LU factorization.
To get the LU factorization see torch.lu, which can be used with torch.lu_solve or torch.lu_unpack.
X = torch.solve(B, A).solution
should be replaced with
X = torch.linalg.solve(A, B) (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068694/work/aten/src/ATen/native/BatchLinearAlgebra.cpp:766.)
  out1, out2 = torch.solve(input.to(dtype), A.to(dtype))
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch metrics: {&#39;accuracy&#39;: 0.3338, &#39;crossentropy&#39;: 1.788828515625}
Epoch metrics: {&#39;accuracy&#39;: 0.4098, &#39;crossentropy&#39;: 1.562552734375}
Epoch metrics: {&#39;accuracy&#39;: 0.4922, &#39;crossentropy&#39;: 1.396963671875}
Epoch metrics: {&#39;accuracy&#39;: 0.503, &#39;crossentropy&#39;: 1.35877587890625}
Epoch metrics: {&#39;accuracy&#39;: 0.5458, &#39;crossentropy&#39;: 1.275010546875}
Epoch metrics: {&#39;accuracy&#39;: 0.586, &#39;crossentropy&#39;: 1.146974609375}
Epoch metrics: {&#39;accuracy&#39;: 0.4356, &#39;crossentropy&#39;: 1.87033828125}
Epoch 7: 0.4356 worse than 0.586, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.616, &#39;crossentropy&#39;: 1.11372587890625}
Epoch metrics: {&#39;accuracy&#39;: 0.5892, &#39;crossentropy&#39;: 1.24898505859375}
Epoch 9: 0.5892 worse than 0.616, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.606, &#39;crossentropy&#39;: 1.1485330078125}
Epoch 10: 0.606 worse than 0.616, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.6214, &#39;crossentropy&#39;: 1.12935126953125}
Epoch metrics: {&#39;accuracy&#39;: 0.641, &#39;crossentropy&#39;: 1.06390244140625}
Epoch metrics: {&#39;accuracy&#39;: 0.6182, &#39;crossentropy&#39;: 1.17152060546875}
Epoch 13: 0.6182 worse than 0.641, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.6498, &#39;crossentropy&#39;: 1.0512513671875}
Epoch metrics: {&#39;accuracy&#39;: 0.6548, &#39;crossentropy&#39;: 1.04202216796875}
Epoch metrics: {&#39;accuracy&#39;: 0.6492, &#39;crossentropy&#39;: 1.1751919921875}
Epoch 16: 0.6492 worse than 0.6548, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.6402, &#39;crossentropy&#39;: 1.11607685546875}
Epoch 17: 0.6402 worse than 0.6548, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.6982, &#39;crossentropy&#39;: 0.93934482421875}
Epoch metrics: {&#39;accuracy&#39;: 0.7002, &#39;crossentropy&#39;: 0.94554892578125}
Epoch metrics: {&#39;accuracy&#39;: 0.6688, &#39;crossentropy&#39;: 1.1248337890625}
Epoch 20: 0.6688 worse than 0.7002, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.717, &#39;crossentropy&#39;: 0.87272060546875}
Epoch metrics: {&#39;accuracy&#39;: 0.6488, &#39;crossentropy&#39;: 1.27194912109375}
Epoch 22: 0.6488 worse than 0.717, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.6544, &#39;crossentropy&#39;: 1.2549419921875}
Epoch 23: 0.6544 worse than 0.717, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.713, &#39;crossentropy&#39;: 0.95235283203125}
Epoch 24: 0.713 worse than 0.717, patience: 3/20!
Epoch metrics: {&#39;accuracy&#39;: 0.713, &#39;crossentropy&#39;: 0.950769140625}
Epoch 25: 0.713 worse than 0.717, patience: 4/20!
Epoch metrics: {&#39;accuracy&#39;: 0.6884, &#39;crossentropy&#39;: 1.1287990234375}
Epoch 26: 0.6884 worse than 0.717, patience: 5/20!
Epoch metrics: {&#39;accuracy&#39;: 0.7202, &#39;crossentropy&#39;: 0.98443134765625}
Epoch metrics: {&#39;accuracy&#39;: 0.7266, &#39;crossentropy&#39;: 0.97618134765625}
Epoch metrics: {&#39;accuracy&#39;: 0.7064, &#39;crossentropy&#39;: 1.06831044921875}
Epoch 29: 0.7064 worse than 0.7266, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.6964, &#39;crossentropy&#39;: 1.20238486328125}
Epoch 30: 0.6964 worse than 0.7266, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.7028, &#39;crossentropy&#39;: 1.14810732421875}
Epoch 31: 0.7028 worse than 0.7266, patience: 3/20!
Epoch metrics: {&#39;accuracy&#39;: 0.6836, &#39;crossentropy&#39;: 1.23035732421875}
Epoch 32: 0.6836 worse than 0.7266, patience: 4/20!
Epoch metrics: {&#39;accuracy&#39;: 0.7164, &#39;crossentropy&#39;: 1.15417001953125}
Epoch 33: 0.7164 worse than 0.7266, patience: 5/20!
Epoch metrics: {&#39;accuracy&#39;: 0.7328, &#39;crossentropy&#39;: 1.0592923828125}
Epoch metrics: {&#39;accuracy&#39;: 0.7194, &#39;crossentropy&#39;: 1.1219935546875}
Epoch 35: 0.7194 worse than 0.7328, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.7428, &#39;crossentropy&#39;: 0.9920734375}
Epoch metrics: {&#39;accuracy&#39;: 0.7472, &#39;crossentropy&#39;: 1.0149998046875}
Epoch metrics: {&#39;accuracy&#39;: 0.739, &#39;crossentropy&#39;: 1.13475}
Epoch 38: 0.739 worse than 0.7472, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.7428, &#39;crossentropy&#39;: 1.0816396484375}
Epoch 39: 0.7428 worse than 0.7472, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.753, &#39;crossentropy&#39;: 0.96909736328125}
Restoring best snapshot: best_score: 0.753 @ epoch 40
Epoch    40: reducing learning rate of group 0 to 1.0000e-03.
Epoch metrics: {&#39;accuracy&#39;: 0.7908, &#39;crossentropy&#39;: 0.809996044921875}
Epoch metrics: {&#39;accuracy&#39;: 0.788, &#39;crossentropy&#39;: 0.8049732421875}
Epoch 42: 0.788 worse than 0.7908, patience: 1/10!
Epoch metrics: {&#39;accuracy&#39;: 0.7908, &#39;crossentropy&#39;: 0.80625439453125}
Epoch 43: 0.7908 worse than 0.7908, patience: 2/10!
Epoch metrics: {&#39;accuracy&#39;: 0.7892, &#39;crossentropy&#39;: 0.8100119140625}
Epoch 44: 0.7892 worse than 0.7908, patience: 3/10!
Epoch metrics: {&#39;accuracy&#39;: 0.792, &#39;crossentropy&#39;: 0.810284765625}
Epoch metrics: {&#39;accuracy&#39;: 0.79, &#39;crossentropy&#39;: 0.82533388671875}
Epoch 46: 0.79 worse than 0.792, patience: 1/10!
Epoch metrics: {&#39;accuracy&#39;: 0.7906, &#39;crossentropy&#39;: 0.8209787109375}
Epoch 47: 0.7906 worse than 0.792, patience: 2/10!
Epoch metrics: {&#39;accuracy&#39;: 0.7926, &#39;crossentropy&#39;: 0.8402470703125}
Epoch metrics: {&#39;accuracy&#39;: 0.7922, &#39;crossentropy&#39;: 0.8365568359375}
Epoch 49: 0.7922 worse than 0.7926, patience: 1/10!
Epoch metrics: {&#39;accuracy&#39;: 0.7878, &#39;crossentropy&#39;: 0.83913984375}
Epoch 50: 0.7878 worse than 0.7926, patience: 2/10!
Epoch metrics: {&#39;accuracy&#39;: 0.791, &#39;crossentropy&#39;: 0.839034375}
Epoch 51: 0.791 worse than 0.7926, patience: 3/10!
Epoch metrics: {&#39;accuracy&#39;: 0.7938, &#39;crossentropy&#39;: 0.8464892578125}
Epoch metrics: {&#39;accuracy&#39;: 0.791, &#39;crossentropy&#39;: 0.85840830078125}
Epoch 53: 0.791 worse than 0.7938, patience: 1/10!
Epoch metrics: {&#39;accuracy&#39;: 0.7946, &#39;crossentropy&#39;: 0.85860537109375}
Epoch metrics: {&#39;accuracy&#39;: 0.795, &#39;crossentropy&#39;: 0.857058203125}
Epoch metrics: {&#39;accuracy&#39;: 0.7916, &#39;crossentropy&#39;: 0.86314091796875}
Epoch 56: 0.7916 worse than 0.795, patience: 1/10!
Epoch metrics: {&#39;accuracy&#39;: 0.7938, &#39;crossentropy&#39;: 0.8699662109375}
Epoch 57: 0.7938 worse than 0.795, patience: 2/10!
Epoch metrics: {&#39;accuracy&#39;: 0.7912, &#39;crossentropy&#39;: 0.8700767578125}
Epoch 58: 0.7912 worse than 0.795, patience: 3/10!
Epoch metrics: {&#39;accuracy&#39;: 0.7922, &#39;crossentropy&#39;: 0.87140712890625}
Epoch 59: 0.7922 worse than 0.795, patience: 4/10!
Epoch metrics: {&#39;accuracy&#39;: 0.7928, &#39;crossentropy&#39;: 0.8758435546875}
Epoch 60: 0.7928 worse than 0.795, patience: 5/10!
Restoring best snapshot: best_score: 0.795 @ epoch 55
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;epochs&#39;: [{&#39;accuracy&#39;: 0.3338, &#39;crossentropy&#39;: 1.788828515625},
  {&#39;accuracy&#39;: 0.4098, &#39;crossentropy&#39;: 1.562552734375},
  {&#39;accuracy&#39;: 0.4922, &#39;crossentropy&#39;: 1.396963671875},
  {&#39;accuracy&#39;: 0.503, &#39;crossentropy&#39;: 1.35877587890625},
  {&#39;accuracy&#39;: 0.5458, &#39;crossentropy&#39;: 1.275010546875},
  {&#39;accuracy&#39;: 0.586, &#39;crossentropy&#39;: 1.146974609375},
  {&#39;accuracy&#39;: 0.4356, &#39;crossentropy&#39;: 1.87033828125},
  {&#39;accuracy&#39;: 0.616, &#39;crossentropy&#39;: 1.11372587890625},
  {&#39;accuracy&#39;: 0.5892, &#39;crossentropy&#39;: 1.24898505859375},
  {&#39;accuracy&#39;: 0.606, &#39;crossentropy&#39;: 1.1485330078125},
  {&#39;accuracy&#39;: 0.6214, &#39;crossentropy&#39;: 1.12935126953125},
  {&#39;accuracy&#39;: 0.641, &#39;crossentropy&#39;: 1.06390244140625},
  {&#39;accuracy&#39;: 0.6182, &#39;crossentropy&#39;: 1.17152060546875},
  {&#39;accuracy&#39;: 0.6498, &#39;crossentropy&#39;: 1.0512513671875},
  {&#39;accuracy&#39;: 0.6548, &#39;crossentropy&#39;: 1.04202216796875},
  {&#39;accuracy&#39;: 0.6492, &#39;crossentropy&#39;: 1.1751919921875},
  {&#39;accuracy&#39;: 0.6402, &#39;crossentropy&#39;: 1.11607685546875},
  {&#39;accuracy&#39;: 0.6982, &#39;crossentropy&#39;: 0.93934482421875},
  {&#39;accuracy&#39;: 0.7002, &#39;crossentropy&#39;: 0.94554892578125},
  {&#39;accuracy&#39;: 0.6688, &#39;crossentropy&#39;: 1.1248337890625},
  {&#39;accuracy&#39;: 0.717, &#39;crossentropy&#39;: 0.87272060546875},
  {&#39;accuracy&#39;: 0.6488, &#39;crossentropy&#39;: 1.27194912109375},
  {&#39;accuracy&#39;: 0.6544, &#39;crossentropy&#39;: 1.2549419921875},
  {&#39;accuracy&#39;: 0.713, &#39;crossentropy&#39;: 0.95235283203125},
  {&#39;accuracy&#39;: 0.713, &#39;crossentropy&#39;: 0.950769140625},
  {&#39;accuracy&#39;: 0.6884, &#39;crossentropy&#39;: 1.1287990234375},
  {&#39;accuracy&#39;: 0.7202, &#39;crossentropy&#39;: 0.98443134765625},
  {&#39;accuracy&#39;: 0.7266, &#39;crossentropy&#39;: 0.97618134765625},
  {&#39;accuracy&#39;: 0.7064, &#39;crossentropy&#39;: 1.06831044921875},
  {&#39;accuracy&#39;: 0.6964, &#39;crossentropy&#39;: 1.20238486328125},
  {&#39;accuracy&#39;: 0.7028, &#39;crossentropy&#39;: 1.14810732421875},
  {&#39;accuracy&#39;: 0.6836, &#39;crossentropy&#39;: 1.23035732421875},
  {&#39;accuracy&#39;: 0.7164, &#39;crossentropy&#39;: 1.15417001953125},
  {&#39;accuracy&#39;: 0.7328, &#39;crossentropy&#39;: 1.0592923828125},
  {&#39;accuracy&#39;: 0.7194, &#39;crossentropy&#39;: 1.1219935546875},
  {&#39;accuracy&#39;: 0.7428, &#39;crossentropy&#39;: 0.9920734375},
  {&#39;accuracy&#39;: 0.7472, &#39;crossentropy&#39;: 1.0149998046875},
  {&#39;accuracy&#39;: 0.739, &#39;crossentropy&#39;: 1.13475},
  {&#39;accuracy&#39;: 0.7428, &#39;crossentropy&#39;: 1.0816396484375},
  {&#39;accuracy&#39;: 0.753, &#39;crossentropy&#39;: 0.96909736328125},
  {&#39;accuracy&#39;: 0.7908, &#39;crossentropy&#39;: 0.809996044921875},
  {&#39;accuracy&#39;: 0.788, &#39;crossentropy&#39;: 0.8049732421875},
  {&#39;accuracy&#39;: 0.7908, &#39;crossentropy&#39;: 0.80625439453125},
  {&#39;accuracy&#39;: 0.7892, &#39;crossentropy&#39;: 0.8100119140625},
  {&#39;accuracy&#39;: 0.792, &#39;crossentropy&#39;: 0.810284765625},
  {&#39;accuracy&#39;: 0.79, &#39;crossentropy&#39;: 0.82533388671875},
  {&#39;accuracy&#39;: 0.7906, &#39;crossentropy&#39;: 0.8209787109375},
  {&#39;accuracy&#39;: 0.7926, &#39;crossentropy&#39;: 0.8402470703125},
  {&#39;accuracy&#39;: 0.7922, &#39;crossentropy&#39;: 0.8365568359375},
  {&#39;accuracy&#39;: 0.7878, &#39;crossentropy&#39;: 0.83913984375},
  {&#39;accuracy&#39;: 0.791, &#39;crossentropy&#39;: 0.839034375},
  {&#39;accuracy&#39;: 0.7938, &#39;crossentropy&#39;: 0.8464892578125},
  {&#39;accuracy&#39;: 0.791, &#39;crossentropy&#39;: 0.85840830078125},
  {&#39;accuracy&#39;: 0.7946, &#39;crossentropy&#39;: 0.85860537109375},
  {&#39;accuracy&#39;: 0.795, &#39;crossentropy&#39;: 0.857058203125},
  {&#39;accuracy&#39;: 0.7916, &#39;crossentropy&#39;: 0.86314091796875},
  {&#39;accuracy&#39;: 0.7938, &#39;crossentropy&#39;: 0.8699662109375},
  {&#39;accuracy&#39;: 0.7912, &#39;crossentropy&#39;: 0.8700767578125},
  {&#39;accuracy&#39;: 0.7922, &#39;crossentropy&#39;: 0.87140712890625},
  {&#39;accuracy&#39;: 0.7928, &#39;crossentropy&#39;: 0.8758435546875}],
 &#39;era_epochs&#39;: [40]}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils</span> <span class="kn">import</span> <span class="n">data</span>

<span class="n">model_trainer</span> <span class="o">=</span> <span class="n">Cifar10ModelWorkshopPaperTrainer</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">resnet18_dropout_head</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_validation_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_train_dataloader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">train</span> <span class="o">*</span> <span class="mf">0.4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">))</span>
<span class="n">validation_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_evaluation_dataloader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">validation</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_evaluation_dataloader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">test</span><span class="p">)</span>

<span class="n">log</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">trained_model</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_trained</span><span class="p">(</span>
    <span class="n">train_loader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span>
    <span class="n">train_augmentations</span><span class="o">=</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">train_augmentations</span><span class="p">,</span>
    <span class="n">validation_loader</span><span class="o">=</span><span class="n">validation_loader</span><span class="p">,</span>
    <span class="n">log</span><span class="o">=</span><span class="n">log</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">log</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>18000
NeurIPS Workshop Style
Limit schedule/max epochs updated: [60, 100], 120
Epoch metrics: {&#39;accuracy&#39;: 0.4184, &#39;crossentropy&#39;: 1.63369365234375}
Epoch metrics: {&#39;accuracy&#39;: 0.456, &#39;crossentropy&#39;: 1.4933126953125}
Epoch metrics: {&#39;accuracy&#39;: 0.543, &#39;crossentropy&#39;: 1.3087578125}
Epoch metrics: {&#39;accuracy&#39;: 0.571, &#39;crossentropy&#39;: 1.1830423828125}
Epoch metrics: {&#39;accuracy&#39;: 0.5636, &#39;crossentropy&#39;: 1.35126435546875}
Epoch 5: 0.5636 worse than 0.571, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.6126, &#39;crossentropy&#39;: 1.17582822265625}
Epoch metrics: {&#39;accuracy&#39;: 0.6516, &#39;crossentropy&#39;: 1.06289931640625}
Epoch metrics: {&#39;accuracy&#39;: 0.6872, &#39;crossentropy&#39;: 0.9359330078125}
Epoch metrics: {&#39;accuracy&#39;: 0.7182, &#39;crossentropy&#39;: 0.834603515625}
Epoch metrics: {&#39;accuracy&#39;: 0.673, &#39;crossentropy&#39;: 1.0332705078125}
Epoch 10: 0.673 worse than 0.7182, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.6648, &#39;crossentropy&#39;: 1.11091875}
Epoch 11: 0.6648 worse than 0.7182, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.7474, &#39;crossentropy&#39;: 0.79964736328125}
Epoch metrics: {&#39;accuracy&#39;: 0.7222, &#39;crossentropy&#39;: 0.87187158203125}
Epoch 13: 0.7222 worse than 0.7474, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.7692, &#39;crossentropy&#39;: 0.684801904296875}
Epoch metrics: {&#39;accuracy&#39;: 0.7658, &#39;crossentropy&#39;: 0.698701025390625}
Epoch 15: 0.7658 worse than 0.7692, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.6694, &#39;crossentropy&#39;: 1.12339189453125}
Epoch 16: 0.6694 worse than 0.7692, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.6588, &#39;crossentropy&#39;: 1.31867578125}
Epoch 17: 0.6588 worse than 0.7692, patience: 3/20!
Epoch metrics: {&#39;accuracy&#39;: 0.7566, &#39;crossentropy&#39;: 0.83489873046875}
Epoch 18: 0.7566 worse than 0.7692, patience: 4/20!
Epoch metrics: {&#39;accuracy&#39;: 0.764, &#39;crossentropy&#39;: 0.7868427734375}
Epoch 19: 0.764 worse than 0.7692, patience: 5/20!
Epoch metrics: {&#39;accuracy&#39;: 0.771, &#39;crossentropy&#39;: 0.7335056640625}
Epoch metrics: {&#39;accuracy&#39;: 0.78, &#39;crossentropy&#39;: 0.68211630859375}
Epoch metrics: {&#39;accuracy&#39;: 0.7698, &#39;crossentropy&#39;: 0.779892431640625}
Epoch 22: 0.7698 worse than 0.78, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.7848, &#39;crossentropy&#39;: 0.76476728515625}
Epoch metrics: {&#39;accuracy&#39;: 0.8066, &#39;crossentropy&#39;: 0.662639306640625}
Epoch metrics: {&#39;accuracy&#39;: 0.7958, &#39;crossentropy&#39;: 0.697049951171875}
Epoch 25: 0.7958 worse than 0.8066, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.8042, &#39;crossentropy&#39;: 0.646352392578125}
Epoch 26: 0.8042 worse than 0.8066, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.7918, &#39;crossentropy&#39;: 0.7113486328125}
Epoch 27: 0.7918 worse than 0.8066, patience: 3/20!
Epoch metrics: {&#39;accuracy&#39;: 0.7766, &#39;crossentropy&#39;: 0.787007177734375}
Epoch 28: 0.7766 worse than 0.8066, patience: 4/20!
Epoch metrics: {&#39;accuracy&#39;: 0.783, &#39;crossentropy&#39;: 0.775112353515625}
Epoch 29: 0.783 worse than 0.8066, patience: 5/20!
Epoch metrics: {&#39;accuracy&#39;: 0.7978, &#39;crossentropy&#39;: 0.73684912109375}
Epoch 30: 0.7978 worse than 0.8066, patience: 6/20!
Epoch metrics: {&#39;accuracy&#39;: 0.8136, &#39;crossentropy&#39;: 0.6715294921875}
Epoch metrics: {&#39;accuracy&#39;: 0.7884, &#39;crossentropy&#39;: 0.785458935546875}
Epoch 32: 0.7884 worse than 0.8136, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.8174, &#39;crossentropy&#39;: 0.632445166015625}
Epoch metrics: {&#39;accuracy&#39;: 0.8098, &#39;crossentropy&#39;: 0.716309423828125}
Epoch 34: 0.8098 worse than 0.8174, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.7994, &#39;crossentropy&#39;: 0.752028955078125}
Epoch 35: 0.7994 worse than 0.8174, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.8072, &#39;crossentropy&#39;: 0.7335771484375}
Epoch 36: 0.8072 worse than 0.8174, patience: 3/20!
Epoch metrics: {&#39;accuracy&#39;: 0.8234, &#39;crossentropy&#39;: 0.698743310546875}
Epoch metrics: {&#39;accuracy&#39;: 0.8198, &#39;crossentropy&#39;: 0.70983583984375}
Epoch 38: 0.8198 worse than 0.8234, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.8174, &#39;crossentropy&#39;: 0.696649951171875}
Epoch 39: 0.8174 worse than 0.8234, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.8224, &#39;crossentropy&#39;: 0.6847814453125}
Epoch 40: 0.8224 worse than 0.8234, patience: 3/20!
Epoch metrics: {&#39;accuracy&#39;: 0.8192, &#39;crossentropy&#39;: 0.68914091796875}
Epoch 41: 0.8192 worse than 0.8234, patience: 4/20!
Epoch metrics: {&#39;accuracy&#39;: 0.8196, &#39;crossentropy&#39;: 0.753547802734375}
Epoch 42: 0.8196 worse than 0.8234, patience: 5/20!
Epoch metrics: {&#39;accuracy&#39;: 0.816, &#39;crossentropy&#39;: 0.732692138671875}
Epoch 43: 0.816 worse than 0.8234, patience: 6/20!
Epoch metrics: {&#39;accuracy&#39;: 0.8308, &#39;crossentropy&#39;: 0.6603810546875}
Epoch metrics: {&#39;accuracy&#39;: 0.8366, &#39;crossentropy&#39;: 0.678079296875}
Epoch metrics: {&#39;accuracy&#39;: 0.8232, &#39;crossentropy&#39;: 0.7539904296875}
Epoch 46: 0.8232 worse than 0.8366, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.8088, &#39;crossentropy&#39;: 0.8309908203125}
Epoch 47: 0.8088 worse than 0.8366, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.828, &#39;crossentropy&#39;: 0.725307177734375}
Epoch 48: 0.828 worse than 0.8366, patience: 3/20!
Epoch metrics: {&#39;accuracy&#39;: 0.825, &#39;crossentropy&#39;: 0.74897607421875}
Epoch 49: 0.825 worse than 0.8366, patience: 4/20!
Epoch metrics: {&#39;accuracy&#39;: 0.8312, &#39;crossentropy&#39;: 0.7099451171875}
Epoch 50: 0.8312 worse than 0.8366, patience: 5/20!
Epoch metrics: {&#39;accuracy&#39;: 0.8368, &#39;crossentropy&#39;: 0.707602392578125}
Epoch metrics: {&#39;accuracy&#39;: 0.829, &#39;crossentropy&#39;: 0.78075107421875}
Epoch 52: 0.829 worse than 0.8368, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.8342, &#39;crossentropy&#39;: 0.7069453125}
Epoch 53: 0.8342 worse than 0.8368, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.8302, &#39;crossentropy&#39;: 0.71642744140625}
Epoch 54: 0.8302 worse than 0.8368, patience: 3/20!
Epoch metrics: {&#39;accuracy&#39;: 0.8426, &#39;crossentropy&#39;: 0.6962521484375}
Epoch metrics: {&#39;accuracy&#39;: 0.8374, &#39;crossentropy&#39;: 0.667905029296875}
Epoch 56: 0.8374 worse than 0.8426, patience: 1/20!
Epoch metrics: {&#39;accuracy&#39;: 0.8342, &#39;crossentropy&#39;: 0.743208349609375}
Epoch 57: 0.8342 worse than 0.8426, patience: 2/20!
Epoch metrics: {&#39;accuracy&#39;: 0.828, &#39;crossentropy&#39;: 0.72863759765625}
Epoch 58: 0.828 worse than 0.8426, patience: 3/20!
Epoch metrics: {&#39;accuracy&#39;: 0.8392, &#39;crossentropy&#39;: 0.6911654296875}
Epoch 59: 0.8392 worse than 0.8426, patience: 4/20!
Epoch metrics: {&#39;accuracy&#39;: 0.8422, &#39;crossentropy&#39;: 0.678407177734375}
Epoch 60: 0.8422 worse than 0.8426, patience: 5/20!
Epoch    60: reducing learning rate of group 0 to 1.0000e-03.
Epoch metrics: {&#39;accuracy&#39;: 0.8624, &#39;crossentropy&#39;: 0.561701416015625}
Epoch metrics: {&#39;accuracy&#39;: 0.8654, &#39;crossentropy&#39;: 0.54707998046875}
Epoch metrics: {&#39;accuracy&#39;: 0.8706, &#39;crossentropy&#39;: 0.54209775390625}
Epoch metrics: {&#39;accuracy&#39;: 0.8722, &#39;crossentropy&#39;: 0.538364013671875}
Epoch metrics: {&#39;accuracy&#39;: 0.8712, &#39;crossentropy&#39;: 0.540614208984375}
Epoch 65: 0.8712 worse than 0.8722, patience: 1/10!
Epoch metrics: {&#39;accuracy&#39;: 0.871, &#39;crossentropy&#39;: 0.540376513671875}
Epoch 66: 0.871 worse than 0.8722, patience: 2/10!
Epoch metrics: {&#39;accuracy&#39;: 0.872, &#39;crossentropy&#39;: 0.534648388671875}
Epoch 67: 0.872 worse than 0.8722, patience: 3/10!
Epoch metrics: {&#39;accuracy&#39;: 0.8714, &#39;crossentropy&#39;: 0.53286865234375}
Epoch 68: 0.8714 worse than 0.8722, patience: 4/10!
Epoch metrics: {&#39;accuracy&#39;: 0.8718, &#39;crossentropy&#39;: 0.53768935546875}
Epoch 69: 0.8718 worse than 0.8722, patience: 5/10!
Epoch metrics: {&#39;accuracy&#39;: 0.8722, &#39;crossentropy&#39;: 0.53575908203125}
Epoch 70: 0.8722 worse than 0.8722, patience: 6/10!
Epoch metrics: {&#39;accuracy&#39;: 0.8718, &#39;crossentropy&#39;: 0.54225185546875}
Epoch 71: 0.8718 worse than 0.8722, patience: 7/10!
Epoch metrics: {&#39;accuracy&#39;: 0.8734, &#39;crossentropy&#39;: 0.542415234375}
Epoch metrics: {&#39;accuracy&#39;: 0.8714, &#39;crossentropy&#39;: 0.54105703125}
Epoch 73: 0.8714 worse than 0.8734, patience: 1/10!
Epoch metrics: {&#39;accuracy&#39;: 0.8726, &#39;crossentropy&#39;: 0.53963525390625}
Epoch 74: 0.8726 worse than 0.8734, patience: 2/10!
Epoch metrics: {&#39;accuracy&#39;: 0.873, &#39;crossentropy&#39;: 0.5408787109375}
Epoch 75: 0.873 worse than 0.8734, patience: 3/10!
Epoch metrics: {&#39;accuracy&#39;: 0.8744, &#39;crossentropy&#39;: 0.54072890625}
Epoch metrics: {&#39;accuracy&#39;: 0.8742, &#39;crossentropy&#39;: 0.544073974609375}
Epoch 77: 0.8742 worse than 0.8744, patience: 1/10!
Epoch metrics: {&#39;accuracy&#39;: 0.8734, &#39;crossentropy&#39;: 0.54320126953125}
Epoch 78: 0.8734 worse than 0.8744, patience: 2/10!
Epoch metrics: {&#39;accuracy&#39;: 0.8736, &#39;crossentropy&#39;: 0.54428427734375}
Epoch 79: 0.8736 worse than 0.8744, patience: 3/10!
Epoch metrics: {&#39;accuracy&#39;: 0.8732, &#39;crossentropy&#39;: 0.542178857421875}
Epoch 80: 0.8732 worse than 0.8744, patience: 4/10!
Epoch metrics: {&#39;accuracy&#39;: 0.8746, &#39;crossentropy&#39;: 0.546287109375}
Epoch metrics: {&#39;accuracy&#39;: 0.8742, &#39;crossentropy&#39;: 0.543280126953125}
Epoch 82: 0.8742 worse than 0.8746, patience: 1/10!
Epoch metrics: {&#39;accuracy&#39;: 0.8732, &#39;crossentropy&#39;: 0.543013818359375}
Epoch 83: 0.8732 worse than 0.8746, patience: 2/10!
Epoch metrics: {&#39;accuracy&#39;: 0.8744, &#39;crossentropy&#39;: 0.54249775390625}
Epoch 84: 0.8744 worse than 0.8746, patience: 3/10!
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Engine run is terminating due to exception: 
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-13-1cab8c9fe78e&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">     11</span> 
<span class="ansi-green-intense-fg ansi-bold">     12</span> log <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">{</span><span class="ansi-blue-fg">}</span>
<span class="ansi-green-fg">---&gt; 13</span><span class="ansi-red-fg"> trained_model = model_trainer.get_trained(
</span><span class="ansi-green-intense-fg ansi-bold">     14</span>     train_loader<span class="ansi-blue-fg">=</span>train_loader<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">     15</span>     train_augmentations<span class="ansi-blue-fg">=</span>split_dataset<span class="ansi-blue-fg">.</span>train_augmentations<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">&lt;ipython-input-10-cb1f23b3a3f3&gt;</span> in <span class="ansi-cyan-fg">get_trained</span><span class="ansi-blue-fg">(self, train_loader, train_augmentations, validation_loader, log, loss, validation_loss)</span>
<span class="ansi-green-intense-fg ansi-bold">     77</span> 
<span class="ansi-green-intense-fg ansi-bold">     78</span>         print<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#34;NeurIPS Workshop Style&#34;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 79</span><span class="ansi-red-fg">         train_with_schedule(
</span><span class="ansi-green-intense-fg ansi-bold">     80</span>             model<span class="ansi-blue-fg">=</span>model_optimizer<span class="ansi-blue-fg">.</span>model<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">     81</span>             optimizer<span class="ansi-blue-fg">=</span>model_optimizer<span class="ansi-blue-fg">.</span>optimizer<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/black_box_model_training.py</span> in <span class="ansi-cyan-fg">train_with_schedule</span><span class="ansi-blue-fg">(model, training_samples, validation_samples, train_loader, validation_loader, patience_schedule, factor_schedule, max_epochs, device, training_log, loss, validation_loss, optimizer, prefer_accuracy, train_augmentations, limit_schedule)</span>
<span class="ansi-green-intense-fg ansi-bold">    266</span> 
<span class="ansi-green-intense-fg ansi-bold">    267</span>     <span class="ansi-red-fg"># Kick everything off</span>
<span class="ansi-green-fg">--&gt; 268</span><span class="ansi-red-fg">     </span>trainer<span class="ansi-blue-fg">.</span>run<span class="ansi-blue-fg">(</span>train_loader<span class="ansi-blue-fg">,</span> max_epochs<span class="ansi-blue-fg">=</span>max_epochs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    269</span> 
<span class="ansi-green-intense-fg ansi-bold">    270</span>     <span class="ansi-red-fg"># Return the optimizer in case we want to continue training.</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">run</span><span class="ansi-blue-fg">(self, data, max_epochs, epoch_length, seed)</span>
<span class="ansi-green-intense-fg ansi-bold">    696</span> 
<span class="ansi-green-intense-fg ansi-bold">    697</span>         self<span class="ansi-blue-fg">.</span>state<span class="ansi-blue-fg">.</span>dataloader <span class="ansi-blue-fg">=</span> data
<span class="ansi-green-fg">--&gt; 698</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_internal_run<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    699</span> 
<span class="ansi-green-intense-fg ansi-bold">    700</span>     <span class="ansi-blue-fg">@</span>staticmethod

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">_internal_run</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    769</span>             self<span class="ansi-blue-fg">.</span>_dataloader_iter <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span>
<span class="ansi-green-intense-fg ansi-bold">    770</span>             self<span class="ansi-blue-fg">.</span>logger<span class="ansi-blue-fg">.</span>error<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">f&#34;Engine run is terminating due to exception: {e}&#34;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 771</span><span class="ansi-red-fg">             </span>self<span class="ansi-blue-fg">.</span>_handle_exception<span class="ansi-blue-fg">(</span>e<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    772</span> 
<span class="ansi-green-intense-fg ansi-bold">    773</span>         self<span class="ansi-blue-fg">.</span>_dataloader_iter <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">_handle_exception</span><span class="ansi-blue-fg">(self, e)</span>
<span class="ansi-green-intense-fg ansi-bold">    464</span>             self<span class="ansi-blue-fg">.</span>_fire_event<span class="ansi-blue-fg">(</span>Events<span class="ansi-blue-fg">.</span>EXCEPTION_RAISED<span class="ansi-blue-fg">,</span> e<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    465</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 466</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">raise</span> e
<span class="ansi-green-intense-fg ansi-bold">    467</span> 
<span class="ansi-green-intense-fg ansi-bold">    468</span>     <span class="ansi-blue-fg">@</span>property

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">_internal_run</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    739</span>                     self<span class="ansi-blue-fg">.</span>_setup_engine<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    740</span> 
<span class="ansi-green-fg">--&gt; 741</span><span class="ansi-red-fg">                 </span>time_taken <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_run_once_on_dataset<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    742</span>                 <span class="ansi-red-fg"># time is available for handlers but must be update after fire</span>
<span class="ansi-green-intense-fg ansi-bold">    743</span>                 self<span class="ansi-blue-fg">.</span>state<span class="ansi-blue-fg">.</span>times<span class="ansi-blue-fg">[</span>Events<span class="ansi-blue-fg">.</span>EPOCH_COMPLETED<span class="ansi-blue-fg">.</span>name<span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> time_taken

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">_run_once_on_dataset</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    829</span>                 self<span class="ansi-blue-fg">.</span>state<span class="ansi-blue-fg">.</span>iteration <span class="ansi-blue-fg">+=</span> <span class="ansi-cyan-fg">1</span>
<span class="ansi-green-intense-fg ansi-bold">    830</span>                 self<span class="ansi-blue-fg">.</span>_fire_event<span class="ansi-blue-fg">(</span>Events<span class="ansi-blue-fg">.</span>ITERATION_STARTED<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 831</span><span class="ansi-red-fg">                 </span>self<span class="ansi-blue-fg">.</span>state<span class="ansi-blue-fg">.</span>output <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_process_function<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>state<span class="ansi-blue-fg">.</span>batch<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    832</span>                 self<span class="ansi-blue-fg">.</span>_fire_event<span class="ansi-blue-fg">(</span>Events<span class="ansi-blue-fg">.</span>ITERATION_COMPLETED<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    833</span> 

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/__init__.py</span> in <span class="ansi-cyan-fg">update</span><span class="ansi-blue-fg">(engine, batch)</span>
<span class="ansi-green-intense-fg ansi-bold">    108</span>             optimizer<span class="ansi-blue-fg">.</span>step<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    109</span>             optimizer<span class="ansi-blue-fg">.</span>zero_grad<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 110</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> output_transform<span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">,</span> y_pred<span class="ansi-blue-fg">,</span> loss<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    111</span> 
<span class="ansi-green-intense-fg ansi-bold">    112</span>     <span class="ansi-green-fg">return</span> update

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/__init__.py</span> in <span class="ansi-cyan-fg">&lt;lambda&gt;</span><span class="ansi-blue-fg">(x, y, y_pred, loss)</span>
<span class="ansi-green-intense-fg ansi-bold">    384</span>     non_blocking<span class="ansi-blue-fg">:</span> bool <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">False</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    385</span>     prepare_batch<span class="ansi-blue-fg">:</span> Callable <span class="ansi-blue-fg">=</span> _prepare_batch<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">--&gt; 386</span><span class="ansi-red-fg">     </span>output_transform<span class="ansi-blue-fg">:</span> Callable <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">lambda</span> x<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">,</span> y_pred<span class="ansi-blue-fg">,</span> loss<span class="ansi-blue-fg">:</span> loss<span class="ansi-blue-fg">.</span>item<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    387</span>     deterministic<span class="ansi-blue-fg">:</span> bool <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">False</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    388</span>     amp_mode<span class="ansi-blue-fg">:</span> Optional<span class="ansi-blue-fg">[</span>str<span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span>

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils</span> <span class="kn">import</span> <span class="n">data</span>

<span class="n">model_trainer</span> <span class="o">=</span> <span class="n">Cifar10ModelWorkshopPaperTrainer</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">resnet18_dropout_head</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_train_dataloader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">train</span> <span class="o">*</span> <span class="mf">0.4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">))</span>
<span class="n">validation_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_evaluation_dataloader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">validation</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_evaluation_dataloader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">test</span><span class="p">)</span>

<span class="n">log</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">trained_model</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_trained</span><span class="p">(</span>
    <span class="n">train_loader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span>
    <span class="n">train_augmentations</span><span class="o">=</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">train_augmentations</span><span class="p">,</span>
    <span class="n">validation_loader</span><span class="o">=</span><span class="n">validation_loader</span><span class="p">,</span>
    <span class="n">log</span><span class="o">=</span><span class="n">log</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">log</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>18000
NeurIPS WOrkshop Style
Epoch metrics: {&#39;accuracy&#39;: 0.3082, &#39;crossentropy&#39;: 1.7973075674057006}
Epoch metrics: {&#39;accuracy&#39;: 0.3784, &#39;crossentropy&#39;: 1.701580082321167}
Epoch metrics: {&#39;accuracy&#39;: 0.4304, &#39;crossentropy&#39;: 1.5768954347610473}
Epoch metrics: {&#39;accuracy&#39;: 0.4898, &#39;crossentropy&#39;: 1.4669325416564942}
Epoch metrics: {&#39;accuracy&#39;: 0.4954, &#39;crossentropy&#39;: 1.4981587272644044}
Epoch metrics: {&#39;accuracy&#39;: 0.5328, &#39;crossentropy&#39;: 1.409426467514038}
Epoch metrics: {&#39;accuracy&#39;: 0.5946, &#39;crossentropy&#39;: 1.2132721630096435}
Epoch metrics: {&#39;accuracy&#39;: 0.6196, &#39;crossentropy&#39;: 1.15281331615448}
Epoch metrics: {&#39;accuracy&#39;: 0.612, &#39;crossentropy&#39;: 1.2480723501205444}
RestoringEarlyStopping: 1 / 5
Epoch metrics: {&#39;accuracy&#39;: 0.5356, &#39;crossentropy&#39;: 1.6043412952423095}
RestoringEarlyStopping: 2 / 5
Epoch metrics: {&#39;accuracy&#39;: 0.6232, &#39;crossentropy&#39;: 1.1425624122619629}
Epoch metrics: {&#39;accuracy&#39;: 0.647, &#39;crossentropy&#39;: 1.0633803052902222}
Epoch metrics: {&#39;accuracy&#39;: 0.6696, &#39;crossentropy&#39;: 1.0703337482452393}
Epoch metrics: {&#39;accuracy&#39;: 0.6778, &#39;crossentropy&#39;: 1.024672212600708}
Epoch metrics: {&#39;accuracy&#39;: 0.7276, &#39;crossentropy&#39;: 0.8393620066642761}
Epoch metrics: {&#39;accuracy&#39;: 0.7292, &#39;crossentropy&#39;: 0.8811147254943847}
Epoch metrics: {&#39;accuracy&#39;: 0.7116, &#39;crossentropy&#39;: 0.9226495706558228}
RestoringEarlyStopping: 1 / 5
Epoch metrics: {&#39;accuracy&#39;: 0.7432, &#39;crossentropy&#39;: 0.8460798347473144}
Epoch metrics: {&#39;accuracy&#39;: 0.7504, &#39;crossentropy&#39;: 0.8222217173576355}
Epoch metrics: {&#39;accuracy&#39;: 0.7672, &#39;crossentropy&#39;: 0.7539731317520142}
Epoch metrics: {&#39;accuracy&#39;: 0.7452, &#39;crossentropy&#39;: 0.9202061416625976}
RestoringEarlyStopping: 1 / 5
Epoch metrics: {&#39;accuracy&#39;: 0.7788, &#39;crossentropy&#39;: 0.7562990008354187}
Epoch metrics: {&#39;accuracy&#39;: 0.7864, &#39;crossentropy&#39;: 0.7357828869819641}
Epoch metrics: {&#39;accuracy&#39;: 0.7922, &#39;crossentropy&#39;: 0.6908394595146179}
Epoch metrics: {&#39;accuracy&#39;: 0.7866, &#39;crossentropy&#39;: 0.7044798341751098}
RestoringEarlyStopping: 1 / 5
Epoch metrics: {&#39;accuracy&#39;: 0.742, &#39;crossentropy&#39;: 0.8993771001815796}
RestoringEarlyStopping: 2 / 5
Epoch metrics: {&#39;accuracy&#39;: 0.7672, &#39;crossentropy&#39;: 0.7785236550331116}
RestoringEarlyStopping: 3 / 5
Epoch metrics: {&#39;accuracy&#39;: 0.7868, &#39;crossentropy&#39;: 0.7275433395385742}
RestoringEarlyStopping: 4 / 5
Epoch metrics: {&#39;accuracy&#39;: 0.7766, &#39;crossentropy&#39;: 0.7658989503860474}
RestoringEarlyStopping: 5 / 5
RestoringEarlyStopping: Out of patience
RestoringEarlyStopping: Restoring best parameters. (Score: 0.7922)
RestoringEarlyStopping: Restoring optimizer.
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;epochs&#39;: [{&#39;accuracy&#39;: 0.3082, &#39;crossentropy&#39;: 1.7973075674057006},
  {&#39;accuracy&#39;: 0.3784, &#39;crossentropy&#39;: 1.701580082321167},
  {&#39;accuracy&#39;: 0.4304, &#39;crossentropy&#39;: 1.5768954347610473},
  {&#39;accuracy&#39;: 0.4898, &#39;crossentropy&#39;: 1.4669325416564942},
  {&#39;accuracy&#39;: 0.4954, &#39;crossentropy&#39;: 1.4981587272644044},
  {&#39;accuracy&#39;: 0.5328, &#39;crossentropy&#39;: 1.409426467514038},
  {&#39;accuracy&#39;: 0.5946, &#39;crossentropy&#39;: 1.2132721630096435},
  {&#39;accuracy&#39;: 0.6196, &#39;crossentropy&#39;: 1.15281331615448},
  {&#39;accuracy&#39;: 0.612, &#39;crossentropy&#39;: 1.2480723501205444},
  {&#39;accuracy&#39;: 0.5356, &#39;crossentropy&#39;: 1.6043412952423095},
  {&#39;accuracy&#39;: 0.6232, &#39;crossentropy&#39;: 1.1425624122619629},
  {&#39;accuracy&#39;: 0.647, &#39;crossentropy&#39;: 1.0633803052902222},
  {&#39;accuracy&#39;: 0.6696, &#39;crossentropy&#39;: 1.0703337482452393},
  {&#39;accuracy&#39;: 0.6778, &#39;crossentropy&#39;: 1.024672212600708},
  {&#39;accuracy&#39;: 0.7276, &#39;crossentropy&#39;: 0.8393620066642761},
  {&#39;accuracy&#39;: 0.7292, &#39;crossentropy&#39;: 0.8811147254943847},
  {&#39;accuracy&#39;: 0.7116, &#39;crossentropy&#39;: 0.9226495706558228},
  {&#39;accuracy&#39;: 0.7432, &#39;crossentropy&#39;: 0.8460798347473144},
  {&#39;accuracy&#39;: 0.7504, &#39;crossentropy&#39;: 0.8222217173576355},
  {&#39;accuracy&#39;: 0.7672, &#39;crossentropy&#39;: 0.7539731317520142},
  {&#39;accuracy&#39;: 0.7452, &#39;crossentropy&#39;: 0.9202061416625976},
  {&#39;accuracy&#39;: 0.7788, &#39;crossentropy&#39;: 0.7562990008354187},
  {&#39;accuracy&#39;: 0.7864, &#39;crossentropy&#39;: 0.7357828869819641},
  {&#39;accuracy&#39;: 0.7922, &#39;crossentropy&#39;: 0.6908394595146179},
  {&#39;accuracy&#39;: 0.7866, &#39;crossentropy&#39;: 0.7044798341751098},
  {&#39;accuracy&#39;: 0.742, &#39;crossentropy&#39;: 0.8993771001815796},
  {&#39;accuracy&#39;: 0.7672, &#39;crossentropy&#39;: 0.7785236550331116},
  {&#39;accuracy&#39;: 0.7868, &#39;crossentropy&#39;: 0.7275433395385742},
  {&#39;accuracy&#39;: 0.7766, &#39;crossentropy&#39;: 0.7658989503860474}],
 &#39;best_epoch&#39;: 24}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils</span> <span class="kn">import</span> <span class="n">data</span>

<span class="n">model_trainer</span> <span class="o">=</span> <span class="n">Cifar10ModelTrainer</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">max_training_epochs</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_train_dataloader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">train</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">))</span>
<span class="n">validation_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_evaluation_dataloader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">validation</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_evaluation_dataloader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">test</span><span class="p">)</span>

<span class="n">log</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">trained_model</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_trained</span><span class="p">(</span>
    <span class="n">train_loader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span>
    <span class="n">train_augmentations</span><span class="o">=</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">train_augmentations</span><span class="p">,</span>
    <span class="n">validation_loader</span><span class="o">=</span><span class="n">validation_loader</span><span class="p">,</span>
    <span class="n">log</span><span class="o">=</span><span class="n">log</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">log</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>5000
Cosine Annealing
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">batchbald_redux.consistent_mc_dropout</span> <span class="kn">import</span> <span class="n">GradEmbeddingType</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="n">trained_model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_grad_embeddings</span><span class="p">(</span>
        <span class="n">num_samples</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">loader</span><span class="o">=</span><span class="n">test_loader</span><span class="p">,</span>
        <span class="n">loss</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">nll_loss</span><span class="p">,</span>
        <span class="n">grad_embedding_type</span><span class="o">=</span><span class="n">GradEmbeddingType</span><span class="o">.</span><span class="n">LINEAR</span><span class="p">,</span>
        <span class="n">model_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span>
        <span class="n">storage_device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
    <span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="n">trained_model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_grad_embeddings</span><span class="p">(</span>
        <span class="n">num_samples</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">loader</span><span class="o">=</span><span class="n">test_loader</span><span class="p">,</span>
        <span class="n">loss</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">nll_loss</span><span class="p">,</span>
        <span class="n">grad_embedding_type</span><span class="o">=</span><span class="n">GradEmbeddingType</span><span class="o">.</span><span class="n">LINEAR</span><span class="p">,</span>
        <span class="n">model_labels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span>
        <span class="n">storage_device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
    <span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>torch.Size([10000, 1, 5120])
torch.Size([10000, 1, 5120])
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils</span> <span class="kn">import</span> <span class="n">data</span>

<span class="n">model_trainer</span> <span class="o">=</span> <span class="n">Cifar10ModelTrainer</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_train_dataloader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">train</span> <span class="o">*</span> <span class="mf">0.4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">))</span>
<span class="n">validation_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_evaluation_dataloader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">validation</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_evaluation_dataloader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">test</span><span class="p">)</span>

<span class="n">log</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">trained_model</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_trained</span><span class="p">(</span>
    <span class="n">train_loader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span>
    <span class="n">train_augmentations</span><span class="o">=</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">train_augmentations</span><span class="p">,</span>
    <span class="n">validation_loader</span><span class="o">=</span><span class="n">validation_loader</span><span class="p">,</span>
    <span class="n">log</span><span class="o">=</span><span class="n">log</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>18000
Cosine Annealing
Epoch 1 metrics: {&#39;accuracy&#39;: 0.2856, &#39;crossentropy&#39;: 1.8545497650146485}
Epoch 2 metrics: {&#39;accuracy&#39;: 0.3292, &#39;crossentropy&#39;: 1.9277066995620729}
Epoch 3 metrics: {&#39;accuracy&#39;: 0.4584, &#39;crossentropy&#39;: 1.534279344177246}
Epoch 4 metrics: {&#39;accuracy&#39;: 0.498, &#39;crossentropy&#39;: 1.4638728162765502}
Epoch 5 metrics: {&#39;accuracy&#39;: 0.5098, &#39;crossentropy&#39;: 1.437373586654663}
Epoch 6 metrics: {&#39;accuracy&#39;: 0.5594, &#39;crossentropy&#39;: 1.3292468334197998}
Epoch 7 metrics: {&#39;accuracy&#39;: 0.6114, &#39;crossentropy&#39;: 1.163236389541626}
Epoch 8 metrics: {&#39;accuracy&#39;: 0.5862, &#39;crossentropy&#39;: 1.226002060508728}
Epoch 9 metrics: {&#39;accuracy&#39;: 0.6426, &#39;crossentropy&#39;: 1.0702646913528442}
Epoch 10 metrics: {&#39;accuracy&#39;: 0.661, &#39;crossentropy&#39;: 1.0213278537750243}
Epoch 11 metrics: {&#39;accuracy&#39;: 0.6952, &#39;crossentropy&#39;: 0.9394193833351135}
Epoch 12 metrics: {&#39;accuracy&#39;: 0.6614, &#39;crossentropy&#39;: 0.9984549903869628}
Epoch 13 metrics: {&#39;accuracy&#39;: 0.6828, &#39;crossentropy&#39;: 1.0071536222457886}
Epoch 14 metrics: {&#39;accuracy&#39;: 0.708, &#39;crossentropy&#39;: 0.9346793626785278}
Epoch 15 metrics: {&#39;accuracy&#39;: 0.7324, &#39;crossentropy&#39;: 0.8567409112930298}
Epoch 16 metrics: {&#39;accuracy&#39;: 0.7352, &#39;crossentropy&#39;: 0.8462186522483826}
Epoch 17 metrics: {&#39;accuracy&#39;: 0.7158, &#39;crossentropy&#39;: 0.9333689485549926}
Epoch 18 metrics: {&#39;accuracy&#39;: 0.7558, &#39;crossentropy&#39;: 0.8051220417976379}
Epoch 19 metrics: {&#39;accuracy&#39;: 0.6974, &#39;crossentropy&#39;: 1.034203429222107}
Epoch 20 metrics: {&#39;accuracy&#39;: 0.7742, &#39;crossentropy&#39;: 0.7360812670707703}
Epoch 21 metrics: {&#39;accuracy&#39;: 0.7702, &#39;crossentropy&#39;: 0.7432255446434021}
Epoch 22 metrics: {&#39;accuracy&#39;: 0.782, &#39;crossentropy&#39;: 0.7339959760665894}
Epoch 23 metrics: {&#39;accuracy&#39;: 0.7646, &#39;crossentropy&#39;: 0.8096233380317688}
Epoch 24 metrics: {&#39;accuracy&#39;: 0.7802, &#39;crossentropy&#39;: 0.7205158989906311}
Epoch 25 metrics: {&#39;accuracy&#39;: 0.7536, &#39;crossentropy&#39;: 0.7887222961425782}
Epoch 26 metrics: {&#39;accuracy&#39;: 0.7716, &#39;crossentropy&#39;: 0.8186643391609192}
Epoch 27 metrics: {&#39;accuracy&#39;: 0.7692, &#39;crossentropy&#39;: 0.7962150002479553}
Epoch 28 metrics: {&#39;accuracy&#39;: 0.8002, &#39;crossentropy&#39;: 0.6736455117225647}
Epoch 29 metrics: {&#39;accuracy&#39;: 0.7864, &#39;crossentropy&#39;: 0.7181077597618103}
Epoch 30 metrics: {&#39;accuracy&#39;: 0.7872, &#39;crossentropy&#39;: 0.7404170677185059}
Epoch 31 metrics: {&#39;accuracy&#39;: 0.779, &#39;crossentropy&#39;: 0.7604064460754395}
Epoch 32 metrics: {&#39;accuracy&#39;: 0.7766, &#39;crossentropy&#39;: 0.8294541075706482}
Epoch 33 metrics: {&#39;accuracy&#39;: 0.7964, &#39;crossentropy&#39;: 0.7467875930786133}
Epoch 34 metrics: {&#39;accuracy&#39;: 0.7868, &#39;crossentropy&#39;: 0.8013256266593933}
Epoch 35 metrics: {&#39;accuracy&#39;: 0.7656, &#39;crossentropy&#39;: 0.8753616209030152}
Epoch 36 metrics: {&#39;accuracy&#39;: 0.8204, &#39;crossentropy&#39;: 0.6367582839965821}
Epoch 37 metrics: {&#39;accuracy&#39;: 0.8242, &#39;crossentropy&#39;: 0.6399408193588256}
Epoch 38 metrics: {&#39;accuracy&#39;: 0.8062, &#39;crossentropy&#39;: 0.7217883975982666}
Epoch 39 metrics: {&#39;accuracy&#39;: 0.8152, &#39;crossentropy&#39;: 0.6884591849327087}
Epoch 40 metrics: {&#39;accuracy&#39;: 0.8016, &#39;crossentropy&#39;: 0.7723951833724976}
Epoch 41 metrics: {&#39;accuracy&#39;: 0.8196, &#39;crossentropy&#39;: 0.6628482033729554}
Epoch 42 metrics: {&#39;accuracy&#39;: 0.8118, &#39;crossentropy&#39;: 0.7181119831085205}
Epoch 43 metrics: {&#39;accuracy&#39;: 0.8124, &#39;crossentropy&#39;: 0.6956645809173584}
Epoch 44 metrics: {&#39;accuracy&#39;: 0.7956, &#39;crossentropy&#39;: 0.8467483345031739}
Epoch 45 metrics: {&#39;accuracy&#39;: 0.8092, &#39;crossentropy&#39;: 0.7528219615936279}
Epoch 46 metrics: {&#39;accuracy&#39;: 0.7892, &#39;crossentropy&#39;: 0.9269635530471801}
Epoch 47 metrics: {&#39;accuracy&#39;: 0.8328, &#39;crossentropy&#39;: 0.6333340282440185}
Epoch 48 metrics: {&#39;accuracy&#39;: 0.8022, &#39;crossentropy&#39;: 0.7965955832481384}
Epoch 49 metrics: {&#39;accuracy&#39;: 0.824, &#39;crossentropy&#39;: 0.6557772603988647}
Epoch 50 metrics: {&#39;accuracy&#39;: 0.8074, &#39;crossentropy&#39;: 0.8091998703956604}
Epoch 51 metrics: {&#39;accuracy&#39;: 0.7956, &#39;crossentropy&#39;: 0.9136038031578064}
Epoch 52 metrics: {&#39;accuracy&#39;: 0.8342, &#39;crossentropy&#39;: 0.6638007917404175}
Epoch 53 metrics: {&#39;accuracy&#39;: 0.8362, &#39;crossentropy&#39;: 0.6500532857894897}
Epoch 54 metrics: {&#39;accuracy&#39;: 0.8294, &#39;crossentropy&#39;: 0.6875188645362854}
Epoch 55 metrics: {&#39;accuracy&#39;: 0.8334, &#39;crossentropy&#39;: 0.6365359700202942}
Epoch 56 metrics: {&#39;accuracy&#39;: 0.8106, &#39;crossentropy&#39;: 0.8157225450515747}
Epoch 57 metrics: {&#39;accuracy&#39;: 0.7856, &#39;crossentropy&#39;: 1.0377094486236573}
Epoch 58 metrics: {&#39;accuracy&#39;: 0.8354, &#39;crossentropy&#39;: 0.6808976434707642}
Epoch 59 metrics: {&#39;accuracy&#39;: 0.8184, &#39;crossentropy&#39;: 0.7892855514526367}
Epoch 60 metrics: {&#39;accuracy&#39;: 0.798, &#39;crossentropy&#39;: 0.9396205501556396}
Epoch 61 metrics: {&#39;accuracy&#39;: 0.8248, &#39;crossentropy&#39;: 0.7595659711837769}
Epoch 62 metrics: {&#39;accuracy&#39;: 0.8034, &#39;crossentropy&#39;: 0.9257151521682739}
Epoch 63 metrics: {&#39;accuracy&#39;: 0.8424, &#39;crossentropy&#39;: 0.6549510976791382}
Epoch 64 metrics: {&#39;accuracy&#39;: 0.825, &#39;crossentropy&#39;: 0.7364507520675659}
Epoch 65 metrics: {&#39;accuracy&#39;: 0.8368, &#39;crossentropy&#39;: 0.7309814467430115}
Epoch 66 metrics: {&#39;accuracy&#39;: 0.8336, &#39;crossentropy&#39;: 0.7399176309585571}
Epoch 67 metrics: {&#39;accuracy&#39;: 0.842, &#39;crossentropy&#39;: 0.6872009261131287}
Epoch 68 metrics: {&#39;accuracy&#39;: 0.8178, &#39;crossentropy&#39;: 0.8373127025604248}
Epoch 69 metrics: {&#39;accuracy&#39;: 0.8438, &#39;crossentropy&#39;: 0.685840180683136}
Epoch 70 metrics: {&#39;accuracy&#39;: 0.8378, &#39;crossentropy&#39;: 0.7026629771232605}
Epoch 71 metrics: {&#39;accuracy&#39;: 0.8336, &#39;crossentropy&#39;: 0.7679980454444886}
Epoch 72 metrics: {&#39;accuracy&#39;: 0.8456, &#39;crossentropy&#39;: 0.6975786490440369}
Epoch 73 metrics: {&#39;accuracy&#39;: 0.8238, &#39;crossentropy&#39;: 0.8190247141838074}
Epoch 74 metrics: {&#39;accuracy&#39;: 0.8438, &#39;crossentropy&#39;: 0.73705371799469}
Epoch 75 metrics: {&#39;accuracy&#39;: 0.8386, &#39;crossentropy&#39;: 0.7477448069572449}
Epoch 76 metrics: {&#39;accuracy&#39;: 0.8482, &#39;crossentropy&#39;: 0.6885799756050109}
Epoch 77 metrics: {&#39;accuracy&#39;: 0.8376, &#39;crossentropy&#39;: 0.7597014122009277}
Epoch 78 metrics: {&#39;accuracy&#39;: 0.841, &#39;crossentropy&#39;: 0.8079666268348694}
Epoch 79 metrics: {&#39;accuracy&#39;: 0.8506, &#39;crossentropy&#39;: 0.721381614112854}
Epoch 80 metrics: {&#39;accuracy&#39;: 0.8434, &#39;crossentropy&#39;: 0.778343196105957}
Epoch 81 metrics: {&#39;accuracy&#39;: 0.8526, &#39;crossentropy&#39;: 0.6730792145729065}
Epoch 82 metrics: {&#39;accuracy&#39;: 0.8212, &#39;crossentropy&#39;: 0.9540710098266602}
Epoch 83 metrics: {&#39;accuracy&#39;: 0.8494, &#39;crossentropy&#39;: 0.6839977670669556}
Epoch 84 metrics: {&#39;accuracy&#39;: 0.8536, &#39;crossentropy&#39;: 0.7026290508270263}
Epoch 85 metrics: {&#39;accuracy&#39;: 0.8498, &#39;crossentropy&#39;: 0.7334547729492188}
Epoch 86 metrics: {&#39;accuracy&#39;: 0.846, &#39;crossentropy&#39;: 0.7746248898506165}
Epoch 87 metrics: {&#39;accuracy&#39;: 0.8528, &#39;crossentropy&#39;: 0.6996674884796142}
Epoch 88 metrics: {&#39;accuracy&#39;: 0.838, &#39;crossentropy&#39;: 0.7748713617324829}
Epoch 89 metrics: {&#39;accuracy&#39;: 0.8442, &#39;crossentropy&#39;: 0.7649139569282531}
Epoch 90 metrics: {&#39;accuracy&#39;: 0.851, &#39;crossentropy&#39;: 0.703072527217865}
Epoch 91 metrics: {&#39;accuracy&#39;: 0.8528, &#39;crossentropy&#39;: 0.6958219986915588}
Epoch 92 metrics: {&#39;accuracy&#39;: 0.8368, &#39;crossentropy&#39;: 0.7910226912498474}
Epoch 93 metrics: {&#39;accuracy&#39;: 0.8574, &#39;crossentropy&#39;: 0.6537726356506348}
Epoch 94 metrics: {&#39;accuracy&#39;: 0.8614, &#39;crossentropy&#39;: 0.6826119378089904}
Epoch 95 metrics: {&#39;accuracy&#39;: 0.8426, &#39;crossentropy&#39;: 0.8041058448791504}
Epoch 96 metrics: {&#39;accuracy&#39;: 0.8328, &#39;crossentropy&#39;: 0.8932533625602722}
Epoch 97 metrics: {&#39;accuracy&#39;: 0.8472, &#39;crossentropy&#39;: 0.7472060799598694}
Epoch 98 metrics: {&#39;accuracy&#39;: 0.8412, &#39;crossentropy&#39;: 0.8056079147338867}
Epoch 99 metrics: {&#39;accuracy&#39;: 0.8494, &#39;crossentropy&#39;: 0.7593761708259582}
Epoch 100 metrics: {&#39;accuracy&#39;: 0.8508, &#39;crossentropy&#39;: 0.7163452644348145}
Epoch 101 metrics: {&#39;accuracy&#39;: 0.8458, &#39;crossentropy&#39;: 0.753485200881958}
Epoch 102 metrics: {&#39;accuracy&#39;: 0.8616, &#39;crossentropy&#39;: 0.6732524274826049}
Epoch 103 metrics: {&#39;accuracy&#39;: 0.8404, &#39;crossentropy&#39;: 0.8011472591400146}
Epoch 104 metrics: {&#39;accuracy&#39;: 0.845, &#39;crossentropy&#39;: 0.75767584400177}
Epoch 105 metrics: {&#39;accuracy&#39;: 0.86, &#39;crossentropy&#39;: 0.7234556740760804}
Epoch 106 metrics: {&#39;accuracy&#39;: 0.8606, &#39;crossentropy&#39;: 0.6999372383117676}
Epoch 107 metrics: {&#39;accuracy&#39;: 0.8564, &#39;crossentropy&#39;: 0.7358453497886658}
Epoch 108 metrics: {&#39;accuracy&#39;: 0.8468, &#39;crossentropy&#39;: 0.8046362591743469}
Epoch 109 metrics: {&#39;accuracy&#39;: 0.8374, &#39;crossentropy&#39;: 0.8557856467247009}
Epoch 110 metrics: {&#39;accuracy&#39;: 0.8496, &#39;crossentropy&#39;: 0.7620479378700257}
Epoch 111 metrics: {&#39;accuracy&#39;: 0.8522, &#39;crossentropy&#39;: 0.7193976620674133}
Epoch 112 metrics: {&#39;accuracy&#39;: 0.8528, &#39;crossentropy&#39;: 0.7287584713935852}
Epoch 113 metrics: {&#39;accuracy&#39;: 0.8532, &#39;crossentropy&#39;: 0.7560758545875549}
Epoch 114 metrics: {&#39;accuracy&#39;: 0.8438, &#39;crossentropy&#39;: 0.8252616525650024}
Epoch 115 metrics: {&#39;accuracy&#39;: 0.8514, &#39;crossentropy&#39;: 0.7799418643951416}
Epoch 116 metrics: {&#39;accuracy&#39;: 0.8488, &#39;crossentropy&#39;: 0.8075506601333619}
Epoch 117 metrics: {&#39;accuracy&#39;: 0.8552, &#39;crossentropy&#39;: 0.7097553594589233}
Epoch 118 metrics: {&#39;accuracy&#39;: 0.866, &#39;crossentropy&#39;: 0.6738803176879883}
Epoch 119 metrics: {&#39;accuracy&#39;: 0.8618, &#39;crossentropy&#39;: 0.7208435382843018}
Epoch 120 metrics: {&#39;accuracy&#39;: 0.8572, &#39;crossentropy&#39;: 0.7373522766113281}
Epoch 121 metrics: {&#39;accuracy&#39;: 0.8338, &#39;crossentropy&#39;: 0.9548956916809082}
Epoch 122 metrics: {&#39;accuracy&#39;: 0.8602, &#39;crossentropy&#39;: 0.6994466906547546}
Epoch 123 metrics: {&#39;accuracy&#39;: 0.8672, &#39;crossentropy&#39;: 0.6992287550926208}
Epoch 124 metrics: {&#39;accuracy&#39;: 0.8666, &#39;crossentropy&#39;: 0.7011544188499451}
Epoch 125 metrics: {&#39;accuracy&#39;: 0.861, &#39;crossentropy&#39;: 0.7161647013664245}
Epoch 126 metrics: {&#39;accuracy&#39;: 0.8672, &#39;crossentropy&#39;: 0.6650666800498962}
Epoch 127 metrics: {&#39;accuracy&#39;: 0.8696, &#39;crossentropy&#39;: 0.691644019985199}
Epoch 128 metrics: {&#39;accuracy&#39;: 0.8654, &#39;crossentropy&#39;: 0.6885326607704163}
Epoch 129 metrics: {&#39;accuracy&#39;: 0.8578, &#39;crossentropy&#39;: 0.7805585440635681}
Epoch 130 metrics: {&#39;accuracy&#39;: 0.871, &#39;crossentropy&#39;: 0.6927882253646851}
Epoch 131 metrics: {&#39;accuracy&#39;: 0.863, &#39;crossentropy&#39;: 0.7523870921134949}
Epoch 132 metrics: {&#39;accuracy&#39;: 0.8562, &#39;crossentropy&#39;: 0.7506723625183106}
Epoch 133 metrics: {&#39;accuracy&#39;: 0.8664, &#39;crossentropy&#39;: 0.7025162903785706}
Epoch 134 metrics: {&#39;accuracy&#39;: 0.8642, &#39;crossentropy&#39;: 0.7176886338233948}
Epoch 135 metrics: {&#39;accuracy&#39;: 0.8646, &#39;crossentropy&#39;: 0.7192893412590027}
Epoch 136 metrics: {&#39;accuracy&#39;: 0.855, &#39;crossentropy&#39;: 0.7549131596565246}
Epoch 137 metrics: {&#39;accuracy&#39;: 0.8708, &#39;crossentropy&#39;: 0.6984952207565308}
Epoch 138 metrics: {&#39;accuracy&#39;: 0.8684, &#39;crossentropy&#39;: 0.6908443077087403}
Epoch 139 metrics: {&#39;accuracy&#39;: 0.8684, &#39;crossentropy&#39;: 0.6770447429656983}
Epoch 140 metrics: {&#39;accuracy&#39;: 0.862, &#39;crossentropy&#39;: 0.685473792552948}
Epoch 141 metrics: {&#39;accuracy&#39;: 0.8656, &#39;crossentropy&#39;: 0.7229589156150817}
Epoch 142 metrics: {&#39;accuracy&#39;: 0.8686, &#39;crossentropy&#39;: 0.6789560466766358}
Epoch 143 metrics: {&#39;accuracy&#39;: 0.8734, &#39;crossentropy&#39;: 0.6885281230926513}
Epoch 144 metrics: {&#39;accuracy&#39;: 0.8638, &#39;crossentropy&#39;: 0.7147123766899108}
Epoch 145 metrics: {&#39;accuracy&#39;: 0.8726, &#39;crossentropy&#39;: 0.6722450366020203}
Epoch 146 metrics: {&#39;accuracy&#39;: 0.8668, &#39;crossentropy&#39;: 0.7223228028297425}
Epoch 147 metrics: {&#39;accuracy&#39;: 0.8696, &#39;crossentropy&#39;: 0.7305106444358825}
Epoch 148 metrics: {&#39;accuracy&#39;: 0.8676, &#39;crossentropy&#39;: 0.6805039556503296}
Epoch 149 metrics: {&#39;accuracy&#39;: 0.8674, &#39;crossentropy&#39;: 0.7053425640106201}
Epoch 150 metrics: {&#39;accuracy&#39;: 0.863, &#39;crossentropy&#39;: 0.7328518979072571}
Epoch 151 metrics: {&#39;accuracy&#39;: 0.8712, &#39;crossentropy&#39;: 0.6749421430587769}
Epoch 152 metrics: {&#39;accuracy&#39;: 0.8748, &#39;crossentropy&#39;: 0.6622314817428588}
Epoch 153 metrics: {&#39;accuracy&#39;: 0.8744, &#39;crossentropy&#39;: 0.6548304243087768}
Epoch 154 metrics: {&#39;accuracy&#39;: 0.8758, &#39;crossentropy&#39;: 0.6484699404716492}
Epoch 155 metrics: {&#39;accuracy&#39;: 0.868, &#39;crossentropy&#39;: 0.6999514840126038}
Epoch 156 metrics: {&#39;accuracy&#39;: 0.8708, &#39;crossentropy&#39;: 0.6997609419822692}
Epoch 157 metrics: {&#39;accuracy&#39;: 0.8734, &#39;crossentropy&#39;: 0.7046216305732727}
Epoch 158 metrics: {&#39;accuracy&#39;: 0.8762, &#39;crossentropy&#39;: 0.6821415965080261}
Epoch 159 metrics: {&#39;accuracy&#39;: 0.8702, &#39;crossentropy&#39;: 0.6919474114418029}
Epoch 160 metrics: {&#39;accuracy&#39;: 0.8724, &#39;crossentropy&#39;: 0.7077758668899536}
Epoch 161 metrics: {&#39;accuracy&#39;: 0.8762, &#39;crossentropy&#39;: 0.691142723941803}
Epoch 162 metrics: {&#39;accuracy&#39;: 0.872, &#39;crossentropy&#39;: 0.6785869790077209}
Epoch 163 metrics: {&#39;accuracy&#39;: 0.8802, &#39;crossentropy&#39;: 0.64453285446167}
Epoch 164 metrics: {&#39;accuracy&#39;: 0.8752, &#39;crossentropy&#39;: 0.6522824264526367}
Epoch 165 metrics: {&#39;accuracy&#39;: 0.8782, &#39;crossentropy&#39;: 0.6569128186225891}
Epoch 166 metrics: {&#39;accuracy&#39;: 0.8772, &#39;crossentropy&#39;: 0.6522456070899963}
Epoch 167 metrics: {&#39;accuracy&#39;: 0.8768, &#39;crossentropy&#39;: 0.6587914772033692}
Epoch 168 metrics: {&#39;accuracy&#39;: 0.8808, &#39;crossentropy&#39;: 0.650617962360382}
Epoch 169 metrics: {&#39;accuracy&#39;: 0.8778, &#39;crossentropy&#39;: 0.6405186521530152}
Epoch 170 metrics: {&#39;accuracy&#39;: 0.8804, &#39;crossentropy&#39;: 0.6306645065307617}
Epoch 171 metrics: {&#39;accuracy&#39;: 0.8824, &#39;crossentropy&#39;: 0.6277330803871155}
Epoch 172 metrics: {&#39;accuracy&#39;: 0.8842, &#39;crossentropy&#39;: 0.634911201953888}
Epoch 173 metrics: {&#39;accuracy&#39;: 0.8848, &#39;crossentropy&#39;: 0.6472932760238648}
Epoch 174 metrics: {&#39;accuracy&#39;: 0.8812, &#39;crossentropy&#39;: 0.6192628698348999}
Epoch 175 metrics: {&#39;accuracy&#39;: 0.8792, &#39;crossentropy&#39;: 0.6423950766563415}
Epoch 176 metrics: {&#39;accuracy&#39;: 0.8792, &#39;crossentropy&#39;: 0.6570449501037597}
Epoch 177 metrics: {&#39;accuracy&#39;: 0.8824, &#39;crossentropy&#39;: 0.6550199915885925}
Epoch 178 metrics: {&#39;accuracy&#39;: 0.8834, &#39;crossentropy&#39;: 0.6283490198135376}
Epoch 179 metrics: {&#39;accuracy&#39;: 0.8842, &#39;crossentropy&#39;: 0.6220402395248413}
Epoch 180 metrics: {&#39;accuracy&#39;: 0.8874, &#39;crossentropy&#39;: 0.6278664695739746}
Epoch 181 metrics: {&#39;accuracy&#39;: 0.882, &#39;crossentropy&#39;: 0.6533350936889648}
Epoch 182 metrics: {&#39;accuracy&#39;: 0.8858, &#39;crossentropy&#39;: 0.6367190044403076}
Epoch 183 metrics: {&#39;accuracy&#39;: 0.8842, &#39;crossentropy&#39;: 0.6244511122703552}
Epoch 184 metrics: {&#39;accuracy&#39;: 0.8792, &#39;crossentropy&#39;: 0.6344222054481506}
Epoch 185 metrics: {&#39;accuracy&#39;: 0.88, &#39;crossentropy&#39;: 0.6288470969200134}
Epoch 186 metrics: {&#39;accuracy&#39;: 0.8834, &#39;crossentropy&#39;: 0.6233252975463868}
Epoch 187 metrics: {&#39;accuracy&#39;: 0.8828, &#39;crossentropy&#39;: 0.6126835848808289}
Epoch 188 metrics: {&#39;accuracy&#39;: 0.8822, &#39;crossentropy&#39;: 0.62097612657547}
Epoch 189 metrics: {&#39;accuracy&#39;: 0.8828, &#39;crossentropy&#39;: 0.5974698554992676}
Epoch 190 metrics: {&#39;accuracy&#39;: 0.883, &#39;crossentropy&#39;: 0.6193984685897828}
Epoch 191 metrics: {&#39;accuracy&#39;: 0.8848, &#39;crossentropy&#39;: 0.6072008012771607}
Epoch 192 metrics: {&#39;accuracy&#39;: 0.8818, &#39;crossentropy&#39;: 0.6194289293289185}
Epoch 193 metrics: {&#39;accuracy&#39;: 0.8838, &#39;crossentropy&#39;: 0.6068023470878601}
Epoch 194 metrics: {&#39;accuracy&#39;: 0.8854, &#39;crossentropy&#39;: 0.5973319814682007}
Epoch 195 metrics: {&#39;accuracy&#39;: 0.8844, &#39;crossentropy&#39;: 0.6199771155357361}
Epoch 196 metrics: {&#39;accuracy&#39;: 0.882, &#39;crossentropy&#39;: 0.6171613084793091}
Epoch 197 metrics: {&#39;accuracy&#39;: 0.8854, &#39;crossentropy&#39;: 0.5921084924697876}
Epoch 198 metrics: {&#39;accuracy&#39;: 0.8818, &#39;crossentropy&#39;: 0.6241772885322571}
Epoch 199 metrics: {&#39;accuracy&#39;: 0.8852, &#39;crossentropy&#39;: 0.597427645111084}
Epoch 200 metrics: {&#39;accuracy&#39;: 0.8834, &#39;crossentropy&#39;: 0.5921060774803162}
Epoch 201 metrics: {&#39;accuracy&#39;: 0.8844, &#39;crossentropy&#39;: 0.5941774314880371}
Epoch 202 metrics: {&#39;accuracy&#39;: 0.8862, &#39;crossentropy&#39;: 0.5887086565017701}
Epoch 203 metrics: {&#39;accuracy&#39;: 0.8862, &#39;crossentropy&#39;: 0.5922266948699951}
Epoch 204 metrics: {&#39;accuracy&#39;: 0.8864, &#39;crossentropy&#39;: 0.5924130989074707}
Epoch 205 metrics: {&#39;accuracy&#39;: 0.8866, &#39;crossentropy&#39;: 0.5928044528007508}
Epoch 206 metrics: {&#39;accuracy&#39;: 0.8866, &#39;crossentropy&#39;: 0.5902848583221435}
Epoch 207 metrics: {&#39;accuracy&#39;: 0.886, &#39;crossentropy&#39;: 0.5854803153038025}
Epoch 208 metrics: {&#39;accuracy&#39;: 0.8852, &#39;crossentropy&#39;: 0.5830728775978088}
Epoch 209 metrics: {&#39;accuracy&#39;: 0.8854, &#39;crossentropy&#39;: 0.5821076240539551}
Epoch 210 metrics: {&#39;accuracy&#39;: 0.8858, &#39;crossentropy&#39;: 0.5769341907501221}
Epoch 211 metrics: {&#39;accuracy&#39;: 0.8876, &#39;crossentropy&#39;: 0.5652683254241944}
Epoch 212 metrics: {&#39;accuracy&#39;: 0.886, &#39;crossentropy&#39;: 0.5674199729919434}
Epoch 213 metrics: {&#39;accuracy&#39;: 0.8892, &#39;crossentropy&#39;: 0.5732382596969604}
Epoch 214 metrics: {&#39;accuracy&#39;: 0.8878, &#39;crossentropy&#39;: 0.5762968244552612}
Epoch 215 metrics: {&#39;accuracy&#39;: 0.8864, &#39;crossentropy&#39;: 0.5726380308151245}
Epoch 216 metrics: {&#39;accuracy&#39;: 0.8876, &#39;crossentropy&#39;: 0.569606763458252}
Epoch 217 metrics: {&#39;accuracy&#39;: 0.8876, &#39;crossentropy&#39;: 0.5632205394744874}
Epoch 218 metrics: {&#39;accuracy&#39;: 0.8868, &#39;crossentropy&#39;: 0.5655683919906617}
Epoch 219 metrics: {&#39;accuracy&#39;: 0.8878, &#39;crossentropy&#39;: 0.5721477480888366}
Epoch 220 metrics: {&#39;accuracy&#39;: 0.889, &#39;crossentropy&#39;: 0.5749097256660461}
Epoch 221 metrics: {&#39;accuracy&#39;: 0.8892, &#39;crossentropy&#39;: 0.5699309700965881}
Epoch 222 metrics: {&#39;accuracy&#39;: 0.8904, &#39;crossentropy&#39;: 0.5623799489974975}
Epoch 223 metrics: {&#39;accuracy&#39;: 0.8878, &#39;crossentropy&#39;: 0.5649431234359741}
Epoch 224 metrics: {&#39;accuracy&#39;: 0.8884, &#39;crossentropy&#39;: 0.5615118761062622}
Epoch 225 metrics: {&#39;accuracy&#39;: 0.888, &#39;crossentropy&#39;: 0.5721969318389892}
Epoch 226 metrics: {&#39;accuracy&#39;: 0.8876, &#39;crossentropy&#39;: 0.5655677375793458}
Epoch 227 metrics: {&#39;accuracy&#39;: 0.8866, &#39;crossentropy&#39;: 0.5643915587425232}
Epoch 228 metrics: {&#39;accuracy&#39;: 0.8874, &#39;crossentropy&#39;: 0.5717823468208313}
Epoch 229 metrics: {&#39;accuracy&#39;: 0.8904, &#39;crossentropy&#39;: 0.563829190826416}
Epoch 230 metrics: {&#39;accuracy&#39;: 0.8894, &#39;crossentropy&#39;: 0.561688598537445}
Epoch 231 metrics: {&#39;accuracy&#39;: 0.8882, &#39;crossentropy&#39;: 0.5561195303916932}
Epoch 232 metrics: {&#39;accuracy&#39;: 0.8886, &#39;crossentropy&#39;: 0.5569055274963379}
Epoch 233 metrics: {&#39;accuracy&#39;: 0.8874, &#39;crossentropy&#39;: 0.5591052185058594}
Epoch 234 metrics: {&#39;accuracy&#39;: 0.8892, &#39;crossentropy&#39;: 0.5619488019943237}
Epoch 235 metrics: {&#39;accuracy&#39;: 0.8906, &#39;crossentropy&#39;: 0.55289466714859}
Epoch 236 metrics: {&#39;accuracy&#39;: 0.8884, &#39;crossentropy&#39;: 0.5621278694152833}
Epoch 237 metrics: {&#39;accuracy&#39;: 0.888, &#39;crossentropy&#39;: 0.560072559928894}
Epoch 238 metrics: {&#39;accuracy&#39;: 0.8886, &#39;crossentropy&#39;: 0.5565862071990967}
Epoch 239 metrics: {&#39;accuracy&#39;: 0.8872, &#39;crossentropy&#39;: 0.5680286551475525}
Epoch 240 metrics: {&#39;accuracy&#39;: 0.8892, &#39;crossentropy&#39;: 0.5613680129051208}
Epoch 241 metrics: {&#39;accuracy&#39;: 0.888, &#39;crossentropy&#39;: 0.5582245405197144}
Epoch 242 metrics: {&#39;accuracy&#39;: 0.888, &#39;crossentropy&#39;: 0.5672383170127868}
Epoch 243 metrics: {&#39;accuracy&#39;: 0.8858, &#39;crossentropy&#39;: 0.5582973077774048}
Epoch 244 metrics: {&#39;accuracy&#39;: 0.8884, &#39;crossentropy&#39;: 0.5530762175559998}
Epoch 245 metrics: {&#39;accuracy&#39;: 0.8868, &#39;crossentropy&#39;: 0.559892483139038}
Epoch 246 metrics: {&#39;accuracy&#39;: 0.8878, &#39;crossentropy&#39;: 0.5517046320915222}
Epoch 247 metrics: {&#39;accuracy&#39;: 0.886, &#39;crossentropy&#39;: 0.5505643743515015}
Epoch 248 metrics: {&#39;accuracy&#39;: 0.8876, &#39;crossentropy&#39;: 0.5559379597663879}
Epoch 249 metrics: {&#39;accuracy&#39;: 0.8898, &#39;crossentropy&#39;: 0.5522927379608155}
Epoch 250 metrics: {&#39;accuracy&#39;: 0.8876, &#39;crossentropy&#39;: 0.5519060923576355}
Epoch 251 metrics: {&#39;accuracy&#39;: 0.8888, &#39;crossentropy&#39;: 0.5511935290336609}
Epoch 252 metrics: {&#39;accuracy&#39;: 0.8864, &#39;crossentropy&#39;: 0.5495532639503479}
Epoch 253 metrics: {&#39;accuracy&#39;: 0.8876, &#39;crossentropy&#39;: 0.5490799542427063}
Epoch 254 metrics: {&#39;accuracy&#39;: 0.8896, &#39;crossentropy&#39;: 0.5532227585792542}
Epoch 255 metrics: {&#39;accuracy&#39;: 0.888, &#39;crossentropy&#39;: 0.5596931102752686}
Epoch 256 metrics: {&#39;accuracy&#39;: 0.8872, &#39;crossentropy&#39;: 0.5523460603713989}
Epoch 257 metrics: {&#39;accuracy&#39;: 0.8902, &#39;crossentropy&#39;: 0.5434131070137024}
Epoch 258 metrics: {&#39;accuracy&#39;: 0.8894, &#39;crossentropy&#39;: 0.5493420634269714}
Epoch 259 metrics: {&#39;accuracy&#39;: 0.8902, &#39;crossentropy&#39;: 0.5456006191253662}
Epoch 260 metrics: {&#39;accuracy&#39;: 0.8894, &#39;crossentropy&#39;: 0.5460159462928772}
Epoch 261 metrics: {&#39;accuracy&#39;: 0.8902, &#39;crossentropy&#39;: 0.552637745475769}
Epoch 262 metrics: {&#39;accuracy&#39;: 0.8894, &#39;crossentropy&#39;: 0.5497317007064819}
Epoch 263 metrics: {&#39;accuracy&#39;: 0.8884, &#39;crossentropy&#39;: 0.5570216917991638}
Epoch 264 metrics: {&#39;accuracy&#39;: 0.8868, &#39;crossentropy&#39;: 0.5517818427085877}
Epoch 265 metrics: {&#39;accuracy&#39;: 0.8886, &#39;crossentropy&#39;: 0.5460380856513977}
Epoch 266 metrics: {&#39;accuracy&#39;: 0.8892, &#39;crossentropy&#39;: 0.5437191630363465}
Epoch 267 metrics: {&#39;accuracy&#39;: 0.8912, &#39;crossentropy&#39;: 0.5481618978500367}
Epoch 268 metrics: {&#39;accuracy&#39;: 0.8902, &#39;crossentropy&#39;: 0.5451211562156677}
Epoch 269 metrics: {&#39;accuracy&#39;: 0.8876, &#39;crossentropy&#39;: 0.5521842562675476}
Epoch 270 metrics: {&#39;accuracy&#39;: 0.8874, &#39;crossentropy&#39;: 0.5430374388694763}
Epoch 271 metrics: {&#39;accuracy&#39;: 0.888, &#39;crossentropy&#39;: 0.5483050139427185}
Epoch 272 metrics: {&#39;accuracy&#39;: 0.8868, &#39;crossentropy&#39;: 0.5483657761573791}
Epoch 273 metrics: {&#39;accuracy&#39;: 0.8896, &#39;crossentropy&#39;: 0.5414332080841064}
Epoch 274 metrics: {&#39;accuracy&#39;: 0.8894, &#39;crossentropy&#39;: 0.5544344073295593}
Epoch 275 metrics: {&#39;accuracy&#39;: 0.8904, &#39;crossentropy&#39;: 0.5478388912200928}
Epoch 276 metrics: {&#39;accuracy&#39;: 0.8908, &#39;crossentropy&#39;: 0.5519512662887573}
Epoch 277 metrics: {&#39;accuracy&#39;: 0.8914, &#39;crossentropy&#39;: 0.5468340723991394}
Epoch 278 metrics: {&#39;accuracy&#39;: 0.889, &#39;crossentropy&#39;: 0.5476910656929016}
Epoch 279 metrics: {&#39;accuracy&#39;: 0.8908, &#39;crossentropy&#39;: 0.5396752041816711}
Epoch 280 metrics: {&#39;accuracy&#39;: 0.8896, &#39;crossentropy&#39;: 0.543235572719574}
Epoch 281 metrics: {&#39;accuracy&#39;: 0.8892, &#39;crossentropy&#39;: 0.5425547796249389}
Epoch 282 metrics: {&#39;accuracy&#39;: 0.8906, &#39;crossentropy&#39;: 0.5452956100463867}
Epoch 283 metrics: {&#39;accuracy&#39;: 0.8892, &#39;crossentropy&#39;: 0.5486729020118714}
Epoch 284 metrics: {&#39;accuracy&#39;: 0.8888, &#39;crossentropy&#39;: 0.5486828422546387}
Epoch 285 metrics: {&#39;accuracy&#39;: 0.8896, &#39;crossentropy&#39;: 0.5463020894050599}
Epoch 286 metrics: {&#39;accuracy&#39;: 0.8884, &#39;crossentropy&#39;: 0.5451721060752869}
Epoch 287 metrics: {&#39;accuracy&#39;: 0.8892, &#39;crossentropy&#39;: 0.5483986428260803}
Epoch 288 metrics: {&#39;accuracy&#39;: 0.8876, &#39;crossentropy&#39;: 0.5477032614707946}
Epoch 289 metrics: {&#39;accuracy&#39;: 0.8896, &#39;crossentropy&#39;: 0.5468354002952576}
Epoch 290 metrics: {&#39;accuracy&#39;: 0.8888, &#39;crossentropy&#39;: 0.5541053038597107}
Epoch 291 metrics: {&#39;accuracy&#39;: 0.8888, &#39;crossentropy&#39;: 0.5460178703308105}
Epoch 292 metrics: {&#39;accuracy&#39;: 0.8894, &#39;crossentropy&#39;: 0.5467668138504028}
Epoch 293 metrics: {&#39;accuracy&#39;: 0.89, &#39;crossentropy&#39;: 0.5452041365623475}
Epoch 294 metrics: {&#39;accuracy&#39;: 0.8886, &#39;crossentropy&#39;: 0.5521361680984497}
Epoch 295 metrics: {&#39;accuracy&#39;: 0.8896, &#39;crossentropy&#39;: 0.5496299787521363}
Epoch 296 metrics: {&#39;accuracy&#39;: 0.8896, &#39;crossentropy&#39;: 0.5530377503395081}
Epoch 297 metrics: {&#39;accuracy&#39;: 0.8874, &#39;crossentropy&#39;: 0.5526186201095581}
Epoch 298 metrics: {&#39;accuracy&#39;: 0.89, &#39;crossentropy&#39;: 0.5443681015968322}
Epoch 299 metrics: {&#39;accuracy&#39;: 0.8896, &#39;crossentropy&#39;: 0.5474069827079773}
Epoch 300 metrics: {&#39;accuracy&#39;: 0.8892, &#39;crossentropy&#39;: 0.5428712361335755}
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">trained_model</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">loader</span><span class="o">=</span><span class="n">test_loader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;accuracy&#39;: 0.8923, &#39;crossentropy&#39;: tensor(0.4584)}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils</span> <span class="kn">import</span> <span class="n">data</span>

<span class="n">model_trainer</span> <span class="o">=</span> <span class="n">Cifar10ModelTrainer</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_train_dataloader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">train</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">validation_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_evaluation_dataloader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">validation</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_evaluation_dataloader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">test</span><span class="p">)</span>

<span class="n">log</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">trained_model</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_trained</span><span class="p">(</span>
    <span class="n">train_loader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span>
    <span class="n">train_augmentations</span><span class="o">=</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">train_augmentations</span><span class="p">,</span>
    <span class="n">validation_loader</span><span class="o">=</span><span class="n">validation_loader</span><span class="p">,</span>
    <span class="n">log</span><span class="o">=</span><span class="n">log</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Cosine Annealing
Epoch 1 metrics: {&#39;accuracy&#39;: 0.2164, &#39;crossentropy&#39;: 2.1492774982452394}
Epoch 2 metrics: {&#39;accuracy&#39;: 0.2372, &#39;crossentropy&#39;: 1.9290581993103026}
Epoch 3 metrics: {&#39;accuracy&#39;: 0.2882, &#39;crossentropy&#39;: 1.8837613988876343}
Epoch 4 metrics: {&#39;accuracy&#39;: 0.2794, &#39;crossentropy&#39;: 2.0415959819793703}
Epoch 5 metrics: {&#39;accuracy&#39;: 0.3364, &#39;crossentropy&#39;: 1.7633274457931518}
Epoch 6 metrics: {&#39;accuracy&#39;: 0.3352, &#39;crossentropy&#39;: 1.8306858547210694}
Epoch 7 metrics: {&#39;accuracy&#39;: 0.3744, &#39;crossentropy&#39;: 1.675206308555603}
Epoch 8 metrics: {&#39;accuracy&#39;: 0.391, &#39;crossentropy&#39;: 1.6241544921875}
Epoch 9 metrics: {&#39;accuracy&#39;: 0.4128, &#39;crossentropy&#39;: 1.6204852634429932}
Epoch 10 metrics: {&#39;accuracy&#39;: 0.3924, &#39;crossentropy&#39;: 1.8160644733428954}
Epoch 11 metrics: {&#39;accuracy&#39;: 0.4326, &#39;crossentropy&#39;: 1.6231806396484374}
Epoch 12 metrics: {&#39;accuracy&#39;: 0.4442, &#39;crossentropy&#39;: 1.5932003860473634}
Epoch 13 metrics: {&#39;accuracy&#39;: 0.4844, &#39;crossentropy&#39;: 1.4626072359085083}
Epoch 14 metrics: {&#39;accuracy&#39;: 0.4606, &#39;crossentropy&#39;: 1.6034251977920533}
Epoch 15 metrics: {&#39;accuracy&#39;: 0.485, &#39;crossentropy&#39;: 1.4774507816314697}
Epoch 16 metrics: {&#39;accuracy&#39;: 0.5332, &#39;crossentropy&#39;: 1.3882559200286866}
Epoch 17 metrics: {&#39;accuracy&#39;: 0.4782, &#39;crossentropy&#39;: 1.6575186491012572}
Epoch 18 metrics: {&#39;accuracy&#39;: 0.4776, &#39;crossentropy&#39;: 1.5798493549346924}
Epoch 19 metrics: {&#39;accuracy&#39;: 0.5468, &#39;crossentropy&#39;: 1.3278626495361328}
Epoch 20 metrics: {&#39;accuracy&#39;: 0.5158, &#39;crossentropy&#39;: 1.486465266418457}
Epoch 21 metrics: {&#39;accuracy&#39;: 0.5556, &#39;crossentropy&#39;: 1.3565663835525512}
Epoch 22 metrics: {&#39;accuracy&#39;: 0.5378, &#39;crossentropy&#39;: 1.4065797653198242}
Epoch 23 metrics: {&#39;accuracy&#39;: 0.5392, &#39;crossentropy&#39;: 1.554705366897583}
Epoch 24 metrics: {&#39;accuracy&#39;: 0.519, &#39;crossentropy&#39;: 1.5612750759124756}
Epoch 25 metrics: {&#39;accuracy&#39;: 0.5714, &#39;crossentropy&#39;: 1.4186917364120484}
Epoch 26 metrics: {&#39;accuracy&#39;: 0.5642, &#39;crossentropy&#39;: 1.4817778198242189}
Epoch 27 metrics: {&#39;accuracy&#39;: 0.5726, &#39;crossentropy&#39;: 1.3985243167877197}
Epoch 28 metrics: {&#39;accuracy&#39;: 0.5534, &#39;crossentropy&#39;: 1.4795425735473633}
Epoch 29 metrics: {&#39;accuracy&#39;: 0.5862, &#39;crossentropy&#39;: 1.2989042516708373}
Epoch 30 metrics: {&#39;accuracy&#39;: 0.6064, &#39;crossentropy&#39;: 1.3191610109329224}
Epoch 31 metrics: {&#39;accuracy&#39;: 0.595, &#39;crossentropy&#39;: 1.3418997720718384}
Epoch 32 metrics: {&#39;accuracy&#39;: 0.5756, &#39;crossentropy&#39;: 1.4530495958328247}
Epoch 33 metrics: {&#39;accuracy&#39;: 0.5842, &#39;crossentropy&#39;: 1.661891321182251}
Epoch 34 metrics: {&#39;accuracy&#39;: 0.6206, &#39;crossentropy&#39;: 1.2836292247772216}
Epoch 35 metrics: {&#39;accuracy&#39;: 0.5882, &#39;crossentropy&#39;: 1.3914262773513795}
Epoch 36 metrics: {&#39;accuracy&#39;: 0.5902, &#39;crossentropy&#39;: 1.492536619567871}
Epoch 37 metrics: {&#39;accuracy&#39;: 0.572, &#39;crossentropy&#39;: 1.5827240232467652}
Epoch 38 metrics: {&#39;accuracy&#39;: 0.5958, &#39;crossentropy&#39;: 1.6376944299697875}
Epoch 39 metrics: {&#39;accuracy&#39;: 0.5614, &#39;crossentropy&#39;: 1.755116641998291}
Epoch 40 metrics: {&#39;accuracy&#39;: 0.6226, &#39;crossentropy&#39;: 1.4571272537231446}
Epoch 41 metrics: {&#39;accuracy&#39;: 0.6134, &#39;crossentropy&#39;: 1.4448774215698241}
Epoch 42 metrics: {&#39;accuracy&#39;: 0.5778, &#39;crossentropy&#39;: 1.5845903659820557}
Epoch 43 metrics: {&#39;accuracy&#39;: 0.6396, &#39;crossentropy&#39;: 1.338677777671814}
Epoch 44 metrics: {&#39;accuracy&#39;: 0.63, &#39;crossentropy&#39;: 1.430566248512268}
Epoch 45 metrics: {&#39;accuracy&#39;: 0.6302, &#39;crossentropy&#39;: 1.5538471431732177}
Epoch 46 metrics: {&#39;accuracy&#39;: 0.6282, &#39;crossentropy&#39;: 1.5694222000122071}
Epoch 47 metrics: {&#39;accuracy&#39;: 0.61, &#39;crossentropy&#39;: 1.6805202793121339}
Epoch 48 metrics: {&#39;accuracy&#39;: 0.6284, &#39;crossentropy&#39;: 1.4869282711029053}
Epoch 49 metrics: {&#39;accuracy&#39;: 0.6432, &#39;crossentropy&#39;: 1.4181401374816895}
Epoch 50 metrics: {&#39;accuracy&#39;: 0.6162, &#39;crossentropy&#39;: 1.5683718784332275}
Epoch 51 metrics: {&#39;accuracy&#39;: 0.6616, &#39;crossentropy&#39;: 1.363122608947754}
Epoch 52 metrics: {&#39;accuracy&#39;: 0.652, &#39;crossentropy&#39;: 1.4454259424209595}
Epoch 53 metrics: {&#39;accuracy&#39;: 0.6806, &#39;crossentropy&#39;: 1.336198017501831}
Epoch 54 metrics: {&#39;accuracy&#39;: 0.6792, &#39;crossentropy&#39;: 1.2796468240737915}
Epoch 55 metrics: {&#39;accuracy&#39;: 0.6796, &#39;crossentropy&#39;: 1.3375492029190064}
Epoch 56 metrics: {&#39;accuracy&#39;: 0.655, &#39;crossentropy&#39;: 1.534458289337158}
Epoch 57 metrics: {&#39;accuracy&#39;: 0.6702, &#39;crossentropy&#39;: 1.5365722450256347}
Epoch 58 metrics: {&#39;accuracy&#39;: 0.6636, &#39;crossentropy&#39;: 1.4429270286560059}
Epoch 59 metrics: {&#39;accuracy&#39;: 0.6896, &#39;crossentropy&#39;: 1.4279500259399414}
Epoch 60 metrics: {&#39;accuracy&#39;: 0.6104, &#39;crossentropy&#39;: 2.047204118728638}
Epoch 61 metrics: {&#39;accuracy&#39;: 0.6426, &#39;crossentropy&#39;: 1.700003238105774}
Epoch 62 metrics: {&#39;accuracy&#39;: 0.6498, &#39;crossentropy&#39;: 1.7223677753448485}
Epoch 63 metrics: {&#39;accuracy&#39;: 0.674, &#39;crossentropy&#39;: 1.568129213142395}
Epoch 64 metrics: {&#39;accuracy&#39;: 0.679, &#39;crossentropy&#39;: 1.5233797443389892}
Epoch 65 metrics: {&#39;accuracy&#39;: 0.6556, &#39;crossentropy&#39;: 1.5988889015197754}
Epoch 66 metrics: {&#39;accuracy&#39;: 0.681, &#39;crossentropy&#39;: 1.5559561515808105}
Epoch 67 metrics: {&#39;accuracy&#39;: 0.6558, &#39;crossentropy&#39;: 1.5861485748291015}
Epoch 68 metrics: {&#39;accuracy&#39;: 0.6684, &#39;crossentropy&#39;: 1.6005359226226807}
Epoch 69 metrics: {&#39;accuracy&#39;: 0.683, &#39;crossentropy&#39;: 1.556698197364807}
Epoch 70 metrics: {&#39;accuracy&#39;: 0.666, &#39;crossentropy&#39;: 1.8341962125778197}
Epoch 71 metrics: {&#39;accuracy&#39;: 0.6646, &#39;crossentropy&#39;: 1.7240430130004882}
Epoch 72 metrics: {&#39;accuracy&#39;: 0.6864, &#39;crossentropy&#39;: 1.688390433883667}
Epoch 73 metrics: {&#39;accuracy&#39;: 0.6898, &#39;crossentropy&#39;: 1.4424149753570557}
Epoch 74 metrics: {&#39;accuracy&#39;: 0.6784, &#39;crossentropy&#39;: 1.5320212787628174}
Epoch 75 metrics: {&#39;accuracy&#39;: 0.6572, &#39;crossentropy&#39;: 1.9239155548095703}
Epoch 76 metrics: {&#39;accuracy&#39;: 0.6994, &#39;crossentropy&#39;: 1.503293971633911}
Epoch 77 metrics: {&#39;accuracy&#39;: 0.6802, &#39;crossentropy&#39;: 1.7182488130569458}
Epoch 78 metrics: {&#39;accuracy&#39;: 0.6624, &#39;crossentropy&#39;: 2.040979455757141}
Epoch 79 metrics: {&#39;accuracy&#39;: 0.7108, &#39;crossentropy&#39;: 1.5265844261169434}
Epoch 80 metrics: {&#39;accuracy&#39;: 0.639, &#39;crossentropy&#39;: 2.047646946144104}
Epoch 81 metrics: {&#39;accuracy&#39;: 0.697, &#39;crossentropy&#39;: 1.5622214616775512}
Epoch 82 metrics: {&#39;accuracy&#39;: 0.6968, &#39;crossentropy&#39;: 1.747803352355957}
Epoch 83 metrics: {&#39;accuracy&#39;: 0.664, &#39;crossentropy&#39;: 1.9821340461730956}
Epoch 84 metrics: {&#39;accuracy&#39;: 0.679, &#39;crossentropy&#39;: 1.7599634023666382}
Epoch 85 metrics: {&#39;accuracy&#39;: 0.6754, &#39;crossentropy&#39;: 1.7645211408615111}
Epoch 86 metrics: {&#39;accuracy&#39;: 0.6918, &#39;crossentropy&#39;: 1.7371683568954468}
Epoch 87 metrics: {&#39;accuracy&#39;: 0.6808, &#39;crossentropy&#39;: 1.8495920518875122}
Epoch 88 metrics: {&#39;accuracy&#39;: 0.7046, &#39;crossentropy&#39;: 1.6057298624038696}
Epoch 89 metrics: {&#39;accuracy&#39;: 0.7, &#39;crossentropy&#39;: 1.5827246383666993}
Epoch 90 metrics: {&#39;accuracy&#39;: 0.7134, &#39;crossentropy&#39;: 1.6326092628479003}
Epoch 91 metrics: {&#39;accuracy&#39;: 0.689, &#39;crossentropy&#39;: 1.8398972099304198}
Epoch 92 metrics: {&#39;accuracy&#39;: 0.6988, &#39;crossentropy&#39;: 1.703945962524414}
Epoch 93 metrics: {&#39;accuracy&#39;: 0.6928, &#39;crossentropy&#39;: 1.8319120206832886}
Epoch 94 metrics: {&#39;accuracy&#39;: 0.6742, &#39;crossentropy&#39;: 1.9307451648712157}
Epoch 95 metrics: {&#39;accuracy&#39;: 0.6652, &#39;crossentropy&#39;: 1.9839211711883544}
Epoch 96 metrics: {&#39;accuracy&#39;: 0.7014, &#39;crossentropy&#39;: 1.753114981651306}
Epoch 97 metrics: {&#39;accuracy&#39;: 0.7168, &#39;crossentropy&#39;: 1.583624532699585}
Epoch 98 metrics: {&#39;accuracy&#39;: 0.7178, &#39;crossentropy&#39;: 1.5080754125595093}
Epoch 99 metrics: {&#39;accuracy&#39;: 0.7008, &#39;crossentropy&#39;: 1.691151003074646}
Epoch 100 metrics: {&#39;accuracy&#39;: 0.7082, &#39;crossentropy&#39;: 1.786831614112854}
Epoch 101 metrics: {&#39;accuracy&#39;: 0.7048, &#39;crossentropy&#39;: 1.8026102556228638}
Epoch 102 metrics: {&#39;accuracy&#39;: 0.7088, &#39;crossentropy&#39;: 1.778138516998291}
Epoch 103 metrics: {&#39;accuracy&#39;: 0.7074, &#39;crossentropy&#39;: 1.7982812139511108}
Epoch 104 metrics: {&#39;accuracy&#39;: 0.699, &#39;crossentropy&#39;: 1.975844974899292}
Epoch 105 metrics: {&#39;accuracy&#39;: 0.719, &#39;crossentropy&#39;: 1.7399523822784424}
Epoch 106 metrics: {&#39;accuracy&#39;: 0.6984, &#39;crossentropy&#39;: 1.851081118774414}
Epoch 107 metrics: {&#39;accuracy&#39;: 0.7116, &#39;crossentropy&#39;: 1.8264789319992065}
Epoch 108 metrics: {&#39;accuracy&#39;: 0.7048, &#39;crossentropy&#39;: 1.852280344581604}
Epoch 109 metrics: {&#39;accuracy&#39;: 0.7158, &#39;crossentropy&#39;: 1.6651891231536866}
Epoch 110 metrics: {&#39;accuracy&#39;: 0.7026, &#39;crossentropy&#39;: 1.9465272687911988}
Epoch 111 metrics: {&#39;accuracy&#39;: 0.7, &#39;crossentropy&#39;: 1.869952957725525}
Epoch 112 metrics: {&#39;accuracy&#39;: 0.7044, &#39;crossentropy&#39;: 1.903688197517395}
Epoch 113 metrics: {&#39;accuracy&#39;: 0.711, &#39;crossentropy&#39;: 1.826317674446106}
Epoch 114 metrics: {&#39;accuracy&#39;: 0.7004, &#39;crossentropy&#39;: 1.98455932598114}
Epoch 115 metrics: {&#39;accuracy&#39;: 0.7118, &#39;crossentropy&#39;: 1.847875990486145}
Epoch 116 metrics: {&#39;accuracy&#39;: 0.7208, &#39;crossentropy&#39;: 1.6717159650802613}
Epoch 117 metrics: {&#39;accuracy&#39;: 0.723, &#39;crossentropy&#39;: 1.768020641708374}
Epoch 118 metrics: {&#39;accuracy&#39;: 0.726, &#39;crossentropy&#39;: 1.7357866855621338}
Epoch 119 metrics: {&#39;accuracy&#39;: 0.7172, &#39;crossentropy&#39;: 1.8671522586822509}
Epoch 120 metrics: {&#39;accuracy&#39;: 0.7108, &#39;crossentropy&#39;: 1.839890744972229}
Epoch 121 metrics: {&#39;accuracy&#39;: 0.7262, &#39;crossentropy&#39;: 1.7940632837295531}
Epoch 122 metrics: {&#39;accuracy&#39;: 0.7254, &#39;crossentropy&#39;: 1.739738676071167}
Epoch 123 metrics: {&#39;accuracy&#39;: 0.7354, &#39;crossentropy&#39;: 1.7203208097457885}
Epoch 124 metrics: {&#39;accuracy&#39;: 0.6992, &#39;crossentropy&#39;: 2.108544366455078}
Epoch 125 metrics: {&#39;accuracy&#39;: 0.727, &#39;crossentropy&#39;: 1.7606943075180053}
Epoch 126 metrics: {&#39;accuracy&#39;: 0.736, &#39;crossentropy&#39;: 1.6882964929580688}
Epoch 127 metrics: {&#39;accuracy&#39;: 0.7374, &#39;crossentropy&#39;: 1.7407338274002075}
Epoch 128 metrics: {&#39;accuracy&#39;: 0.7314, &#39;crossentropy&#39;: 1.760880549621582}
Epoch 129 metrics: {&#39;accuracy&#39;: 0.7208, &#39;crossentropy&#39;: 1.8498917400360106}
Epoch 130 metrics: {&#39;accuracy&#39;: 0.7208, &#39;crossentropy&#39;: 1.8959340000152587}
Epoch 131 metrics: {&#39;accuracy&#39;: 0.7142, &#39;crossentropy&#39;: 2.0124451528549194}
Epoch 132 metrics: {&#39;accuracy&#39;: 0.7232, &#39;crossentropy&#39;: 1.9201104499816894}
Epoch 133 metrics: {&#39;accuracy&#39;: 0.7304, &#39;crossentropy&#39;: 1.8375703491210937}
Epoch 134 metrics: {&#39;accuracy&#39;: 0.7116, &#39;crossentropy&#39;: 2.088616641998291}
Epoch 135 metrics: {&#39;accuracy&#39;: 0.7184, &#39;crossentropy&#39;: 1.978208535194397}
Epoch 136 metrics: {&#39;accuracy&#39;: 0.7208, &#39;crossentropy&#39;: 1.8705389200210571}
Epoch 137 metrics: {&#39;accuracy&#39;: 0.7178, &#39;crossentropy&#39;: 1.8655729164123536}
Epoch 138 metrics: {&#39;accuracy&#39;: 0.7346, &#39;crossentropy&#39;: 1.8156576793670653}
Epoch 139 metrics: {&#39;accuracy&#39;: 0.7268, &#39;crossentropy&#39;: 1.9502580039978028}
Epoch 140 metrics: {&#39;accuracy&#39;: 0.7266, &#39;crossentropy&#39;: 1.8996942594528199}
Epoch 141 metrics: {&#39;accuracy&#39;: 0.731, &#39;crossentropy&#39;: 1.7910018768310547}
Epoch 142 metrics: {&#39;accuracy&#39;: 0.7302, &#39;crossentropy&#39;: 1.8320497930526733}
Epoch 143 metrics: {&#39;accuracy&#39;: 0.7412, &#39;crossentropy&#39;: 1.6873140272140503}
Epoch 144 metrics: {&#39;accuracy&#39;: 0.7404, &#39;crossentropy&#39;: 1.7187595129013062}
Epoch 145 metrics: {&#39;accuracy&#39;: 0.741, &#39;crossentropy&#39;: 1.7379650772094726}
Epoch 146 metrics: {&#39;accuracy&#39;: 0.7342, &#39;crossentropy&#39;: 1.7737857412338256}
Epoch 147 metrics: {&#39;accuracy&#39;: 0.736, &#39;crossentropy&#39;: 1.828852554321289}
Epoch 148 metrics: {&#39;accuracy&#39;: 0.7372, &#39;crossentropy&#39;: 1.7541490106582642}
Epoch 149 metrics: {&#39;accuracy&#39;: 0.7304, &#39;crossentropy&#39;: 1.9460332218170167}
Epoch 150 metrics: {&#39;accuracy&#39;: 0.742, &#39;crossentropy&#39;: 1.8300790777206422}
Epoch 151 metrics: {&#39;accuracy&#39;: 0.742, &#39;crossentropy&#39;: 1.7707745203018188}
Epoch 152 metrics: {&#39;accuracy&#39;: 0.7442, &#39;crossentropy&#39;: 1.7096362951278687}
Epoch 153 metrics: {&#39;accuracy&#39;: 0.7482, &#39;crossentropy&#39;: 1.7197347803115846}
Epoch 154 metrics: {&#39;accuracy&#39;: 0.7404, &#39;crossentropy&#39;: 1.8146707033157348}
Epoch 155 metrics: {&#39;accuracy&#39;: 0.7466, &#39;crossentropy&#39;: 1.689366346168518}
Epoch 156 metrics: {&#39;accuracy&#39;: 0.7484, &#39;crossentropy&#39;: 1.76810826587677}
Epoch 157 metrics: {&#39;accuracy&#39;: 0.744, &#39;crossentropy&#39;: 1.7717388998031616}
Epoch 158 metrics: {&#39;accuracy&#39;: 0.7396, &#39;crossentropy&#39;: 1.7943604690551758}
Epoch 159 metrics: {&#39;accuracy&#39;: 0.7418, &#39;crossentropy&#39;: 1.8290934688568115}
Epoch 160 metrics: {&#39;accuracy&#39;: 0.7444, &#39;crossentropy&#39;: 1.7629362171173095}
Epoch 161 metrics: {&#39;accuracy&#39;: 0.744, &#39;crossentropy&#39;: 1.8049781238555909}
Epoch 162 metrics: {&#39;accuracy&#39;: 0.7504, &#39;crossentropy&#39;: 1.7380799936294555}
Epoch 163 metrics: {&#39;accuracy&#39;: 0.751, &#39;crossentropy&#39;: 1.776394571685791}
Epoch 164 metrics: {&#39;accuracy&#39;: 0.7538, &#39;crossentropy&#39;: 1.7701518190383911}
Epoch 165 metrics: {&#39;accuracy&#39;: 0.7462, &#39;crossentropy&#39;: 1.7895368011474608}
Epoch 166 metrics: {&#39;accuracy&#39;: 0.7454, &#39;crossentropy&#39;: 1.806629451942444}
Epoch 167 metrics: {&#39;accuracy&#39;: 0.7514, &#39;crossentropy&#39;: 1.747896582221985}
Epoch 168 metrics: {&#39;accuracy&#39;: 0.747, &#39;crossentropy&#39;: 1.7956759510040283}
Epoch 169 metrics: {&#39;accuracy&#39;: 0.7448, &#39;crossentropy&#39;: 1.7847340812683106}
Epoch 170 metrics: {&#39;accuracy&#39;: 0.7434, &#39;crossentropy&#39;: 1.7952884168624879}
Epoch 171 metrics: {&#39;accuracy&#39;: 0.7376, &#39;crossentropy&#39;: 1.850986799621582}
Epoch 172 metrics: {&#39;accuracy&#39;: 0.747, &#39;crossentropy&#39;: 1.7756878700256347}
Epoch 173 metrics: {&#39;accuracy&#39;: 0.7438, &#39;crossentropy&#39;: 1.8509971067428588}
Epoch 174 metrics: {&#39;accuracy&#39;: 0.742, &#39;crossentropy&#39;: 1.8420905973434447}
Epoch 175 metrics: {&#39;accuracy&#39;: 0.7412, &#39;crossentropy&#39;: 1.8683632846832274}
Epoch 176 metrics: {&#39;accuracy&#39;: 0.7512, &#39;crossentropy&#39;: 1.7546294881820679}
Epoch 177 metrics: {&#39;accuracy&#39;: 0.7498, &#39;crossentropy&#39;: 1.8416410556793212}
Epoch 178 metrics: {&#39;accuracy&#39;: 0.7514, &#39;crossentropy&#39;: 1.753549331855774}
Epoch 179 metrics: {&#39;accuracy&#39;: 0.749, &#39;crossentropy&#39;: 1.7738783197402954}
Epoch 180 metrics: {&#39;accuracy&#39;: 0.7454, &#39;crossentropy&#39;: 1.8118638408660888}
Epoch 181 metrics: {&#39;accuracy&#39;: 0.7476, &#39;crossentropy&#39;: 1.7813485111236573}
Epoch 182 metrics: {&#39;accuracy&#39;: 0.746, &#39;crossentropy&#39;: 1.8107934679031372}
Epoch 183 metrics: {&#39;accuracy&#39;: 0.7448, &#39;crossentropy&#39;: 1.831620743751526}
Epoch 184 metrics: {&#39;accuracy&#39;: 0.745, &#39;crossentropy&#39;: 1.789025442123413}
Epoch 185 metrics: {&#39;accuracy&#39;: 0.7458, &#39;crossentropy&#39;: 1.8282613931655884}
Epoch 186 metrics: {&#39;accuracy&#39;: 0.7496, &#39;crossentropy&#39;: 1.735549228477478}
Epoch 187 metrics: {&#39;accuracy&#39;: 0.7518, &#39;crossentropy&#39;: 1.751326756286621}
Epoch 188 metrics: {&#39;accuracy&#39;: 0.7498, &#39;crossentropy&#39;: 1.7462286001205445}
Epoch 189 metrics: {&#39;accuracy&#39;: 0.7462, &#39;crossentropy&#39;: 1.7955290658950807}
Epoch 190 metrics: {&#39;accuracy&#39;: 0.7526, &#39;crossentropy&#39;: 1.7689809701919557}
Epoch 191 metrics: {&#39;accuracy&#39;: 0.7498, &#39;crossentropy&#39;: 1.7410721433639527}
Epoch 192 metrics: {&#39;accuracy&#39;: 0.7478, &#39;crossentropy&#39;: 1.7681575706481933}
Epoch 193 metrics: {&#39;accuracy&#39;: 0.7484, &#39;crossentropy&#39;: 1.7971847404479981}
Epoch 194 metrics: {&#39;accuracy&#39;: 0.7504, &#39;crossentropy&#39;: 1.781201608276367}
Epoch 195 metrics: {&#39;accuracy&#39;: 0.7498, &#39;crossentropy&#39;: 1.7511244403839112}
Epoch 196 metrics: {&#39;accuracy&#39;: 0.7538, &#39;crossentropy&#39;: 1.7446035387039185}
Epoch 197 metrics: {&#39;accuracy&#39;: 0.749, &#39;crossentropy&#39;: 1.7559877395629884}
Epoch 198 metrics: {&#39;accuracy&#39;: 0.7482, &#39;crossentropy&#39;: 1.7675554174423218}
Epoch 199 metrics: {&#39;accuracy&#39;: 0.7536, &#39;crossentropy&#39;: 1.758990524482727}
Epoch 200 metrics: {&#39;accuracy&#39;: 0.7506, &#39;crossentropy&#39;: 1.7426933135986329}
Epoch 201 metrics: {&#39;accuracy&#39;: 0.75, &#39;crossentropy&#39;: 1.75348480052948}
Epoch 202 metrics: {&#39;accuracy&#39;: 0.748, &#39;crossentropy&#39;: 1.7537748149871826}
Epoch 203 metrics: {&#39;accuracy&#39;: 0.7496, &#39;crossentropy&#39;: 1.7738485204696655}
Epoch 204 metrics: {&#39;accuracy&#39;: 0.7532, &#39;crossentropy&#39;: 1.7541701692581178}
Epoch 205 metrics: {&#39;accuracy&#39;: 0.7498, &#39;crossentropy&#39;: 1.7663930812835693}
Epoch 206 metrics: {&#39;accuracy&#39;: 0.749, &#39;crossentropy&#39;: 1.7786988178253174}
Epoch 207 metrics: {&#39;accuracy&#39;: 0.7526, &#39;crossentropy&#39;: 1.7437051475524903}
Epoch 208 metrics: {&#39;accuracy&#39;: 0.7538, &#39;crossentropy&#39;: 1.7248931865692139}
Epoch 209 metrics: {&#39;accuracy&#39;: 0.7544, &#39;crossentropy&#39;: 1.71589019947052}
Epoch 210 metrics: {&#39;accuracy&#39;: 0.7516, &#39;crossentropy&#39;: 1.758341605758667}
Epoch 211 metrics: {&#39;accuracy&#39;: 0.756, &#39;crossentropy&#39;: 1.741941227722168}
Epoch 212 metrics: {&#39;accuracy&#39;: 0.7562, &#39;crossentropy&#39;: 1.7454945798873902}
Epoch 213 metrics: {&#39;accuracy&#39;: 0.757, &#39;crossentropy&#39;: 1.7174640022277832}
Epoch 214 metrics: {&#39;accuracy&#39;: 0.7574, &#39;crossentropy&#39;: 1.7383282976150514}
Epoch 215 metrics: {&#39;accuracy&#39;: 0.7608, &#39;crossentropy&#39;: 1.7221782392501832}
Epoch 216 metrics: {&#39;accuracy&#39;: 0.7552, &#39;crossentropy&#39;: 1.7076754961013794}
Epoch 217 metrics: {&#39;accuracy&#39;: 0.7542, &#39;crossentropy&#39;: 1.7182720067977906}
Epoch 218 metrics: {&#39;accuracy&#39;: 0.7578, &#39;crossentropy&#39;: 1.6952446559906005}
Epoch 219 metrics: {&#39;accuracy&#39;: 0.7554, &#39;crossentropy&#39;: 1.7280960943222046}
Epoch 220 metrics: {&#39;accuracy&#39;: 0.755, &#39;crossentropy&#39;: 1.7495066160202026}
Epoch 221 metrics: {&#39;accuracy&#39;: 0.7572, &#39;crossentropy&#39;: 1.7330620851516723}
Epoch 222 metrics: {&#39;accuracy&#39;: 0.759, &#39;crossentropy&#39;: 1.7078282203674315}
Epoch 223 metrics: {&#39;accuracy&#39;: 0.7608, &#39;crossentropy&#39;: 1.7290487628936768}
Epoch 224 metrics: {&#39;accuracy&#39;: 0.7572, &#39;crossentropy&#39;: 1.7303240739822388}
Epoch 225 metrics: {&#39;accuracy&#39;: 0.7582, &#39;crossentropy&#39;: 1.717389938735962}
Epoch 226 metrics: {&#39;accuracy&#39;: 0.7556, &#39;crossentropy&#39;: 1.7268558807373047}
Epoch 227 metrics: {&#39;accuracy&#39;: 0.7586, &#39;crossentropy&#39;: 1.7337241804122925}
Epoch 228 metrics: {&#39;accuracy&#39;: 0.7562, &#39;crossentropy&#39;: 1.7270678817749023}
Epoch 229 metrics: {&#39;accuracy&#39;: 0.7576, &#39;crossentropy&#39;: 1.7182663452148437}
Epoch 230 metrics: {&#39;accuracy&#39;: 0.7576, &#39;crossentropy&#39;: 1.7021702903747558}
Epoch 231 metrics: {&#39;accuracy&#39;: 0.7562, &#39;crossentropy&#39;: 1.7144253566741943}
Epoch 232 metrics: {&#39;accuracy&#39;: 0.7566, &#39;crossentropy&#39;: 1.7321986429214478}
Epoch 233 metrics: {&#39;accuracy&#39;: 0.7566, &#39;crossentropy&#39;: 1.7183519495010375}
Epoch 234 metrics: {&#39;accuracy&#39;: 0.7552, &#39;crossentropy&#39;: 1.7462016277313233}
Epoch 235 metrics: {&#39;accuracy&#39;: 0.7556, &#39;crossentropy&#39;: 1.7180176303863526}
Epoch 236 metrics: {&#39;accuracy&#39;: 0.757, &#39;crossentropy&#39;: 1.7254634140014649}
Epoch 237 metrics: {&#39;accuracy&#39;: 0.7556, &#39;crossentropy&#39;: 1.7285911252975463}
Epoch 238 metrics: {&#39;accuracy&#39;: 0.7574, &#39;crossentropy&#39;: 1.683826693725586}
Epoch 239 metrics: {&#39;accuracy&#39;: 0.7566, &#39;crossentropy&#39;: 1.7150617109298707}
Epoch 240 metrics: {&#39;accuracy&#39;: 0.7544, &#39;crossentropy&#39;: 1.7322680219650268}
Epoch 241 metrics: {&#39;accuracy&#39;: 0.755, &#39;crossentropy&#39;: 1.7005619104385377}
Epoch 242 metrics: {&#39;accuracy&#39;: 0.756, &#39;crossentropy&#39;: 1.7127049654006958}
Epoch 243 metrics: {&#39;accuracy&#39;: 0.7546, &#39;crossentropy&#39;: 1.7187364250183106}
Epoch 244 metrics: {&#39;accuracy&#39;: 0.7562, &#39;crossentropy&#39;: 1.6745201164245604}
Epoch 245 metrics: {&#39;accuracy&#39;: 0.7558, &#39;crossentropy&#39;: 1.726686424255371}
Epoch 246 metrics: {&#39;accuracy&#39;: 0.7562, &#39;crossentropy&#39;: 1.7162207075119018}
Epoch 247 metrics: {&#39;accuracy&#39;: 0.7548, &#39;crossentropy&#39;: 1.7088313955307006}
Epoch 248 metrics: {&#39;accuracy&#39;: 0.755, &#39;crossentropy&#39;: 1.7047726398468017}
Epoch 249 metrics: {&#39;accuracy&#39;: 0.7558, &#39;crossentropy&#39;: 1.700604621887207}
Epoch 250 metrics: {&#39;accuracy&#39;: 0.7548, &#39;crossentropy&#39;: 1.715393025779724}
Epoch 251 metrics: {&#39;accuracy&#39;: 0.7564, &#39;crossentropy&#39;: 1.7037671222686768}
Epoch 252 metrics: {&#39;accuracy&#39;: 0.7562, &#39;crossentropy&#39;: 1.7186790084838868}
Epoch 253 metrics: {&#39;accuracy&#39;: 0.7568, &#39;crossentropy&#39;: 1.7143670669555664}
Epoch 254 metrics: {&#39;accuracy&#39;: 0.7552, &#39;crossentropy&#39;: 1.6969462743759156}
Epoch 255 metrics: {&#39;accuracy&#39;: 0.7568, &#39;crossentropy&#39;: 1.7325983026504517}
Epoch 256 metrics: {&#39;accuracy&#39;: 0.7558, &#39;crossentropy&#39;: 1.7111919023513793}
Epoch 257 metrics: {&#39;accuracy&#39;: 0.7532, &#39;crossentropy&#39;: 1.6999373943328857}
Epoch 258 metrics: {&#39;accuracy&#39;: 0.7542, &#39;crossentropy&#39;: 1.7167243534088135}
Epoch 259 metrics: {&#39;accuracy&#39;: 0.7566, &#39;crossentropy&#39;: 1.70211136302948}
Epoch 260 metrics: {&#39;accuracy&#39;: 0.756, &#39;crossentropy&#39;: 1.7309243520736695}
Epoch 261 metrics: {&#39;accuracy&#39;: 0.7562, &#39;crossentropy&#39;: 1.7007623559951783}
Epoch 262 metrics: {&#39;accuracy&#39;: 0.7532, &#39;crossentropy&#39;: 1.7180386194229127}
Epoch 263 metrics: {&#39;accuracy&#39;: 0.7546, &#39;crossentropy&#39;: 1.7187950462341308}
Epoch 264 metrics: {&#39;accuracy&#39;: 0.7536, &#39;crossentropy&#39;: 1.7222141962051392}
Epoch 265 metrics: {&#39;accuracy&#39;: 0.7564, &#39;crossentropy&#39;: 1.6984967140197753}
Epoch 266 metrics: {&#39;accuracy&#39;: 0.7558, &#39;crossentropy&#39;: 1.703884732055664}
Epoch 267 metrics: {&#39;accuracy&#39;: 0.7548, &#39;crossentropy&#39;: 1.7002727746963502}
Epoch 268 metrics: {&#39;accuracy&#39;: 0.7554, &#39;crossentropy&#39;: 1.7004230436325074}
Epoch 269 metrics: {&#39;accuracy&#39;: 0.7566, &#39;crossentropy&#39;: 1.6978841403961182}
Epoch 270 metrics: {&#39;accuracy&#39;: 0.7558, &#39;crossentropy&#39;: 1.6998144533157349}
Epoch 271 metrics: {&#39;accuracy&#39;: 0.756, &#39;crossentropy&#39;: 1.7053843914031983}
Epoch 272 metrics: {&#39;accuracy&#39;: 0.7524, &#39;crossentropy&#39;: 1.7117718711853027}
Epoch 273 metrics: {&#39;accuracy&#39;: 0.7552, &#39;crossentropy&#39;: 1.708799320411682}
Epoch 274 metrics: {&#39;accuracy&#39;: 0.755, &#39;crossentropy&#39;: 1.6985661289215088}
Epoch 275 metrics: {&#39;accuracy&#39;: 0.7556, &#39;crossentropy&#39;: 1.7029306161880493}
Epoch 276 metrics: {&#39;accuracy&#39;: 0.7516, &#39;crossentropy&#39;: 1.7356026754379272}
Epoch 277 metrics: {&#39;accuracy&#39;: 0.758, &#39;crossentropy&#39;: 1.7030886268615724}
Epoch 278 metrics: {&#39;accuracy&#39;: 0.7542, &#39;crossentropy&#39;: 1.7299008548736572}
Epoch 279 metrics: {&#39;accuracy&#39;: 0.7552, &#39;crossentropy&#39;: 1.6949047395706176}
Epoch 280 metrics: {&#39;accuracy&#39;: 0.7574, &#39;crossentropy&#39;: 1.7116279424667358}
Epoch 281 metrics: {&#39;accuracy&#39;: 0.7536, &#39;crossentropy&#39;: 1.7003714113235473}
Epoch 282 metrics: {&#39;accuracy&#39;: 0.7542, &#39;crossentropy&#39;: 1.6931275115966797}
Epoch 283 metrics: {&#39;accuracy&#39;: 0.7534, &#39;crossentropy&#39;: 1.6780114456176758}
Epoch 284 metrics: {&#39;accuracy&#39;: 0.7548, &#39;crossentropy&#39;: 1.7185584741592408}
Epoch 285 metrics: {&#39;accuracy&#39;: 0.7536, &#39;crossentropy&#39;: 1.7136097019195558}
Epoch 286 metrics: {&#39;accuracy&#39;: 0.756, &#39;crossentropy&#39;: 1.6972362438201904}
Epoch 287 metrics: {&#39;accuracy&#39;: 0.755, &#39;crossentropy&#39;: 1.714221834564209}
Epoch 288 metrics: {&#39;accuracy&#39;: 0.7568, &#39;crossentropy&#39;: 1.67931552734375}
Epoch 289 metrics: {&#39;accuracy&#39;: 0.7548, &#39;crossentropy&#39;: 1.7092952177047729}
Epoch 290 metrics: {&#39;accuracy&#39;: 0.7564, &#39;crossentropy&#39;: 1.7008082876205444}
Epoch 291 metrics: {&#39;accuracy&#39;: 0.7558, &#39;crossentropy&#39;: 1.6882962390899658}
Epoch 292 metrics: {&#39;accuracy&#39;: 0.7552, &#39;crossentropy&#39;: 1.6931142219543458}
Epoch 293 metrics: {&#39;accuracy&#39;: 0.7556, &#39;crossentropy&#39;: 1.7219937639236451}
Epoch 294 metrics: {&#39;accuracy&#39;: 0.7542, &#39;crossentropy&#39;: 1.7356434558868408}
Epoch 295 metrics: {&#39;accuracy&#39;: 0.7552, &#39;crossentropy&#39;: 1.7052037885665894}
Epoch 296 metrics: {&#39;accuracy&#39;: 0.7542, &#39;crossentropy&#39;: 1.7217666845321655}
Epoch 297 metrics: {&#39;accuracy&#39;: 0.7544, &#39;crossentropy&#39;: 1.7073020112991333}
Epoch 298 metrics: {&#39;accuracy&#39;: 0.7562, &#39;crossentropy&#39;: 1.7094356815338134}
Epoch 299 metrics: {&#39;accuracy&#39;: 0.7534, &#39;crossentropy&#39;: 1.7303889541625976}
Epoch 300 metrics: {&#39;accuracy&#39;: 0.756, &#39;crossentropy&#39;: 1.704508249282837}
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">trained_model</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">loader</span><span class="o">=</span><span class="n">test_loader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;accuracy&#39;: 0.7593, &#39;crossentropy&#39;: tensor(1.3171)}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils</span> <span class="kn">import</span> <span class="n">data</span>

<span class="n">model_trainer</span> <span class="o">=</span> <span class="n">Cifar10ModelTrainer</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_train_dataloader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">train</span> <span class="o">*</span> <span class="mf">0.06</span><span class="p">)</span>
<span class="n">validation_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_evaluation_dataloader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">validation</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_evaluation_dataloader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">test</span><span class="p">)</span>

<span class="n">log</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">trained_model</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_trained</span><span class="p">(</span>
    <span class="n">train_loader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span>
    <span class="n">train_augmentations</span><span class="o">=</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">train_augmentations</span><span class="p">,</span>
    <span class="n">validation_loader</span><span class="o">=</span><span class="n">validation_loader</span><span class="p">,</span>
    <span class="n">log</span><span class="o">=</span><span class="n">log</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Cosine Annealing
Epoch 1 metrics: {&#39;accuracy&#39;: 0.195, &#39;crossentropy&#39;: 2.2275007415771486}
Epoch 2 metrics: {&#39;accuracy&#39;: 0.2544, &#39;crossentropy&#39;: 1.9551373893737793}
Epoch 3 metrics: {&#39;accuracy&#39;: 0.2624, &#39;crossentropy&#39;: 1.9743153453826905}
Epoch 4 metrics: {&#39;accuracy&#39;: 0.3196, &#39;crossentropy&#39;: 1.793511326980591}
Epoch 5 metrics: {&#39;accuracy&#39;: 0.3322, &#39;crossentropy&#39;: 1.7936479278564452}
Epoch 6 metrics: {&#39;accuracy&#39;: 0.3802, &#39;crossentropy&#39;: 1.6548445222854615}
Epoch 7 metrics: {&#39;accuracy&#39;: 0.397, &#39;crossentropy&#39;: 1.6764303909301759}
Epoch 8 metrics: {&#39;accuracy&#39;: 0.402, &#39;crossentropy&#39;: 1.6659705043792725}
Epoch 9 metrics: {&#39;accuracy&#39;: 0.4102, &#39;crossentropy&#39;: 1.6029461530685425}
Epoch 10 metrics: {&#39;accuracy&#39;: 0.4536, &#39;crossentropy&#39;: 1.5197191888809205}
Epoch 11 metrics: {&#39;accuracy&#39;: 0.4498, &#39;crossentropy&#39;: 1.526081286239624}
Epoch 12 metrics: {&#39;accuracy&#39;: 0.4644, &#39;crossentropy&#39;: 1.6233149143218994}
Epoch 13 metrics: {&#39;accuracy&#39;: 0.484, &#39;crossentropy&#39;: 1.5035313310623168}
Epoch 14 metrics: {&#39;accuracy&#39;: 0.4802, &#39;crossentropy&#39;: 1.5805600301742553}
Epoch 15 metrics: {&#39;accuracy&#39;: 0.4802, &#39;crossentropy&#39;: 1.6135048929214477}
Epoch 16 metrics: {&#39;accuracy&#39;: 0.5, &#39;crossentropy&#39;: 1.7078393663406373}
Epoch 17 metrics: {&#39;accuracy&#39;: 0.4758, &#39;crossentropy&#39;: 1.7879548362731934}
Epoch 18 metrics: {&#39;accuracy&#39;: 0.5334, &#39;crossentropy&#39;: 1.4923369665145874}
Epoch 19 metrics: {&#39;accuracy&#39;: 0.4754, &#39;crossentropy&#39;: 1.7693965662002564}
Epoch 20 metrics: {&#39;accuracy&#39;: 0.5038, &#39;crossentropy&#39;: 1.625737899017334}
Epoch 21 metrics: {&#39;accuracy&#39;: 0.5378, &#39;crossentropy&#39;: 1.4750005517959595}
Epoch 22 metrics: {&#39;accuracy&#39;: 0.5364, &#39;crossentropy&#39;: 1.7414169107437134}
Epoch 23 metrics: {&#39;accuracy&#39;: 0.5634, &#39;crossentropy&#39;: 1.4580804355621337}
Epoch 24 metrics: {&#39;accuracy&#39;: 0.5646, &#39;crossentropy&#39;: 1.5308198135375977}
Epoch 25 metrics: {&#39;accuracy&#39;: 0.544, &#39;crossentropy&#39;: 1.6010465715408326}
Epoch 26 metrics: {&#39;accuracy&#39;: 0.4906, &#39;crossentropy&#39;: 2.484989644622803}
Epoch 27 metrics: {&#39;accuracy&#39;: 0.5444, &#39;crossentropy&#39;: 1.7441176502227784}
Epoch 28 metrics: {&#39;accuracy&#39;: 0.5734, &#39;crossentropy&#39;: 1.5949208166122437}
Epoch 29 metrics: {&#39;accuracy&#39;: 0.547, &#39;crossentropy&#39;: 1.9925661281585694}
Epoch 30 metrics: {&#39;accuracy&#39;: 0.5416, &#39;crossentropy&#39;: 1.677072798538208}
Epoch 31 metrics: {&#39;accuracy&#39;: 0.58, &#39;crossentropy&#39;: 1.6823016321182251}
Epoch 32 metrics: {&#39;accuracy&#39;: 0.5624, &#39;crossentropy&#39;: 1.7964260828018188}
Epoch 33 metrics: {&#39;accuracy&#39;: 0.5872, &#39;crossentropy&#39;: 1.5960037258148194}
Epoch 34 metrics: {&#39;accuracy&#39;: 0.5884, &#39;crossentropy&#39;: 1.8452243558883668}
Epoch 35 metrics: {&#39;accuracy&#39;: 0.5226, &#39;crossentropy&#39;: 2.390915496826172}
Epoch 36 metrics: {&#39;accuracy&#39;: 0.5862, &#39;crossentropy&#39;: 1.751786165046692}
Epoch 37 metrics: {&#39;accuracy&#39;: 0.5546, &#39;crossentropy&#39;: 2.283739311981201}
Epoch 38 metrics: {&#39;accuracy&#39;: 0.6002, &#39;crossentropy&#39;: 1.8924382423400878}
Epoch 39 metrics: {&#39;accuracy&#39;: 0.6044, &#39;crossentropy&#39;: 1.843834720993042}
Epoch 40 metrics: {&#39;accuracy&#39;: 0.557, &#39;crossentropy&#39;: 2.5205303379058837}
Epoch 41 metrics: {&#39;accuracy&#39;: 0.6, &#39;crossentropy&#39;: 2.0484943454742433}
Epoch 42 metrics: {&#39;accuracy&#39;: 0.5678, &#39;crossentropy&#39;: 2.2353332565307618}
Epoch 43 metrics: {&#39;accuracy&#39;: 0.6056, &#39;crossentropy&#39;: 1.9236523778915404}
Epoch 44 metrics: {&#39;accuracy&#39;: 0.6086, &#39;crossentropy&#39;: 2.0088993383407594}
Epoch 45 metrics: {&#39;accuracy&#39;: 0.5854, &#39;crossentropy&#39;: 2.0999632850646974}
Epoch 46 metrics: {&#39;accuracy&#39;: 0.6124, &#39;crossentropy&#39;: 2.0430711101531984}
Epoch 47 metrics: {&#39;accuracy&#39;: 0.5824, &#39;crossentropy&#39;: 2.463464071273804}
Epoch 48 metrics: {&#39;accuracy&#39;: 0.5152, &#39;crossentropy&#39;: 3.106986325073242}
Epoch 49 metrics: {&#39;accuracy&#39;: 0.5628, &#39;crossentropy&#39;: 3.0276481426239013}
Epoch 50 metrics: {&#39;accuracy&#39;: 0.5918, &#39;crossentropy&#39;: 2.4354282920837402}
Epoch 51 metrics: {&#39;accuracy&#39;: 0.6016, &#39;crossentropy&#39;: 2.4161296077728274}
Epoch 52 metrics: {&#39;accuracy&#39;: 0.6054, &#39;crossentropy&#39;: 2.1799372734069826}
Epoch 53 metrics: {&#39;accuracy&#39;: 0.6186, &#39;crossentropy&#39;: 2.320051356124878}
Epoch 54 metrics: {&#39;accuracy&#39;: 0.6206, &#39;crossentropy&#39;: 2.2799232097625732}
Epoch 55 metrics: {&#39;accuracy&#39;: 0.5348, &#39;crossentropy&#39;: 3.0492108322143556}
Epoch 56 metrics: {&#39;accuracy&#39;: 0.6016, &#39;crossentropy&#39;: 2.4531355388641356}
Epoch 57 metrics: {&#39;accuracy&#39;: 0.551, &#39;crossentropy&#39;: 3.044118001174927}
Epoch 58 metrics: {&#39;accuracy&#39;: 0.603, &#39;crossentropy&#39;: 2.3964352600097656}
Epoch 59 metrics: {&#39;accuracy&#39;: 0.6266, &#39;crossentropy&#39;: 2.265823505783081}
Epoch 60 metrics: {&#39;accuracy&#39;: 0.5736, &#39;crossentropy&#39;: 2.7588639423370362}
Epoch 61 metrics: {&#39;accuracy&#39;: 0.5724, &#39;crossentropy&#39;: 3.2521114952087404}
Epoch 62 metrics: {&#39;accuracy&#39;: 0.6122, &#39;crossentropy&#39;: 2.504523838043213}
Epoch 63 metrics: {&#39;accuracy&#39;: 0.6152, &#39;crossentropy&#39;: 2.3536159328460693}
Epoch 64 metrics: {&#39;accuracy&#39;: 0.6342, &#39;crossentropy&#39;: 2.0525430145263672}
Epoch 65 metrics: {&#39;accuracy&#39;: 0.5866, &#39;crossentropy&#39;: 2.92167788772583}
Epoch 66 metrics: {&#39;accuracy&#39;: 0.6068, &#39;crossentropy&#39;: 2.8618898265838624}
Epoch 67 metrics: {&#39;accuracy&#39;: 0.617, &#39;crossentropy&#39;: 2.496814747238159}
Epoch 68 metrics: {&#39;accuracy&#39;: 0.6126, &#39;crossentropy&#39;: 2.672058623123169}
Epoch 69 metrics: {&#39;accuracy&#39;: 0.6252, &#39;crossentropy&#39;: 2.4534772537231446}
Epoch 70 metrics: {&#39;accuracy&#39;: 0.606, &#39;crossentropy&#39;: 2.6408395263671873}
Epoch 71 metrics: {&#39;accuracy&#39;: 0.6114, &#39;crossentropy&#39;: 2.454712201309204}
Epoch 72 metrics: {&#39;accuracy&#39;: 0.6094, &#39;crossentropy&#39;: 2.6132784965515135}
Epoch 73 metrics: {&#39;accuracy&#39;: 0.6212, &#39;crossentropy&#39;: 2.4521360389709472}
Epoch 74 metrics: {&#39;accuracy&#39;: 0.6124, &#39;crossentropy&#39;: 2.5769725296020507}
Epoch 75 metrics: {&#39;accuracy&#39;: 0.645, &#39;crossentropy&#39;: 2.324598404312134}
Epoch 76 metrics: {&#39;accuracy&#39;: 0.587, &#39;crossentropy&#39;: 2.565751948928833}
Epoch 77 metrics: {&#39;accuracy&#39;: 0.6134, &#39;crossentropy&#39;: 2.442854005050659}
Epoch 78 metrics: {&#39;accuracy&#39;: 0.6374, &#39;crossentropy&#39;: 2.322680012893677}
Epoch 79 metrics: {&#39;accuracy&#39;: 0.6328, &#39;crossentropy&#39;: 2.522608646774292}
Epoch 80 metrics: {&#39;accuracy&#39;: 0.643, &#39;crossentropy&#39;: 2.56666565322876}
Epoch 81 metrics: {&#39;accuracy&#39;: 0.6378, &#39;crossentropy&#39;: 2.55048551902771}
Epoch 82 metrics: {&#39;accuracy&#39;: 0.6262, &#39;crossentropy&#39;: 2.5220425621032714}
Epoch 83 metrics: {&#39;accuracy&#39;: 0.6482, &#39;crossentropy&#39;: 2.3307431190490724}
Epoch 84 metrics: {&#39;accuracy&#39;: 0.6428, &#39;crossentropy&#39;: 2.538757446670532}
Epoch 85 metrics: {&#39;accuracy&#39;: 0.653, &#39;crossentropy&#39;: 2.531304301071167}
Epoch 86 metrics: {&#39;accuracy&#39;: 0.6514, &#39;crossentropy&#39;: 2.4802711391448975}
Epoch 87 metrics: {&#39;accuracy&#39;: 0.6408, &#39;crossentropy&#39;: 2.519509112930298}
Epoch 88 metrics: {&#39;accuracy&#39;: 0.6302, &#39;crossentropy&#39;: 2.8033425285339355}
Epoch 89 metrics: {&#39;accuracy&#39;: 0.5906, &#39;crossentropy&#39;: 3.1088540802001954}
Epoch 90 metrics: {&#39;accuracy&#39;: 0.6518, &#39;crossentropy&#39;: 2.364090956878662}
Epoch 91 metrics: {&#39;accuracy&#39;: 0.649, &#39;crossentropy&#39;: 2.437061553955078}
Epoch 92 metrics: {&#39;accuracy&#39;: 0.6098, &#39;crossentropy&#39;: 2.992073026275635}
Epoch 93 metrics: {&#39;accuracy&#39;: 0.6298, &#39;crossentropy&#39;: 2.565552684020996}
Epoch 94 metrics: {&#39;accuracy&#39;: 0.632, &#39;crossentropy&#39;: 2.482003544616699}
Epoch 95 metrics: {&#39;accuracy&#39;: 0.6386, &#39;crossentropy&#39;: 2.474025467300415}
Epoch 96 metrics: {&#39;accuracy&#39;: 0.6198, &#39;crossentropy&#39;: 2.7246614974975585}
Epoch 97 metrics: {&#39;accuracy&#39;: 0.6288, &#39;crossentropy&#39;: 2.563767330932617}
Epoch 98 metrics: {&#39;accuracy&#39;: 0.6334, &#39;crossentropy&#39;: 2.4633625190734865}
Epoch 99 metrics: {&#39;accuracy&#39;: 0.6444, &#39;crossentropy&#39;: 2.4796057315826414}
Epoch 100 metrics: {&#39;accuracy&#39;: 0.6602, &#39;crossentropy&#39;: 2.3063468326568604}
Epoch 101 metrics: {&#39;accuracy&#39;: 0.6418, &#39;crossentropy&#39;: 2.6951640800476073}
Epoch 102 metrics: {&#39;accuracy&#39;: 0.659, &#39;crossentropy&#39;: 2.5758142349243163}
Epoch 103 metrics: {&#39;accuracy&#39;: 0.6398, &#39;crossentropy&#39;: 2.6922632511138915}
Epoch 104 metrics: {&#39;accuracy&#39;: 0.65, &#39;crossentropy&#39;: 2.513911172866821}
Epoch 105 metrics: {&#39;accuracy&#39;: 0.6348, &#39;crossentropy&#39;: 2.892625143814087}
Epoch 106 metrics: {&#39;accuracy&#39;: 0.6426, &#39;crossentropy&#39;: 2.7528413955688475}
Epoch 107 metrics: {&#39;accuracy&#39;: 0.6386, &#39;crossentropy&#39;: 2.7084561500549316}
Epoch 108 metrics: {&#39;accuracy&#39;: 0.6522, &#39;crossentropy&#39;: 2.6051291774749754}
Epoch 109 metrics: {&#39;accuracy&#39;: 0.6592, &#39;crossentropy&#39;: 2.4843068431854247}
Epoch 110 metrics: {&#39;accuracy&#39;: 0.6586, &#39;crossentropy&#39;: 2.4939362491607664}
Epoch 111 metrics: {&#39;accuracy&#39;: 0.655, &#39;crossentropy&#39;: 2.613300040435791}
Epoch 112 metrics: {&#39;accuracy&#39;: 0.6512, &#39;crossentropy&#39;: 2.637877791595459}
Epoch 113 metrics: {&#39;accuracy&#39;: 0.6398, &#39;crossentropy&#39;: 2.7666606281280517}
Epoch 114 metrics: {&#39;accuracy&#39;: 0.641, &#39;crossentropy&#39;: 2.64063610458374}
Epoch 115 metrics: {&#39;accuracy&#39;: 0.636, &#39;crossentropy&#39;: 2.971825}
Epoch 116 metrics: {&#39;accuracy&#39;: 0.6508, &#39;crossentropy&#39;: 2.697191888809204}
Epoch 117 metrics: {&#39;accuracy&#39;: 0.6586, &#39;crossentropy&#39;: 2.843339631652832}
Epoch 118 metrics: {&#39;accuracy&#39;: 0.6452, &#39;crossentropy&#39;: 2.714418073272705}
Epoch 119 metrics: {&#39;accuracy&#39;: 0.6432, &#39;crossentropy&#39;: 2.867455952835083}
Epoch 120 metrics: {&#39;accuracy&#39;: 0.6438, &#39;crossentropy&#39;: 2.6972543994903564}
Epoch 121 metrics: {&#39;accuracy&#39;: 0.6538, &#39;crossentropy&#39;: 2.5744204502105714}
Epoch 122 metrics: {&#39;accuracy&#39;: 0.6558, &#39;crossentropy&#39;: 2.515961482620239}
Epoch 123 metrics: {&#39;accuracy&#39;: 0.6554, &#39;crossentropy&#39;: 2.6600591705322265}
Epoch 124 metrics: {&#39;accuracy&#39;: 0.6532, &#39;crossentropy&#39;: 2.7306379859924315}
Epoch 125 metrics: {&#39;accuracy&#39;: 0.6576, &#39;crossentropy&#39;: 2.5831187984466553}
Epoch 126 metrics: {&#39;accuracy&#39;: 0.6526, &#39;crossentropy&#39;: 2.671724322128296}
Epoch 127 metrics: {&#39;accuracy&#39;: 0.6386, &#39;crossentropy&#39;: 2.900815308380127}
Epoch 128 metrics: {&#39;accuracy&#39;: 0.6572, &#39;crossentropy&#39;: 2.6214982219696044}
Epoch 129 metrics: {&#39;accuracy&#39;: 0.6624, &#39;crossentropy&#39;: 2.6940071323394776}
Epoch 130 metrics: {&#39;accuracy&#39;: 0.657, &#39;crossentropy&#39;: 2.6408819049835204}
Epoch 131 metrics: {&#39;accuracy&#39;: 0.6516, &#39;crossentropy&#39;: 2.711736809921265}
Epoch 132 metrics: {&#39;accuracy&#39;: 0.6548, &#39;crossentropy&#39;: 2.7338013511657713}
Epoch 133 metrics: {&#39;accuracy&#39;: 0.66, &#39;crossentropy&#39;: 2.610374885559082}
Epoch 134 metrics: {&#39;accuracy&#39;: 0.649, &#39;crossentropy&#39;: 2.849789385986328}
Epoch 135 metrics: {&#39;accuracy&#39;: 0.6596, &#39;crossentropy&#39;: 2.668262892532349}
Epoch 136 metrics: {&#39;accuracy&#39;: 0.6646, &#39;crossentropy&#39;: 2.5967228511810303}
Epoch 137 metrics: {&#39;accuracy&#39;: 0.6666, &#39;crossentropy&#39;: 2.5540610416412353}
Epoch 138 metrics: {&#39;accuracy&#39;: 0.6598, &#39;crossentropy&#39;: 2.6203109561920166}
Epoch 139 metrics: {&#39;accuracy&#39;: 0.657, &#39;crossentropy&#39;: 2.678562328338623}
Epoch 140 metrics: {&#39;accuracy&#39;: 0.6622, &#39;crossentropy&#39;: 2.6265086269378664}
Epoch 141 metrics: {&#39;accuracy&#39;: 0.643, &#39;crossentropy&#39;: 2.8907856174468995}
Epoch 142 metrics: {&#39;accuracy&#39;: 0.6684, &#39;crossentropy&#39;: 2.6456907455444334}
Epoch 143 metrics: {&#39;accuracy&#39;: 0.6616, &#39;crossentropy&#39;: 2.6921839332580566}
Epoch 144 metrics: {&#39;accuracy&#39;: 0.656, &#39;crossentropy&#39;: 2.8150816570281982}
Epoch 145 metrics: {&#39;accuracy&#39;: 0.6518, &#39;crossentropy&#39;: 2.890988484573364}
Epoch 146 metrics: {&#39;accuracy&#39;: 0.6392, &#39;crossentropy&#39;: 2.862138520812988}
Epoch 147 metrics: {&#39;accuracy&#39;: 0.6504, &#39;crossentropy&#39;: 2.8185749015808104}
Epoch 148 metrics: {&#39;accuracy&#39;: 0.6536, &#39;crossentropy&#39;: 2.825258309173584}
Epoch 149 metrics: {&#39;accuracy&#39;: 0.6548, &#39;crossentropy&#39;: 2.814702058029175}
Epoch 150 metrics: {&#39;accuracy&#39;: 0.6594, &#39;crossentropy&#39;: 2.7494749687194826}
Epoch 151 metrics: {&#39;accuracy&#39;: 0.6616, &#39;crossentropy&#39;: 2.699591756820679}
Epoch 152 metrics: {&#39;accuracy&#39;: 0.6636, &#39;crossentropy&#39;: 2.5651773036956786}
Epoch 153 metrics: {&#39;accuracy&#39;: 0.6646, &#39;crossentropy&#39;: 2.5723829193115235}
Epoch 154 metrics: {&#39;accuracy&#39;: 0.654, &#39;crossentropy&#39;: 2.683935082244873}
Epoch 155 metrics: {&#39;accuracy&#39;: 0.6578, &#39;crossentropy&#39;: 2.5824686824798584}
Epoch 156 metrics: {&#39;accuracy&#39;: 0.6634, &#39;crossentropy&#39;: 2.627465510177612}
Epoch 157 metrics: {&#39;accuracy&#39;: 0.658, &#39;crossentropy&#39;: 2.721166914367676}
Epoch 158 metrics: {&#39;accuracy&#39;: 0.6678, &#39;crossentropy&#39;: 2.5950584911346435}
Epoch 159 metrics: {&#39;accuracy&#39;: 0.6654, &#39;crossentropy&#39;: 2.5482390319824217}
Epoch 160 metrics: {&#39;accuracy&#39;: 0.6728, &#39;crossentropy&#39;: 2.5297875328063966}
Epoch 161 metrics: {&#39;accuracy&#39;: 0.6642, &#39;crossentropy&#39;: 2.549560933303833}
Epoch 162 metrics: {&#39;accuracy&#39;: 0.6724, &#39;crossentropy&#39;: 2.514709270095825}
Epoch 163 metrics: {&#39;accuracy&#39;: 0.6662, &#39;crossentropy&#39;: 2.6739890377044677}
Epoch 164 metrics: {&#39;accuracy&#39;: 0.6712, &#39;crossentropy&#39;: 2.5637472816467284}
Epoch 165 metrics: {&#39;accuracy&#39;: 0.6732, &#39;crossentropy&#39;: 2.5383569297790527}
Epoch 166 metrics: {&#39;accuracy&#39;: 0.6726, &#39;crossentropy&#39;: 2.520796799468994}
Epoch 167 metrics: {&#39;accuracy&#39;: 0.6716, &#39;crossentropy&#39;: 2.5000243618011475}
Epoch 168 metrics: {&#39;accuracy&#39;: 0.6716, &#39;crossentropy&#39;: 2.547315874862671}
Epoch 169 metrics: {&#39;accuracy&#39;: 0.6702, &#39;crossentropy&#39;: 2.5479700859069823}
Epoch 170 metrics: {&#39;accuracy&#39;: 0.6722, &#39;crossentropy&#39;: 2.5254847366333006}
Epoch 171 metrics: {&#39;accuracy&#39;: 0.674, &#39;crossentropy&#39;: 2.5466954513549807}
Epoch 172 metrics: {&#39;accuracy&#39;: 0.675, &#39;crossentropy&#39;: 2.4717196552276612}
Epoch 173 metrics: {&#39;accuracy&#39;: 0.6724, &#39;crossentropy&#39;: 2.517987104034424}
Epoch 174 metrics: {&#39;accuracy&#39;: 0.6706, &#39;crossentropy&#39;: 2.542851198577881}
Epoch 175 metrics: {&#39;accuracy&#39;: 0.6744, &#39;crossentropy&#39;: 2.4931444522857666}
Epoch 176 metrics: {&#39;accuracy&#39;: 0.6752, &#39;crossentropy&#39;: 2.511356197357178}
Epoch 177 metrics: {&#39;accuracy&#39;: 0.6766, &#39;crossentropy&#39;: 2.5000491394042967}
Epoch 178 metrics: {&#39;accuracy&#39;: 0.674, &#39;crossentropy&#39;: 2.4963913146972656}
Epoch 179 metrics: {&#39;accuracy&#39;: 0.6722, &#39;crossentropy&#39;: 2.515770890045166}
Epoch 180 metrics: {&#39;accuracy&#39;: 0.6734, &#39;crossentropy&#39;: 2.4821668014526366}
Epoch 181 metrics: {&#39;accuracy&#39;: 0.6774, &#39;crossentropy&#39;: 2.4697856773376463}
Epoch 182 metrics: {&#39;accuracy&#39;: 0.674, &#39;crossentropy&#39;: 2.488811835861206}
Epoch 183 metrics: {&#39;accuracy&#39;: 0.6744, &#39;crossentropy&#39;: 2.5062671604156495}
Epoch 184 metrics: {&#39;accuracy&#39;: 0.6718, &#39;crossentropy&#39;: 2.523798867416382}
Epoch 185 metrics: {&#39;accuracy&#39;: 0.6704, &#39;crossentropy&#39;: 2.546375835418701}
Epoch 186 metrics: {&#39;accuracy&#39;: 0.673, &#39;crossentropy&#39;: 2.517531550216675}
Epoch 187 metrics: {&#39;accuracy&#39;: 0.6718, &#39;crossentropy&#39;: 2.5210089611053466}
Epoch 188 metrics: {&#39;accuracy&#39;: 0.6764, &#39;crossentropy&#39;: 2.5385321853637697}
Epoch 189 metrics: {&#39;accuracy&#39;: 0.6762, &#39;crossentropy&#39;: 2.525834504699707}
Epoch 190 metrics: {&#39;accuracy&#39;: 0.675, &#39;crossentropy&#39;: 2.5133980121612547}
Epoch 191 metrics: {&#39;accuracy&#39;: 0.6742, &#39;crossentropy&#39;: 2.4870833194732667}
Epoch 192 metrics: {&#39;accuracy&#39;: 0.6756, &#39;crossentropy&#39;: 2.508055226135254}
Epoch 193 metrics: {&#39;accuracy&#39;: 0.6726, &#39;crossentropy&#39;: 2.466618900680542}
Epoch 194 metrics: {&#39;accuracy&#39;: 0.6738, &#39;crossentropy&#39;: 2.481247635269165}
Epoch 195 metrics: {&#39;accuracy&#39;: 0.676, &#39;crossentropy&#39;: 2.501637008666992}
Epoch 196 metrics: {&#39;accuracy&#39;: 0.6736, &#39;crossentropy&#39;: 2.4742876903533935}
Epoch 197 metrics: {&#39;accuracy&#39;: 0.6728, &#39;crossentropy&#39;: 2.521630255126953}
Epoch 198 metrics: {&#39;accuracy&#39;: 0.6746, &#39;crossentropy&#39;: 2.484155728149414}
Epoch 199 metrics: {&#39;accuracy&#39;: 0.6744, &#39;crossentropy&#39;: 2.487708026123047}
Epoch 200 metrics: {&#39;accuracy&#39;: 0.672, &#39;crossentropy&#39;: 2.510010821533203}
Epoch 201 metrics: {&#39;accuracy&#39;: 0.6714, &#39;crossentropy&#39;: 2.501680049133301}
Epoch 202 metrics: {&#39;accuracy&#39;: 0.6742, &#39;crossentropy&#39;: 2.494542570877075}
Epoch 203 metrics: {&#39;accuracy&#39;: 0.6742, &#39;crossentropy&#39;: 2.5026391651153563}
Epoch 204 metrics: {&#39;accuracy&#39;: 0.6714, &#39;crossentropy&#39;: 2.479823846435547}
Epoch 205 metrics: {&#39;accuracy&#39;: 0.6728, &#39;crossentropy&#39;: 2.500494379043579}
Epoch 206 metrics: {&#39;accuracy&#39;: 0.6742, &#39;crossentropy&#39;: 2.465902960586548}
Epoch 207 metrics: {&#39;accuracy&#39;: 0.6748, &#39;crossentropy&#39;: 2.507644288635254}
Epoch 208 metrics: {&#39;accuracy&#39;: 0.6762, &#39;crossentropy&#39;: 2.4923356647491457}
Epoch 209 metrics: {&#39;accuracy&#39;: 0.6744, &#39;crossentropy&#39;: 2.4851944339752197}
Epoch 210 metrics: {&#39;accuracy&#39;: 0.676, &#39;crossentropy&#39;: 2.471399641418457}
Epoch 211 metrics: {&#39;accuracy&#39;: 0.6742, &#39;crossentropy&#39;: 2.48411247215271}
Epoch 212 metrics: {&#39;accuracy&#39;: 0.6736, &#39;crossentropy&#39;: 2.4647130630493166}
Epoch 213 metrics: {&#39;accuracy&#39;: 0.6776, &#39;crossentropy&#39;: 2.4999272789001465}
Epoch 214 metrics: {&#39;accuracy&#39;: 0.6784, &#39;crossentropy&#39;: 2.4666568771362303}
Epoch 215 metrics: {&#39;accuracy&#39;: 0.6776, &#39;crossentropy&#39;: 2.4399658046722412}
Epoch 216 metrics: {&#39;accuracy&#39;: 0.6736, &#39;crossentropy&#39;: 2.459940484237671}
Epoch 217 metrics: {&#39;accuracy&#39;: 0.6764, &#39;crossentropy&#39;: 2.455937529754639}
Epoch 218 metrics: {&#39;accuracy&#39;: 0.678, &#39;crossentropy&#39;: 2.4509685855865477}
Epoch 219 metrics: {&#39;accuracy&#39;: 0.675, &#39;crossentropy&#39;: 2.437345257949829}
Epoch 220 metrics: {&#39;accuracy&#39;: 0.675, &#39;crossentropy&#39;: 2.4548923709869386}
Epoch 221 metrics: {&#39;accuracy&#39;: 0.6784, &#39;crossentropy&#39;: 2.4382892360687256}
Epoch 222 metrics: {&#39;accuracy&#39;: 0.676, &#39;crossentropy&#39;: 2.459956135559082}
Epoch 223 metrics: {&#39;accuracy&#39;: 0.6764, &#39;crossentropy&#39;: 2.4580553783416748}
Epoch 224 metrics: {&#39;accuracy&#39;: 0.674, &#39;crossentropy&#39;: 2.4496274616241456}
Epoch 225 metrics: {&#39;accuracy&#39;: 0.6776, &#39;crossentropy&#39;: 2.457004451751709}
Epoch 226 metrics: {&#39;accuracy&#39;: 0.678, &#39;crossentropy&#39;: 2.4328000297546386}
Epoch 227 metrics: {&#39;accuracy&#39;: 0.6754, &#39;crossentropy&#39;: 2.4555637378692627}
Epoch 228 metrics: {&#39;accuracy&#39;: 0.6758, &#39;crossentropy&#39;: 2.4445664875030517}
Epoch 229 metrics: {&#39;accuracy&#39;: 0.6766, &#39;crossentropy&#39;: 2.449093216705322}
Epoch 230 metrics: {&#39;accuracy&#39;: 0.6736, &#39;crossentropy&#39;: 2.425094723510742}
Epoch 231 metrics: {&#39;accuracy&#39;: 0.675, &#39;crossentropy&#39;: 2.4614727993011476}
Epoch 232 metrics: {&#39;accuracy&#39;: 0.677, &#39;crossentropy&#39;: 2.4432150547027587}
Epoch 233 metrics: {&#39;accuracy&#39;: 0.6774, &#39;crossentropy&#39;: 2.475752858734131}
Epoch 234 metrics: {&#39;accuracy&#39;: 0.6748, &#39;crossentropy&#39;: 2.4554464023590086}
Epoch 235 metrics: {&#39;accuracy&#39;: 0.6776, &#39;crossentropy&#39;: 2.4431961097717285}
Epoch 236 metrics: {&#39;accuracy&#39;: 0.6768, &#39;crossentropy&#39;: 2.472152670288086}
Epoch 237 metrics: {&#39;accuracy&#39;: 0.6778, &#39;crossentropy&#39;: 2.4386870681762693}
Epoch 238 metrics: {&#39;accuracy&#39;: 0.6738, &#39;crossentropy&#39;: 2.4197988330841063}
Epoch 239 metrics: {&#39;accuracy&#39;: 0.678, &#39;crossentropy&#39;: 2.4275214179992677}
Epoch 240 metrics: {&#39;accuracy&#39;: 0.6758, &#39;crossentropy&#39;: 2.432341135787964}
Epoch 241 metrics: {&#39;accuracy&#39;: 0.6756, &#39;crossentropy&#39;: 2.4078450607299806}
Epoch 242 metrics: {&#39;accuracy&#39;: 0.6766, &#39;crossentropy&#39;: 2.4142181816101074}
Epoch 243 metrics: {&#39;accuracy&#39;: 0.6738, &#39;crossentropy&#39;: 2.4447541358947755}
Epoch 244 metrics: {&#39;accuracy&#39;: 0.677, &#39;crossentropy&#39;: 2.4430173404693605}
Epoch 245 metrics: {&#39;accuracy&#39;: 0.6762, &#39;crossentropy&#39;: 2.4064275592803956}
Epoch 246 metrics: {&#39;accuracy&#39;: 0.6746, &#39;crossentropy&#39;: 2.441832574462891}
Epoch 247 metrics: {&#39;accuracy&#39;: 0.6754, &#39;crossentropy&#39;: 2.4583245403289795}
Epoch 248 metrics: {&#39;accuracy&#39;: 0.6762, &#39;crossentropy&#39;: 2.4131958583831787}
Epoch 249 metrics: {&#39;accuracy&#39;: 0.6782, &#39;crossentropy&#39;: 2.4499823318481444}
Epoch 250 metrics: {&#39;accuracy&#39;: 0.6756, &#39;crossentropy&#39;: 2.4543353870391846}
Epoch 251 metrics: {&#39;accuracy&#39;: 0.6736, &#39;crossentropy&#39;: 2.4446485149383546}
Epoch 252 metrics: {&#39;accuracy&#39;: 0.6738, &#39;crossentropy&#39;: 2.4498222522735595}
Epoch 253 metrics: {&#39;accuracy&#39;: 0.674, &#39;crossentropy&#39;: 2.4392303424835204}
Epoch 254 metrics: {&#39;accuracy&#39;: 0.6742, &#39;crossentropy&#39;: 2.4353042053222658}
Epoch 255 metrics: {&#39;accuracy&#39;: 0.6784, &#39;crossentropy&#39;: 2.4838941242218016}
Epoch 256 metrics: {&#39;accuracy&#39;: 0.6778, &#39;crossentropy&#39;: 2.4182816226959227}
Epoch 257 metrics: {&#39;accuracy&#39;: 0.6764, &#39;crossentropy&#39;: 2.4243657051086425}
Epoch 258 metrics: {&#39;accuracy&#39;: 0.6766, &#39;crossentropy&#39;: 2.4650497291564943}
Epoch 259 metrics: {&#39;accuracy&#39;: 0.6766, &#39;crossentropy&#39;: 2.455877131652832}
Epoch 260 metrics: {&#39;accuracy&#39;: 0.677, &#39;crossentropy&#39;: 2.4400979614257814}
Epoch 261 metrics: {&#39;accuracy&#39;: 0.674, &#39;crossentropy&#39;: 2.414813304519653}
Epoch 262 metrics: {&#39;accuracy&#39;: 0.6764, &#39;crossentropy&#39;: 2.4436942234039307}
Epoch 263 metrics: {&#39;accuracy&#39;: 0.6728, &#39;crossentropy&#39;: 2.4271271675109864}
Epoch 264 metrics: {&#39;accuracy&#39;: 0.6766, &#39;crossentropy&#39;: 2.420365217971802}
Epoch 265 metrics: {&#39;accuracy&#39;: 0.6768, &#39;crossentropy&#39;: 2.4282263999938967}
Epoch 266 metrics: {&#39;accuracy&#39;: 0.6748, &#39;crossentropy&#39;: 2.419319035720825}
Epoch 267 metrics: {&#39;accuracy&#39;: 0.6764, &#39;crossentropy&#39;: 2.44576756439209}
Epoch 268 metrics: {&#39;accuracy&#39;: 0.6794, &#39;crossentropy&#39;: 2.4275263942718506}
Epoch 269 metrics: {&#39;accuracy&#39;: 0.6752, &#39;crossentropy&#39;: 2.4333084587097167}
Epoch 270 metrics: {&#39;accuracy&#39;: 0.675, &#39;crossentropy&#39;: 2.4635192783355713}
Epoch 271 metrics: {&#39;accuracy&#39;: 0.6764, &#39;crossentropy&#39;: 2.4337949756622312}
Epoch 272 metrics: {&#39;accuracy&#39;: 0.6742, &#39;crossentropy&#39;: 2.421456132888794}
Epoch 273 metrics: {&#39;accuracy&#39;: 0.6754, &#39;crossentropy&#39;: 2.4948803550720213}
Epoch 274 metrics: {&#39;accuracy&#39;: 0.6762, &#39;crossentropy&#39;: 2.4148812217712403}
Epoch 275 metrics: {&#39;accuracy&#39;: 0.6736, &#39;crossentropy&#39;: 2.430330587387085}
Epoch 276 metrics: {&#39;accuracy&#39;: 0.6752, &#39;crossentropy&#39;: 2.4521533084869387}
Epoch 277 metrics: {&#39;accuracy&#39;: 0.6762, &#39;crossentropy&#39;: 2.457790599822998}
Epoch 278 metrics: {&#39;accuracy&#39;: 0.677, &#39;crossentropy&#39;: 2.4241583477020265}
Epoch 279 metrics: {&#39;accuracy&#39;: 0.6786, &#39;crossentropy&#39;: 2.428473749923706}
Epoch 280 metrics: {&#39;accuracy&#39;: 0.6766, &#39;crossentropy&#39;: 2.4389997650146484}
Epoch 281 metrics: {&#39;accuracy&#39;: 0.674, &#39;crossentropy&#39;: 2.4454905895233154}
Epoch 282 metrics: {&#39;accuracy&#39;: 0.6756, &#39;crossentropy&#39;: 2.403413757324219}
Epoch 283 metrics: {&#39;accuracy&#39;: 0.6782, &#39;crossentropy&#39;: 2.413132022857666}
Epoch 284 metrics: {&#39;accuracy&#39;: 0.6788, &#39;crossentropy&#39;: 2.4135424282073976}
Epoch 285 metrics: {&#39;accuracy&#39;: 0.6786, &#39;crossentropy&#39;: 2.4336018367767336}
Epoch 286 metrics: {&#39;accuracy&#39;: 0.6738, &#39;crossentropy&#39;: 2.385467792892456}
Epoch 287 metrics: {&#39;accuracy&#39;: 0.6762, &#39;crossentropy&#39;: 2.4554801387786864}
Epoch 288 metrics: {&#39;accuracy&#39;: 0.6758, &#39;crossentropy&#39;: 2.4104957710266115}
Epoch 289 metrics: {&#39;accuracy&#39;: 0.6786, &#39;crossentropy&#39;: 2.4168723720550536}
Epoch 290 metrics: {&#39;accuracy&#39;: 0.678, &#39;crossentropy&#39;: 2.4242772369384764}
Epoch 291 metrics: {&#39;accuracy&#39;: 0.6778, &#39;crossentropy&#39;: 2.4174008445739745}
Epoch 292 metrics: {&#39;accuracy&#39;: 0.6762, &#39;crossentropy&#39;: 2.452844713973999}
Epoch 293 metrics: {&#39;accuracy&#39;: 0.676, &#39;crossentropy&#39;: 2.44308024520874}
Epoch 294 metrics: {&#39;accuracy&#39;: 0.678, &#39;crossentropy&#39;: 2.4303935497283935}
Epoch 295 metrics: {&#39;accuracy&#39;: 0.6762, &#39;crossentropy&#39;: 2.4341884449005127}
Epoch 296 metrics: {&#39;accuracy&#39;: 0.6794, &#39;crossentropy&#39;: 2.4184077697753907}
Epoch 297 metrics: {&#39;accuracy&#39;: 0.6752, &#39;crossentropy&#39;: 2.4065731983184815}
Epoch 298 metrics: {&#39;accuracy&#39;: 0.676, &#39;crossentropy&#39;: 2.4273660774230956}
Epoch 299 metrics: {&#39;accuracy&#39;: 0.6746, &#39;crossentropy&#39;: 2.4285712856292725}
Epoch 300 metrics: {&#39;accuracy&#39;: 0.6726, &#39;crossentropy&#39;: 2.4365912525177}
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">trained_model</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">loader</span><span class="o">=</span><span class="n">test_loader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;accuracy&#39;: 0.6753, &#39;crossentropy&#39;: tensor(1.8744)}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="CIFAR-100">CIFAR-100<a class="anchor-link" href="#CIFAR-100"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">split_dataset</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span>
    <span class="s2">&quot;CIFAR-100&quot;</span><span class="p">,</span> <span class="n">normalize_like_cifar10</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">train_augmentation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">validation_set_size</span><span class="o">=</span><span class="mi">5000</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Files already downloaded and verified
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils</span> <span class="kn">import</span> <span class="n">data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;num_workers&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s2">&quot;pin_memory&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">train</span> <span class="o">*</span> <span class="mf">0.4</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">validation_loader</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">validation</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="n">model_optimizer</span> <span class="o">=</span> <span class="n">Cifar10BayesianResnetFactory</span><span class="p">()</span><span class="o">.</span><span class="n">create_model_optimizer</span><span class="p">()</span>
<span class="n">train_with_schedule</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model_optimizer</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">model_optimizer</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span>
    <span class="n">train_loader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span>
    <span class="n">validation_loader</span><span class="o">=</span><span class="n">validation_loader</span><span class="p">,</span>
    <span class="n">patience_schedule</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
    <span class="n">factor_schedule</span><span class="o">=</span><span class="p">[</span><span class="mf">0.1</span><span class="p">],</span>
    <span class="n">max_epochs</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span>
    <span class="n">training_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">validation_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">training_log</span><span class="o">=</span><span class="p">{},</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch metrics: {&#39;accuracy&#39;: 0.037, &#39;crossentropy&#39;: 4.40652554473877}
Epoch metrics: {&#39;accuracy&#39;: 0.0492, &#39;crossentropy&#39;: 4.2037655502319335}
Epoch metrics: {&#39;accuracy&#39;: 0.061, &#39;crossentropy&#39;: 4.198613374328613}
Epoch metrics: {&#39;accuracy&#39;: 0.0564, &#39;crossentropy&#39;: 4.067956605148315}
Epoch 4: 0.0564 worse than 0.061, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.0838, &#39;crossentropy&#39;: 4.026535692596435}
Epoch metrics: {&#39;accuracy&#39;: 0.0804, &#39;crossentropy&#39;: 4.04006093826294}
Epoch 6: 0.0804 worse than 0.0838, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.0916, &#39;crossentropy&#39;: 3.950498880004883}
Epoch metrics: {&#39;accuracy&#39;: 0.1032, &#39;crossentropy&#39;: 3.9708983085632323}
Epoch metrics: {&#39;accuracy&#39;: 0.1142, &#39;crossentropy&#39;: 3.8166026466369627}
Epoch metrics: {&#39;accuracy&#39;: 0.117, &#39;crossentropy&#39;: 3.8180666912078856}
Epoch metrics: {&#39;accuracy&#39;: 0.1002, &#39;crossentropy&#39;: 3.947795548248291}
Epoch 11: 0.1002 worse than 0.117, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.1012, &#39;crossentropy&#39;: 3.8586297302246093}
Epoch 12: 0.1012 worse than 0.117, patience: 2/3!
Epoch metrics: {&#39;accuracy&#39;: 0.1334, &#39;crossentropy&#39;: 3.7211234298706053}
Epoch metrics: {&#39;accuracy&#39;: 0.1526, &#39;crossentropy&#39;: 3.6456055068969726}
Epoch metrics: {&#39;accuracy&#39;: 0.1506, &#39;crossentropy&#39;: 3.639182250213623}
Epoch 15: 0.1506 worse than 0.1526, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.1556, &#39;crossentropy&#39;: 3.5743414745330813}
Epoch metrics: {&#39;accuracy&#39;: 0.1798, &#39;crossentropy&#39;: 3.5142369106292723}
Epoch metrics: {&#39;accuracy&#39;: 0.1766, &#39;crossentropy&#39;: 3.4968504013061525}
Epoch 18: 0.1766 worse than 0.1798, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.19, &#39;crossentropy&#39;: 3.415262245178223}
Epoch metrics: {&#39;accuracy&#39;: 0.2, &#39;crossentropy&#39;: 3.436680059814453}
Epoch metrics: {&#39;accuracy&#39;: 0.2038, &#39;crossentropy&#39;: 3.479621842575073}
Epoch metrics: {&#39;accuracy&#39;: 0.1874, &#39;crossentropy&#39;: 3.492301457977295}
Epoch 22: 0.1874 worse than 0.2038, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.2194, &#39;crossentropy&#39;: 3.321240447998047}
Epoch metrics: {&#39;accuracy&#39;: 0.2264, &#39;crossentropy&#39;: 3.2894559776306154}
Epoch metrics: {&#39;accuracy&#39;: 0.2468, &#39;crossentropy&#39;: 3.2592536624908446}
Epoch metrics: {&#39;accuracy&#39;: 0.255, &#39;crossentropy&#39;: 3.1534479541778566}
Epoch metrics: {&#39;accuracy&#39;: 0.2574, &#39;crossentropy&#39;: 3.194382339859009}
Epoch metrics: {&#39;accuracy&#39;: 0.2588, &#39;crossentropy&#39;: 3.2088769870758056}
Epoch metrics: {&#39;accuracy&#39;: 0.2538, &#39;crossentropy&#39;: 3.1996145584106443}
Epoch 29: 0.2538 worse than 0.2588, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.2868, &#39;crossentropy&#39;: 3.048496583557129}
Epoch metrics: {&#39;accuracy&#39;: 0.285, &#39;crossentropy&#39;: 3.0462064266204836}
Epoch 31: 0.285 worse than 0.2868, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.2916, &#39;crossentropy&#39;: 3.0441914291381837}
Epoch metrics: {&#39;accuracy&#39;: 0.3042, &#39;crossentropy&#39;: 2.9938636936187746}
Epoch metrics: {&#39;accuracy&#39;: 0.3142, &#39;crossentropy&#39;: 2.9616074798583982}
Epoch metrics: {&#39;accuracy&#39;: 0.3128, &#39;crossentropy&#39;: 3.0372639751434325}
Epoch 35: 0.3128 worse than 0.3142, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.3266, &#39;crossentropy&#39;: 2.9172872680664064}
Epoch metrics: {&#39;accuracy&#39;: 0.332, &#39;crossentropy&#39;: 2.8956572322845457}
Epoch metrics: {&#39;accuracy&#39;: 0.3346, &#39;crossentropy&#39;: 2.8784393520355223}
Epoch metrics: {&#39;accuracy&#39;: 0.3478, &#39;crossentropy&#39;: 2.834599676513672}
Epoch metrics: {&#39;accuracy&#39;: 0.3372, &#39;crossentropy&#39;: 2.8797668670654297}
Epoch 40: 0.3372 worse than 0.3478, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.3616, &#39;crossentropy&#39;: 2.7556054058074952}
Epoch metrics: {&#39;accuracy&#39;: 0.3524, &#39;crossentropy&#39;: 2.8509595169067383}
Epoch 42: 0.3524 worse than 0.3616, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.3544, &#39;crossentropy&#39;: 2.8260359642028807}
Epoch 43: 0.3544 worse than 0.3616, patience: 2/3!
Epoch metrics: {&#39;accuracy&#39;: 0.3708, &#39;crossentropy&#39;: 2.761400556564331}
Epoch metrics: {&#39;accuracy&#39;: 0.3746, &#39;crossentropy&#39;: 2.743904900741577}
Epoch metrics: {&#39;accuracy&#39;: 0.3752, &#39;crossentropy&#39;: 2.752844585418701}
Epoch metrics: {&#39;accuracy&#39;: 0.391, &#39;crossentropy&#39;: 2.7870617553710937}
Epoch metrics: {&#39;accuracy&#39;: 0.3912, &#39;crossentropy&#39;: 2.6811590377807617}
Epoch metrics: {&#39;accuracy&#39;: 0.392, &#39;crossentropy&#39;: 2.7096566692352293}
Epoch metrics: {&#39;accuracy&#39;: 0.3922, &#39;crossentropy&#39;: 2.6482392658233644}
Epoch metrics: {&#39;accuracy&#39;: 0.4076, &#39;crossentropy&#39;: 2.69913618888855}
Epoch metrics: {&#39;accuracy&#39;: 0.3926, &#39;crossentropy&#39;: 2.7104971210479736}
Epoch 52: 0.3926 worse than 0.4076, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.4212, &#39;crossentropy&#39;: 2.7271564582824706}
Epoch metrics: {&#39;accuracy&#39;: 0.3974, &#39;crossentropy&#39;: 2.7731422164916992}
Epoch 54: 0.3974 worse than 0.4212, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.4226, &#39;crossentropy&#39;: 2.7127608409881594}
Epoch metrics: {&#39;accuracy&#39;: 0.4286, &#39;crossentropy&#39;: 2.686399506378174}
Epoch metrics: {&#39;accuracy&#39;: 0.4234, &#39;crossentropy&#39;: 2.731360105895996}
Epoch 57: 0.4234 worse than 0.4286, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.4368, &#39;crossentropy&#39;: 2.6142911724090574}
Epoch metrics: {&#39;accuracy&#39;: 0.4238, &#39;crossentropy&#39;: 2.699748579788208}
Epoch 59: 0.4238 worse than 0.4368, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.4228, &#39;crossentropy&#39;: 2.831049083137512}
Epoch 60: 0.4228 worse than 0.4368, patience: 2/3!
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.005
    weight_decay: 0.0005
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">evaluate_old</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model_optimizer</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">loader</span><span class="o">=</span><span class="n">test_loader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;accuracy&#39;: 0.5724, &#39;crossentropy&#39;: 3.0206112657546997}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>57.24% is better than Random acquisition in VAAL (Variational Adversarial Active Learning, <a href="https://arxiv.org/abs/1904.00370">https://arxiv.org/abs/1904.00370</a>) and also better than the reported CoreSet AL results: 50.5%?</p>
<hr>
<p>"Task-Aware Variational Adversarial Active Learning" (<a href="https://arxiv.org/abs/2002.04709">https://arxiv.org/abs/2002.04709</a>) reports much better numbers for Random on ResNet, however: 64%.</p>
<p>They state:</p>
<blockquote><p>ResNet18 [13] was used for all task learners and stochastic gradient descent (SGD) was used with momentum 0.9 and weight decay 0.005. Learning rate was 0.1 for the first 160 epochs and then 0.01 for the last 40 epochs.</p>
</blockquote>
<p>We leave this as a TODO.</p>

</div>
</div>
</div>
</div>
 

