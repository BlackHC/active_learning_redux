---

title: Some Models


keywords: fastai
sidebar: home_sidebar

summary: "To avoid copy-pasta"
description: "To avoid copy-pasta"
nb_path: "06c_resnet_models.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 06c_resnet_models.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">models</span>

<span class="kn">from</span> <span class="nn">batchbald_redux.consistent_mc_dropout</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">BayesianModule</span><span class="p">,</span>
    <span class="n">ConsistentMCDropout</span><span class="p">,</span>
    <span class="n">ConsistentMCDropout2d</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.model_optimizer_factory</span> <span class="kn">import</span> <span class="n">ModelOptimizer</span><span class="p">,</span> <span class="n">ModelOptimizerFactory</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="conv3x3" class="doc_header"><code>conv3x3</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/resnet_models.py#L42" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>conv3x3</code>(<strong><code>in_planes</code></strong>, <strong><code>out_planes</code></strong>, <strong><code>stride</code></strong>=<em><code>1</code></em>, <strong><code>groups</code></strong>=<em><code>1</code></em>, <strong><code>dilation</code></strong>=<em><code>1</code></em>)</p>
</blockquote>
<p>3x3 convolution with padding</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="conv1x1" class="doc_header"><code>conv1x1</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/resnet_models.py#L56" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>conv1x1</code>(<strong><code>in_planes</code></strong>, <strong><code>out_planes</code></strong>, <strong><code>stride</code></strong>=<em><code>1</code></em>)</p>
</blockquote>
<p>1x1 convolution</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BasicBlock" class="doc_header"><code>class</code> <code>BasicBlock</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/resnet_models.py#L61" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BasicBlock</code>(<strong><code>inplanes</code></strong>, <strong><code>planes</code></strong>, <strong><code>stride</code></strong>=<em><code>1</code></em>, <strong><code>downsample</code></strong>=<em><code>None</code></em>, <strong><code>groups</code></strong>=<em><code>1</code></em>, <strong><code>base_width</code></strong>=<em><code>64</code></em>, <strong><code>dilation</code></strong>=<em><code>1</code></em>, <strong><code>norm_layer</code></strong>=<em><code>None</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Bottleneck" class="doc_header"><code>class</code> <code>Bottleneck</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/resnet_models.py#L102" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Bottleneck</code>(<strong><code>inplanes</code></strong>, <strong><code>planes</code></strong>, <strong><code>stride</code></strong>=<em><code>1</code></em>, <strong><code>downsample</code></strong>=<em><code>None</code></em>, <strong><code>groups</code></strong>=<em><code>1</code></em>, <strong><code>base_width</code></strong>=<em><code>64</code></em>, <strong><code>dilation</code></strong>=<em><code>1</code></em>, <strong><code>norm_layer</code></strong>=<em><code>None</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BayesianResNet" class="doc_header"><code>class</code> <code>BayesianResNet</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/resnet_models.py#L146" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BayesianResNet</code>(<strong><code>block</code></strong>, <strong><code>layers</code></strong>, <strong><code>num_classes</code></strong>=<em><code>1000</code></em>, <strong><code>zero_init_residual</code></strong>=<em><code>False</code></em>, <strong><code>groups</code></strong>=<em><code>1</code></em>, <strong><code>width_per_group</code></strong>=<em><code>64</code></em>, <strong><code>replace_stride_with_dilation</code></strong>=<em><code>None</code></em>, <strong><code>norm_layer</code></strong>=<em><code>None</code></em>) :: <a href="/batchbald_redux/consistent_mc_dropout.html#BayesianModule"><code>BayesianModule</code></a></p>
</blockquote>
<p>A module that we can sample multiple times from given a single input batch.</p>
<p>To be efficient, the module allows for a part of the forward pass to be deterministic.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="bayesian_resnet18" class="doc_header"><code>bayesian_resnet18</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/resnet_models.py#L288" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>bayesian_resnet18</code>(<strong><code>cifar_mod</code></strong>=<em><code>False</code></em>, <strong><code>pretrained</code></strong>=<em><code>False</code></em>, <strong><code>progress</code></strong>=<em><code>True</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Constructs a ResNet-18 model.</p>
<p>Args:
    pretrained (bool): If True, returns a model pre-trained on ImageNet
    progress (bool): If True, displays a progress bar of the download to stderr</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="bayesian_resnet34" class="doc_header"><code>bayesian_resnet34</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/resnet_models.py#L298" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>bayesian_resnet34</code>(<strong><code>cifar_mod</code></strong>=<em><code>False</code></em>, <strong><code>pretrained</code></strong>=<em><code>False</code></em>, <strong><code>progress</code></strong>=<em><code>True</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Constructs a ResNet-34 model.</p>
<p>Args:
    pretrained (bool): If True, returns a model pre-trained on ImageNet
    progress (bool): If True, displays a progress bar of the download to stderr</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">torch.hub</span> <span class="kn">import</span> <span class="n">load_state_dict_from_url</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>

<span class="n">model_urls</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;resnet18&quot;</span><span class="p">:</span> <span class="s2">&quot;https://download.pytorch.org/models/resnet18-5c106cde.pth&quot;</span><span class="p">,</span>
    <span class="s2">&quot;resnet34&quot;</span><span class="p">:</span> <span class="s2">&quot;https://download.pytorch.org/models/resnet34-333f7ec4.pth&quot;</span><span class="p">,</span>
    <span class="s2">&quot;resnet50&quot;</span><span class="p">:</span> <span class="s2">&quot;https://download.pytorch.org/models/resnet50-19c8e357.pth&quot;</span><span class="p">,</span>
    <span class="s2">&quot;resnet101&quot;</span><span class="p">:</span> <span class="s2">&quot;https://download.pytorch.org/models/resnet101-5d3b4d8f.pth&quot;</span><span class="p">,</span>
    <span class="s2">&quot;resnet152&quot;</span><span class="p">:</span> <span class="s2">&quot;https://download.pytorch.org/models/resnet152-b121ed2d.pth&quot;</span><span class="p">,</span>
    <span class="s2">&quot;resnext50_32x4d&quot;</span><span class="p">:</span> <span class="s2">&quot;https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth&quot;</span><span class="p">,</span>
    <span class="s2">&quot;resnext101_32x8d&quot;</span><span class="p">:</span> <span class="s2">&quot;https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth&quot;</span><span class="p">,</span>
<span class="p">}</span>


<span class="k">def</span> <span class="nf">conv3x3</span><span class="p">(</span><span class="n">in_planes</span><span class="p">,</span> <span class="n">out_planes</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;3x3 convolution with padding&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
        <span class="n">in_planes</span><span class="p">,</span>
        <span class="n">out_planes</span><span class="p">,</span>
        <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span>
        <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">,</span>
        <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">conv1x1</span><span class="p">(</span><span class="n">in_planes</span><span class="p">,</span> <span class="n">out_planes</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;1x1 convolution&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_planes</span><span class="p">,</span> <span class="n">out_planes</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">BasicBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="n">expansion</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">inplanes</span><span class="p">,</span> <span class="n">planes</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">downsample</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">base_width</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">norm_layer</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BasicBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">norm_layer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">norm_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span>
        <span class="k">if</span> <span class="n">groups</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">base_width</span> <span class="o">!=</span> <span class="mi">64</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;BasicBlock only supports groups=1 and base_width=64&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dilation</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Dilation &gt; 1 not supported in BasicBlock&quot;</span><span class="p">)</span>
        <span class="c1"># Both self.conv1 and self.downsample layers downsample the input when stride != 1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv3x3</span><span class="p">(</span><span class="n">inplanes</span><span class="p">,</span> <span class="n">planes</span><span class="p">,</span> <span class="n">stride</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">norm_layer</span><span class="p">(</span><span class="n">planes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv3x3</span><span class="p">(</span><span class="n">planes</span><span class="p">,</span> <span class="n">planes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">norm_layer</span><span class="p">(</span><span class="n">planes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span> <span class="o">=</span> <span class="n">downsample</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">identity</span> <span class="o">=</span> <span class="n">x</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">identity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">+=</span> <span class="n">identity</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>


<span class="k">class</span> <span class="nc">Bottleneck</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="n">expansion</span> <span class="o">=</span> <span class="mi">4</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">inplanes</span><span class="p">,</span> <span class="n">planes</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">downsample</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">base_width</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">norm_layer</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Bottleneck</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">norm_layer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">norm_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span>
        <span class="n">width</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">planes</span> <span class="o">*</span> <span class="p">(</span><span class="n">base_width</span> <span class="o">/</span> <span class="mf">64.0</span><span class="p">))</span> <span class="o">*</span> <span class="n">groups</span>
        <span class="c1"># Both self.conv2 and self.downsample layers downsample the input when stride != 1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">conv1x1</span><span class="p">(</span><span class="n">inplanes</span><span class="p">,</span> <span class="n">width</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">norm_layer</span><span class="p">(</span><span class="n">width</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">conv3x3</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">dilation</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">norm_layer</span><span class="p">(</span><span class="n">width</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">conv1x1</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">planes</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">expansion</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn3</span> <span class="o">=</span> <span class="n">norm_layer</span><span class="p">(</span><span class="n">planes</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">expansion</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span> <span class="o">=</span> <span class="n">downsample</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">identity</span> <span class="o">=</span> <span class="n">x</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">identity</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">downsample</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">+=</span> <span class="n">identity</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>


<span class="k">class</span> <span class="nc">BayesianResNet</span><span class="p">(</span><span class="n">BayesianModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">block</span><span class="p">,</span>
        <span class="n">layers</span><span class="p">,</span>
        <span class="n">num_classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">zero_init_residual</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">width_per_group</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
        <span class="n">replace_stride_with_dilation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">norm_layer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">norm_layer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">norm_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_norm_layer</span> <span class="o">=</span> <span class="n">norm_layer</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">inplanes</span> <span class="o">=</span> <span class="mi">64</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dilation</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">replace_stride_with_dilation</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># each element in the tuple indicates if we should replace</span>
            <span class="c1"># the 2x2 stride with a dilated convolution instead</span>
            <span class="n">replace_stride_with_dilation</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">replace_stride_with_dilation</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;replace_stride_with_dilation should be None &quot;</span>
                <span class="s2">&quot;or a 3-element tuple, got </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">replace_stride_with_dilation</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">groups</span> <span class="o">=</span> <span class="n">groups</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_width</span> <span class="o">=</span> <span class="n">width_per_group</span>

        <span class="c1"># This gets reset when cifar_mod=True below</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inplanes</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">norm_layer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inplanes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># This gets reset when cifar_mod=True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maxpool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_layer</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_layer</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">layers</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dilate</span><span class="o">=</span><span class="n">replace_stride_with_dilation</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_layer</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">layers</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dilate</span><span class="o">=</span><span class="n">replace_stride_with_dilation</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_layer</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">layers</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dilate</span><span class="o">=</span><span class="n">replace_stride_with_dilation</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">avgpool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="c1"># self.fc = nn.Linear(512 * block.expansion, num_classes)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">ConsistentMCDropout</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span> <span class="o">*</span> <span class="n">block</span><span class="o">.</span><span class="n">expansion</span><span class="p">,</span> <span class="mi">256</span> <span class="o">*</span> <span class="n">block</span><span class="o">.</span><span class="n">expansion</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">ConsistentMCDropout</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span> <span class="o">*</span> <span class="n">block</span><span class="o">.</span><span class="n">expansion</span><span class="p">,</span> <span class="mi">256</span> <span class="o">*</span> <span class="n">block</span><span class="o">.</span><span class="n">expansion</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;fan_out&quot;</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">)):</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Zero-initialize the last BN in each residual branch,</span>
        <span class="c1"># so that the residual branch starts with zeros, and each residual block behaves like an identity.</span>
        <span class="c1"># This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677</span>
        <span class="k">if</span> <span class="n">zero_init_residual</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">Bottleneck</span><span class="p">):</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bn3</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">BasicBlock</span><span class="p">):</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bn2</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_make_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block</span><span class="p">,</span> <span class="n">planes</span><span class="p">,</span> <span class="n">blocks</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dilate</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">norm_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_norm_layer</span>
        <span class="n">downsample</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">previous_dilation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dilation</span>
        <span class="k">if</span> <span class="n">dilate</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dilation</span> <span class="o">*=</span> <span class="n">stride</span>
            <span class="n">stride</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">stride</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">inplanes</span> <span class="o">!=</span> <span class="n">planes</span> <span class="o">*</span> <span class="n">block</span><span class="o">.</span><span class="n">expansion</span><span class="p">:</span>
            <span class="n">downsample</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">conv1x1</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inplanes</span><span class="p">,</span> <span class="n">planes</span> <span class="o">*</span> <span class="n">block</span><span class="o">.</span><span class="n">expansion</span><span class="p">,</span> <span class="n">stride</span><span class="p">),</span> <span class="n">norm_layer</span><span class="p">(</span><span class="n">planes</span> <span class="o">*</span> <span class="n">block</span><span class="o">.</span><span class="n">expansion</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">block</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">inplanes</span><span class="p">,</span> <span class="n">planes</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">downsample</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_width</span><span class="p">,</span> <span class="n">previous_dilation</span><span class="p">,</span> <span class="n">norm_layer</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inplanes</span> <span class="o">=</span> <span class="n">planes</span> <span class="o">*</span> <span class="n">block</span><span class="o">.</span><span class="n">expansion</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">blocks</span><span class="p">):</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">block</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">inplanes</span><span class="p">,</span>
                    <span class="n">planes</span><span class="p">,</span>
                    <span class="n">groups</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">,</span>
                    <span class="n">base_width</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">base_width</span><span class="p">,</span>
                    <span class="n">dilation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span>
                    <span class="n">norm_layer</span><span class="o">=</span><span class="n">norm_layer</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">deterministic_forward_impl</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxpool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer4</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">avgpool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">mc_forward_impl</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="k">def</span> <span class="nf">_bayesian_resnet</span><span class="p">(</span><span class="n">arch</span><span class="p">,</span> <span class="n">block</span><span class="p">,</span> <span class="n">layers</span><span class="p">,</span> <span class="n">cifar_mod</span><span class="p">,</span> <span class="n">pretrained</span><span class="p">,</span> <span class="n">progress</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">BayesianResNet</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="n">layers</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">cifar_mod</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">maxpool</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">pretrained</span><span class="p">:</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">cifar_mod</span>
        <span class="n">state_dict</span> <span class="o">=</span> <span class="n">load_state_dict_from_url</span><span class="p">(</span><span class="n">model_urls</span><span class="p">[</span><span class="n">arch</span><span class="p">],</span> <span class="n">progress</span><span class="o">=</span><span class="n">progress</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">model</span>


<span class="k">def</span> <span class="nf">bayesian_resnet18</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> <span class="n">cifar_mod</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">progress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructs a ResNet-18 model.</span>

<span class="sd">    Args:</span>
<span class="sd">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span>
<span class="sd">        progress (bool): If True, displays a progress bar of the download to stderr</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_bayesian_resnet</span><span class="p">(</span><span class="s2">&quot;resnet18&quot;</span><span class="p">,</span> <span class="n">BasicBlock</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">cifar_mod</span><span class="p">,</span> <span class="n">pretrained</span><span class="p">,</span> <span class="n">progress</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">bayesian_resnet34</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> <span class="n">cifar_mod</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">progress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructs a ResNet-34 model.</span>

<span class="sd">    Args:</span>
<span class="sd">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span>
<span class="sd">        progress (bool): If True, displays a progress bar of the download to stderr</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_bayesian_resnet</span><span class="p">(</span><span class="s2">&quot;resnet34&quot;</span><span class="p">,</span> <span class="n">BasicBlock</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">cifar_mod</span><span class="p">,</span> <span class="n">pretrained</span><span class="p">,</span> <span class="n">progress</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Cifar10BayesianResnetFactory" class="doc_header"><code>class</code> <code>Cifar10BayesianResnetFactory</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/resnet_models.py#L311" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Cifar10BayesianResnetFactory</code>() :: <a href="/batchbald_redux/model_optimizer_factory.html#ModelOptimizerFactory"><code>ModelOptimizerFactory</code></a></p>
</blockquote>
<p>Cifar10BayesianResnetFactory()</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">Cifar10BayesianResnetFactory</span><span class="p">(</span><span class="n">ModelOptimizerFactory</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">create_model_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelOptimizer</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">bayesian_resnet18</span><span class="p">(</span><span class="n">cifar_mod</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ModelOptimizer</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="CIFAR-10-40%-baseline">CIFAR-10 40% baseline<a class="anchor-link" href="#CIFAR-10-40%-baseline"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">batchbald_redux.datasets</span> <span class="kn">import</span> <span class="n">get_dataset</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.black_box_model_training</span> <span class="kn">import</span> <span class="n">train_with_schedule</span><span class="p">,</span> <span class="n">evaluate</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">split_dataset</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span><span class="s2">&quot;CIFAR-10&quot;</span><span class="p">,</span> <span class="n">normalize_like_cifar10</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">train_augmentation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">validation_set_size</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils</span> <span class="kn">import</span> <span class="n">data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;num_workers&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s2">&quot;pin_memory&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">train</span> <span class="o">*</span> <span class="mf">0.4</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">validation_loader</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">validation</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="n">model_optimizer</span> <span class="o">=</span> <span class="n">Cifar10BayesianResnetFactory</span><span class="p">()</span><span class="o">.</span><span class="n">create_model_optimizer</span><span class="p">()</span>
<span class="n">train_with_schedule</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model_optimizer</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">model_optimizer</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">train_loader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">validation_loader</span><span class="o">=</span><span class="n">validation_loader</span><span class="p">,</span> <span class="n">patience_schedule</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="n">factor_schedule</span><span class="o">=</span><span class="p">[</span><span class="mf">0.1</span><span class="p">],</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">training_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">training_log</span><span class="o">=</span><span class="p">{})</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch metrics: {&#39;accuracy&#39;: 0.4036, &#39;crossentropy&#39;: 1.7882676845550538}
Epoch metrics: {&#39;accuracy&#39;: 0.4834, &#39;crossentropy&#39;: 1.481701950454712}
Epoch metrics: {&#39;accuracy&#39;: 0.5428, &#39;crossentropy&#39;: 1.3699166606903077}
Epoch metrics: {&#39;accuracy&#39;: 0.501, &#39;crossentropy&#39;: 1.5626290748596192}
Epoch 4: 0.501 worse than 0.5428, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.601, &#39;crossentropy&#39;: 1.2635912508010865}
Epoch metrics: {&#39;accuracy&#39;: 0.6266, &#39;crossentropy&#39;: 1.187613642501831}
Epoch metrics: {&#39;accuracy&#39;: 0.6734, &#39;crossentropy&#39;: 1.0052011548995972}
Epoch metrics: {&#39;accuracy&#39;: 0.682, &#39;crossentropy&#39;: 1.0248640705108643}
Epoch metrics: {&#39;accuracy&#39;: 0.7096, &#39;crossentropy&#39;: 0.9396376174926758}
Epoch metrics: {&#39;accuracy&#39;: 0.7272, &#39;crossentropy&#39;: 0.8418712997436524}
Epoch metrics: {&#39;accuracy&#39;: 0.7102, &#39;crossentropy&#39;: 0.992177451467514}
Epoch 11: 0.7102 worse than 0.7272, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.7522, &#39;crossentropy&#39;: 0.8086827343940735}
Epoch metrics: {&#39;accuracy&#39;: 0.7696, &#39;crossentropy&#39;: 0.7537960346221924}
Epoch metrics: {&#39;accuracy&#39;: 0.677, &#39;crossentropy&#39;: 1.2522793543338775}
Epoch 14: 0.677 worse than 0.7696, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.7704, &#39;crossentropy&#39;: 0.7572291868209838}
Epoch metrics: {&#39;accuracy&#39;: 0.788, &#39;crossentropy&#39;: 0.6703125279903411}
Epoch metrics: {&#39;accuracy&#39;: 0.8058, &#39;crossentropy&#39;: 0.6643583700180054}
Epoch metrics: {&#39;accuracy&#39;: 0.7888, &#39;crossentropy&#39;: 0.7042493198394776}
Epoch 18: 0.7888 worse than 0.8058, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.7828, &#39;crossentropy&#39;: 0.7735469184875489}
Epoch 19: 0.7828 worse than 0.8058, patience: 2/3!
Epoch metrics: {&#39;accuracy&#39;: 0.7842, &#39;crossentropy&#39;: 0.8083664597511292}
Epoch 20: 0.7842 worse than 0.8058, patience: 3/3!
Epoch metrics: {&#39;accuracy&#39;: 0.7916, &#39;crossentropy&#39;: 0.745104105758667}
Epoch 21: 0.7916 worse than 0.8058, patience: 4/3!
Epoch    21: reducing learning rate of group 0 to 1.0000e-04.
Epoch metrics: {&#39;accuracy&#39;: 0.8576, &#39;crossentropy&#39;: 0.488191157746315}
Epoch metrics: {&#39;accuracy&#39;: 0.8572, &#39;crossentropy&#39;: 0.48753206486701967}
Epoch 23: 0.8572 worse than 0.8576, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.8598, &#39;crossentropy&#39;: 0.48893280182480814}
Epoch metrics: {&#39;accuracy&#39;: 0.863, &#39;crossentropy&#39;: 0.4871544968008995}
Epoch metrics: {&#39;accuracy&#39;: 0.8594, &#39;crossentropy&#39;: 0.500533379971981}
Epoch 26: 0.8594 worse than 0.863, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.8614, &#39;crossentropy&#39;: 0.4965192899346352}
Epoch 27: 0.8614 worse than 0.863, patience: 2/3!
Epoch metrics: {&#39;accuracy&#39;: 0.8592, &#39;crossentropy&#39;: 0.5033470409154892}
Epoch 28: 0.8592 worse than 0.863, patience: 3/3!
Epoch metrics: {&#39;accuracy&#39;: 0.8594, &#39;crossentropy&#39;: 0.504065201023221}
Epoch 29: 0.8594 worse than 0.863, patience: 4/3!
Epoch    29: reducing learning rate of group 0 to 1.0000e-05.
Epoch metrics: {&#39;accuracy&#39;: 0.8616, &#39;crossentropy&#39;: 0.49568186736106873}
Epoch 30: 0.8616 worse than 0.863, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.8628, &#39;crossentropy&#39;: 0.4986858606278896}
Epoch 31: 0.8628 worse than 0.863, patience: 2/3!
Epoch metrics: {&#39;accuracy&#39;: 0.8658, &#39;crossentropy&#39;: 0.5025872270286084}
Epoch metrics: {&#39;accuracy&#39;: 0.8616, &#39;crossentropy&#39;: 0.4966917310476303}
Epoch 33: 0.8616 worse than 0.8658, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.864, &#39;crossentropy&#39;: 0.5035948188602924}
Epoch 34: 0.864 worse than 0.8658, patience: 2/3!
Epoch metrics: {&#39;accuracy&#39;: 0.864, &#39;crossentropy&#39;: 0.49511414707899093}
Epoch 35: 0.864 worse than 0.8658, patience: 3/3!
Epoch metrics: {&#39;accuracy&#39;: 0.8628, &#39;crossentropy&#39;: 0.5081136326342821}
Epoch 36: 0.8628 worse than 0.8658, patience: 4/3!
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-05
    weight_decay: 0.0005
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model_optimizer</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">loader</span><span class="o">=</span><span class="n">test_loader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;accuracy&#39;: 0.8638, &#39;crossentropy&#39;: 0.5297188091278077}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="CIFAR-100">CIFAR-100<a class="anchor-link" href="#CIFAR-100"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">split_dataset</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span><span class="s2">&quot;CIFAR-100&quot;</span><span class="p">,</span> <span class="n">normalize_like_cifar10</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">train_augmentation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">validation_set_size</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Files already downloaded and verified
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils</span> <span class="kn">import</span> <span class="n">data</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;num_workers&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s2">&quot;pin_memory&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">train</span> <span class="o">*</span> <span class="mf">0.4</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">validation_loader</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">validation</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">split_dataset</span><span class="o">.</span><span class="n">test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="n">model_optimizer</span> <span class="o">=</span> <span class="n">Cifar10BayesianResnetFactory</span><span class="p">()</span><span class="o">.</span><span class="n">create_model_optimizer</span><span class="p">()</span>
<span class="n">train_with_schedule</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model_optimizer</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">model_optimizer</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">train_loader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">validation_loader</span><span class="o">=</span><span class="n">validation_loader</span><span class="p">,</span> <span class="n">patience_schedule</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="n">factor_schedule</span><span class="o">=</span><span class="p">[</span><span class="mf">0.1</span><span class="p">],</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">training_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">training_log</span><span class="o">=</span><span class="p">{})</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch metrics: {&#39;accuracy&#39;: 0.037, &#39;crossentropy&#39;: 4.40652554473877}
Epoch metrics: {&#39;accuracy&#39;: 0.0492, &#39;crossentropy&#39;: 4.2037655502319335}
Epoch metrics: {&#39;accuracy&#39;: 0.061, &#39;crossentropy&#39;: 4.198613374328613}
Epoch metrics: {&#39;accuracy&#39;: 0.0564, &#39;crossentropy&#39;: 4.067956605148315}
Epoch 4: 0.0564 worse than 0.061, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.0838, &#39;crossentropy&#39;: 4.026535692596435}
Epoch metrics: {&#39;accuracy&#39;: 0.0804, &#39;crossentropy&#39;: 4.04006093826294}
Epoch 6: 0.0804 worse than 0.0838, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.0916, &#39;crossentropy&#39;: 3.950498880004883}
Epoch metrics: {&#39;accuracy&#39;: 0.1032, &#39;crossentropy&#39;: 3.9708983085632323}
Epoch metrics: {&#39;accuracy&#39;: 0.1142, &#39;crossentropy&#39;: 3.8166026466369627}
Epoch metrics: {&#39;accuracy&#39;: 0.117, &#39;crossentropy&#39;: 3.8180666912078856}
Epoch metrics: {&#39;accuracy&#39;: 0.1002, &#39;crossentropy&#39;: 3.947795548248291}
Epoch 11: 0.1002 worse than 0.117, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.1012, &#39;crossentropy&#39;: 3.8586297302246093}
Epoch 12: 0.1012 worse than 0.117, patience: 2/3!
Epoch metrics: {&#39;accuracy&#39;: 0.1334, &#39;crossentropy&#39;: 3.7211234298706053}
Epoch metrics: {&#39;accuracy&#39;: 0.1526, &#39;crossentropy&#39;: 3.6456055068969726}
Epoch metrics: {&#39;accuracy&#39;: 0.1506, &#39;crossentropy&#39;: 3.639182250213623}
Epoch 15: 0.1506 worse than 0.1526, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.1556, &#39;crossentropy&#39;: 3.5743414745330813}
Epoch metrics: {&#39;accuracy&#39;: 0.1798, &#39;crossentropy&#39;: 3.5142369106292723}
Epoch metrics: {&#39;accuracy&#39;: 0.1766, &#39;crossentropy&#39;: 3.4968504013061525}
Epoch 18: 0.1766 worse than 0.1798, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.19, &#39;crossentropy&#39;: 3.415262245178223}
Epoch metrics: {&#39;accuracy&#39;: 0.2, &#39;crossentropy&#39;: 3.436680059814453}
Epoch metrics: {&#39;accuracy&#39;: 0.2038, &#39;crossentropy&#39;: 3.479621842575073}
Epoch metrics: {&#39;accuracy&#39;: 0.1874, &#39;crossentropy&#39;: 3.492301457977295}
Epoch 22: 0.1874 worse than 0.2038, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.2194, &#39;crossentropy&#39;: 3.321240447998047}
Epoch metrics: {&#39;accuracy&#39;: 0.2264, &#39;crossentropy&#39;: 3.2894559776306154}
Epoch metrics: {&#39;accuracy&#39;: 0.2468, &#39;crossentropy&#39;: 3.2592536624908446}
Epoch metrics: {&#39;accuracy&#39;: 0.255, &#39;crossentropy&#39;: 3.1534479541778566}
Epoch metrics: {&#39;accuracy&#39;: 0.2574, &#39;crossentropy&#39;: 3.194382339859009}
Epoch metrics: {&#39;accuracy&#39;: 0.2588, &#39;crossentropy&#39;: 3.2088769870758056}
Epoch metrics: {&#39;accuracy&#39;: 0.2538, &#39;crossentropy&#39;: 3.1996145584106443}
Epoch 29: 0.2538 worse than 0.2588, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.2868, &#39;crossentropy&#39;: 3.048496583557129}
Epoch metrics: {&#39;accuracy&#39;: 0.285, &#39;crossentropy&#39;: 3.0462064266204836}
Epoch 31: 0.285 worse than 0.2868, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.2916, &#39;crossentropy&#39;: 3.0441914291381837}
Epoch metrics: {&#39;accuracy&#39;: 0.3042, &#39;crossentropy&#39;: 2.9938636936187746}
Epoch metrics: {&#39;accuracy&#39;: 0.3142, &#39;crossentropy&#39;: 2.9616074798583982}
Epoch metrics: {&#39;accuracy&#39;: 0.3128, &#39;crossentropy&#39;: 3.0372639751434325}
Epoch 35: 0.3128 worse than 0.3142, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.3266, &#39;crossentropy&#39;: 2.9172872680664064}
Epoch metrics: {&#39;accuracy&#39;: 0.332, &#39;crossentropy&#39;: 2.8956572322845457}
Epoch metrics: {&#39;accuracy&#39;: 0.3346, &#39;crossentropy&#39;: 2.8784393520355223}
Epoch metrics: {&#39;accuracy&#39;: 0.3478, &#39;crossentropy&#39;: 2.834599676513672}
Epoch metrics: {&#39;accuracy&#39;: 0.3372, &#39;crossentropy&#39;: 2.8797668670654297}
Epoch 40: 0.3372 worse than 0.3478, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.3616, &#39;crossentropy&#39;: 2.7556054058074952}
Epoch metrics: {&#39;accuracy&#39;: 0.3524, &#39;crossentropy&#39;: 2.8509595169067383}
Epoch 42: 0.3524 worse than 0.3616, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.3544, &#39;crossentropy&#39;: 2.8260359642028807}
Epoch 43: 0.3544 worse than 0.3616, patience: 2/3!
Epoch metrics: {&#39;accuracy&#39;: 0.3708, &#39;crossentropy&#39;: 2.761400556564331}
Epoch metrics: {&#39;accuracy&#39;: 0.3746, &#39;crossentropy&#39;: 2.743904900741577}
Epoch metrics: {&#39;accuracy&#39;: 0.3752, &#39;crossentropy&#39;: 2.752844585418701}
Epoch metrics: {&#39;accuracy&#39;: 0.391, &#39;crossentropy&#39;: 2.7870617553710937}
Epoch metrics: {&#39;accuracy&#39;: 0.3912, &#39;crossentropy&#39;: 2.6811590377807617}
Epoch metrics: {&#39;accuracy&#39;: 0.392, &#39;crossentropy&#39;: 2.7096566692352293}
Epoch metrics: {&#39;accuracy&#39;: 0.3922, &#39;crossentropy&#39;: 2.6482392658233644}
Epoch metrics: {&#39;accuracy&#39;: 0.4076, &#39;crossentropy&#39;: 2.69913618888855}
Epoch metrics: {&#39;accuracy&#39;: 0.3926, &#39;crossentropy&#39;: 2.7104971210479736}
Epoch 52: 0.3926 worse than 0.4076, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.4212, &#39;crossentropy&#39;: 2.7271564582824706}
Epoch metrics: {&#39;accuracy&#39;: 0.3974, &#39;crossentropy&#39;: 2.7731422164916992}
Epoch 54: 0.3974 worse than 0.4212, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.4226, &#39;crossentropy&#39;: 2.7127608409881594}
Epoch metrics: {&#39;accuracy&#39;: 0.4286, &#39;crossentropy&#39;: 2.686399506378174}
Epoch metrics: {&#39;accuracy&#39;: 0.4234, &#39;crossentropy&#39;: 2.731360105895996}
Epoch 57: 0.4234 worse than 0.4286, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.4368, &#39;crossentropy&#39;: 2.6142911724090574}
Epoch metrics: {&#39;accuracy&#39;: 0.4238, &#39;crossentropy&#39;: 2.699748579788208}
Epoch 59: 0.4238 worse than 0.4368, patience: 1/3!
Epoch metrics: {&#39;accuracy&#39;: 0.4228, &#39;crossentropy&#39;: 2.831049083137512}
Epoch 60: 0.4228 worse than 0.4368, patience: 2/3!
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.005
    weight_decay: 0.0005
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model_optimizer</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">loader</span><span class="o">=</span><span class="n">test_loader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;accuracy&#39;: 0.5724, &#39;crossentropy&#39;: 3.0206112657546997}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>57.24% is better than Random acquisition in VAAL (Variational Adversarial Active Learning, <a href="https://arxiv.org/abs/1904.00370">https://arxiv.org/abs/1904.00370</a>) and also better than the reported CoreSet AL results: 50.5%?</p>
<hr>
<p>"Task-Aware Variational Adversarial Active Learning" (<a href="https://arxiv.org/abs/2002.04709">https://arxiv.org/abs/2002.04709</a>) reports much better numbers for Random on ResNet, however: 64%.</p>
<p>They state:</p>
<blockquote><p>ResNet18 [13] was used for all task learners and stochastic gradient descent (SGD) was used with momentum 0.9 and weight decay 0.005. Learning rate was 0.1 for the first 160 epochs and then 0.01 for the last 40 epochs.</p>
</blockquote>
<p>We leave this as a TODO.</p>

</div>
</div>
</div>
</div>
 

