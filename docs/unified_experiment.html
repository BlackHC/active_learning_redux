---

title: Unified Experiment Code


keywords: fastai
sidebar: home_sidebar

summary: "Resistance is futile."
description: "Resistance is futile."
nb_path: "08d_unified_experiment.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 08d_unified_experiment.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Appended /home/blackhc/PycharmProjects/bald-ical/src to paths
Switched to directory /home/blackhc/PycharmProjects/bald-ical
%load_ext autoreload
%autoreload 2
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Import modules and functions were are going to use.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">dataclasses</span>
<span class="kn">import</span> <span class="nn">traceback</span>
<span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Type</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.utils.data</span>
<span class="kn">from</span> <span class="nn">blackhc.project</span> <span class="kn">import</span> <span class="n">is_run_from_ipython</span>
<span class="kn">from</span> <span class="nn">blackhc.project.experiment</span> <span class="kn">import</span> <span class="n">embedded_experiments</span>

<span class="kn">import</span> <span class="nn">wandb</span>

<span class="kn">import</span> <span class="nn">batchbald_redux.acquisition_functions.batchbald</span>
<span class="kn">import</span> <span class="nn">batchbald_redux.acquisition_functions.epig</span>
<span class="kn">from</span> <span class="nn">batchbald_redux</span> <span class="kn">import</span> <span class="n">acquisition_functions</span><span class="p">,</span> <span class="n">baseline_acquisition_functions</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.acquisition_functions</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">CandidateBatchComputer</span><span class="p">,</span>
    <span class="n">EvalDatasetBatchComputer</span><span class="p">,</span>
    <span class="n">EvalModelBatchComputer</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.black_box_model_training</span> <span class="kn">import</span> <span class="n">evaluate</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.dataset_challenges</span> <span class="kn">import</span> <span class="n">get_base_dataset_index</span><span class="p">,</span> <span class="n">get_target</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.di</span> <span class="kn">import</span> <span class="n">DependencyInjection</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.experiment_data</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ExperimentData</span><span class="p">,</span>
    <span class="n">ExperimentDataConfig</span><span class="p">,</span>
    <span class="n">OoDDatasetConfig</span><span class="p">,</span>
    <span class="n">StandardExperimentDataConfig</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.experiment_logging</span> <span class="kn">import</span> <span class="n">init_wandb</span><span class="p">,</span> <span class="n">log2wandb</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.models</span> <span class="kn">import</span> <span class="n">MnistModelTrainer</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.resnet_models</span> <span class="kn">import</span> <span class="n">Cifar10ModelTrainer</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.train_eval_model</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">TrainEvalModel</span><span class="p">,</span>
    <span class="n">TrainSelfDistillationEvalModel</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.trained_model</span> <span class="kn">import</span> <span class="n">BayesianEnsembleModelTrainer</span><span class="p">,</span> <span class="n">ModelTrainer</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ActiveLearner" class="doc_header"><code>class</code> <code>ActiveLearner</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/unified_experiment.py#L49" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ActiveLearner</code>(<strong><code>acquisition_size</code></strong>:<code>int</code>, <strong><code>max_training_set</code></strong>:<code>int</code>, <strong><code>num_validation_samples</code></strong>:<code>int</code>, <strong><code>acquisition_function</code></strong>:<code>Union</code>[<code>CandidateBatchComputer</code>, <code>EvalModelBatchComputer</code>], <strong><code>train_eval_model</code></strong>:<code>TrainEvalModel</code>, <strong><code>model_trainer</code></strong>:<code>ModelTrainer</code>, <strong><code>data</code></strong>:<a href="/batchbald_redux/experiment_cifar10_xmi_labels_clean.html#ExperimentData"><code>ExperimentData</code></a>, <strong><code>disable_training_augmentations</code></strong>:<code>bool</code>, <strong><code>device</code></strong>:<code>Optional</code>)</p>
</blockquote>
<p>ActiveLearner(acquisition_size: int, max_training_set: int, num_validation_samples: int, acquisition_function: Union[batchbald_redux.acquisition_functions.candidate_batch_computers.CandidateBatchComputer, batchbald_redux.acquisition_functions.candidate_batch_computers.EvalModelBatchComputer], train_eval_model: batchbald_redux.train_eval_model.TrainEvalModel, model_trainer: batchbald_redux.trained_model.ModelTrainer, data: batchbald_redux.experiment_data.ExperimentData, disable_training_augmentations: bool, device: Optional)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="UnifiedExperiment" class="doc_header"><code>class</code> <code>UnifiedExperiment</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/unified_experiment.py#L219" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>UnifiedExperiment</code>(<strong><code>seed</code></strong>:<code>int</code>, <strong><code>experiment_data_config</code></strong>:<a href="/batchbald_redux/experiment_cifar10_xmi_labels_clean.html#ExperimentDataConfig"><code>ExperimentDataConfig</code></a>, <strong><code>acquisition_size</code></strong>:<code>int</code>=<em><code>5</code></em>, <strong><code>max_training_set</code></strong>:<code>int</code>=<em><code>200</code></em>, <strong><code>max_training_epochs</code></strong>:<code>int</code>=<em><code>300</code></em>, <strong><code>num_pool_samples</code></strong>:<code>int</code>=<em><code>100</code></em>, <strong><code>num_validation_samples</code></strong>:<code>int</code>=<em><code>20</code></em>, <strong><code>num_training_samples</code></strong>:<code>int</code>=<em><code>1</code></em>, <strong><code>device</code></strong>:<code>str</code>=<em><code>'cuda'</code></em>, <strong><code>acquisition_function</code></strong>:<code>Union</code>[<code>Type</code>[<code>CandidateBatchComputer</code>], <code>Type</code>[<code>EvalModelBatchComputer</code>]]=<em><code>None</code></em>, <strong><code>train_eval_model</code></strong>:<code>Type</code>[<code>TrainEvalModel</code>]=<em><code>TrainSelfDistillationEvalModel</code></em>, <strong><code>model_trainer_factory</code></strong>:<code>Type</code>[<code>ModelTrainer</code>]=<em><code>None</code></em>, <strong><code>ensemble_size</code></strong>:<code>int</code>=<em><code>1</code></em>, <strong><code>temperature</code></strong>:<code>float</code>=<em><code>1.0</code></em>, <strong><code>coldness</code></strong>:<code>float</code>=<em><code>1.0</code></em>, <strong><code>stochastic_mode</code></strong>:<code>StochasticMode</code>=<em><code>None</code></em>, <strong><code>epig_bootstrap_type</code></strong>:<code>BootstrapType</code>=<em><code>&lt;BootstrapType.NO_BOOTSTRAP: 0&gt;</code></em>, <strong><code>epig_bootstrap_factor</code></strong>:<code>float</code>=<em><code>1.0</code></em>, <strong><code>epig_dtype</code></strong>:<code>dtype</code>=<em><code>torch.float64</code></em>, <strong><code>disable_training_augmentations</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>cache_explicit_eval_model</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>resnet18_dropout_head</code></strong>:<code>bool</code>=<em><code>True</code></em>)</p>
</blockquote>
<p>UnifiedExperiment(seed: int, experiment_data_config: batchbald_redux.experiment_data.ExperimentDataConfig, acquisition_size: int = 5, max_training_set: int = 200, max_training_epochs: int = 300, num_pool_samples: int = 100, num_validation_samples: int = 20, num_training_samples: int = 1, device: str = 'cuda', acquisition_function: Union[Type[batchbald_redux.acquisition_functions.candidate_batch_computers.CandidateBatchComputer], Type[batchbald_redux.acquisition_functions.candidate_batch_computers.EvalModelBatchComputer]] = None, train_eval_model: Type[batchbald_redux.train_eval_model.TrainEvalModel] = &lt;class 'batchbald_redux.train_eval_model.TrainSelfDistillationEvalModel'&gt;, model_trainer_factory: Type[batchbald_redux.trained_model.ModelTrainer] = None, ensemble_size: int = 1, temperature: float = 1.0, coldness: float = 1.0, stochastic_mode: batchbald_redux.acquisition_functions.stochastic_acquisition.StochasticMode = None, epig_bootstrap_type: batchbald_redux.acquisition_functions.epig.BootstrapType = &lt;BootstrapType.NO_BOOTSTRAP: 0&gt;, epig_bootstrap_factor: float = 1.0, epig_dtype: torch.dtype = torch.float64, disable_training_augmentations: bool = False, cache_explicit_eval_model: bool = False, resnet18_dropout_head: bool = True)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">ActiveLearner</span><span class="p">:</span>
    <span class="n">acquisition_size</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">max_training_set</span><span class="p">:</span> <span class="nb">int</span>

    <span class="n">num_validation_samples</span><span class="p">:</span> <span class="nb">int</span>

    <span class="n">acquisition_function</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">CandidateBatchComputer</span><span class="p">,</span> <span class="n">EvalModelBatchComputer</span><span class="p">]</span>
    <span class="n">train_eval_model</span><span class="p">:</span> <span class="n">TrainEvalModel</span>
    <span class="n">model_trainer</span><span class="p">:</span> <span class="n">ModelTrainer</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">ExperimentData</span>

    <span class="n">disable_training_augmentations</span><span class="p">:</span> <span class="nb">bool</span>

    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log</span><span class="p">):</span>
        <span class="n">log</span><span class="p">[</span><span class="s2">&quot;seed&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">seed</span><span class="p">()</span>

        <span class="c1"># Active Learning setup</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span>

        <span class="n">train_augmentations</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">train_augmentations</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">disable_training_augmentations</span> <span class="k">else</span> <span class="kc">None</span>

        <span class="n">model_trainer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_trainer</span>
        <span class="n">train_eval_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_eval_model</span>

        <span class="n">train_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_train_dataloader</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">training_dataset</span><span class="p">)</span>
        <span class="n">pool_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_evaluation_dataloader</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">pool_dataset</span><span class="p">)</span>
        <span class="n">validation_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_evaluation_dataloader</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">validation_dataset</span><span class="p">)</span>
        <span class="n">test_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_evaluation_dataloader</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">test_dataset</span><span class="p">)</span>

        <span class="n">log</span><span class="p">[</span><span class="s2">&quot;active_learning_steps&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">active_learning_steps</span> <span class="o">=</span> <span class="n">log</span><span class="p">[</span><span class="s2">&quot;active_learning_steps&quot;</span><span class="p">]</span>

        <span class="n">acquisition_function</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">acquisition_function</span>

        <span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">max_iterations</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span>
            <span class="mf">1.5</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_training_set</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">training_dataset</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">acquisition_size</span>
        <span class="p">)</span>

        <span class="c1"># Active Training Loop</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">training_set_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">training_dataset</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training set size </span><span class="si">{</span><span class="n">training_set_size</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>

            <span class="c1"># iteration_log = dict(training={}, pool_training={}, evaluation_metrics=None, acquisition=None)</span>
            <span class="n">active_learning_steps</span><span class="o">.</span><span class="n">append</span><span class="p">({})</span>
            <span class="n">iteration_log</span> <span class="o">=</span> <span class="n">active_learning_steps</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

            <span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;training&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

            <span class="c1"># TODO: this is a hack! :(</span>
            <span class="k">if</span> <span class="n">data</span><span class="o">.</span><span class="n">ood_dataset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">validation_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
            <span class="k">elif</span> <span class="n">data</span><span class="o">.</span><span class="n">ood_exposure</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">KLDivLoss</span><span class="p">(</span><span class="n">log_target</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;batchmean&quot;</span><span class="p">)</span>
                <span class="n">validation_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">validation_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>

            <span class="n">trained_model</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_trained</span><span class="p">(</span>
                <span class="n">train_loader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span>
                <span class="n">train_augmentations</span><span class="o">=</span><span class="n">train_augmentations</span><span class="p">,</span>
                <span class="n">validation_loader</span><span class="o">=</span><span class="n">validation_loader</span><span class="p">,</span>
                <span class="n">log</span><span class="o">=</span><span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;training&quot;</span><span class="p">],</span>
                <span class="n">wandb_key_path</span><span class="o">=</span><span class="s2">&quot;model_training&quot;</span><span class="p">,</span>
                <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
                <span class="n">validation_loss</span><span class="o">=</span><span class="n">validation_loss</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">evaluation_metrics</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">trained_model</span><span class="p">,</span>
                <span class="n">num_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_validation_samples</span><span class="p">,</span>
                <span class="n">loader</span><span class="o">=</span><span class="n">test_loader</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="n">storage_device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;evaluation_metrics&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">evaluation_metrics</span>
            <span class="n">log2wandb</span><span class="p">(</span><span class="n">evaluation_metrics</span><span class="p">,</span> <span class="n">commit</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Perf after training </span><span class="si">{</span><span class="n">evaluation_metrics</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">training_set_size</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_training_set</span> <span class="ow">or</span> <span class="n">num_iterations</span> <span class="o">&gt;=</span> <span class="n">max_iterations</span><span class="p">:</span>
                <span class="n">log2wandb</span><span class="p">({},</span> <span class="n">commit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Done.&quot;</span><span class="p">)</span>
                <span class="k">break</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">acquisition_function</span><span class="p">,</span> <span class="n">CandidateBatchComputer</span><span class="p">):</span>
                <span class="n">candidate_batch</span> <span class="o">=</span> <span class="n">acquisition_function</span><span class="o">.</span><span class="n">compute_candidate_batch</span><span class="p">(</span><span class="n">trained_model</span><span class="p">,</span> <span class="n">pool_loader</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">acquisition_function</span><span class="p">,</span> <span class="n">EvalDatasetBatchComputer</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">evaluation_dataset</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">eval_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_evaluation_dataloader</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">evaluation_dataset</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">eval_loader</span> <span class="o">=</span> <span class="n">pool_loader</span>

                <span class="n">candidate_batch</span> <span class="o">=</span> <span class="n">acquisition_function</span><span class="o">.</span><span class="n">compute_candidate_batch</span><span class="p">(</span>
                    <span class="n">model</span><span class="o">=</span><span class="n">trained_model</span><span class="p">,</span> <span class="n">pool_loader</span><span class="o">=</span><span class="n">pool_loader</span><span class="p">,</span> <span class="n">eval_loader</span><span class="o">=</span><span class="n">eval_loader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">acquisition_function</span><span class="p">,</span> <span class="n">EvalModelBatchComputer</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">evaluation_dataset</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">evaluation_dataset</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">pool_dataset</span>

                <span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;eval_training&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="n">trained_eval_model</span> <span class="o">=</span> <span class="n">train_eval_model</span><span class="p">(</span>
                    <span class="n">model_trainer</span><span class="o">=</span><span class="n">model_trainer</span><span class="p">,</span>
                    <span class="n">training_dataset</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">training_dataset</span><span class="p">,</span>
                    <span class="n">train_augmentations</span><span class="o">=</span><span class="n">train_augmentations</span><span class="p">,</span>
                    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">eval_dataset</span><span class="p">,</span>
                    <span class="n">validation_loader</span><span class="o">=</span><span class="n">validation_loader</span><span class="p">,</span>
                    <span class="n">trained_model</span><span class="o">=</span><span class="n">trained_model</span><span class="p">,</span>
                    <span class="n">storage_device</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                    <span class="n">training_log</span><span class="o">=</span><span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;eval_training&quot;</span><span class="p">],</span>
                    <span class="n">wandb_key_path</span><span class="o">=</span><span class="s2">&quot;eval_model_training&quot;</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="n">candidate_batch</span> <span class="o">=</span> <span class="n">acquisition_function</span><span class="o">.</span><span class="n">compute_candidate_batch</span><span class="p">(</span>
                    <span class="n">trained_model</span><span class="p">,</span> <span class="n">trained_eval_model</span><span class="p">,</span> <span class="n">pool_loader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown acquisition function </span><span class="si">{</span><span class="n">acquisition_function</span><span class="si">}</span><span class="s2">!&quot;</span><span class="p">)</span>

            <span class="n">candidate_global_dataset_indices</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">candidate_labels</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">candidate_images</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">candidate_batch</span><span class="o">.</span><span class="n">indices</span><span class="p">:</span>
                <span class="n">base_di</span> <span class="o">=</span> <span class="n">get_base_dataset_index</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">pool_dataset</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span>
                <span class="n">dataset_type</span> <span class="o">=</span> <span class="s2">&quot;ood&quot;</span> <span class="k">if</span> <span class="n">base_di</span><span class="o">.</span><span class="n">dataset</span> <span class="o">==</span> <span class="n">data</span><span class="o">.</span><span class="n">ood_dataset</span> <span class="k">else</span> <span class="s2">&quot;id&quot;</span>
                <span class="n">candidate_global_dataset_indices</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">dataset_type</span><span class="p">,</span> <span class="n">base_di</span><span class="o">.</span><span class="n">index</span><span class="p">))</span>
                <span class="k">if</span> <span class="n">dataset_type</span> <span class="o">==</span> <span class="s2">&quot;id&quot;</span><span class="p">:</span>
                    <span class="n">label</span> <span class="o">=</span> <span class="n">get_target</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">pool_dataset</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">label</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="n">candidate_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
                <span class="n">candidate_images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">wandb</span><span class="o">.</span><span class="n">Image</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">pool_dataset</span><span class="p">[</span><span class="n">index</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span>

            <span class="n">acquisition_info</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
                <span class="n">indices</span><span class="o">=</span><span class="n">candidate_global_dataset_indices</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">candidate_labels</span><span class="p">,</span> <span class="n">scores</span><span class="o">=</span><span class="n">candidate_batch</span><span class="o">.</span><span class="n">scores</span>
            <span class="p">)</span>
            <span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;acquisition&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">acquisition_info</span>

            <span class="n">acquistion_batch_table</span> <span class="o">=</span> <span class="n">wandb</span><span class="o">.</span><span class="n">Table</span><span class="p">(</span>
                <span class="n">data</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">candidate_global_dataset_indices</span><span class="p">),</span> <span class="n">candidate_images</span><span class="p">,</span> <span class="n">candidate_labels</span><span class="p">,</span> <span class="n">candidate_batch</span><span class="o">.</span><span class="n">scores</span><span class="p">)),</span>
                <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;dataset&quot;</span><span class="p">,</span> <span class="s2">&quot;index&quot;</span><span class="p">,</span> <span class="s2">&quot;sample&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">,</span> <span class="s2">&quot;score&quot;</span><span class="p">])</span>
            <span class="n">log2wandb</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">acquisition</span><span class="o">=</span><span class="n">acquistion_batch_table</span><span class="p">),</span> <span class="n">commit</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="nb">print</span><span class="p">(</span><span class="n">candidate_batch</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">candidate_global_dataset_indices</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">data</span><span class="o">.</span><span class="n">ood_dataset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">acquire</span><span class="p">(</span><span class="n">candidate_batch</span><span class="o">.</span><span class="n">indices</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">data</span><span class="o">.</span><span class="n">ood_exposure</span><span class="p">:</span>
                <span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">acquire</span><span class="p">(</span><span class="n">candidate_batch</span><span class="o">.</span><span class="n">indices</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">acquire</span><span class="p">(</span>
                    <span class="p">[</span><span class="n">index</span> <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">candidate_batch</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">candidate_labels</span><span class="p">)</span> <span class="k">if</span> <span class="n">label</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="p">)</span>

            <span class="n">ls</span> <span class="o">=</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">score</span><span class="si">:</span><span class="s2">.4</span><span class="si">}</span><span class="s2">)&quot;</span> <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">candidate_labels</span><span class="p">,</span> <span class="n">candidate_batch</span><span class="o">.</span><span class="n">scores</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Acquiring (label, score)s: </span><span class="si">{</span><span class="n">ls</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="n">num_iterations</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">log2wandb</span><span class="p">({},</span> <span class="n">commit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>




<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">UnifiedExperiment</span><span class="p">:</span>
    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span>

    <span class="n">experiment_data_config</span><span class="p">:</span> <span class="n">ExperimentDataConfig</span>

    <span class="n">acquisition_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">max_training_set</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">200</span>

    <span class="n">max_training_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">300</span>

    <span class="n">num_pool_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">num_validation_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="n">num_training_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span>
    <span class="n">acquisition_function</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
        <span class="n">Type</span><span class="p">[</span><span class="n">CandidateBatchComputer</span><span class="p">],</span> <span class="n">Type</span><span class="p">[</span><span class="n">EvalModelBatchComputer</span><span class="p">]</span>
    <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># acquisition_functions.BALD</span>
    <span class="n">train_eval_model</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">TrainEvalModel</span><span class="p">]</span> <span class="o">=</span> <span class="n">TrainSelfDistillationEvalModel</span>
    <span class="n">model_trainer_factory</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">ModelTrainer</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Cifar10ModelTrainer</span>
    <span class="n">ensemble_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">coldness</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">stochastic_mode</span><span class="p">:</span> <span class="n">acquisition_functions</span><span class="o">.</span><span class="n">StochasticMode</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">epig_bootstrap_type</span><span class="p">:</span> <span class="n">acquisition_functions</span><span class="o">.</span><span class="n">BootstrapType</span> <span class="o">=</span> <span class="n">acquisition_functions</span><span class="o">.</span><span class="n">BootstrapType</span><span class="o">.</span><span class="n">NO_BOOTSTRAP</span>
    <span class="n">epig_bootstrap_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">epig_dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">double</span>
    <span class="n">disable_training_augmentations</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">cache_explicit_eval_model</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">resnet18_dropout_head</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">load_experiment_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ExperimentData</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">experiment_data_config</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">experiment_data_config</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Simple Dependency Injection</span>
    <span class="k">def</span> <span class="nf">create_acquisition_function</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">di</span> <span class="o">=</span> <span class="n">DependencyInjection</span><span class="p">(</span><span class="nb">vars</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">di</span><span class="o">.</span><span class="n">create_dataclass_type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">acquisition_function</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">create_train_eval_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TrainEvalModel</span><span class="p">:</span>
        <span class="n">di</span> <span class="o">=</span> <span class="n">DependencyInjection</span><span class="p">(</span><span class="nb">vars</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">di</span><span class="o">.</span><span class="n">create_dataclass_type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_eval_model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">create_model_trainer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelTrainer</span><span class="p">:</span>
        <span class="n">di</span> <span class="o">=</span> <span class="n">DependencyInjection</span><span class="p">(</span><span class="nb">vars</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">di</span><span class="o">.</span><span class="n">create_dataclass_type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_trainer_factory</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">store</span><span class="p">,</span> <span class="n">project</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">entity</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">init_wandb</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">project</span><span class="o">=</span><span class="n">project</span><span class="p">,</span> <span class="n">entity</span><span class="o">=</span><span class="n">entity</span><span class="p">)</span>

        <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

        <span class="c1"># Active Learning setup</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_experiment_data</span><span class="p">()</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;dataset_info&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">training</span><span class="o">=</span><span class="nb">repr</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">base_dataset</span><span class="p">),</span> <span class="n">test</span><span class="o">=</span><span class="nb">repr</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">test_dataset</span><span class="p">))</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;initial_training_set_indices&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">initial_training_set_indices</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;evaluation_set_indices&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">evaluation_set_indices</span>

        <span class="nb">print</span><span class="p">(</span><span class="n">wandb</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>

        <span class="n">wandb</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">initial_training_set_indices</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">initial_training_set_indices</span>
        <span class="n">wandb</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">evaluation_set_indices</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">evaluation_set_indices</span>
        <span class="n">wandb</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;dataset_info&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">store</span><span class="p">[</span><span class="s2">&quot;dataset_info&quot;</span><span class="p">]</span>

        <span class="n">acquisition_function</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_acquisition_function</span><span class="p">()</span>
        <span class="n">model_trainer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_model_trainer</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ensemble_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">model_trainer</span> <span class="o">=</span> <span class="n">BayesianEnsembleModelTrainer</span><span class="p">(</span><span class="n">model_trainer</span><span class="o">=</span><span class="n">model_trainer</span><span class="p">,</span> <span class="n">ensemble_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ensemble_size</span><span class="p">)</span>
        <span class="n">train_eval_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_train_eval_model</span><span class="p">()</span>

        <span class="n">active_learner</span> <span class="o">=</span> <span class="n">ActiveLearner</span><span class="p">(</span>
            <span class="n">acquisition_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">acquisition_size</span><span class="p">,</span>
            <span class="n">max_training_set</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_training_set</span><span class="p">,</span>
            <span class="n">num_validation_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_validation_samples</span><span class="p">,</span>
            <span class="n">disable_training_augmentations</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">disable_training_augmentations</span><span class="p">,</span>
            <span class="n">acquisition_function</span><span class="o">=</span><span class="n">acquisition_function</span><span class="p">,</span>
            <span class="n">train_eval_model</span><span class="o">=</span><span class="n">train_eval_model</span><span class="p">,</span>
            <span class="n">model_trainer</span><span class="o">=</span><span class="n">model_trainer</span><span class="p">,</span>
            <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">active_learner</span><span class="p">(</span><span class="n">store</span><span class="p">)</span>

        <span class="n">wandb</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="CIFAR-10-vs-SVHN-Coverage">CIFAR-10 vs SVHN Coverage<a class="anchor-link" href="#CIFAR-10-vs-SVHN-Coverage"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># OOD experiment (ood_exposure=True)</span>

<span class="n">experiment</span> <span class="o">=</span> <span class="n">UnifiedExperiment</span><span class="p">(</span>
    <span class="n">experiment_data_config</span><span class="o">=</span><span class="n">StandardExperimentDataConfig</span><span class="p">(</span>
        <span class="n">id_dataset_name</span><span class="o">=</span><span class="s2">&quot;CIFAR-10&quot;</span><span class="p">,</span>
        <span class="n">id_repetitions</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">initial_training_set_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">validation_set_size</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span>
        <span class="n">validation_split_random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">evaluation_set_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">add_dataset_noise</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">ood_dataset_config</span><span class="o">=</span><span class="n">OoDDatasetConfig</span><span class="p">(</span><span class="n">ood_dataset_name</span><span class="o">=</span><span class="s2">&quot;SVHN&quot;</span><span class="p">,</span> <span class="n">ood_repetitions</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ood_exposure</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="p">),</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">max_training_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">max_training_set</span><span class="o">=</span><span class="mi">20</span> <span class="o">+</span> <span class="mi">40</span><span class="p">,</span>
    <span class="n">acquisition_function</span><span class="o">=</span><span class="n">acquisition_functions</span><span class="o">.</span><span class="n">EvalBALD</span><span class="p">,</span>
    <span class="n">acquisition_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">num_pool_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span>
    <span class="n">model_trainer_factory</span><span class="o">=</span><span class="n">Cifar10ModelTrainer</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">experiment</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
<span class="n">results</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
Finishing last run (ID:aku693l3) before initializing another...
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
Waiting for W&B process to finish... <strong style="color:green">(success).</strong>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<style>
    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }
    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }
    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }
    </style>
<div class="wandb-row"><div class="wandb-col"><h3>Run history:</h3><br/><table class="wandb"><tr><td>accuracy</td><td></td></tr><tr><td>crossentropy</td><td></td></tr></table><br/></div><div class="wandb-col"><h3>Run summary:</h3><br/><table class="wandb"><tr><td>accuracy</td><td>0.1347</td></tr><tr><td>crossentropy</td><td>2.82898</td></tr></table><br/></div></div>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
Synced <strong style="color:#cdcd00">warm-frog-29</strong>: <a href="https://wandb.ai/oatml-andreas-kirsch/balds/runs/aku693l3" target="_blank">https://wandb.ai/oatml-andreas-kirsch/balds/runs/aku693l3</a><br/>Synced 7 W&B file(s), 2 media file(s), 2 artifact file(s) and 1 other file(s)
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
Find logs at: <code>./wandb/run-20220329_233637-aku693l3/logs</code>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
Successfully finished last run (ID:aku693l3). Initializing new run:<br/>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
Tracking run with wandb version 0.12.11
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
Run data is saved locally in <code>/home/blackhc/PycharmProjects/bald-ical/wandb/run-20220329_234126-1ypey12i</code>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
Syncing run <strong><a href="https://wandb.ai/oatml-andreas-kirsch/balds/runs/1ypey12i" target="_blank">logical-sky-30</a></strong> to <a href="https://wandb.ai/oatml-andreas-kirsch/balds" target="_blank">Weights & Biases</a> (<a href="https://wandb.me/run" target="_blank">docs</a>)<br/>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>StandardExperimentDataConfig(id_dataset_name=&#39;CIFAR-10&#39;, id_repetitions=1, initial_training_set_size=20, validation_set_size=4096, validation_split_random_state=0, evaluation_set_size=100, add_dataset_noise=False, ood_dataset_config=OoDDatasetConfig(ood_dataset_name=&#39;SVHN&#39;, ood_repetitions=1, ood_exposure=True))
Files already downloaded and verified
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  return floored.astype(np.int)
/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  return floored.astype(np.int)
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Files already downloaded and verified
Using downloaded and verified file: data/SVHN/train_32x32.mat
Using downloaded and verified file: data/SVHN/test_32x32.mat
Creating: EvalBALD(
	acquisition_size=10,
	num_pool_samples=2
)
Creating: Cifar10ModelTrainer(
	device=cuda,
	num_training_samples=1,
	num_validation_samples=20,
	max_training_epochs=1,
	resnet18_dropout_head=True
)
Creating: TrainSelfDistillationEvalModel(
	num_pool_samples=2
)
Training set size 20:
Cosine Annealing
Epoch 1 metrics: {&#39;accuracy&#39;: 0.154541015625, &#39;crossentropy&#39;: 2.862379550933838}
{&#39;model_training/val_metrics&#39;: &lt;wandb.data_types.Table object at 0x7f0799f11f10&gt;}
Perf after training {&#39;accuracy&#39;: 0.1541, &#39;crossentropy&#39;: tensor(3.0044), &#39;_timestamp&#39;: 1648593712, &#39;_runtime&#39;: 22}
Cosine Annealing
Epoch 1 metrics: {&#39;accuracy&#39;: 0.1435546875, &#39;crossentropy&#39;: 3.026398181915283}
{&#39;eval_model_training/val_metrics&#39;: &lt;wandb.data_types.Table object at 0x7f07c177c580&gt;}
CandidateBatch(scores=[0.3816788122930761, 0.3317175225401599, 0.32684077470870476, 0.3212715738959917, 0.3033749222400953, 0.29973815835430556, 0.26754721437207163, 0.24061902113350073, 0.2403405246164286, 0.23710088041350744], indices=[21310, 21661, 44743, 38475, 20607, 44277, 12902, 21346, 1781, 21758])
[(&#39;id&#39;, 21368), (&#39;id&#39;, 21721), (&#39;id&#39;, 44862), (&#39;id&#39;, 38577), (&#39;id&#39;, 20663), (&#39;id&#39;, 44396), (&#39;id&#39;, 12939), (&#39;id&#39;, 21404), (&#39;id&#39;, 1785), (&#39;id&#39;, 21818)]
Acquiring (label, score)s: [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.3817), [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.3317), [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.3268), [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0] (0.3213), [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.3034), [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.2997), [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.2675), [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.2406), [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.2403), [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.2371)
Training set size 30:
Cosine Annealing
Epoch 1 metrics: {&#39;accuracy&#39;: 0.119873046875, &#39;crossentropy&#39;: 4.216228008270264}
{&#39;model_training/val_metrics&#39;: &lt;wandb.data_types.Table object at 0x7f07c1d5c6a0&gt;}
Perf after training {&#39;accuracy&#39;: 0.1222, &#39;crossentropy&#39;: tensor(4.1356), &#39;_timestamp&#39;: 1648593769, &#39;_runtime&#39;: 79}
Cosine Annealing
Epoch 1 metrics: {&#39;accuracy&#39;: 0.109130859375, &#39;crossentropy&#39;: 3.500084400177002}
{&#39;eval_model_training/val_metrics&#39;: &lt;wandb.data_types.Table object at 0x7f07c1caf7c0&gt;}
CandidateBatch(scores=[0.21867522846637125, 0.2101063854798288, 0.20666524736882375, 0.20331715117299004, 0.19524105010430692, 0.19418641012215432, 0.19253779516748343, 0.19150922932782832, 0.19143859141716066, 0.19138801446643264], indices=[24722, 25481, 27799, 28859, 42953, 113588, 7257, 39606, 26323, 33047])
[(&#39;id&#39;, 24796), (&#39;id&#39;, 25556), (&#39;id&#39;, 27881), (&#39;id&#39;, 28945), (&#39;id&#39;, 43075), (&#39;ood&#39;, 67814), (&#39;id&#39;, 7277), (&#39;id&#39;, 39719), (&#39;id&#39;, 26401), (&#39;id&#39;, 33145)]
Acquiring (label, score)s: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.2187), [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.2101), [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.2067), [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0] (0.2033), [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0] (0.1952), None (0.1942), [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.1925), [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0] (0.1915), [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.1914), [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.1914)
Training set size 40:
Cosine Annealing
Epoch 1 metrics: {&#39;accuracy&#39;: 0.133544921875, &#39;crossentropy&#39;: 2.502493143081665}
{&#39;model_training/val_metrics&#39;: &lt;wandb.data_types.Table object at 0x7f07c1b290a0&gt;}
Perf after training {&#39;accuracy&#39;: 0.1381, &#39;crossentropy&#39;: tensor(2.5190), &#39;_timestamp&#39;: 1648593827, &#39;_runtime&#39;: 137}
Cosine Annealing
Epoch 1 metrics: {&#39;accuracy&#39;: 0.1201171875, &#39;crossentropy&#39;: 2.577338695526123}
{&#39;eval_model_training/val_metrics&#39;: &lt;wandb.data_types.Table object at 0x7f079a370790&gt;}
CandidateBatch(scores=[0.09172990652392099, 0.08829474870894338, 0.0863878269997842, 0.08142393182192453, 0.08050506704075877, 0.07990204524133615, 0.07874156879792693, 0.07829794974283999, 0.07769372730451463, 0.07690283872905357], indices=[42208, 25572, 834, 13411, 20428, 3284, 116509, 4580, 30359, 28842])
[(&#39;id&#39;, 42337), (&#39;id&#39;, 25650), (&#39;id&#39;, 837), (&#39;id&#39;, 13455), (&#39;id&#39;, 20486), (&#39;id&#39;, 3292), (&#39;ood&#39;, 70745), (&#39;id&#39;, 4592), (&#39;id&#39;, 30457), (&#39;id&#39;, 28933)]
Acquiring (label, score)s: [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.09173), [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.08829), [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.08639), [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0] (0.08142), [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.08051), [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.0799), None (0.07874), [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.0783), [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.07769), [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.0769)
Training set size 50:
Cosine Annealing
Epoch 1 metrics: {&#39;accuracy&#39;: 0.133544921875, &#39;crossentropy&#39;: 2.488408327102661}
{&#39;model_training/val_metrics&#39;: &lt;wandb.data_types.Table object at 0x7f079a28d700&gt;}
Perf after training {&#39;accuracy&#39;: 0.1417, &#39;crossentropy&#39;: tensor(2.5165), &#39;_timestamp&#39;: 1648593884, &#39;_runtime&#39;: 194}
Cosine Annealing
Epoch 1 metrics: {&#39;accuracy&#39;: 0.1298828125, &#39;crossentropy&#39;: 2.4977221488952637}
{&#39;eval_model_training/val_metrics&#39;: &lt;wandb.data_types.Table object at 0x7f07c1c3d040&gt;}
CandidateBatch(scores=[0.08591357444346825, 0.08356831646563201, 0.08232351005987715, 0.08211691012048217, 0.07984823655790785, 0.07167130397536559, 0.07004597462415396, 0.06785446123492345, 0.06612761906994691, 0.06589297521912707], indices=[27564, 3406, 36502, 18037, 11208, 37065, 17467, 2437, 2524, 28375])
[(&#39;id&#39;, 27655), (&#39;id&#39;, 3416), (&#39;id&#39;, 36619), (&#39;id&#39;, 18093), (&#39;id&#39;, 11244), (&#39;id&#39;, 37186), (&#39;id&#39;, 17521), (&#39;id&#39;, 2445), (&#39;id&#39;, 2532), (&#39;id&#39;, 28470)]
Acquiring (label, score)s: [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.08591), [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0] (0.08357), [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.08232), [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.08212), [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0] (0.07985), [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0] (0.07167), [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0] (0.07005), [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.06785), [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.06613), [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.06589)
Training set size 60:
Cosine Annealing
Epoch 1 metrics: {&#39;accuracy&#39;: 0.139892578125, &#39;crossentropy&#39;: 2.311521530151367}
{&#39;model_training/val_metrics&#39;: &lt;wandb.data_types.Table object at 0x7f079a1d9e80&gt;}
Perf after training {&#39;accuracy&#39;: 0.1407, &#39;crossentropy&#39;: tensor(2.3343), &#39;_timestamp&#39;: 1648593941, &#39;_runtime&#39;: 251}
Done.

</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
Waiting for W&B process to finish... <strong style="color:green">(success).</strong>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<style>
    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }
    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }
    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }
    </style>
<div class="wandb-row"><div class="wandb-col"><h3>Run history:</h3><br/><table class="wandb"><tr><td>accuracy</td><td></td></tr><tr><td>crossentropy</td><td></td></tr></table><br/></div><div class="wandb-col"><h3>Run summary:</h3><br/><table class="wandb"><tr><td>accuracy</td><td>0.1407</td></tr><tr><td>crossentropy</td><td>2.33432</td></tr></table><br/></div></div>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
Synced <strong style="color:#cdcd00">logical-sky-30</strong>: <a href="https://wandb.ai/oatml-andreas-kirsch/balds/runs/1ypey12i" target="_blank">https://wandb.ai/oatml-andreas-kirsch/balds/runs/1ypey12i</a><br/>Synced 7 W&B file(s), 13 media file(s), 53 artifact file(s) and 2 other file(s)
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
Find logs at: <code>./wandb/run-20220329_234126-1ypey12i/logs</code>
</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;dataset_info&#39;: {&#39;training&#39;: &#34;&#39;CIFAR-10 (Train, seed=0, 45904 samples)&#39; | one_hot_targets{&#39;num_classes&#39;: 10} + &#39;SVHN (Train, seed=0, 73257 samples)&#39; | uniform_targets{&#39;num_classes&#39;: 10}&#34;,
  &#39;test&#39;: &#34;&#39;CIFAR-10 (Test)&#39;&#34;},
 &#39;initial_training_set_indices&#39;: [29863,
  22519,
  21079,
  37521,
  15583,
  23405,
  44362,
  35084,
  29380,
  26994,
  39909,
  29333,
  527,
  31668,
  43591,
  12293,
  39247,
  36879,
  7979,
  33280],
 &#39;evaluation_set_indices&#39;: [4291,
  37709,
  11949,
  12149,
  17798,
  32245,
  235,
  38778,
  32864,
  39123,
  22797,
  43486,
  5813,
  40306,
  4570,
  15667,
  36937,
  25830,
  2404,
  30096,
  19730,
  11343,
  17034,
  43455,
  15770,
  7894,
  36848,
  11067,
  12968,
  29454,
  33432,
  21672,
  38040,
  259,
  29571,
  41639,
  43971,
  13338,
  42364,
  11109,
  18814,
  21474,
  10681,
  40169,
  9997,
  12784,
  22626,
  36949,
  33130,
  13688,
  6466,
  28263,
  45060,
  10422,
  7005,
  3143,
  26143,
  28581,
  13207,
  10038,
  6750,
  21221,
  9097,
  26989,
  26153,
  13087,
  28498,
  39840,
  26870,
  24298,
  24804,
  28038,
  17767,
  31439,
  1247,
  2171,
  6804,
  5126,
  42102,
  11902,
  27726,
  34553,
  8995,
  23268,
  42247,
  40748,
  4329,
  18148,
  33008,
  18855,
  4043,
  6625,
  15957,
  19208,
  23415,
  19554,
  7878,
  20565,
  7036,
  8754],
 &#39;seed&#39;: 15600026805985405365,
 &#39;active_learning_steps&#39;: [{&#39;training&#39;: {&#39;epochs&#39;: [{&#39;accuracy&#39;: 0.154541015625,
      &#39;crossentropy&#39;: 2.862379550933838}]},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.1541,
    &#39;crossentropy&#39;: tensor(3.0044),
    &#39;_timestamp&#39;: 1648593712,
    &#39;_runtime&#39;: 22},
   &#39;eval_training&#39;: {&#39;epochs&#39;: [{&#39;accuracy&#39;: 0.1435546875,
      &#39;crossentropy&#39;: 3.026398181915283}]},
   &#39;acquisition&#39;: {&#39;indices&#39;: [(&#39;id&#39;, 21368),
     (&#39;id&#39;, 21721),
     (&#39;id&#39;, 44862),
     (&#39;id&#39;, 38577),
     (&#39;id&#39;, 20663),
     (&#39;id&#39;, 44396),
     (&#39;id&#39;, 12939),
     (&#39;id&#39;, 21404),
     (&#39;id&#39;, 1785),
     (&#39;id&#39;, 21818)],
    &#39;labels&#39;: [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],
     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]],
    &#39;scores&#39;: [0.3816788122930761,
     0.3317175225401599,
     0.32684077470870476,
     0.3212715738959917,
     0.3033749222400953,
     0.29973815835430556,
     0.26754721437207163,
     0.24061902113350073,
     0.2403405246164286,
     0.23710088041350744]}},
  {&#39;training&#39;: {&#39;epochs&#39;: [{&#39;accuracy&#39;: 0.119873046875,
      &#39;crossentropy&#39;: 4.216228008270264}]},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.1222,
    &#39;crossentropy&#39;: tensor(4.1356),
    &#39;_timestamp&#39;: 1648593769,
    &#39;_runtime&#39;: 79},
   &#39;eval_training&#39;: {&#39;epochs&#39;: [{&#39;accuracy&#39;: 0.109130859375,
      &#39;crossentropy&#39;: 3.500084400177002}]},
   &#39;acquisition&#39;: {&#39;indices&#39;: [(&#39;id&#39;, 24796),
     (&#39;id&#39;, 25556),
     (&#39;id&#39;, 27881),
     (&#39;id&#39;, 28945),
     (&#39;id&#39;, 43075),
     (&#39;ood&#39;, 67814),
     (&#39;id&#39;, 7277),
     (&#39;id&#39;, 39719),
     (&#39;id&#39;, 26401),
     (&#39;id&#39;, 33145)],
    &#39;labels&#39;: [[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],
     [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0],
     None,
     [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],
     [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]],
    &#39;scores&#39;: [0.21867522846637125,
     0.2101063854798288,
     0.20666524736882375,
     0.20331715117299004,
     0.19524105010430692,
     0.19418641012215432,
     0.19253779516748343,
     0.19150922932782832,
     0.19143859141716066,
     0.19138801446643264]}},
  {&#39;training&#39;: {&#39;epochs&#39;: [{&#39;accuracy&#39;: 0.133544921875,
      &#39;crossentropy&#39;: 2.502493143081665}]},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.1381,
    &#39;crossentropy&#39;: tensor(2.5190),
    &#39;_timestamp&#39;: 1648593827,
    &#39;_runtime&#39;: 137},
   &#39;eval_training&#39;: {&#39;epochs&#39;: [{&#39;accuracy&#39;: 0.1201171875,
      &#39;crossentropy&#39;: 2.577338695526123}]},
   &#39;acquisition&#39;: {&#39;indices&#39;: [(&#39;id&#39;, 42337),
     (&#39;id&#39;, 25650),
     (&#39;id&#39;, 837),
     (&#39;id&#39;, 13455),
     (&#39;id&#39;, 20486),
     (&#39;id&#39;, 3292),
     (&#39;ood&#39;, 70745),
     (&#39;id&#39;, 4592),
     (&#39;id&#39;, 30457),
     (&#39;id&#39;, 28933)],
    &#39;labels&#39;: [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],
     [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     None,
     [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]],
    &#39;scores&#39;: [0.09172990652392099,
     0.08829474870894338,
     0.0863878269997842,
     0.08142393182192453,
     0.08050506704075877,
     0.07990204524133615,
     0.07874156879792693,
     0.07829794974283999,
     0.07769372730451463,
     0.07690283872905357]}},
  {&#39;training&#39;: {&#39;epochs&#39;: [{&#39;accuracy&#39;: 0.133544921875,
      &#39;crossentropy&#39;: 2.488408327102661}]},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.1417,
    &#39;crossentropy&#39;: tensor(2.5165),
    &#39;_timestamp&#39;: 1648593884,
    &#39;_runtime&#39;: 194},
   &#39;eval_training&#39;: {&#39;epochs&#39;: [{&#39;accuracy&#39;: 0.1298828125,
      &#39;crossentropy&#39;: 2.4977221488952637}]},
   &#39;acquisition&#39;: {&#39;indices&#39;: [(&#39;id&#39;, 27655),
     (&#39;id&#39;, 3416),
     (&#39;id&#39;, 36619),
     (&#39;id&#39;, 18093),
     (&#39;id&#39;, 11244),
     (&#39;id&#39;, 37186),
     (&#39;id&#39;, 17521),
     (&#39;id&#39;, 2445),
     (&#39;id&#39;, 2532),
     (&#39;id&#39;, 28470)],
    &#39;labels&#39;: [[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],
     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],
     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],
     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],
     [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]],
    &#39;scores&#39;: [0.08591357444346825,
     0.08356831646563201,
     0.08232351005987715,
     0.08211691012048217,
     0.07984823655790785,
     0.07167130397536559,
     0.07004597462415396,
     0.06785446123492345,
     0.06612761906994691,
     0.06589297521912707]}},
  {&#39;training&#39;: {&#39;epochs&#39;: [{&#39;accuracy&#39;: 0.139892578125,
      &#39;crossentropy&#39;: 2.311521530151367}]},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.1407,
    &#39;crossentropy&#39;: tensor(2.3343),
    &#39;_timestamp&#39;: 1648593941,
    &#39;_runtime&#39;: 251}}]}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># OOD experiment (ood_exposure=False)</span>

<span class="n">experiment</span> <span class="o">=</span> <span class="n">UnifiedExperiment</span><span class="p">(</span>
    <span class="n">experiment_data_config</span><span class="o">=</span><span class="n">StandardExperimentDataConfig</span><span class="p">(</span>
        <span class="n">id_dataset_name</span><span class="o">=</span><span class="s2">&quot;CIFAR-10&quot;</span><span class="p">,</span>
        <span class="n">id_repetitions</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">initial_training_set_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">validation_set_size</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span>
        <span class="n">validation_split_random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">evaluation_set_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">add_dataset_noise</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">ood_dataset_config</span><span class="o">=</span><span class="n">OoDDatasetConfig</span><span class="p">(</span><span class="n">ood_dataset_name</span><span class="o">=</span><span class="s2">&quot;SVHN&quot;</span><span class="p">,</span> <span class="n">ood_repetitions</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ood_exposure</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
    <span class="p">),</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">max_training_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">max_training_set</span><span class="o">=</span><span class="mi">20</span> <span class="o">+</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">acquisition_function</span><span class="o">=</span><span class="n">acquisition_functions</span><span class="o">.</span><span class="n">EvalBALD</span><span class="p">,</span>
    <span class="n">acquisition_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">num_pool_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">experiment</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
<span class="n">results</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="MNIST-vs-FashionMNIST-Coverage">MNIST vs FashionMNIST Coverage<a class="anchor-link" href="#MNIST-vs-FashionMNIST-Coverage"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># MNIST OOD experiment (ood_exposure=True)</span>

<span class="n">experiment</span> <span class="o">=</span> <span class="n">UnifiedExperiment</span><span class="p">(</span>
    <span class="n">experiment_data_config</span><span class="o">=</span><span class="n">StandardExperimentDataConfig</span><span class="p">(</span>
        <span class="n">id_dataset_name</span><span class="o">=</span><span class="s2">&quot;MNIST&quot;</span><span class="p">,</span>
        <span class="n">id_repetitions</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">initial_training_set_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">validation_set_size</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span>
        <span class="n">validation_split_random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">evaluation_set_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">add_dataset_noise</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">ood_dataset_config</span><span class="o">=</span><span class="n">OoDDatasetConfig</span><span class="p">(</span><span class="n">ood_dataset_name</span><span class="o">=</span><span class="s2">&quot;FashionMNIST&quot;</span><span class="p">,</span> <span class="n">ood_repetitions</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ood_exposure</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="p">),</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">max_training_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">max_training_set</span><span class="o">=</span><span class="mi">20</span> <span class="o">+</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">acquisition_function</span><span class="o">=</span><span class="n">acquisition_functions</span><span class="o">.</span><span class="n">BALD</span><span class="p">,</span>
    <span class="n">acquisition_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">model_trainer_factory</span><span class="o">=</span><span class="n">MnistModelTrainer</span><span class="p">,</span>
    <span class="n">num_pool_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">experiment</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
<span class="n">results</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  return floored.astype(np.int)
/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  return floored.astype(np.int)
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Creating: BALD(
	acquisition_size=10,
	num_pool_samples=2
)
Creating: MnistModelTrainer(
	device=cuda,
	num_training_samples=1,
	num_validation_samples=20,
	max_training_epochs=1
)
Creating: TrainSelfDistillationEvalModel(
	num_pool_samples=2
)
Training set size 20:
Epoch metrics: {&#39;accuracy&#39;: 0.554931640625, &#39;crossentropy&#39;: 1.8601678125560284}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.554931640625)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.5582, &#39;crossentropy&#39;: tensor(1.6005)}
CandidateBatch(scores=[0.5286269187927246, 0.5206483602523804, 0.5205633640289307, 0.5157134532928467, 0.5151408314704895, 0.513818621635437, 0.5130301117897034, 0.5124313831329346, 0.5110619068145752, 0.5096436738967896], indices=[19319, 24059, 30835, 46776, 43171, 49218, 47110, 22783, 6099, 43495])
[(&#39;id&#39;, 19365), (&#39;id&#39;, 24112), (&#39;id&#39;, 30906), (&#39;id&#39;, 46876), (&#39;id&#39;, 43266), (&#39;id&#39;, 49321), (&#39;id&#39;, 47210), (&#39;id&#39;, 22832), (&#39;id&#39;, 6113), (&#39;id&#39;, 43590)]
Acquiring (label, score)s: [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.5286), [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0] (0.5206), [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.5206), [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.5157), [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.5151), [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.5138), [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.513), [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.5124), [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.5111), [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] (0.5096)
Training set size 30:
Epoch metrics: {&#39;accuracy&#39;: 0.349853515625, &#39;crossentropy&#39;: 1.974664144217968}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.349853515625)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.3325, &#39;crossentropy&#39;: tensor(1.9364)}
Done.
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;dataset_info&#39;: {&#39;training&#39;: &#34;&#39;MNIST (Train, seed=0, 55904 samples)&#39; | one_hot_targets{&#39;num_classes&#39;: 10} + &#39;FashionMNIST (Train, seed=0, 60000 samples)&#39; | uniform_targets{&#39;num_classes&#39;: 10}&#34;,
  &#39;test&#39;: &#34;&#39;MNIST (Test)&#39;&#34;},
 &#39;initial_training_set_indices&#39;: [47227,
  11511,
  18383,
  41080,
  32837,
  24393,
  23904,
  11784,
  20439,
  35043,
  27367,
  30426,
  32361,
  26116,
  24386,
  4689,
  44895,
  24211,
  17212,
  3478],
 &#39;evaluation_set_indices&#39;: [49,
  12425,
  22159,
  22739,
  701,
  11289,
  4629,
  53972,
  52127,
  6277,
  18804,
  25364,
  18841,
  12957,
  10232,
  42477,
  35057,
  43089,
  48907,
  15149,
  24587,
  52160,
  19050,
  30188,
  50376,
  17140,
  26654,
  28683,
  36031,
  32477,
  32792,
  52660,
  52712,
  49702,
  40661,
  10190,
  18143,
  16617,
  54012,
  38376,
  1924,
  39518,
  1625,
  7896,
  1701,
  28972,
  3717,
  42815,
  6274,
  44154,
  44312,
  10944,
  14937,
  6358,
  1182,
  55213,
  9292,
  33572,
  13252,
  30667,
  31242,
  51852,
  33800,
  42491,
  31258,
  42348,
  42109,
  47515,
  1844,
  9314,
  18329,
  15263,
  52934,
  25225,
  25735,
  13117,
  23192,
  17351,
  23132,
  26475,
  51941,
  40334,
  46024,
  46042,
  28571,
  53385,
  11382,
  53290,
  31958,
  3733,
  4076,
  16680,
  51381,
  39998,
  23778,
  54301,
  49814,
  172,
  27228,
  16975],
 &#39;seed&#39;: 11606190315698255273,
 &#39;active_learning_steps&#39;: [{&#39;training&#39;: {&#39;epochs&#39;: [{&#39;accuracy&#39;: 0.554931640625,
      &#39;crossentropy&#39;: 1.8601678125560284}],
    &#39;best_epoch&#39;: 1},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.5582, &#39;crossentropy&#39;: tensor(1.6005)},
   &#39;acquisition&#39;: {&#39;indices&#39;: [(&#39;id&#39;, 19365),
     (&#39;id&#39;, 24112),
     (&#39;id&#39;, 30906),
     (&#39;id&#39;, 46876),
     (&#39;id&#39;, 43266),
     (&#39;id&#39;, 49321),
     (&#39;id&#39;, 47210),
     (&#39;id&#39;, 22832),
     (&#39;id&#39;, 6113),
     (&#39;id&#39;, 43590)],
    &#39;labels&#39;: [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],
     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]],
    &#39;scores&#39;: [0.5286269187927246,
     0.5206483602523804,
     0.5205633640289307,
     0.5157134532928467,
     0.5151408314704895,
     0.513818621635437,
     0.5130301117897034,
     0.5124313831329346,
     0.5110619068145752,
     0.5096436738967896]}},
  {&#39;training&#39;: {&#39;epochs&#39;: [{&#39;accuracy&#39;: 0.349853515625,
      &#39;crossentropy&#39;: 1.974664144217968}],
    &#39;best_epoch&#39;: 1},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.3325,
    &#39;crossentropy&#39;: tensor(1.9364)}}]}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="MNIST-only">MNIST only<a class="anchor-link" href="#MNIST-only"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># MNIST experiment (ood_exposure=False)</span>

<span class="n">experiment</span> <span class="o">=</span> <span class="n">UnifiedExperiment</span><span class="p">(</span>
    <span class="n">experiment_data_config</span><span class="o">=</span><span class="n">StandardExperimentDataConfig</span><span class="p">(</span>
        <span class="n">id_dataset_name</span><span class="o">=</span><span class="s2">&quot;MNIST&quot;</span><span class="p">,</span>
        <span class="n">id_repetitions</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">initial_training_set_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">validation_set_size</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span>
        <span class="n">validation_split_random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">evaluation_set_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">add_dataset_noise</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">ood_dataset_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">max_training_epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">max_training_set</span><span class="o">=</span><span class="mi">20</span> <span class="o">+</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">acquisition_function</span><span class="o">=</span><span class="n">acquisition_functions</span><span class="o">.</span><span class="n">BALD</span><span class="p">,</span>
    <span class="n">acquisition_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">model_trainer_factory</span><span class="o">=</span><span class="n">MnistModelTrainer</span><span class="p">,</span>
    <span class="n">num_pool_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">experiment</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
<span class="n">results</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Creating: BALD(
	acquisition_size=10,
	num_pool_samples=2
)
Creating: MnistModelTrainer(
	device=cuda,
	num_training_samples=1,
	num_validation_samples=20,
	max_training_epochs=5
)
Creating: TrainSelfDistillationEvalModel(
	num_pool_samples=2
)
Training set size 20:
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  return floored.astype(np.int)
/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  return floored.astype(np.int)
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch metrics: {&#39;accuracy&#39;: 0.603759765625, &#39;crossentropy&#39;: 1.8048731945455074}
Epoch metrics: {&#39;accuracy&#39;: 0.679931640625, &#39;crossentropy&#39;: 1.5223335921764374}
Epoch metrics: {&#39;accuracy&#39;: 0.679443359375, &#39;crossentropy&#39;: 1.623240053653717}
RestoringEarlyStopping: 1 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.690673828125, &#39;crossentropy&#39;: 1.8084253370761871}
Epoch metrics: {&#39;accuracy&#39;: 0.685302734375, &#39;crossentropy&#39;: 1.965613130480051}
RestoringEarlyStopping: 1 / 20
RestoringEarlyStopping: Restoring best parameters. (Score: 0.690673828125)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.696, &#39;crossentropy&#39;: tensor(0.9803)}
CandidateBatch(scores=[0.6911463737487793, 0.6911274120211601, 0.6905933320522308, 0.6904804110527039, 0.6904016882181168, 0.6902305968105793, 0.6902124583721161, 0.6899457620456815, 0.6899281330406666, 0.6897666100412607], indices=[14719, 272, 7182, 27445, 43809, 7177, 11858, 45104, 22187, 36008])
[(&#39;id&#39;, 14750), (&#39;id&#39;, 274), (&#39;id&#39;, 7199), (&#39;id&#39;, 27510), (&#39;id&#39;, 43904), (&#39;id&#39;, 7194), (&#39;id&#39;, 11885), (&#39;id&#39;, 45202), (&#39;id&#39;, 22235), (&#39;id&#39;, 36091)]
Acquiring (label, score)s: 1 (0.6911), 0 (0.6911), 8 (0.6906), 7 (0.6905), 7 (0.6904), 9 (0.6902), 2 (0.6902), 7 (0.6899), 1 (0.6899), 9 (0.6898)
Training set size 30:
Epoch metrics: {&#39;accuracy&#39;: 0.45263671875, &#39;crossentropy&#39;: 1.9057771041989326}
Epoch metrics: {&#39;accuracy&#39;: 0.709716796875, &#39;crossentropy&#39;: 1.3960129246115685}
Epoch metrics: {&#39;accuracy&#39;: 0.74609375, &#39;crossentropy&#39;: 1.32473498955369}
Epoch metrics: {&#39;accuracy&#39;: 0.7431640625, &#39;crossentropy&#39;: 1.4398422054946423}
RestoringEarlyStopping: 1 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.7548828125, &#39;crossentropy&#39;: 1.4579520002007484}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.7548828125)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.751, &#39;crossentropy&#39;: tensor(0.8279)}
Done.
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;dataset_info&#39;: {&#39;training&#39;: &#34;&#39;MNIST (Train, seed=0, 55904 samples)&#39;&#34;,
  &#39;test&#39;: &#34;&#39;MNIST (Test)&#39;&#34;},
 &#39;initial_training_set_indices&#39;: [47227,
  11511,
  18383,
  41080,
  32837,
  24393,
  23904,
  11784,
  20439,
  35043,
  27367,
  30426,
  32361,
  26116,
  24386,
  4689,
  44895,
  24211,
  17212,
  3478],
 &#39;evaluation_set_indices&#39;: [49,
  12425,
  22159,
  22739,
  701,
  11289,
  4629,
  53972,
  52127,
  6277,
  18804,
  25364,
  18841,
  12957,
  10232,
  42477,
  35057,
  43089,
  48907,
  15149,
  24587,
  52160,
  19050,
  30188,
  50376,
  17140,
  26654,
  28683,
  36031,
  32477,
  32792,
  52660,
  52712,
  49702,
  40661,
  10190,
  18143,
  16617,
  54012,
  38376,
  1924,
  39518,
  1625,
  7896,
  1701,
  28972,
  3717,
  42815,
  6274,
  44154,
  44312,
  10944,
  14937,
  6358,
  1182,
  55213,
  9292,
  33572,
  13252,
  30667,
  31242,
  51852,
  33800,
  42491,
  31258,
  42348,
  42109,
  47515,
  1844,
  9314,
  18329,
  15263,
  52934,
  25225,
  25735,
  13117,
  23192,
  17351,
  23132,
  26475,
  51941,
  40334,
  46024,
  46042,
  28571,
  53385,
  11382,
  53290,
  31958,
  3733,
  4076,
  16680,
  51381,
  39998,
  23778,
  54301,
  49814,
  172,
  27228,
  16975],
 &#39;seed&#39;: 3576085144693815017,
 &#39;active_learning_steps&#39;: [{&#39;training&#39;: {&#39;epochs&#39;: [{&#39;accuracy&#39;: 0.603759765625,
      &#39;crossentropy&#39;: 1.8048731945455074},
     {&#39;accuracy&#39;: 0.679931640625, &#39;crossentropy&#39;: 1.5223335921764374},
     {&#39;accuracy&#39;: 0.679443359375, &#39;crossentropy&#39;: 1.623240053653717},
     {&#39;accuracy&#39;: 0.690673828125, &#39;crossentropy&#39;: 1.8084253370761871},
     {&#39;accuracy&#39;: 0.685302734375, &#39;crossentropy&#39;: 1.965613130480051}],
    &#39;best_epoch&#39;: 4},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.696, &#39;crossentropy&#39;: tensor(0.9803)},
   &#39;acquisition&#39;: {&#39;indices&#39;: [(&#39;id&#39;, 14750),
     (&#39;id&#39;, 274),
     (&#39;id&#39;, 7199),
     (&#39;id&#39;, 27510),
     (&#39;id&#39;, 43904),
     (&#39;id&#39;, 7194),
     (&#39;id&#39;, 11885),
     (&#39;id&#39;, 45202),
     (&#39;id&#39;, 22235),
     (&#39;id&#39;, 36091)],
    &#39;labels&#39;: [1, 0, 8, 7, 7, 9, 2, 7, 1, 9],
    &#39;scores&#39;: [0.6911463737487793,
     0.6911274120211601,
     0.6905933320522308,
     0.6904804110527039,
     0.6904016882181168,
     0.6902305968105793,
     0.6902124583721161,
     0.6899457620456815,
     0.6899281330406666,
     0.6897666100412607]}},
  {&#39;training&#39;: {&#39;epochs&#39;: [{&#39;accuracy&#39;: 0.45263671875,
      &#39;crossentropy&#39;: 1.9057771041989326},
     {&#39;accuracy&#39;: 0.709716796875, &#39;crossentropy&#39;: 1.3960129246115685},
     {&#39;accuracy&#39;: 0.74609375, &#39;crossentropy&#39;: 1.32473498955369},
     {&#39;accuracy&#39;: 0.7431640625, &#39;crossentropy&#39;: 1.4398422054946423},
     {&#39;accuracy&#39;: 0.7548828125, &#39;crossentropy&#39;: 1.4579520002007484}],
    &#39;best_epoch&#39;: 5},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.751, &#39;crossentropy&#39;: tensor(0.8279)}}]}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="MNIST-only-+-BADGE">MNIST only + BADGE<a class="anchor-link" href="#MNIST-only-+-BADGE"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># MNIST experiment (ood_exposure=False)</span>

<span class="n">experiment</span> <span class="o">=</span> <span class="n">UnifiedExperiment</span><span class="p">(</span>
    <span class="n">experiment_data_config</span><span class="o">=</span><span class="n">StandardExperimentDataConfig</span><span class="p">(</span>
        <span class="n">id_dataset_name</span><span class="o">=</span><span class="s2">&quot;MNIST&quot;</span><span class="p">,</span>
        <span class="n">id_repetitions</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">initial_training_set_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">validation_set_size</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span>
        <span class="n">validation_split_random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">evaluation_set_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">add_dataset_noise</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">ood_dataset_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">max_training_epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">max_training_set</span><span class="o">=</span><span class="mi">20</span> <span class="o">+</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">acquisition_function</span><span class="o">=</span><span class="n">baseline_acquisition_functions</span><span class="o">.</span><span class="n">BADGE</span><span class="p">,</span>
    <span class="n">acquisition_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">model_trainer_factory</span><span class="o">=</span><span class="n">MnistModelTrainer</span><span class="p">,</span>
    <span class="n">num_pool_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">experiment</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
<span class="n">results</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Creating: BADGE(
	acquisition_size=10
)
Creating: MnistModelTrainer(
	device=cuda,
	num_training_samples=1,
	num_validation_samples=20,
	max_training_epochs=5
)
Creating: TrainSelfDistillationEvalModel(
	num_pool_samples=2
)
Training set size 20:
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  return floored.astype(np.int)
/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  return floored.astype(np.int)
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch metrics: {&#39;accuracy&#39;: 0.512451171875, &#39;crossentropy&#39;: 1.9132713787257671}
Epoch metrics: {&#39;accuracy&#39;: 0.63818359375, &#39;crossentropy&#39;: 1.6632042974233627}
Epoch metrics: {&#39;accuracy&#39;: 0.68994140625, &#39;crossentropy&#39;: 1.746895831078291}
Epoch metrics: {&#39;accuracy&#39;: 0.66845703125, &#39;crossentropy&#39;: 2.059821903705597}
RestoringEarlyStopping: 1 / 20
Epoch metrics: {&#39;accuracy&#39;: 0.677001953125, &#39;crossentropy&#39;: 2.216190990060568}
RestoringEarlyStopping: 2 / 20
RestoringEarlyStopping: Restoring best parameters. (Score: 0.68994140625)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.6936, &#39;crossentropy&#39;: tensor(0.9935)}
#Samps	Total Distance
1	5031186.862045288
2	4363374.027002335
3	3427368.4897241592
4	3124580.681898117
5	3120869.71295166
6	3018759.9706284828
7	2842746.541076125
8	2612532.148223342
9	2498573.2148422613
CandidateBatch(scores=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], indices=[115, 1318, 9981, 10663, 12903, 54210, 36623, 25029, 31107, 24184])
[(&#39;id&#39;, 116), (&#39;id&#39;, 1322), (&#39;id&#39;, 10001), (&#39;id&#39;, 10685), (&#39;id&#39;, 12931), (&#39;id&#39;, 54329), (&#39;id&#39;, 36706), (&#39;id&#39;, 25086), (&#39;id&#39;, 31178), (&#39;id&#39;, 24238)]
Acquiring (label, score)s: 0 (0.0), 2 (0.0), 9 (0.0), 9 (0.0), 0 (0.0), 2 (0.0), 9 (0.0), 2 (0.0), 5 (0.0), 3 (0.0)
Training set size 30:
Epoch metrics: {&#39;accuracy&#39;: 0.296630859375, &#39;crossentropy&#39;: 2.080603674054146}
Epoch metrics: {&#39;accuracy&#39;: 0.596923828125, &#39;crossentropy&#39;: 1.576156985014677}
Epoch metrics: {&#39;accuracy&#39;: 0.69287109375, &#39;crossentropy&#39;: 1.5450268387794495}
Epoch metrics: {&#39;accuracy&#39;: 0.715576171875, &#39;crossentropy&#39;: 1.5268513858318329}
Epoch metrics: {&#39;accuracy&#39;: 0.69384765625, &#39;crossentropy&#39;: 1.828642327338457}
RestoringEarlyStopping: 1 / 20
RestoringEarlyStopping: Restoring best parameters. (Score: 0.715576171875)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.7307, &#39;crossentropy&#39;: tensor(0.8910)}
Done.
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;dataset_info&#39;: {&#39;training&#39;: &#34;&#39;MNIST (Train, seed=0, 55904 samples)&#39;&#34;,
  &#39;test&#39;: &#34;&#39;MNIST (Test)&#39;&#34;},
 &#39;initial_training_set_indices&#39;: [47227,
  11511,
  18383,
  41080,
  32837,
  24393,
  23904,
  11784,
  20439,
  35043,
  27367,
  30426,
  32361,
  26116,
  24386,
  4689,
  44895,
  24211,
  17212,
  3478],
 &#39;evaluation_set_indices&#39;: [49,
  12425,
  22159,
  22739,
  701,
  11289,
  4629,
  53972,
  52127,
  6277,
  18804,
  25364,
  18841,
  12957,
  10232,
  42477,
  35057,
  43089,
  48907,
  15149,
  24587,
  52160,
  19050,
  30188,
  50376,
  17140,
  26654,
  28683,
  36031,
  32477,
  32792,
  52660,
  52712,
  49702,
  40661,
  10190,
  18143,
  16617,
  54012,
  38376,
  1924,
  39518,
  1625,
  7896,
  1701,
  28972,
  3717,
  42815,
  6274,
  44154,
  44312,
  10944,
  14937,
  6358,
  1182,
  55213,
  9292,
  33572,
  13252,
  30667,
  31242,
  51852,
  33800,
  42491,
  31258,
  42348,
  42109,
  47515,
  1844,
  9314,
  18329,
  15263,
  52934,
  25225,
  25735,
  13117,
  23192,
  17351,
  23132,
  26475,
  51941,
  40334,
  46024,
  46042,
  28571,
  53385,
  11382,
  53290,
  31958,
  3733,
  4076,
  16680,
  51381,
  39998,
  23778,
  54301,
  49814,
  172,
  27228,
  16975],
 &#39;seed&#39;: 4331767114998916037,
 &#39;active_learning_steps&#39;: [{&#39;training&#39;: {&#39;epochs&#39;: [{&#39;accuracy&#39;: 0.512451171875,
      &#39;crossentropy&#39;: 1.9132713787257671},
     {&#39;accuracy&#39;: 0.63818359375, &#39;crossentropy&#39;: 1.6632042974233627},
     {&#39;accuracy&#39;: 0.68994140625, &#39;crossentropy&#39;: 1.746895831078291},
     {&#39;accuracy&#39;: 0.66845703125, &#39;crossentropy&#39;: 2.059821903705597},
     {&#39;accuracy&#39;: 0.677001953125, &#39;crossentropy&#39;: 2.216190990060568}],
    &#39;best_epoch&#39;: 3},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.6936, &#39;crossentropy&#39;: tensor(0.9935)},
   &#39;acquisition&#39;: {&#39;indices&#39;: [(&#39;id&#39;, 116),
     (&#39;id&#39;, 1322),
     (&#39;id&#39;, 10001),
     (&#39;id&#39;, 10685),
     (&#39;id&#39;, 12931),
     (&#39;id&#39;, 54329),
     (&#39;id&#39;, 36706),
     (&#39;id&#39;, 25086),
     (&#39;id&#39;, 31178),
     (&#39;id&#39;, 24238)],
    &#39;labels&#39;: [0, 2, 9, 9, 0, 2, 9, 2, 5, 3],
    &#39;scores&#39;: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}},
  {&#39;training&#39;: {&#39;epochs&#39;: [{&#39;accuracy&#39;: 0.296630859375,
      &#39;crossentropy&#39;: 2.080603674054146},
     {&#39;accuracy&#39;: 0.596923828125, &#39;crossentropy&#39;: 1.576156985014677},
     {&#39;accuracy&#39;: 0.69287109375, &#39;crossentropy&#39;: 1.5450268387794495},
     {&#39;accuracy&#39;: 0.715576171875, &#39;crossentropy&#39;: 1.5268513858318329},
     {&#39;accuracy&#39;: 0.69384765625, &#39;crossentropy&#39;: 1.828642327338457}],
    &#39;best_epoch&#39;: 4},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.7307,
    &#39;crossentropy&#39;: tensor(0.8910)}}]}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="MNIST-only-+-(naive)-EPIG">MNIST only + (naive) EPIG<a class="anchor-link" href="#MNIST-only-+-(naive)-EPIG"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># MNIST experiment (ood_exposure=False)</span>

<span class="n">experiment</span> <span class="o">=</span> <span class="n">UnifiedExperiment</span><span class="p">(</span>
    <span class="n">experiment_data_config</span><span class="o">=</span><span class="n">StandardExperimentDataConfig</span><span class="p">(</span>
        <span class="n">id_dataset_name</span><span class="o">=</span><span class="s2">&quot;MNIST&quot;</span><span class="p">,</span>
        <span class="n">id_repetitions</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">initial_training_set_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">validation_set_size</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span>
        <span class="n">validation_split_random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">evaluation_set_size</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">add_dataset_noise</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">ood_dataset_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">max_training_epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">max_training_set</span><span class="o">=</span><span class="mi">20</span> <span class="o">+</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">acquisition_function</span><span class="o">=</span><span class="n">acquisition_functions</span><span class="o">.</span><span class="n">EPIG</span><span class="p">,</span>
    <span class="n">acquisition_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">model_trainer_factory</span><span class="o">=</span><span class="n">MnistModelTrainer</span><span class="p">,</span>
    <span class="n">num_pool_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">experiment</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
<span class="n">results</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>StandardExperimentDataConfig(id_dataset_name=&#39;MNIST&#39;, id_repetitions=1, initial_training_set_size=20, validation_set_size=4096, validation_split_random_state=0, evaluation_set_size=0, add_dataset_noise=False, ood_dataset_config=None)
Creating: EPIG(
	acquisition_size=10,
	num_pool_samples=100,
	epig_bootstrap_type=BootstrapType.NO_BOOTSTRAP,
	epig_bootstrap_factor=1.0,
	epig_dtype=torch.float64
)
Creating: MnistModelTrainer(
	device=cuda,
	num_training_samples=1,
	num_validation_samples=20,
	max_training_epochs=5
)
Creating: TrainSelfDistillationEvalModel(
	num_pool_samples=100
)
Training set size 20:
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  return floored.astype(np.int)
/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  return floored.astype(np.int)
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch metrics: {&#39;accuracy&#39;: 0.52490234375, &#39;crossentropy&#39;: 1.84434649720788}
Epoch metrics: {&#39;accuracy&#39;: 0.702392578125, &#39;crossentropy&#39;: 1.4298735782504082}
Epoch metrics: {&#39;accuracy&#39;: 0.703857421875, &#39;crossentropy&#39;: 1.5751474872231483}
Epoch metrics: {&#39;accuracy&#39;: 0.71630859375, &#39;crossentropy&#39;: 1.7003575265407562}
Epoch metrics: {&#39;accuracy&#39;: 0.717529296875, &#39;crossentropy&#39;: 1.8638241328299046}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.717529296875)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.7301, &#39;crossentropy&#39;: tensor(0.9447)}
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-17-0cfd1d5a1769&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">     24</span> 
<span class="ansi-green-intense-fg ansi-bold">     25</span> results <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">{</span><span class="ansi-blue-fg">}</span>
<span class="ansi-green-fg">---&gt; 26</span><span class="ansi-red-fg"> </span>experiment<span class="ansi-blue-fg">.</span>run<span class="ansi-blue-fg">(</span>results<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     27</span> results

<span class="ansi-green-fg">&lt;ipython-input-16-495e1001a798&gt;</span> in <span class="ansi-cyan-fg">run</span><span class="ansi-blue-fg">(self, store)</span>
<span class="ansi-green-intense-fg ansi-bold">    216</span>         )
<span class="ansi-green-intense-fg ansi-bold">    217</span> 
<span class="ansi-green-fg">--&gt; 218</span><span class="ansi-red-fg">         </span>active_learner<span class="ansi-blue-fg">(</span>store<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">&lt;ipython-input-16-495e1001a798&gt;</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, log)</span>
<span class="ansi-green-intense-fg ansi-bold">     91</span>                     eval_loader <span class="ansi-blue-fg">=</span> pool_loader
<span class="ansi-green-intense-fg ansi-bold">     92</span> 
<span class="ansi-green-fg">---&gt; 93</span><span class="ansi-red-fg">                 candidate_batch = acquisition_function.compute_candidate_batch(
</span><span class="ansi-green-intense-fg ansi-bold">     94</span>                     model<span class="ansi-blue-fg">=</span>trained_model<span class="ansi-blue-fg">,</span> pool_loader<span class="ansi-blue-fg">=</span>pool_loader<span class="ansi-blue-fg">,</span> eval_loader<span class="ansi-blue-fg">=</span>eval_loader<span class="ansi-blue-fg">,</span> device<span class="ansi-blue-fg">=</span>self<span class="ansi-blue-fg">.</span>device
<span class="ansi-green-intense-fg ansi-bold">     95</span>                 )

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/acquisition_functions.py</span> in <span class="ansi-cyan-fg">compute_candidate_batch</span><span class="ansi-blue-fg">(self, model, eval_loader, pool_loader, device)</span>
<span class="ansi-green-intense-fg ansi-bold">    341</span>         <span class="ansi-red-fg"># NOTE: we are using floats all the way here. Hopefully this won&#39;t be two bad in the two variable case.</span>
<span class="ansi-green-intense-fg ansi-bold">    342</span>         <span class="ansi-red-fg"># torch.double vs torch.float is a 10x speed difference (enough to make double infeasible for exps).</span>
<span class="ansi-green-fg">--&gt; 343</span><span class="ansi-red-fg">         scores_N = get_real_naive_epig_scores(
</span><span class="ansi-green-intense-fg ansi-bold">    344</span>             bootstrap_type<span class="ansi-blue-fg">=</span>self<span class="ansi-blue-fg">.</span>epig_bootstrap_type<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    345</span>             bootstrap_factor<span class="ansi-blue-fg">=</span>self<span class="ansi-blue-fg">.</span>epig_bootstrap_factor<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/autograd/grad_mode.py</span> in <span class="ansi-cyan-fg">decorate_context</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">     24</span>         <span class="ansi-green-fg">def</span> decorate_context<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     25</span>             <span class="ansi-green-fg">with</span> self<span class="ansi-blue-fg">.</span>__class__<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">---&gt; 26</span><span class="ansi-red-fg">                 </span><span class="ansi-green-fg">return</span> func<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     27</span>         <span class="ansi-green-fg">return</span> cast<span class="ansi-blue-fg">(</span>F<span class="ansi-blue-fg">,</span> decorate_context<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     28</span> 

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/batchbald.py</span> in <span class="ansi-cyan-fg">get_real_naive_epig_scores</span><span class="ansi-blue-fg">(bootstrap_type, bootstrap_factor, pool_log_probs_N_K_C, eval_log_probs_E_K_C, dtype, device)</span>
<span class="ansi-green-intense-fg ansi-bold">    746</span> 
<span class="ansi-green-intense-fg ansi-bold">    747</span>         <span class="ansi-blue-fg">@</span>toma<span class="ansi-blue-fg">.</span>execute<span class="ansi-blue-fg">.</span>batch<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">1024</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 748</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">def</span> loop<span class="ansi-blue-fg">(</span>batchsize<span class="ansi-blue-fg">:</span> int<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    749</span>             pbar<span class="ansi-blue-fg">.</span>reset<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    750</span> 

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/toma/__init__.py</span> in <span class="ansi-cyan-fg">execute_batch</span><span class="ansi-blue-fg">(func)</span>
<span class="ansi-green-intense-fg ansi-bold">    175</span> 
<span class="ansi-green-intense-fg ansi-bold">    176</span>             <span class="ansi-green-fg">def</span> execute_batch<span class="ansi-blue-fg">(</span>func<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 177</span><span class="ansi-red-fg">                 </span><span class="ansi-green-fg">return</span> explicit<span class="ansi-blue-fg">.</span>batch<span class="ansi-blue-fg">(</span>func<span class="ansi-blue-fg">,</span> initial_batchsize<span class="ansi-blue-fg">,</span> toma_cache_type<span class="ansi-blue-fg">=</span>cache_type<span class="ansi-blue-fg">,</span> toma_context<span class="ansi-blue-fg">=</span>context<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    178</span> 
<span class="ansi-green-intense-fg ansi-bold">    179</span>             <span class="ansi-green-fg">return</span> execute_batch

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/toma/__init__.py</span> in <span class="ansi-cyan-fg">batch</span><span class="ansi-blue-fg">(func, initial_batchsize, toma_context, toma_cache_type, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    237</span>             <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    238</span>                 value <span class="ansi-blue-fg">=</span> batchsize<span class="ansi-blue-fg">.</span>get<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 239</span><span class="ansi-red-fg">                 </span>result <span class="ansi-blue-fg">=</span> func<span class="ansi-blue-fg">(</span>value<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    240</span>                 gc_cuda<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    241</span>                 <span class="ansi-green-fg">return</span> result

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/batchbald.py</span> in <span class="ansi-cyan-fg">loop</span><span class="ansi-blue-fg">(batchsize)</span>
<span class="ansi-green-intense-fg ansi-bold">    754</span>                 joint_probs_N_E_EC <span class="ansi-blue-fg">=</span> get_joint_probs_N_C_EC_transposed<span class="ansi-blue-fg">(</span>pool_probs_N_C_K<span class="ansi-blue-fg">,</span> chunked_eval_probs_e_K_C<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    755</span>                 weighted_nats_N_C_EC <span class="ansi-blue-fg">=</span> joint_probs_N_E_EC <span class="ansi-blue-fg">*</span> <span class="ansi-blue-fg">-</span>torch<span class="ansi-blue-fg">.</span>log<span class="ansi-blue-fg">(</span>joint_probs_N_E_EC<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 756</span><span class="ansi-red-fg">                 </span>weighted_nats_N_C_EC<span class="ansi-blue-fg">[</span>torch<span class="ansi-blue-fg">.</span>isnan<span class="ansi-blue-fg">(</span>weighted_nats_N_C_EC<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> <span class="ansi-cyan-fg">0.0</span>
<span class="ansi-green-intense-fg ansi-bold">    757</span>                 joint_entropy_N <span class="ansi-blue-fg">=</span> weighted_nats_N_C_EC<span class="ansi-blue-fg">.</span>sum<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">,</span> <span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> keepdim<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">False</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    758</span>                 <span class="ansi-green-fg">del</span> weighted_nats_N_C_EC

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="CIFAR-10-only">CIFAR-10 only<a class="anchor-link" href="#CIFAR-10-only"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># CIFAR-10 experiment (ood_exposure=False)</span>

<span class="n">experiment</span> <span class="o">=</span> <span class="n">UnifiedExperiment</span><span class="p">(</span>
    <span class="n">experiment_data_config</span><span class="o">=</span><span class="n">StandardExperimentDataConfig</span><span class="p">(</span>
        <span class="n">id_dataset_name</span><span class="o">=</span><span class="s2">&quot;CIFAR-10&quot;</span><span class="p">,</span>
        <span class="n">id_repetitions</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">initial_training_set_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">validation_set_size</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span>
        <span class="n">validation_split_random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">evaluation_set_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">add_dataset_noise</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">ood_dataset_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">max_training_epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">max_training_set</span><span class="o">=</span><span class="mi">20</span> <span class="o">+</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">acquisition_function</span><span class="o">=</span><span class="n">acquisition_functions</span><span class="o">.</span><span class="n">BALD</span><span class="p">,</span>
    <span class="n">acquisition_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">model_trainer_factory</span><span class="o">=</span><span class="n">Cifar10ModelTrainer</span><span class="p">,</span>
    <span class="n">num_pool_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">experiment</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
<span class="n">results</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Files already downloaded and verified
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  return floored.astype(np.int)
/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  return floored.astype(np.int)
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Files already downloaded and verified
Creating: BALD(
	acquisition_size=10,
	num_pool_samples=2
)
Creating: Cifar10ModelTrainer(
	device=cuda,
	num_training_samples=1,
	num_validation_samples=20,
	max_training_epochs=5
)
Creating: TrainSelfDistillationEvalModel(
	num_pool_samples=2
)
Training set size 20:
Cosine Annealing
Epoch 1 metrics: {&#39;accuracy&#39;: 0.132080078125, &#39;crossentropy&#39;: 3.556436240673065}
Epoch 2 metrics: {&#39;accuracy&#39;: 0.147705078125, &#39;crossentropy&#39;: 11.288517951965332}
Epoch 3 metrics: {&#39;accuracy&#39;: 0.1484375, &#39;crossentropy&#39;: 9.785008907318115}
Epoch 4 metrics: {&#39;accuracy&#39;: 0.15869140625, &#39;crossentropy&#39;: 9.548845410346985}
Epoch 5 metrics: {&#39;accuracy&#39;: 0.151611328125, &#39;crossentropy&#39;: 9.943562984466553}
Perf after training {&#39;accuracy&#39;: 0.1561, &#39;crossentropy&#39;: tensor(7.4005)}
CandidateBatch(scores=[0.6368825323879719, 0.600792333483696, 0.5738895609974861, 0.5720301643013954, 0.5641722083091736, 0.5616957247257233, 0.540523573756218, 0.5393854081630707, 0.5310562998056412, 0.5249305069446564], indices=[13423, 26613, 32359, 9927, 25536, 1967, 12669, 11213, 15695, 13329])
[(&#39;id&#39;, 13464), (&#39;id&#39;, 26684), (&#39;id&#39;, 32447), (&#39;id&#39;, 9952), (&#39;id&#39;, 25604), (&#39;id&#39;, 1971), (&#39;id&#39;, 12705), (&#39;id&#39;, 11244), (&#39;id&#39;, 15739), (&#39;id&#39;, 13370)]
Acquiring (label, score)s: 0 (0.6369), 0 (0.6008), 0 (0.5739), 0 (0.572), 1 (0.5642), 2 (0.5617), 0 (0.5405), 8 (0.5394), 0 (0.5311), 6 (0.5249)
Training set size 30:
Cosine Annealing
Epoch 1 metrics: {&#39;accuracy&#39;: 0.14208984375, &#39;crossentropy&#39;: 3.128549039363861}
Epoch 2 metrics: {&#39;accuracy&#39;: 0.176513671875, &#39;crossentropy&#39;: 3.5860735476017}
Epoch 3 metrics: {&#39;accuracy&#39;: 0.18994140625, &#39;crossentropy&#39;: 5.4360968470573425}
Epoch 4 metrics: {&#39;accuracy&#39;: 0.193115234375, &#39;crossentropy&#39;: 5.482205808162689}
Epoch 5 metrics: {&#39;accuracy&#39;: 0.181640625, &#39;crossentropy&#39;: 5.63788229227066}
Perf after training {&#39;accuracy&#39;: 0.1767, &#39;crossentropy&#39;: tensor(4.1496)}
Done.
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;dataset_info&#39;: {&#39;training&#39;: &#34;&#39;CIFAR-10 (Train, seed=0, 45904 samples)&#39;&#34;,
  &#39;test&#39;: &#34;&#39;CIFAR-10 (Test)&#39;&#34;},
 &#39;initial_training_set_indices&#39;: [29863,
  22519,
  21079,
  37521,
  15583,
  23405,
  44362,
  35084,
  29380,
  26994,
  39909,
  29333,
  527,
  31668,
  43591,
  12293,
  39247,
  36879,
  7979,
  33280],
 &#39;evaluation_set_indices&#39;: [4291,
  37709,
  11949,
  12149,
  17798,
  32245,
  235,
  38778,
  32864,
  39123,
  22797,
  43486,
  5813,
  40306,
  4570,
  15667,
  36937,
  25830,
  2404,
  30096,
  19730,
  11343,
  17034,
  43455,
  15770,
  7894,
  36848,
  11067,
  12968,
  29454,
  33432,
  21672,
  38040,
  259,
  29571,
  41639,
  43971,
  13338,
  42364,
  11109,
  18814,
  21474,
  10681,
  40169,
  9997,
  12784,
  22626,
  36949,
  33130,
  13688,
  6466,
  28263,
  45060,
  10422,
  7005,
  3143,
  26143,
  28581,
  13207,
  10038,
  6750,
  21221,
  9097,
  26989,
  26153,
  13087,
  28498,
  39840,
  26870,
  24298,
  24804,
  28038,
  17767,
  31439,
  1247,
  2171,
  6804,
  5126,
  42102,
  11902,
  27726,
  34553,
  8995,
  23268,
  42247,
  40748,
  4329,
  18148,
  33008,
  18855,
  4043,
  6625,
  15957,
  19208,
  23415,
  19554,
  7878,
  20565,
  7036,
  8754],
 &#39;seed&#39;: 1085049402368859365,
 &#39;active_learning_steps&#39;: [{&#39;training&#39;: {&#39;epochs&#39;: [{&#39;accuracy&#39;: 0.132080078125,
      &#39;crossentropy&#39;: 3.556436240673065},
     {&#39;accuracy&#39;: 0.147705078125, &#39;crossentropy&#39;: 11.288517951965332},
     {&#39;accuracy&#39;: 0.1484375, &#39;crossentropy&#39;: 9.785008907318115},
     {&#39;accuracy&#39;: 0.15869140625, &#39;crossentropy&#39;: 9.548845410346985},
     {&#39;accuracy&#39;: 0.151611328125, &#39;crossentropy&#39;: 9.943562984466553}]},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.1561, &#39;crossentropy&#39;: tensor(7.4005)},
   &#39;acquisition&#39;: {&#39;indices&#39;: [(&#39;id&#39;, 13464),
     (&#39;id&#39;, 26684),
     (&#39;id&#39;, 32447),
     (&#39;id&#39;, 9952),
     (&#39;id&#39;, 25604),
     (&#39;id&#39;, 1971),
     (&#39;id&#39;, 12705),
     (&#39;id&#39;, 11244),
     (&#39;id&#39;, 15739),
     (&#39;id&#39;, 13370)],
    &#39;labels&#39;: [0, 0, 0, 0, 1, 2, 0, 8, 0, 6],
    &#39;scores&#39;: [0.6368825323879719,
     0.600792333483696,
     0.5738895609974861,
     0.5720301643013954,
     0.5641722083091736,
     0.5616957247257233,
     0.540523573756218,
     0.5393854081630707,
     0.5310562998056412,
     0.5249305069446564]}},
  {&#39;training&#39;: {&#39;epochs&#39;: [{&#39;accuracy&#39;: 0.14208984375,
      &#39;crossentropy&#39;: 3.128549039363861},
     {&#39;accuracy&#39;: 0.176513671875, &#39;crossentropy&#39;: 3.5860735476017},
     {&#39;accuracy&#39;: 0.18994140625, &#39;crossentropy&#39;: 5.4360968470573425},
     {&#39;accuracy&#39;: 0.193115234375, &#39;crossentropy&#39;: 5.482205808162689},
     {&#39;accuracy&#39;: 0.181640625, &#39;crossentropy&#39;: 5.63788229227066}]},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.1767,
    &#39;crossentropy&#39;: tensor(4.1496)}}]}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">configs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">UnifiedExperiment</span><span class="p">(</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">seed</span> <span class="o">+</span> <span class="mi">1234</span><span class="p">,</span>
        <span class="n">experiment_data_config</span><span class="o">=</span><span class="n">StandardExperimentDataConfig</span><span class="p">(</span>
            <span class="n">id_dataset_name</span><span class="o">=</span><span class="n">id_dataset_name</span><span class="p">,</span>
            <span class="n">id_repetitions</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">initial_training_set_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
            <span class="n">validation_set_size</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span>
            <span class="n">validation_split_random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">evaluation_set_size</span><span class="o">=</span><span class="n">evaluation_set_size</span><span class="p">,</span>
            <span class="n">add_dataset_noise</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">ood_dataset_config</span><span class="o">=</span><span class="n">OoDDatasetConfig</span><span class="p">(</span>
                <span class="n">ood_dataset_name</span><span class="o">=</span><span class="n">ood_dataset_name</span><span class="p">,</span> <span class="n">ood_repetitions</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ood_exposure</span><span class="o">=</span><span class="n">ood_exposure</span>
            <span class="p">),</span>
        <span class="p">),</span>
        <span class="n">acquisition_function</span><span class="o">=</span><span class="n">acquisition_function</span><span class="p">,</span>
        <span class="n">acquisition_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">num_pool_samples</span><span class="o">=</span><span class="n">num_pool_samples</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">acquisition_function</span> <span class="ow">in</span> <span class="p">[</span><span class="n">batchbald_redux</span><span class="o">.</span><span class="n">acquisition_functions</span><span class="o">.</span><span class="n">epig</span><span class="o">.</span><span class="n">BatchEvalBALD</span><span class="p">,</span>
                                 <span class="n">batchbald_redux</span><span class="o">.</span><span class="n">acquisition_functions</span><span class="o">.</span><span class="n">batchbald</span><span class="o">.</span><span class="n">BatchBALD</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">evaluation_set_size</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1024</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">num_pool_samples</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">100</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">ood_exposure</span> <span class="ow">in</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">id_dataset_name</span><span class="p">,</span> <span class="n">ood_dataset_name</span> <span class="ow">in</span> <span class="p">[(</span><span class="s2">&quot;CIFAR-10&quot;</span><span class="p">,</span> <span class="s2">&quot;SVHN&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;SVHN&quot;</span><span class="p">,</span> <span class="s2">&quot;CIFAR-10&quot;</span><span class="p">)]</span>
<span class="p">]</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">is_run_from_ipython</span><span class="p">()</span> <span class="ow">and</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">job_id</span><span class="p">,</span> <span class="n">store</span> <span class="ow">in</span> <span class="n">embedded_experiments</span><span class="p">(</span><span class="vm">__file__</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">configs</span><span class="p">)):</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">configs</span><span class="p">[</span><span class="n">job_id</span><span class="p">]</span>
        <span class="n">config</span><span class="o">.</span><span class="n">seed</span> <span class="o">+=</span> <span class="n">job_id</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataclasses</span><span class="o">.</span><span class="n">asdict</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;log&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">config</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">store</span><span class="o">=</span><span class="n">store</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="n">store</span><span class="p">[</span><span class="s2">&quot;exception&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">traceback</span><span class="o">.</span><span class="n">format_exc</span><span class="p">()</span>
            <span class="k">raise</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">configs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>24</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">prettyprinter</span>

<span class="n">prettyprinter</span><span class="o">.</span><span class="n">install_extras</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;dataclasses&quot;</span><span class="p">})</span>

<span class="n">prettyprinter</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">configs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[
    OodExperiment(
        seed=1234,
        uniform_ood=True,
        id_dataset_name=&#39;CIFAR-10&#39;,
        ood_dataset_name=&#39;SVHN&#39;,
        num_pool_samples=100,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.BatchEvalBALD
    ),
    OodExperiment(
        seed=1234,
        uniform_ood=True,
        id_dataset_name=&#39;SVHN&#39;,
        ood_dataset_name=&#39;CIFAR-10&#39;,
        num_pool_samples=100,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.BatchEvalBALD
    ),
    OodExperiment(
        seed=1234,
        uniform_ood=False,
        id_dataset_name=&#39;CIFAR-10&#39;,
        ood_dataset_name=&#39;SVHN&#39;,
        num_pool_samples=100,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.BatchEvalBALD
    ),
    OodExperiment(
        seed=1234,
        uniform_ood=False,
        id_dataset_name=&#39;SVHN&#39;,
        ood_dataset_name=&#39;CIFAR-10&#39;,
        num_pool_samples=100,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.BatchEvalBALD
    ),
    OodExperiment(
        seed=1234,
        uniform_ood=True,
        id_dataset_name=&#39;CIFAR-10&#39;,
        ood_dataset_name=&#39;SVHN&#39;,
        num_pool_samples=100,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.BatchBALD
    ),
    OodExperiment(
        seed=1234,
        uniform_ood=True,
        id_dataset_name=&#39;SVHN&#39;,
        ood_dataset_name=&#39;CIFAR-10&#39;,
        num_pool_samples=100,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.BatchBALD
    ),
    OodExperiment(
        seed=1234,
        uniform_ood=False,
        id_dataset_name=&#39;CIFAR-10&#39;,
        ood_dataset_name=&#39;SVHN&#39;,
        num_pool_samples=100,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.BatchBALD
    ),
    OodExperiment(
        seed=1234,
        uniform_ood=False,
        id_dataset_name=&#39;SVHN&#39;,
        ood_dataset_name=&#39;CIFAR-10&#39;,
        num_pool_samples=100,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.BatchBALD
    ),
    OodExperiment(
        seed=1235,
        uniform_ood=True,
        id_dataset_name=&#39;CIFAR-10&#39;,
        ood_dataset_name=&#39;SVHN&#39;,
        num_pool_samples=100,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.BatchEvalBALD
    ),
    OodExperiment(
        seed=1235,
        uniform_ood=True,
        id_dataset_name=&#39;SVHN&#39;,
        ood_dataset_name=&#39;CIFAR-10&#39;,
        num_pool_samples=100,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.BatchEvalBALD
    ),
    OodExperiment(
        seed=1235,
        uniform_ood=False,
        id_dataset_name=&#39;CIFAR-10&#39;,
        ood_dataset_name=&#39;SVHN&#39;,
        num_pool_samples=100,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.BatchEvalBALD
    ),
    OodExperiment(
        seed=1235,
        uniform_ood=False,
        id_dataset_name=&#39;SVHN&#39;,
        ood_dataset_name=&#39;CIFAR-10&#39;,
        num_pool_samples=100,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.BatchEvalBALD
    ),
    OodExperiment(
        seed=1235,
        uniform_ood=True,
        id_dataset_name=&#39;CIFAR-10&#39;,
        ood_dataset_name=&#39;SVHN&#39;,
        num_pool_samples=100,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.BatchBALD
    ),
    OodExperiment(
        seed=1235,
        uniform_ood=True,
        id_dataset_name=&#39;SVHN&#39;,
        ood_dataset_name=&#39;CIFAR-10&#39;,
        num_pool_samples=100,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.BatchBALD
    ),
    OodExperiment(
        seed=1235,
        uniform_ood=False,
        id_dataset_name=&#39;CIFAR-10&#39;,
        ood_dataset_name=&#39;SVHN&#39;,
        num_pool_samples=100,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.BatchBALD
    ),
    OodExperiment(
        seed=1235,
        uniform_ood=False,
        id_dataset_name=&#39;SVHN&#39;,
        ood_dataset_name=&#39;CIFAR-10&#39;,
        num_pool_samples=100,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.BatchBALD
    )
]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

