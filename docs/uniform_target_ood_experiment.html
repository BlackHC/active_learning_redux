---

title: Uniform Target OOD Experiment


keywords: fastai
sidebar: home_sidebar

summary: "Can we get better by training on our assumptions?"
description: "Can we get better by training on our assumptions?"
nb_path: "09d_uniform_target_ood_experiment.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 09d_uniform_target_ood_experiment.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Appended /home/blackhc/PycharmProjects/bald-ical/src to paths
Switched to directory /home/blackhc/PycharmProjects/bald-ical
%load_ext autoreload
%autoreload 2
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Import modules and functions were are going to use.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">dataclasses</span>
<span class="kn">import</span> <span class="nn">traceback</span>
<span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Type</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.utils.data</span>
<span class="kn">from</span> <span class="nn">blackhc.project</span> <span class="kn">import</span> <span class="n">is_run_from_ipython</span>
<span class="kn">from</span> <span class="nn">blackhc.project.experiment</span> <span class="kn">import</span> <span class="n">embedded_experiments</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>

<span class="kn">import</span> <span class="nn">batchbald_redux.acquisition_functions</span> <span class="k">as</span> <span class="nn">acquisition_functions</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.acquisition_functions</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">CandidateBatchComputer</span><span class="p">,</span>
    <span class="n">EvalCandidateBatchComputer</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.active_learning</span> <span class="kn">import</span> <span class="n">ActiveLearningData</span><span class="p">,</span> <span class="n">RandomFixedLengthSampler</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.black_box_model_training</span> <span class="kn">import</span> <span class="n">evaluate</span><span class="p">,</span> <span class="n">train</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.dataset_challenges</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">AdditiveGaussianNoise</span><span class="p">,</span>
    <span class="n">AliasDataset</span><span class="p">,</span>
    <span class="n">NamedDataset</span><span class="p">,</span>
    <span class="n">get_base_dataset_index</span><span class="p">,</span>
    <span class="n">get_target</span><span class="p">,</span>
    <span class="n">get_balanced_sample_indices_by_class</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.datasets</span> <span class="kn">import</span> <span class="n">train_validation_split</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.di</span> <span class="kn">import</span> <span class="n">DependencyInjection</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.fast_mnist</span> <span class="kn">import</span> <span class="n">FastFashionMNIST</span><span class="p">,</span> <span class="n">FastMNIST</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.model_optimizer_factory</span> <span class="kn">import</span> <span class="n">ModelOptimizerFactory</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.models</span> <span class="kn">import</span> <span class="n">MnistOptimizerFactory</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.train_eval_model</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">TrainEvalModel</span><span class="p">,</span>
    <span class="n">TrainSelfDistillationEvalModel</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.trained_model</span> <span class="kn">import</span> <span class="n">TrainedMCDropoutModel</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ExperimentData" class="doc_header"><code>class</code> <code>ExperimentData</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/uniform_target_ood_experiment.py#L48" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ExperimentData</code>(<strong><code>active_learning</code></strong>:<a href="/batchbald_redux/active_learning.html#ActiveLearningData"><code>ActiveLearningData</code></a>, <strong><code>ood_dataset</code></strong>:<a href="/batchbald_redux/dataset_challenges.html#NamedDataset"><code>NamedDataset</code></a>, <strong><code>validation_dataset</code></strong>:<code>Dataset</code>, <strong><code>test_dataset</code></strong>:<code>Dataset</code>, <strong><code>evaluation_dataset</code></strong>:<code>Dataset</code>, <strong><code>initial_training_set_indices</code></strong>:<code>[&lt;class 'int'&gt;]</code>, <strong><code>evaluation_set_indices</code></strong>:<code>[&lt;class 'int'&gt;]</code>)</p>
</blockquote>
<p>ExperimentData(active_learning: batchbald_redux.active_learning.ActiveLearningData, ood_dataset: batchbald_redux.dataset_challenges.NamedDataset, validation_dataset: torch.utils.data.dataset.Dataset, test_dataset: torch.utils.data.dataset.Dataset, evaluation_dataset: torch.utils.data.dataset.Dataset, initial_training_set_indices: [&lt;class 'int'&gt;], evaluation_set_indices: [&lt;class 'int'&gt;])</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="UniformTargetOodExperiment" class="doc_header"><code>class</code> <code>UniformTargetOodExperiment</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/uniform_target_ood_experiment.py#L59" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>UniformTargetOodExperiment</code>(<strong><code>seed</code></strong>:<code>int</code>=<em><code>1337</code></em>, <strong><code>acquisition_size</code></strong>:<code>int</code>=<em><code>5</code></em>, <strong><code>max_training_set</code></strong>:<code>int</code>=<em><code>450</code></em>, <strong><code>num_pool_samples</code></strong>:<code>int</code>=<em><code>20</code></em>, <strong><code>num_validation_samples</code></strong>:<code>int</code>=<em><code>20</code></em>, <strong><code>num_training_samples</code></strong>:<code>int</code>=<em><code>1</code></em>, <strong><code>num_patience_epochs</code></strong>:<code>int</code>=<em><code>3</code></em>, <strong><code>max_training_epochs</code></strong>:<code>int</code>=<em><code>30</code></em>, <strong><code>training_batch_size</code></strong>:<code>int</code>=<em><code>64</code></em>, <strong><code>device</code></strong>:<code>str</code>=<em><code>'cuda'</code></em>, <strong><code>validation_set_size</code></strong>:<code>int</code>=<em><code>1024</code></em>, <strong><code>evaluation_set_size</code></strong>:<code>int</code>=<em><code>100</code></em>, <strong><code>validation_split_random_state</code></strong>:<code>int</code>=<em><code>0</code></em>, <strong><code>initial_training_set_size</code></strong>:<code>int</code>=<em><code>20</code></em>, <strong><code>samples_per_epoch</code></strong>:<code>int</code>=<em><code>5056</code></em>, <strong><code>mnist_repetitions</code></strong>:<code>float</code>=<em><code>1</code></em>, <strong><code>ood_fmnist_repetitions</code></strong>:<code>float</code>=<em><code>1</code></em>, <strong><code>add_dataset_noise</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>acquisition_function</code></strong>:<code>Union</code>[<code>Type</code>[<a href="/batchbald_redux/acquisition_functions.html#CandidateBatchComputer"><code>CandidateBatchComputer</code></a>], <code>Type</code>[<a href="/batchbald_redux/acquisition_functions.html#EvalCandidateBatchComputer"><code>EvalCandidateBatchComputer</code></a>]]=<em><code>BALD</code></em>, <strong><code>train_eval_model</code></strong>:<a href="/batchbald_redux/train_eval_model.html#TrainEvalModel"><code>TrainEvalModel</code></a>=<em><code>TrainSelfDistillationEvalModel</code></em>, <strong><code>model_optimizer_factory</code></strong>:<code>Type</code>[<a href="/batchbald_redux/model_optimizer_factory.html#ModelOptimizerFactory"><code>ModelOptimizerFactory</code></a>]=<em><code>MnistOptimizerFactory</code></em>, <strong><code>acquisition_function_args</code></strong>:<code>dict</code>=<em><code>None</code></em>, <strong><code>temperature</code></strong>:<code>float</code>=<em><code>0.0</code></em>)</p>
</blockquote>
<p>UniformTargetOodExperiment(seed: int = 1337, acquisition_size: int = 5, max_training_set: int = 450, num_pool_samples: int = 20, num_validation_samples: int = 20, num_training_samples: int = 1, num_patience_epochs: int = 3, max_training_epochs: int = 30, training_batch_size: int = 64, device: str = 'cuda', validation_set_size: int = 1024, evaluation_set_size: int = 100, validation_split_random_state: int = 0, initial_training_set_size: int = 20, samples_per_epoch: int = 5056, mnist_repetitions: float = 1, ood_fmnist_repetitions: float = 1, add_dataset_noise: bool = False, acquisition_function: Union[Type[batchbald_redux.acquisition_functions.CandidateBatchComputer], Type[batchbald_redux.acquisition_functions.EvalCandidateBatchComputer]] = &lt;class 'batchbald_redux.acquisition_functions.BALD'&gt;, train_eval_model: batchbald_redux.train_eval_model.TrainEvalModel = &lt;class 'batchbald_redux.train_eval_model.TrainSelfDistillationEvalModel'&gt;, model_optimizer_factory: Type[batchbald_redux.model_optimizer_factory.ModelOptimizerFactory] = &lt;class 'batchbald_redux.models.MnistOptimizerFactory'&gt;, acquisition_function_args: dict = None, temperature: float = 0.0)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">ExperimentData</span><span class="p">:</span>
    <span class="n">active_learning</span><span class="p">:</span> <span class="n">ActiveLearningData</span>
    <span class="n">ood_dataset</span><span class="p">:</span> <span class="n">NamedDataset</span>
    <span class="n">validation_dataset</span><span class="p">:</span> <span class="n">Dataset</span>
    <span class="n">test_dataset</span><span class="p">:</span> <span class="n">Dataset</span>
    <span class="n">evaluation_dataset</span><span class="p">:</span> <span class="n">Dataset</span>
    <span class="n">initial_training_set_indices</span><span class="p">:</span> <span class="p">[</span><span class="nb">int</span><span class="p">]</span>
    <span class="n">evaluation_set_indices</span><span class="p">:</span> <span class="p">[</span><span class="nb">int</span><span class="p">]</span>


<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">UniformTargetOodExperiment</span><span class="p">:</span>
    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1337</span>
    <span class="n">acquisition_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">max_training_set</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">450</span>
    <span class="n">num_pool_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="n">num_validation_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="n">num_training_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">num_patience_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">max_training_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">30</span>
    <span class="n">training_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span>
    <span class="n">validation_set_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span>
    <span class="n">evaluation_set_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">*</span> <span class="mi">10</span>
    <span class="n">validation_split_random_state</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">initial_training_set_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="n">samples_per_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5056</span>
    <span class="n">mnist_repetitions</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">ood_fmnist_repetitions</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">add_dataset_noise</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">acquisition_function</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
        <span class="n">Type</span><span class="p">[</span><span class="n">CandidateBatchComputer</span><span class="p">],</span> <span class="n">Type</span><span class="p">[</span><span class="n">EvalCandidateBatchComputer</span><span class="p">]</span>
    <span class="p">]</span> <span class="o">=</span> <span class="n">acquisition_functions</span><span class="o">.</span><span class="n">BALD</span>
    <span class="n">train_eval_model</span><span class="p">:</span> <span class="n">TrainEvalModel</span> <span class="o">=</span> <span class="n">TrainSelfDistillationEvalModel</span>
    <span class="n">model_optimizer_factory</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">ModelOptimizerFactory</span><span class="p">]</span> <span class="o">=</span> <span class="n">MnistOptimizerFactory</span>
    <span class="n">acquisition_function_args</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">def</span> <span class="nf">load_experiment_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ExperimentData</span><span class="p">:</span>
        <span class="c1"># num_classes = 10, input_size = 28</span>
        <span class="n">full_train_dataset</span> <span class="o">=</span> <span class="n">NamedDataset</span><span class="p">(</span>
            <span class="n">FastMNIST</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="s2">&quot;FastMNIST (train)&quot;</span>
        <span class="p">)</span>

        <span class="n">ood_dataset</span> <span class="o">=</span> <span class="n">FastFashionMNIST</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">ood_dataset</span> <span class="o">=</span> <span class="n">NamedDataset</span><span class="p">(</span><span class="n">ood_dataset</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;OoD Dataset (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">ood_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples)&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ood_fmnist_repetitions</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">ood_dataset</span> <span class="o">=</span> <span class="n">ood_dataset</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">ood_fmnist_repetitions</span>

        <span class="n">train_dataset</span><span class="p">,</span> <span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">train_validation_split</span><span class="p">(</span>
            <span class="n">full_train_dataset</span><span class="o">=</span><span class="n">full_train_dataset</span><span class="p">,</span>
            <span class="n">full_validation_dataset</span><span class="o">=</span><span class="n">full_train_dataset</span><span class="p">,</span>
            <span class="n">train_labels</span><span class="o">=</span><span class="n">full_train_dataset</span><span class="o">.</span><span class="n">get_targets</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span>
            <span class="n">validation_set_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">validation_set_size</span><span class="p">,</span>
            <span class="n">validation_split_random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">validation_split_random_state</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">AliasDataset</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;FastMNIST (train; </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples)&quot;</span><span class="p">)</span>
        <span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">AliasDataset</span><span class="p">(</span>
            <span class="n">validation_dataset</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;FastMNIST (validation; </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">validation_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples)&quot;</span>
        <span class="p">)</span>

        <span class="c1"># If we reduce the train set, we need to do so before picking the initial train set.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mnist_repetitions</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mnist_repetitions</span>

        <span class="n">num_classes</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">get_num_classes</span><span class="p">()</span>
        <span class="n">initial_samples_per_class</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">initial_training_set_size</span> <span class="o">//</span> <span class="n">num_classes</span>
        <span class="n">evaluation_set_samples_per_class</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluation_set_size</span> <span class="o">//</span> <span class="n">num_classes</span>
        <span class="n">samples_per_class</span> <span class="o">=</span> <span class="n">initial_samples_per_class</span> <span class="o">+</span> <span class="n">evaluation_set_samples_per_class</span>
        <span class="n">balanced_samples_indices</span> <span class="o">=</span> <span class="n">get_balanced_sample_indices_by_class</span><span class="p">(</span>
            <span class="n">train_dataset</span><span class="p">,</span>
            <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span>
            <span class="n">samples_per_class</span><span class="o">=</span><span class="n">samples_per_class</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">validation_split_random_state</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">initial_training_set_indices</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">idx</span> <span class="k">for</span> <span class="n">by_class</span> <span class="ow">in</span> <span class="n">balanced_samples_indices</span><span class="o">.</span><span class="n">values</span><span class="p">()</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">by_class</span><span class="p">[:</span><span class="n">initial_samples_per_class</span><span class="p">]</span>
        <span class="p">]</span>
        <span class="n">evaluation_set_indices</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">idx</span> <span class="k">for</span> <span class="n">by_class</span> <span class="ow">in</span> <span class="n">balanced_samples_indices</span><span class="o">.</span><span class="n">values</span><span class="p">()</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">by_class</span><span class="p">[</span><span class="n">initial_samples_per_class</span><span class="p">:]</span>
        <span class="p">]</span>

        <span class="c1"># If we over-sample the train set, we do so after picking the initial train set to avoid duplicates.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mnist_repetitions</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mnist_repetitions</span>

        <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">+</span> <span class="n">ood_dataset</span><span class="o">.</span><span class="n">uniform_target</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_dataset_noise</span><span class="p">:</span>
            <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">AdditiveGaussianNoise</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>

        <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">FastMNIST</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">NamedDataset</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;FastMNIST (test, </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples)&quot;</span><span class="p">)</span>

        <span class="n">active_learning_data</span> <span class="o">=</span> <span class="n">ActiveLearningData</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>

        <span class="n">active_learning_data</span><span class="o">.</span><span class="n">acquire_base_indices</span><span class="p">(</span><span class="n">initial_training_set_indices</span><span class="p">)</span>
        <span class="n">evaluation_dataset</span> <span class="o">=</span> <span class="n">AliasDataset</span><span class="p">(</span>
            <span class="n">active_learning_data</span><span class="o">.</span><span class="n">extract_dataset_from_base_indices</span><span class="p">(</span><span class="n">evaluation_set_indices</span><span class="p">),</span>
            <span class="sa">f</span><span class="s2">&quot;Evaluation Set (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">evaluation_set_indices</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples)&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">ExperimentData</span><span class="p">(</span>
            <span class="n">active_learning</span><span class="o">=</span><span class="n">active_learning_data</span><span class="p">,</span>
            <span class="n">ood_dataset</span><span class="o">=</span><span class="n">ood_dataset</span><span class="p">,</span>
            <span class="n">validation_dataset</span><span class="o">=</span><span class="n">validation_dataset</span><span class="p">,</span>
            <span class="n">test_dataset</span><span class="o">=</span><span class="n">test_dataset</span><span class="p">,</span>
            <span class="n">evaluation_dataset</span><span class="o">=</span><span class="n">evaluation_dataset</span><span class="p">,</span>
            <span class="n">initial_training_set_indices</span><span class="o">=</span><span class="n">initial_training_set_indices</span><span class="p">,</span>
            <span class="n">evaluation_set_indices</span><span class="o">=</span><span class="n">evaluation_set_indices</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># Simple Dependency Injection</span>
    <span class="k">def</span> <span class="nf">create_acquisition_function</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">di</span> <span class="o">=</span> <span class="n">DependencyInjection</span><span class="p">(</span><span class="nb">vars</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">di</span><span class="o">.</span><span class="n">create_dataclass_type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">acquisition_function</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">create_train_eval_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">runtime_config</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TrainEvalModel</span><span class="p">:</span>
        <span class="n">config</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="nb">vars</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span> <span class="o">**</span><span class="n">runtime_config</span><span class="p">}</span>
        <span class="n">di</span> <span class="o">=</span> <span class="n">DependencyInjection</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="p">[])</span>
        <span class="k">return</span> <span class="n">di</span><span class="o">.</span><span class="n">create_dataclass_type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_eval_model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">store</span><span class="p">):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

        <span class="c1"># Active Learning setup</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_experiment_data</span><span class="p">()</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;dataset_info&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">training</span><span class="o">=</span><span class="nb">repr</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">base_dataset</span><span class="p">),</span> <span class="n">test</span><span class="o">=</span><span class="nb">repr</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">test_dataset</span><span class="p">))</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;initial_training_set_indices&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">initial_training_set_indices</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;evaluation_set_indices&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">evaluation_set_indices</span>

        <span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
            <span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">training_dataset</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training_batch_size</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">RandomFixedLengthSampler</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">training_dataset</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">samples_per_epoch</span><span class="p">),</span>
            <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">pool_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
            <span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">pool_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

        <span class="n">validation_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">validation_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;active_learning_steps&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">active_learning_steps</span> <span class="o">=</span> <span class="n">store</span><span class="p">[</span><span class="s2">&quot;active_learning_steps&quot;</span><span class="p">]</span>

        <span class="n">acquisition_function</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_acquisition_function</span><span class="p">()</span>

        <span class="c1"># Active Training Loop</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">training_set_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">training_dataset</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training set size </span><span class="si">{</span><span class="n">training_set_size</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>

            <span class="c1"># iteration_log = dict(training={}, pool_training={}, evaluation_metrics=None, acquisition=None)</span>
            <span class="n">active_learning_steps</span><span class="o">.</span><span class="n">append</span><span class="p">({})</span>
            <span class="n">iteration_log</span> <span class="o">=</span> <span class="n">active_learning_steps</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

            <span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;training&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

            <span class="n">model_optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_optimizer_factory</span><span class="p">()</span><span class="o">.</span><span class="n">create_model_optimizer</span><span class="p">()</span>

            <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">KLDivLoss</span><span class="p">(</span><span class="n">log_target</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;batchmean&quot;</span><span class="p">)</span>

            <span class="n">train</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">model_optimizer</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="n">model_optimizer</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span>
                <span class="n">training_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_training_samples</span><span class="p">,</span>
                <span class="n">validation_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_validation_samples</span><span class="p">,</span>
                <span class="n">train_loader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span>
                <span class="n">validation_loader</span><span class="o">=</span><span class="n">validation_loader</span><span class="p">,</span>
                <span class="n">patience</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_patience_epochs</span><span class="p">,</span>
                <span class="n">max_epochs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_training_epochs</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="n">training_log</span><span class="o">=</span><span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;training&quot;</span><span class="p">],</span>
                <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
                <span class="n">validation_loss</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">(),</span>
            <span class="p">)</span>

            <span class="n">evaluation_metrics</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">model_optimizer</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="n">num_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_validation_samples</span><span class="p">,</span>
                <span class="n">loader</span><span class="o">=</span><span class="n">test_loader</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;evaluation_metrics&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">evaluation_metrics</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Perf after training </span><span class="si">{</span><span class="n">evaluation_metrics</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">training_set_size</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_training_set</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Done.&quot;</span><span class="p">)</span>
                <span class="k">break</span>

            <span class="n">trained_model</span> <span class="o">=</span> <span class="n">TrainedMCDropoutModel</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_pool_samples</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model_optimizer</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">acquisition_function</span><span class="p">,</span> <span class="n">CandidateBatchComputer</span><span class="p">):</span>
                <span class="n">candidate_batch</span> <span class="o">=</span> <span class="n">acquisition_function</span><span class="o">.</span><span class="n">compute_candidate_batch</span><span class="p">(</span><span class="n">trained_model</span><span class="p">,</span> <span class="n">pool_loader</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">acquisition_function</span><span class="p">,</span> <span class="n">EvalCandidateBatchComputer</span><span class="p">):</span>
                <span class="n">current_max_epochs</span> <span class="o">=</span> <span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;training&quot;</span><span class="p">][</span><span class="s2">&quot;best_epoch&quot;</span><span class="p">]</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluation_set_size</span><span class="p">:</span>
                    <span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">evaluation_dataset</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">pool_dataset</span>

                <span class="n">train_eval_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_train_eval_model</span><span class="p">(</span>
                    <span class="nb">dict</span><span class="p">(</span>
                        <span class="n">max_epochs</span><span class="o">=</span><span class="n">current_max_epochs</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span>
                        <span class="n">training_dataset</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">training_dataset</span><span class="p">,</span>
                        <span class="n">eval_dataset</span><span class="o">=</span><span class="n">eval_dataset</span><span class="p">,</span>
                        <span class="n">validation_loader</span><span class="o">=</span><span class="n">validation_loader</span><span class="p">,</span>
                        <span class="n">trained_model</span><span class="o">=</span><span class="n">trained_model</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>

                <span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;eval_training&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="n">trained_eval_model</span> <span class="o">=</span> <span class="n">train_eval_model</span><span class="p">(</span><span class="n">training_log</span><span class="o">=</span><span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;eval_training&quot;</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

                <span class="n">candidate_batch</span> <span class="o">=</span> <span class="n">acquisition_function</span><span class="o">.</span><span class="n">compute_candidate_batch</span><span class="p">(</span>
                    <span class="n">trained_model</span><span class="p">,</span> <span class="n">trained_eval_model</span><span class="p">,</span> <span class="n">pool_loader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown acquisition function </span><span class="si">{</span><span class="n">acquisition_function</span><span class="si">}</span><span class="s2">!&quot;</span><span class="p">)</span>

            <span class="n">candidate_global_dataset_indices</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">candidate_labels</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">candidate_batch</span><span class="o">.</span><span class="n">indices</span><span class="p">:</span>
                <span class="n">base_di</span> <span class="o">=</span> <span class="n">get_base_dataset_index</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">pool_dataset</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span>
                <span class="n">dataset_type</span> <span class="o">=</span> <span class="s2">&quot;ood&quot;</span> <span class="k">if</span> <span class="n">base_di</span><span class="o">.</span><span class="n">dataset</span> <span class="o">==</span> <span class="n">data</span><span class="o">.</span><span class="n">ood_dataset</span> <span class="k">else</span> <span class="s2">&quot;id&quot;</span>
                <span class="n">candidate_global_dataset_indices</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">dataset_type</span><span class="p">,</span> <span class="n">base_di</span><span class="o">.</span><span class="n">index</span><span class="p">))</span>
                <span class="n">label</span> <span class="o">=</span> <span class="n">get_target</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">pool_dataset</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span>
                <span class="n">candidate_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>

            <span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;acquisition&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
                <span class="n">indices</span><span class="o">=</span><span class="n">candidate_global_dataset_indices</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">candidate_labels</span><span class="p">,</span> <span class="n">scores</span><span class="o">=</span><span class="n">candidate_batch</span><span class="o">.</span><span class="n">scores</span>
            <span class="p">)</span>

            <span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">acquire</span><span class="p">(</span><span class="n">candidate_batch</span><span class="o">.</span><span class="n">indices</span><span class="p">)</span>

            <span class="nb">print</span><span class="p">(</span><span class="n">candidate_batch</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">candidate_global_dataset_indices</span><span class="p">)</span>

            <span class="n">ls</span> <span class="o">=</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">score</span><span class="si">:</span><span class="s2">.4</span><span class="si">}</span><span class="s2">)&quot;</span> <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">candidate_labels</span><span class="p">,</span> <span class="n">candidate_batch</span><span class="o">.</span><span class="n">scores</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Acquiring (label, score)s: </span><span class="si">{</span><span class="n">ls</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">UniformTargetOodExperiment</span><span class="p">(</span><span class="n">mnist_repetitions</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span><span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load_experiment_data</span><span class="p">()</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">base_dataset</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>((FastMNIST (train; 58976 samples))~x0.1 | one_hot_targets{&#39;num_classes&#39;: 10}) + (&#39;OoD Dataset (60000 samples)&#39; | uniform_targets{&#39;num_classes&#39;: 10})</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">experiment</span> <span class="o">=</span> <span class="n">UniformTargetOodExperiment</span><span class="p">(</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">1120</span><span class="p">,</span>
    <span class="n">max_training_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">num_patience_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">max_training_set</span><span class="o">=</span><span class="mi">20</span><span class="o">+</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">acquisition_function</span><span class="o">=</span><span class="n">acquisition_functions</span><span class="o">.</span><span class="n">BALD</span><span class="p">,</span>
    <span class="n">acquisition_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">num_pool_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">mnist_repetitions</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">experiment</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>

<span class="n">experiment</span> <span class="o">=</span> <span class="n">UniformTargetOodExperiment</span><span class="p">(</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">1120</span><span class="p">,</span>
    <span class="n">max_training_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">num_patience_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">max_training_set</span><span class="o">=</span><span class="mi">20</span><span class="o">+</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">acquisition_function</span><span class="o">=</span><span class="n">acquisition_functions</span><span class="o">.</span><span class="n">EvalBALD</span><span class="p">,</span>
    <span class="n">acquisition_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">num_pool_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">mnist_repetitions</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">experiment</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Resolved: BALD with {&#39;acquisition_size&#39;: 10}
Creating: BALD(acquisition_size=10)
Training set size 20:
Epoch metrics: {&#39;accuracy&#39;: 0.6611328125, &#39;crossentropy&#39;: 2.279507040977478}
RestoringEarlyStopping: Restoring best parameters. (Score: -2.279507040977478)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.6939, &#39;crossentropy&#39;: 1.8995209411621095}
CandidateBatch(scores=[0.6928115487098694, 0.6924754567444324, 0.6923950463533401, 0.6923141628503799, 0.6922618746757507, 0.6921998299658298, 0.6921993028372526, 0.6921881128801033, 0.6921360490377992, 0.6921246605925262], indices=[28055, 44134, 1732, 13166, 3774, 39971, 49867, 27407, 33211, 4981])
[(&#39;id&#39;, 12186), (&#39;id&#39;, 20395), (&#39;id&#39;, 9592), (&#39;id&#39;, 4767), (&#39;id&#39;, 24248), (&#39;id&#39;, 14823), (&#39;id&#39;, 23357), (&#39;id&#39;, 48109), (&#39;id&#39;, 55653), (&#39;id&#39;, 7576)]
Acquiring (label, score)s: tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], device=&#39;cuda:0&#39;) (0.6928), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], device=&#39;cuda:0&#39;) (0.6925), tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], device=&#39;cuda:0&#39;) (0.6924), tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], device=&#39;cuda:0&#39;) (0.6923), tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], device=&#39;cuda:0&#39;) (0.6923), tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], device=&#39;cuda:0&#39;) (0.6922), tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], device=&#39;cuda:0&#39;) (0.6922), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], device=&#39;cuda:0&#39;) (0.6922), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], device=&#39;cuda:0&#39;) (0.6921), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], device=&#39;cuda:0&#39;) (0.6921)
Training set size 30:
Epoch metrics: {&#39;accuracy&#39;: 0.671875, &#39;crossentropy&#39;: 1.9831183552742004}
RestoringEarlyStopping: Restoring best parameters. (Score: -1.9831183552742004)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.7112, &#39;crossentropy&#39;: 1.9220587146759034}
Done.
Resolved: EvalBALD with {&#39;acquisition_size&#39;: 10}
Creating: EvalBALD(acquisition_size=10)
Training set size 20:
Epoch metrics: {&#39;accuracy&#39;: 0.6591796875, &#39;crossentropy&#39;: 2.298063039779663}
RestoringEarlyStopping: Restoring best parameters. (Score: -2.298063039779663)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.6933, &#39;crossentropy&#39;: 1.9134324710845947}
Resolved: TrainSelfDistillationEvalModel with {&#39;num_pool_samples&#39;: 2, &#39;num_training_samples&#39;: 1, &#39;num_validation_samples&#39;: 20, &#39;num_patience_epochs&#39;: 1, &#39;max_epochs&#39;: 1, &#39;training_dataset&#39;: &lt;torch.utils.data.dataset.Subset object at 0x7f1420089f40&gt;, &#39;eval_dataset&#39;: Evaluation Set (100 samples), &#39;validation_loader&#39;: &lt;torch.utils.data.dataloader.DataLoader object at 0x7f1420089af0&gt;, &#39;training_batch_size&#39;: 64, &#39;model_optimizer_factory&#39;: &lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, &#39;trained_model&#39;: TrainedMCDropoutModel(num_samples=2, model=BayesianMNISTCNN(
  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))
  (conv1_drop): ConsistentMCDropout2d(p=0.5)
  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
  (conv2_drop): ConsistentMCDropout2d(p=0.5)
  (fc1): Linear(in_features=1024, out_features=128, bias=True)
  (fc1_drop): ConsistentMCDropout(p=0.5)
  (fc2): Linear(in_features=128, out_features=10, bias=True)
)), &#39;samples_per_epoch&#39;: 5056}
Creating: TrainSelfDistillationEvalModel(num_pool_samples=2,num_training_samples=1,num_validation_samples=20,num_patience_epochs=1,max_epochs=1,training_dataset=&lt;torch.utils.data.dataset.Subset object at 0x7f1420089f40&gt;,eval_dataset=Evaluation Set (100 samples),validation_loader=&lt;torch.utils.data.dataloader.DataLoader object at 0x7f1420089af0&gt;,training_batch_size=64,model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;,trained_model=TrainedMCDropoutModel(num_samples=2, model=BayesianMNISTCNN(
  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))
  (conv1_drop): ConsistentMCDropout2d(p=0.5)
  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
  (conv2_drop): ConsistentMCDropout2d(p=0.5)
  (fc1): Linear(in_features=1024, out_features=128, bias=True)
  (fc1_drop): ConsistentMCDropout(p=0.5)
  (fc2): Linear(in_features=128, out_features=10, bias=True)
)),samples_per_epoch=5056)
Epoch metrics: {&#39;accuracy&#39;: 0.6005859375, &#39;crossentropy&#39;: 1.467793881893158}
RestoringEarlyStopping: Restoring best parameters. (Score: -1.467793881893158)
RestoringEarlyStopping: Restoring optimizer.
CandidateBatch(scores=[0.683699443936348, 0.6795189324766397, 0.6782244741916656, 0.6775030717253685, 0.6772962100803852, 0.6772275269031525, 0.677149573341012, 0.6770125590264797, 0.6770039573311806, 0.676617156714201], indices=[6747, 43819, 2764, 16924, 49048, 47858, 12736, 40279, 49723, 38716])
[(&#39;id&#39;, 10350), (&#39;id&#39;, 27315), (&#39;id&#39;, 2891), (&#39;id&#39;, 16856), (&#39;id&#39;, 56699), (&#39;id&#39;, 18905), (&#39;id&#39;, 16540), (&#39;id&#39;, 1448), (&#39;id&#39;, 4488), (&#39;id&#39;, 38960)]
Acquiring (label, score)s: tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], device=&#39;cuda:0&#39;) (0.6837), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], device=&#39;cuda:0&#39;) (0.6795), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], device=&#39;cuda:0&#39;) (0.6782), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], device=&#39;cuda:0&#39;) (0.6775), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], device=&#39;cuda:0&#39;) (0.6773), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], device=&#39;cuda:0&#39;) (0.6772), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device=&#39;cuda:0&#39;) (0.6771), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], device=&#39;cuda:0&#39;) (0.677), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device=&#39;cuda:0&#39;) (0.677), tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], device=&#39;cuda:0&#39;) (0.6766)
Training set size 30:
Epoch metrics: {&#39;accuracy&#39;: 0.6494140625, &#39;crossentropy&#39;: 2.4017910957336426}
RestoringEarlyStopping: Restoring best parameters. (Score: -2.4017910957336426)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.6843, &#39;crossentropy&#39;: 1.9613335731506347}
Done.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">results</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;dataset_info&#39;: {&#39;training&#39;: &#34;(FastMNIST (train; 58976 samples)) + (&#39;OoD Dataset (60000 samples)&#39; | constant_target{&#39;target&#39;: tensor(-1, device=&#39;cuda:0&#39;), &#39;num_classes&#39;: 10})&#34;,
  &#39;test&#39;: &#34;&#39;FastMNIST (test, 10000 samples)&#39;&#34;},
 &#39;initial_training_set_indices&#39;: [30392,
  53434,
  12640,
  8533,
  22304,
  37915,
  58226,
  44119,
  3091,
  14640,
  58125,
  39579,
  43812,
  53689,
  52296,
  46037,
  22015,
  40334,
  57520,
  43803],
 &#39;active_learning_steps&#39;: [{&#39;training&#39;: {&#39;epochs&#39;: [], &#39;best_epoch&#39;: None},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.1129,
    &#39;crossentropy&#39;: 2.35244740562439},
   &#39;acquisition&#39;: {&#39;indices&#39;: [(&#39;ood&#39;, 27822),
     (&#39;id&#39;, 32367),
     (&#39;id&#39;, 55086),
     (&#39;id&#39;, 53929),
     (&#39;id&#39;, 48696),
     (&#39;ood&#39;, 37815),
     (&#39;ood&#39;, 47304),
     (&#39;ood&#39;, 28667),
     (&#39;ood&#39;, 40866),
     (&#39;ood&#39;, 35119)],
    &#39;labels&#39;: [-1, 1, 7, 6, 2, -1, -1, -1, -1, -1],
    &#39;scores&#39;: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}},
  {&#39;training&#39;: {&#39;epochs&#39;: [], &#39;best_epoch&#39;: None},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.071,
    &#39;crossentropy&#39;: 2.376102001571655},
   &#39;acquisition&#39;: {&#39;indices&#39;: [(&#39;id&#39;, 41002),
     (&#39;id&#39;, 35972),
     (&#39;ood&#39;, 49270),
     (&#39;id&#39;, 37994),
     (&#39;id&#39;, 44052),
     (&#39;ood&#39;, 16809),
     (&#39;ood&#39;, 24609),
     (&#39;ood&#39;, 33944),
     (&#39;id&#39;, 58767),
     (&#39;id&#39;, 6319)],
    &#39;labels&#39;: [7, 0, -1, 7, 4, -1, -1, -1, 1, 7],
    &#39;scores&#39;: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}},
  {&#39;training&#39;: {&#39;epochs&#39;: [], &#39;best_epoch&#39;: None},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.111,
    &#39;crossentropy&#39;: 2.3350587436676027},
   &#39;acquisition&#39;: {&#39;indices&#39;: [(&#39;ood&#39;, 56587),
     (&#39;id&#39;, 20397),
     (&#39;id&#39;, 6873),
     (&#39;id&#39;, 56019),
     (&#39;id&#39;, 48733),
     (&#39;ood&#39;, 1957),
     (&#39;id&#39;, 26231),
     (&#39;ood&#39;, 14359),
     (&#39;id&#39;, 41930),
     (&#39;id&#39;, 1835)],
    &#39;labels&#39;: [-1, 3, 8, 8, 5, -1, 8, -1, 4, 6],
    &#39;scores&#39;: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}},
  {&#39;training&#39;: {&#39;epochs&#39;: [], &#39;best_epoch&#39;: None},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.1119,
    &#39;crossentropy&#39;: 2.3316191219329836},
   &#39;acquisition&#39;: {&#39;indices&#39;: [(&#39;id&#39;, 43865),
     (&#39;id&#39;, 53636),
     (&#39;id&#39;, 27693),
     (&#39;id&#39;, 35820),
     (&#39;id&#39;, 2731),
     (&#39;ood&#39;, 7893),
     (&#39;ood&#39;, 1823),
     (&#39;id&#39;, 31015),
     (&#39;ood&#39;, 39435),
     (&#39;ood&#39;, 14496)],
    &#39;labels&#39;: [3, 8, 1, 1, 1, -1, -1, 0, -1, -1],
    &#39;scores&#39;: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}},
  {&#39;training&#39;: {&#39;epochs&#39;: [], &#39;best_epoch&#39;: None},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.1152,
    &#39;crossentropy&#39;: 2.3408010501861574},
   &#39;acquisition&#39;: {&#39;indices&#39;: [(&#39;ood&#39;, 22190),
     (&#39;ood&#39;, 49199),
     (&#39;ood&#39;, 40750),
     (&#39;ood&#39;, 33436),
     (&#39;ood&#39;, 30495),
     (&#39;ood&#39;, 57037),
     (&#39;ood&#39;, 11806),
     (&#39;id&#39;, 13194),
     (&#39;id&#39;, 33972),
     (&#39;ood&#39;, 48450)],
    &#39;labels&#39;: [-1, -1, -1, -1, -1, -1, -1, 9, 5, -1],
    &#39;scores&#39;: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}},
  {&#39;training&#39;: {&#39;epochs&#39;: [], &#39;best_epoch&#39;: None},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.0855,
    &#39;crossentropy&#39;: 2.3611250312805176},
   &#39;acquisition&#39;: {&#39;indices&#39;: [(&#39;ood&#39;, 39262),
     (&#39;id&#39;, 34937),
     (&#39;id&#39;, 15956),
     (&#39;id&#39;, 1193),
     (&#39;id&#39;, 44982),
     (&#39;id&#39;, 24303),
     (&#39;id&#39;, 30815),
     (&#39;ood&#39;, 35232),
     (&#39;ood&#39;, 36119),
     (&#39;id&#39;, 17484)],
    &#39;labels&#39;: [-1, 1, 8, 8, 9, 2, 4, -1, -1, 6],
    &#39;scores&#39;: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}},
  {&#39;training&#39;: {&#39;epochs&#39;: [], &#39;best_epoch&#39;: None},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.0985,
    &#39;crossentropy&#39;: 2.33388900718689},
   &#39;acquisition&#39;: {&#39;indices&#39;: [(&#39;ood&#39;, 19019),
     (&#39;ood&#39;, 50212),
     (&#39;ood&#39;, 25348),
     (&#39;ood&#39;, 21148),
     (&#39;ood&#39;, 21958),
     (&#39;id&#39;, 28372),
     (&#39;ood&#39;, 4170),
     (&#39;id&#39;, 40862),
     (&#39;id&#39;, 6085),
     (&#39;ood&#39;, 4347)],
    &#39;labels&#39;: [-1, -1, -1, -1, -1, 5, -1, 6, 6, -1],
    &#39;scores&#39;: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}},
  {&#39;training&#39;: {&#39;epochs&#39;: [], &#39;best_epoch&#39;: None},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.1075,
    &#39;crossentropy&#39;: 2.3253658111572264},
   &#39;acquisition&#39;: {&#39;indices&#39;: [(&#39;ood&#39;, 5177),
     (&#39;id&#39;, 46455),
     (&#39;ood&#39;, 35272),
     (&#39;ood&#39;, 22434),
     (&#39;ood&#39;, 308),
     (&#39;ood&#39;, 16607),
     (&#39;id&#39;, 50405),
     (&#39;ood&#39;, 26672),
     (&#39;ood&#39;, 12838),
     (&#39;id&#39;, 21140)],
    &#39;labels&#39;: [-1, 6, -1, -1, -1, -1, 4, -1, -1, 4],
    &#39;scores&#39;: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}},
  {&#39;training&#39;: {&#39;epochs&#39;: [], &#39;best_epoch&#39;: None},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.1254,
    &#39;crossentropy&#39;: 2.3452716808319094},
   &#39;acquisition&#39;: {&#39;indices&#39;: [(&#39;ood&#39;, 21307),
     (&#39;id&#39;, 45937),
     (&#39;id&#39;, 35010),
     (&#39;ood&#39;, 3929),
     (&#39;ood&#39;, 49439),
     (&#39;ood&#39;, 26422),
     (&#39;id&#39;, 15513),
     (&#39;ood&#39;, 12990),
     (&#39;id&#39;, 46837),
     (&#39;ood&#39;, 43248)],
    &#39;labels&#39;: [-1, 7, 3, -1, -1, -1, 7, -1, 0, -1],
    &#39;scores&#39;: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}},
  {&#39;training&#39;: {&#39;epochs&#39;: [], &#39;best_epoch&#39;: None},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.0982,
    &#39;crossentropy&#39;: 2.338535634994507},
   &#39;acquisition&#39;: {&#39;indices&#39;: [(&#39;ood&#39;, 2970),
     (&#39;id&#39;, 33981),
     (&#39;id&#39;, 17247),
     (&#39;id&#39;, 28983),
     (&#39;id&#39;, 22921),
     (&#39;id&#39;, 43607),
     (&#39;ood&#39;, 8139),
     (&#39;id&#39;, 45633),
     (&#39;id&#39;, 48652),
     (&#39;ood&#39;, 46241)],
    &#39;labels&#39;: [-1, 9, 5, 3, 7, 7, -1, 6, 8, -1],
    &#39;scores&#39;: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}},
  {&#39;training&#39;: {&#39;epochs&#39;: [], &#39;best_epoch&#39;: None},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.1139,
    &#39;crossentropy&#39;: 2.3268737857818604},
   &#39;acquisition&#39;: {&#39;indices&#39;: [(&#39;ood&#39;, 5285),
     (&#39;ood&#39;, 33865),
     (&#39;ood&#39;, 26001),
     (&#39;id&#39;, 47531),
     (&#39;ood&#39;, 11312),
     (&#39;ood&#39;, 1265),
     (&#39;id&#39;, 56554),
     (&#39;id&#39;, 16369),
     (&#39;ood&#39;, 40025),
     (&#39;id&#39;, 19670)],
    &#39;labels&#39;: [-1, -1, -1, 2, -1, -1, 5, 7, -1, 5],
    &#39;scores&#39;: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}},
  {&#39;training&#39;: {&#39;epochs&#39;: [], &#39;best_epoch&#39;: None},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.0858,
    &#39;crossentropy&#39;: 2.340250019454956},
   &#39;acquisition&#39;: {&#39;indices&#39;: [(&#39;ood&#39;, 52831),
     (&#39;ood&#39;, 22388),
     (&#39;id&#39;, 17241),
     (&#39;ood&#39;, 20468),
     (&#39;id&#39;, 22538),
     (&#39;ood&#39;, 45415),
     (&#39;id&#39;, 56063),
     (&#39;id&#39;, 20651),
     (&#39;id&#39;, 52190),
     (&#39;id&#39;, 48078)],
    &#39;labels&#39;: [-1, -1, 2, -1, 1, -1, 5, 4, 5, 5],
    &#39;scores&#39;: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}},
  {&#39;training&#39;: {&#39;epochs&#39;: [], &#39;best_epoch&#39;: None},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.1047,
    &#39;crossentropy&#39;: 2.3441019859313963},
   &#39;acquisition&#39;: {&#39;indices&#39;: [(&#39;ood&#39;, 23255),
     (&#39;id&#39;, 49078),
     (&#39;id&#39;, 34456),
     (&#39;id&#39;, 7426),
     (&#39;id&#39;, 32375),
     (&#39;ood&#39;, 28384),
     (&#39;id&#39;, 53279),
     (&#39;ood&#39;, 46297),
     (&#39;id&#39;, 23174),
     (&#39;ood&#39;, 722)],
    &#39;labels&#39;: [-1, 4, 6, 4, 8, -1, 9, -1, 4, -1],
    &#39;scores&#39;: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}},
  {&#39;training&#39;: {&#39;epochs&#39;: [], &#39;best_epoch&#39;: None},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.1025,
    &#39;crossentropy&#39;: 2.3361153217315676},
   &#39;acquisition&#39;: {&#39;indices&#39;: [(&#39;ood&#39;, 56973),
     (&#39;ood&#39;, 12847),
     (&#39;ood&#39;, 52008),
     (&#39;ood&#39;, 35025),
     (&#39;id&#39;, 14647),
     (&#39;id&#39;, 48238),
     (&#39;id&#39;, 41955),
     (&#39;id&#39;, 44784),
     (&#39;id&#39;, 37767),
     (&#39;id&#39;, 5447)],
    &#39;labels&#39;: [-1, -1, -1, -1, 9, 2, 2, 2, 4, 7],
    &#39;scores&#39;: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}},
  {&#39;training&#39;: {&#39;epochs&#39;: [], &#39;best_epoch&#39;: None}}]}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">experiment</span> <span class="o">=</span> <span class="n">Experiment</span><span class="p">(</span>
    <span class="n">max_training_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_training_set</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">acquisition_function</span><span class="o">=</span><span class="n">AcquisitionFunction</span><span class="o">.</span><span class="n">randombaldical</span>
<span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">experiment</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>

<span class="n">results</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Training set size 20:
RestoringEarlyStopping: Restoring best parameters. (Score: -6.529030114412308)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.5367, &#39;crossentropy&#39;: 6.438035237884521}
RestoringEarlyStopping: Restoring best parameters. (Score: -5.1637596152722836)
RestoringEarlyStopping: Restoring optimizer.
Acquiring (label, score)s: 8 (0.8711), 8 (0.8687), 3 (0.876), 3 (0.8465), 3 (0.8811)
Training set size 25:
RestoringEarlyStopping: Restoring best parameters. (Score: -4.6851686127483845)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.6256, &#39;crossentropy&#39;: 4.484497045135498}
Done.
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;initial_training_set_indices&#39;: [38043,
  40091,
  17418,
  2094,
  39879,
  3133,
  5011,
  40683,
  54379,
  24287,
  9849,
  59305,
  39508,
  39356,
  8758,
  52579,
  13655,
  7636,
  21562,
  41329],
 &#39;active_learning_steps&#39;: [{&#39;training&#39;: {&#39;epochs&#39;: [{&#39;accuracy&#39;: 0.538818359375,
      &#39;crossentropy&#39;: 6.529030114412308}],
    &#39;best_epoch&#39;: 1},
   &#39;evalution_metrics&#39;: {&#39;accuracy&#39;: 0.5367,
    &#39;crossentropy&#39;: 6.438035237884521},
   &#39;pool_training&#39;: {&#39;epochs&#39;: [{&#39;accuracy&#39;: 0.531005859375,
      &#39;crossentropy&#39;: 5.1637596152722836}],
    &#39;best_epoch&#39;: 1},
   &#39;acquisition&#39;: {&#39;indices&#39;: [63338, 10856, 63452, 81864, 109287],
    &#39;labels&#39;: [8, 8, 3, 3, 3],
    &#39;scores&#39;: [0.8710822958846325,
     0.8687216999221631,
     0.8759664372823723,
     0.8464646732511746,
     0.8810812784952251]}},
  {&#39;training&#39;: {&#39;epochs&#39;: [{&#39;accuracy&#39;: 0.62255859375,
      &#39;crossentropy&#39;: 4.6851686127483845}],
    &#39;best_epoch&#39;: 1},
   &#39;evalution_metrics&#39;: {&#39;accuracy&#39;: 0.6256,
    &#39;crossentropy&#39;: 4.484497045135498}}]}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">configs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">UniformTargetOodExperiment</span><span class="p">(</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
        <span class="n">acquisition_function</span><span class="o">=</span><span class="n">acquisition_functions</span><span class="o">.</span><span class="n">TemperedEvalBALD</span><span class="p">,</span>
        <span class="n">acquisition_size</span><span class="o">=</span><span class="n">acquisition_size</span><span class="p">,</span>
        <span class="n">num_pool_samples</span><span class="o">=</span><span class="n">num_pool_samples</span><span class="p">,</span>
        <span class="n">temperature</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">acquisition_size</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">num_pool_samples</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">100</span><span class="p">]</span>
<span class="p">]</span> <span class="o">+</span> <span class="p">[</span>
    <span class="n">UniformTargetOodExperiment</span><span class="p">(</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
        <span class="n">acquisition_function</span><span class="o">=</span><span class="n">acquisition_functions</span><span class="o">.</span><span class="n">Random</span><span class="p">,</span>
        <span class="n">acquisition_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="p">]</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">is_run_from_ipython</span><span class="p">()</span> <span class="ow">and</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">job_id</span><span class="p">,</span> <span class="n">store</span> <span class="ow">in</span> <span class="n">embedded_experiments</span><span class="p">(</span><span class="vm">__file__</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">configs</span><span class="p">)):</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">configs</span><span class="p">[</span><span class="n">job_id</span><span class="p">]</span>
        <span class="n">config</span><span class="o">.</span><span class="n">seed</span> <span class="o">+=</span> <span class="n">job_id</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataclasses</span><span class="o">.</span><span class="n">asdict</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;log&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">config</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">store</span><span class="o">=</span><span class="n">store</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="n">store</span><span class="p">[</span><span class="s2">&quot;exception&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">traceback</span><span class="o">.</span><span class="n">format_exc</span><span class="p">()</span>
            <span class="k">raise</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">configs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>40</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">configs</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[RejectionOodExperiment(seed=0, acquisition_size=5, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.TemperedBALD&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=8),
 RejectionOodExperiment(seed=0, acquisition_size=10, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.TemperedBALD&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=8),
 RejectionOodExperiment(seed=0, acquisition_size=20, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.TemperedBALD&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=8),
 RejectionOodExperiment(seed=0, acquisition_size=50, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.TemperedBALD&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=8),
 RejectionOodExperiment(seed=1, acquisition_size=5, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.TemperedBALD&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=8),
 RejectionOodExperiment(seed=1, acquisition_size=10, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.TemperedBALD&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=8),
 RejectionOodExperiment(seed=1, acquisition_size=20, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.TemperedBALD&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=8),
 RejectionOodExperiment(seed=1, acquisition_size=50, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.TemperedBALD&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=8),
 RejectionOodExperiment(seed=2, acquisition_size=5, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.TemperedBALD&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=8),
 RejectionOodExperiment(seed=2, acquisition_size=10, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.TemperedBALD&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=8),
 RejectionOodExperiment(seed=2, acquisition_size=20, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.TemperedBALD&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=8),
 RejectionOodExperiment(seed=2, acquisition_size=50, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.TemperedBALD&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=8),
 RejectionOodExperiment(seed=3, acquisition_size=5, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.TemperedBALD&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=8),
 RejectionOodExperiment(seed=3, acquisition_size=10, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.TemperedBALD&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=8),
 RejectionOodExperiment(seed=3, acquisition_size=20, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.TemperedBALD&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=8),
 RejectionOodExperiment(seed=3, acquisition_size=50, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.TemperedBALD&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=8),
 RejectionOodExperiment(seed=4, acquisition_size=5, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.TemperedBALD&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=8),
 RejectionOodExperiment(seed=4, acquisition_size=10, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.TemperedBALD&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=8),
 RejectionOodExperiment(seed=4, acquisition_size=20, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.TemperedBALD&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=8),
 RejectionOodExperiment(seed=4, acquisition_size=50, max_training_set=450, num_pool_samples=50, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.TemperedBALD&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=8),
 RejectionOodExperiment(seed=0, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.Random&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=0.0),
 RejectionOodExperiment(seed=1, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.Random&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=0.0),
 RejectionOodExperiment(seed=2, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.Random&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=0.0),
 RejectionOodExperiment(seed=3, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.Random&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=0.0),
 RejectionOodExperiment(seed=4, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.Random&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=0.0),
 RejectionOodExperiment(seed=5, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.Random&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=0.0),
 RejectionOodExperiment(seed=6, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.Random&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=0.0),
 RejectionOodExperiment(seed=7, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.Random&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=0.0),
 RejectionOodExperiment(seed=8, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.Random&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=0.0),
 RejectionOodExperiment(seed=9, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.Random&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=0.0),
 RejectionOodExperiment(seed=10, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.Random&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=0.0),
 RejectionOodExperiment(seed=11, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.Random&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=0.0),
 RejectionOodExperiment(seed=12, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.Random&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=0.0),
 RejectionOodExperiment(seed=13, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.Random&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=0.0),
 RejectionOodExperiment(seed=14, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.Random&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=0.0),
 RejectionOodExperiment(seed=15, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.Random&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=0.0),
 RejectionOodExperiment(seed=16, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.Random&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=0.0),
 RejectionOodExperiment(seed=17, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.Random&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=0.0),
 RejectionOodExperiment(seed=18, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.Random&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=0.0),
 RejectionOodExperiment(seed=19, acquisition_size=5, max_training_set=450, num_pool_samples=20, num_eval_samples=20, num_training_samples=1, num_patience_epochs=3, max_training_epochs=30, training_batch_size=64, device=&#39;cuda&#39;, validation_set_size=1024, validation_split_random_state=0, initial_training_set_size=20, samples_per_epoch=5056, mnist_repetitions=1, ood_fmnist_repetitions=1, add_dataset_noise=False, acquisition_function=&lt;class &#39;batchbald_redux.acquisition_functions.Random&#39;&gt;, train_eval_model=&lt;class &#39;batchbald_redux.train_eval_model.TrainSelfDistillationPoolModel&#39;&gt;, model_optimizer_factory=&lt;class &#39;batchbald_redux.models.MnistOptimizerFactory&#39;&gt;, acquisition_function_args=None, temperature=0.0)]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

