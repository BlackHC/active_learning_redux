---

title: Experiment CIFAR-10


keywords: fastai
sidebar: home_sidebar

summary: "Can we get better by training on our assumptions?"
description: "Can we get better by training on our assumptions?"
nb_path: "09c_experiment_cifar10_ood_classes.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 09c_experiment_cifar10_ood_classes.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Appended /home/blackhc/PycharmProjects/bald-ical/src to paths
Switched to directory /home/blackhc/PycharmProjects/bald-ical
%load_ext autoreload
%autoreload 2
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Import modules and functions were are going to use.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">dataclasses</span>
<span class="kn">import</span> <span class="nn">traceback</span>

<span class="kn">from</span> <span class="nn">blackhc.project</span> <span class="kn">import</span> <span class="n">is_run_from_ipython</span>
<span class="kn">from</span> <span class="nn">blackhc.project.experiment</span> <span class="kn">import</span> <span class="n">embedded_experiments</span>

<span class="kn">import</span> <span class="nn">batchbald_redux.acquisition_functions.bald</span>
<span class="kn">import</span> <span class="nn">batchbald_redux.acquisition_functions.epig</span>
<span class="kn">from</span> <span class="nn">batchbald_redux</span> <span class="kn">import</span> <span class="n">acquisition_functions</span>
<span class="kn">from</span> <span class="nn">batchbald_redux</span> <span class="kn">import</span> <span class="n">baseline_acquisition_functions</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.experiment_data</span> <span class="kn">import</span> <span class="n">OODClassesDistributionExperimentDataConfig</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.unified_experiment</span> <span class="kn">import</span> <span class="n">UnifiedExperiment</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># (ID: air, automobile, ship and truck, OOD: bird, cat, deer, dog, frog and horse)</span>
<span class="c1"># ood_classes={2, 3, 4, 5, 6, 7}</span>

<span class="n">configs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">UnifiedExperiment</span><span class="p">(</span>
        <span class="n">experiment_data_config</span><span class="o">=</span><span class="n">OODClassesDistributionExperimentDataConfig</span><span class="p">(</span><span class="n">dataset_name</span><span class="o">=</span><span class="s2">&quot;CIFAR-10&quot;</span><span class="p">,</span> <span class="n">repetitions</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                                                          <span class="n">initial_training_set_size</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
                                                                          <span class="n">validation_set_size</span><span class="o">=</span><span class="mi">4000</span><span class="p">,</span>
                                                                          <span class="n">validation_split_random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                                                          <span class="n">evaluation_set_size</span><span class="o">=</span><span class="mi">4000</span><span class="p">,</span>
                                                                          <span class="n">add_dataset_noise</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                                          <span class="n">ood_exposure</span><span class="o">=</span><span class="n">ood_exposure</span><span class="p">,</span> <span class="n">ood_repetitions</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                                                          <span class="n">ood_classes</span><span class="o">=</span><span class="p">{</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">}),</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">seed</span> <span class="o">+</span> <span class="mi">4658</span><span class="p">,</span>
        <span class="n">acquisition_function</span><span class="o">=</span><span class="n">acquisition_function</span><span class="p">,</span>
        <span class="n">acquisition_size</span><span class="o">=</span><span class="n">acquisition_size</span><span class="p">,</span>
        <span class="n">num_pool_samples</span><span class="o">=</span><span class="n">num_pool_samples</span><span class="p">,</span>
        <span class="n">max_training_set</span><span class="o">=</span><span class="mi">11000</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">acquisition_function</span> <span class="ow">in</span> <span class="p">[</span>
        <span class="n">batchbald_redux</span><span class="o">.</span><span class="n">acquisition_functions</span><span class="o">.</span><span class="n">bald</span><span class="o">.</span><span class="n">BALD</span><span class="p">,</span>
        <span class="n">batchbald_redux</span><span class="o">.</span><span class="n">acquisition_functions</span><span class="o">.</span><span class="n">epig</span><span class="o">.</span><span class="n">EPIG</span><span class="p">,</span>
        <span class="n">batchbald_redux</span><span class="o">.</span><span class="n">acquisition_functions</span><span class="o">.</span><span class="n">epig</span><span class="o">.</span><span class="n">EvalBALD</span><span class="p">,</span>
        <span class="n">baseline_acquisition_functions</span><span class="o">.</span><span class="n">BADGE</span><span class="p">,</span>
        <span class="n">acquisition_functions</span><span class="o">.</span><span class="n">Random</span>
    <span class="p">]</span>
    <span class="k">for</span> <span class="n">acquisition_size</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">800</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">num_pool_samples</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">50</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">ood_exposure</span> <span class="ow">in</span> <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">]</span>
<span class="p">]</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">is_run_from_ipython</span><span class="p">()</span> <span class="ow">and</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">job_id</span><span class="p">,</span> <span class="n">store</span> <span class="ow">in</span> <span class="n">embedded_experiments</span><span class="p">(</span><span class="vm">__file__</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">configs</span><span class="p">)):</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">configs</span><span class="p">[</span><span class="n">job_id</span><span class="p">]</span>
        <span class="n">config</span><span class="o">.</span><span class="n">seed</span> <span class="o">+=</span> <span class="n">job_id</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataclasses</span><span class="o">.</span><span class="n">asdict</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;log&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">config</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">store</span><span class="o">=</span><span class="n">store</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="n">store</span><span class="p">[</span><span class="s2">&quot;exception&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">traceback</span><span class="o">.</span><span class="n">format_exc</span><span class="p">()</span>
            <span class="k">raise</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">configs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>50</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">prettyprinter</span>
<span class="n">prettyprinter</span><span class="o">.</span><span class="n">install_extras</span><span class="p">({</span><span class="s2">&quot;dataclasses&quot;</span><span class="p">})</span>
<span class="n">prettyprinter</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">configs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4658,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=False
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4658,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=True
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4658,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=False
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.EPIG
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4658,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=True
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.EPIG
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4658,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=False
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4658,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=True
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4658,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=False
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4658,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=True
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4658,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=False
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.Random
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4658,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=True
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.Random
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4659,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=False
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4659,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=True
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4659,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=False
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.EPIG
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4659,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=True
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.EPIG
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4659,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=False
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4659,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=True
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4659,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=False
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4659,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=True
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4659,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=False
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.Random
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4659,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=True
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.Random
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4660,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=False
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4660,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=True
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4660,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=False
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.EPIG
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4660,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=True
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.EPIG
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4660,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=False
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4660,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=True
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4660,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=False
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4660,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=True
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4660,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=False
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.Random
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4660,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=True
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.Random
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4661,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=False
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4661,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=True
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4661,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=False
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.EPIG
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4661,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=True
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.EPIG
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4661,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=False
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4661,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=True
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4661,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=False
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4661,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=True
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4661,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=False
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.Random
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4661,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=True
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.Random
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4662,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=False
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4662,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=True
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4662,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=False
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.EPIG
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4662,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=True
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.EPIG
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4662,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=False
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4662,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=True
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.EvalBALD
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4662,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=False
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4662,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=True
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.baseline_acquisition_functions.BADGE
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4662,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=False
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.Random
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=4662,
        experiment_data_config=batchbald_redux.experiment_data.OODClassesDistributionExperimentDataConfig(
            dataset_name=&#39;CIFAR-10&#39;,
            repetitions=1,
            initial_training_set_size=400,
            validation_set_size=4096,
            validation_split_random_state=0,
            evaluation_set_size=0,
            add_dataset_noise=False,
            ood_classes={2, 3, 4, 5, 6, 7},
            ood_repetitions=1,
            ood_exposure=True
        ),
        acquisition_size=1000,
        max_training_set=14000,
        num_pool_samples=50,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.Random
    )
]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">store</span><span class="o">=</span><span class="p">{}</span>

<span class="n">configs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max_training_set</span><span class="o">=</span><span class="mi">2000</span>
<span class="n">configs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">experiment_data_config</span><span class="o">.</span><span class="n">initial_training_set_size</span> <span class="o">=</span> <span class="mi">400</span> <span class="c1"># int(50000/10*4-1000)</span>
<span class="n">configs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max_training_epochs</span><span class="o">=</span><span class="mi">100</span>
<span class="n">configs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">num_pool_samples</span><span class="o">=</span><span class="mi">5</span>
<span class="n">configs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">store</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Files already downloaded and verified
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  return floored.astype(np.int)
/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  return floored.astype(np.int)
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Files already downloaded and verified
Initial Samples + Evaluation Set Class Counts: [100, 100, 0, 0, 0, 0, 0, 0, 100, 100]
Creating: BALD(
	acquisition_size=1000,
	num_pool_samples=5
)
Creating: Cifar10ModelTrainer(
	device=cuda,
	num_training_samples=1,
	num_validation_samples=20,
	max_training_epochs=100
)
Creating: TrainSelfDistillationEvalModel(
	num_pool_samples=5
)
Training set size 400:
Cosine Annealing
Epoch 1 metrics: {&#39;accuracy&#39;: 0.30073349633251834, &#39;crossentropy&#39;: 1.3872283714616211}
Epoch 2 metrics: {&#39;accuracy&#39;: 0.3105134474327628, &#39;crossentropy&#39;: 1.1799926874398603}
Epoch 3 metrics: {&#39;accuracy&#39;: 0.42053789731051344, &#39;crossentropy&#39;: 1.6877966684933687}
Epoch 4 metrics: {&#39;accuracy&#39;: 0.41442542787286063, &#39;crossentropy&#39;: 1.2925261637983811}
Epoch 5 metrics: {&#39;accuracy&#39;: 0.45843520782396086, &#39;crossentropy&#39;: 1.4012098525147567}
Epoch 6 metrics: {&#39;accuracy&#39;: 0.5660146699266504, &#39;crossentropy&#39;: 1.4557614230293516}
Epoch 7 metrics: {&#39;accuracy&#39;: 0.5403422982885085, &#39;crossentropy&#39;: 1.8126726727613902}
Epoch 8 metrics: {&#39;accuracy&#39;: 0.4798288508557457, &#39;crossentropy&#39;: 4.618074649703532}
Epoch 9 metrics: {&#39;accuracy&#39;: 0.5819070904645477, &#39;crossentropy&#39;: 2.0352678333926026}
Epoch 10 metrics: {&#39;accuracy&#39;: 0.6124694376528117, &#39;crossentropy&#39;: 2.0051721608434736}
Epoch 11 metrics: {&#39;accuracy&#39;: 0.562958435207824, &#39;crossentropy&#39;: 2.974486264739468}
Epoch 12 metrics: {&#39;accuracy&#39;: 0.5831295843520783, &#39;crossentropy&#39;: 3.7229617571772455}
Epoch 13 metrics: {&#39;accuracy&#39;: 0.5519559902200489, &#39;crossentropy&#39;: 2.5797506352217097}
Epoch 14 metrics: {&#39;accuracy&#39;: 0.6167481662591687, &#39;crossentropy&#39;: 2.5558329526253027}
Epoch 15 metrics: {&#39;accuracy&#39;: 0.6246943765281173, &#39;crossentropy&#39;: 2.5420569519541956}
Epoch 16 metrics: {&#39;accuracy&#39;: 0.5971882640586798, &#39;crossentropy&#39;: 2.4278879276406213}
Epoch 17 metrics: {&#39;accuracy&#39;: 0.6344743276283619, &#39;crossentropy&#39;: 2.3528265154449164}
Epoch 18 metrics: {&#39;accuracy&#39;: 0.6069682151589242, &#39;crossentropy&#39;: 2.6095094593346557}
Epoch 19 metrics: {&#39;accuracy&#39;: 0.6424205378973105, &#39;crossentropy&#39;: 2.882796347141266}
Epoch 20 metrics: {&#39;accuracy&#39;: 0.6246943765281173, &#39;crossentropy&#39;: 2.999511447687312}
Epoch 21 metrics: {&#39;accuracy&#39;: 0.6259168704156479, &#39;crossentropy&#39;: 2.531711501422313}
Epoch 22 metrics: {&#39;accuracy&#39;: 0.6613691931540342, &#39;crossentropy&#39;: 2.3327819636515126}
Epoch 23 metrics: {&#39;accuracy&#39;: 0.6485330073349633, &#39;crossentropy&#39;: 2.495934001390975}
Epoch 24 metrics: {&#39;accuracy&#39;: 0.6528117359413202, &#39;crossentropy&#39;: 2.5606804791755957}
Epoch 25 metrics: {&#39;accuracy&#39;: 0.6393643031784841, &#39;crossentropy&#39;: 2.6216873341492746}
Epoch 26 metrics: {&#39;accuracy&#39;: 0.6479217603911981, &#39;crossentropy&#39;: 2.8604430062263693}
Epoch 27 metrics: {&#39;accuracy&#39;: 0.6191931540342298, &#39;crossentropy&#39;: 2.462630896813129}
Epoch 28 metrics: {&#39;accuracy&#39;: 0.6332518337408313, &#39;crossentropy&#39;: 2.1764630519381947}
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Exception ignored in: &lt;function tqdm.__del__ at 0x7fdf9b2e5f70&gt;
Traceback (most recent call last):
  File &#34;/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/tqdm/std.py&#34;, line 1134, in __del__
    def __del__(self):
KeyboardInterrupt: 
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 29 metrics: {&#39;accuracy&#39;: 0.6723716381418093, &#39;crossentropy&#39;: 2.192221565759561}
Epoch 30 metrics: {&#39;accuracy&#39;: 0.6595354523227384, &#39;crossentropy&#39;: 2.6499609072808825}
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Engine run is terminating due to exception: .
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-7-6f14b027d3e0&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">      5</span> configs<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>max_training_epochs<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">100</span>
<span class="ansi-green-intense-fg ansi-bold">      6</span> configs<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>num_pool_samples<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">5</span>
<span class="ansi-green-fg">----&gt; 7</span><span class="ansi-red-fg"> </span>configs<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>run<span class="ansi-blue-fg">(</span>store<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/unified_experiment.py</span> in <span class="ansi-cyan-fg">run</span><span class="ansi-blue-fg">(self, store)</span>
<span class="ansi-green-intense-fg ansi-bold">    252</span>         )
<span class="ansi-green-intense-fg ansi-bold">    253</span> 
<span class="ansi-green-fg">--&gt; 254</span><span class="ansi-red-fg">         </span>active_learner<span class="ansi-blue-fg">(</span>store<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    255</span> 
<span class="ansi-green-intense-fg ansi-bold">    256</span> <span class="ansi-red-fg"># Cell</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/unified_experiment.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, log)</span>
<span class="ansi-green-intense-fg ansi-bold">    100</span>                 loss <span class="ansi-blue-fg">=</span> validation_loss <span class="ansi-blue-fg">=</span> torch<span class="ansi-blue-fg">.</span>nn<span class="ansi-blue-fg">.</span>NLLLoss<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    101</span> 
<span class="ansi-green-fg">--&gt; 102</span><span class="ansi-red-fg">             trained_model = model_trainer.get_trained(
</span><span class="ansi-green-intense-fg ansi-bold">    103</span>                 train_loader<span class="ansi-blue-fg">=</span>train_loader<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    104</span>                 train_augmentations<span class="ansi-blue-fg">=</span>data<span class="ansi-blue-fg">.</span>train_augmentations<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/resnet_models.py</span> in <span class="ansi-cyan-fg">get_trained</span><span class="ansi-blue-fg">(self, train_loader, train_augmentations, validation_loader, log, loss, validation_loss)</span>
<span class="ansi-green-intense-fg ansi-bold">    400</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    401</span>             print<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#34;Cosine Annealing&#34;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 402</span><span class="ansi-red-fg">             train_with_cosine_annealing(
</span><span class="ansi-green-intense-fg ansi-bold">    403</span>                 model<span class="ansi-blue-fg">=</span>model_optimizer<span class="ansi-blue-fg">.</span>model<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    404</span>                 optimizer<span class="ansi-blue-fg">=</span>model_optimizer<span class="ansi-blue-fg">.</span>optimizer<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/black_box_model_training.py</span> in <span class="ansi-cyan-fg">train_with_cosine_annealing</span><span class="ansi-blue-fg">(model, training_samples, validation_samples, train_loader, validation_loader, max_epochs, device, training_log, loss, validation_loss, optimizer, train_augmentations)</span>
<span class="ansi-green-intense-fg ansi-bold">    346</span> 
<span class="ansi-green-intense-fg ansi-bold">    347</span>     <span class="ansi-red-fg"># Kick everything off</span>
<span class="ansi-green-fg">--&gt; 348</span><span class="ansi-red-fg">     </span>trainer<span class="ansi-blue-fg">.</span>run<span class="ansi-blue-fg">(</span>train_loader<span class="ansi-blue-fg">,</span> max_epochs<span class="ansi-blue-fg">=</span>max_epochs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    349</span> 
<span class="ansi-green-intense-fg ansi-bold">    350</span>     <span class="ansi-red-fg"># Return the optimizer in case we want to continue training.</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">run</span><span class="ansi-blue-fg">(self, data, max_epochs, epoch_length, seed)</span>
<span class="ansi-green-intense-fg ansi-bold">    689</span> 
<span class="ansi-green-intense-fg ansi-bold">    690</span>         self<span class="ansi-blue-fg">.</span>state<span class="ansi-blue-fg">.</span>dataloader <span class="ansi-blue-fg">=</span> data
<span class="ansi-green-fg">--&gt; 691</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_internal_run<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    692</span> 
<span class="ansi-green-intense-fg ansi-bold">    693</span>     <span class="ansi-blue-fg">@</span>staticmethod

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">_internal_run</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    760</span>             self<span class="ansi-blue-fg">.</span>_dataloader_iter <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span>
<span class="ansi-green-intense-fg ansi-bold">    761</span>             self<span class="ansi-blue-fg">.</span>logger<span class="ansi-blue-fg">.</span>error<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#34;Engine run is terminating due to exception: %s.&#34;</span><span class="ansi-blue-fg">,</span> str<span class="ansi-blue-fg">(</span>e<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 762</span><span class="ansi-red-fg">             </span>self<span class="ansi-blue-fg">.</span>_handle_exception<span class="ansi-blue-fg">(</span>e<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    763</span> 
<span class="ansi-green-intense-fg ansi-bold">    764</span>         self<span class="ansi-blue-fg">.</span>_dataloader_iter <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">_handle_exception</span><span class="ansi-blue-fg">(self, e)</span>
<span class="ansi-green-intense-fg ansi-bold">    465</span>             self<span class="ansi-blue-fg">.</span>_fire_event<span class="ansi-blue-fg">(</span>Events<span class="ansi-blue-fg">.</span>EXCEPTION_RAISED<span class="ansi-blue-fg">,</span> e<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    466</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 467</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">raise</span> e
<span class="ansi-green-intense-fg ansi-bold">    468</span> 
<span class="ansi-green-intense-fg ansi-bold">    469</span>     <span class="ansi-blue-fg">@</span>property

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">_internal_run</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    728</span>                     self<span class="ansi-blue-fg">.</span>_setup_engine<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    729</span> 
<span class="ansi-green-fg">--&gt; 730</span><span class="ansi-red-fg">                 </span>time_taken <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_run_once_on_dataset<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    731</span>                 <span class="ansi-red-fg"># time is available for handlers but must be update after fire</span>
<span class="ansi-green-intense-fg ansi-bold">    732</span>                 self<span class="ansi-blue-fg">.</span>state<span class="ansi-blue-fg">.</span>times<span class="ansi-blue-fg">[</span>Events<span class="ansi-blue-fg">.</span>EPOCH_COMPLETED<span class="ansi-blue-fg">.</span>name<span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> time_taken

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">_run_once_on_dataset</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    809</span>                 self<span class="ansi-blue-fg">.</span>state<span class="ansi-blue-fg">.</span>iteration <span class="ansi-blue-fg">+=</span> <span class="ansi-cyan-fg">1</span>
<span class="ansi-green-intense-fg ansi-bold">    810</span>                 self<span class="ansi-blue-fg">.</span>_fire_event<span class="ansi-blue-fg">(</span>Events<span class="ansi-blue-fg">.</span>ITERATION_STARTED<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 811</span><span class="ansi-red-fg">                 </span>self<span class="ansi-blue-fg">.</span>state<span class="ansi-blue-fg">.</span>output <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_process_function<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>state<span class="ansi-blue-fg">.</span>batch<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    812</span>                 self<span class="ansi-blue-fg">.</span>_fire_event<span class="ansi-blue-fg">(</span>Events<span class="ansi-blue-fg">.</span>ITERATION_COMPLETED<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    813</span> 

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/__init__.py</span> in <span class="ansi-cyan-fg">_update</span><span class="ansi-blue-fg">(engine, batch)</span>
<span class="ansi-green-intense-fg ansi-bold">     97</span>         optimizer<span class="ansi-blue-fg">.</span>zero_grad<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     98</span>         x<span class="ansi-blue-fg">,</span> y <span class="ansi-blue-fg">=</span> prepare_batch<span class="ansi-blue-fg">(</span>batch<span class="ansi-blue-fg">,</span> device<span class="ansi-blue-fg">=</span>device<span class="ansi-blue-fg">,</span> non_blocking<span class="ansi-blue-fg">=</span>non_blocking<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 99</span><span class="ansi-red-fg">         </span>y_pred <span class="ansi-blue-fg">=</span> model<span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    100</span>         loss <span class="ansi-blue-fg">=</span> loss_fn<span class="ansi-blue-fg">(</span>y_pred<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    101</span>         loss<span class="ansi-blue-fg">.</span>backward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_call_impl</span><span class="ansi-blue-fg">(self, *input, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    725</span>             result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_slow_forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    726</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 727</span><span class="ansi-red-fg">             </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    728</span>         for hook in itertools.chain(
<span class="ansi-green-intense-fg ansi-bold">    729</span>                 _global_forward_hooks<span class="ansi-blue-fg">.</span>values<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/nn/modules/container.py</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">(self, input)</span>
<span class="ansi-green-intense-fg ansi-bold">    115</span>     <span class="ansi-green-fg">def</span> forward<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> input<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    116</span>         <span class="ansi-green-fg">for</span> module <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 117</span><span class="ansi-red-fg">             </span>input <span class="ansi-blue-fg">=</span> module<span class="ansi-blue-fg">(</span>input<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    118</span>         <span class="ansi-green-fg">return</span> input
<span class="ansi-green-intense-fg ansi-bold">    119</span> 

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_call_impl</span><span class="ansi-blue-fg">(self, *input, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    725</span>             result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_slow_forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    726</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 727</span><span class="ansi-red-fg">             </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    728</span>         for hook in itertools.chain(
<span class="ansi-green-intense-fg ansi-bold">    729</span>                 _global_forward_hooks<span class="ansi-blue-fg">.</span>values<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/nn/modules/container.py</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">(self, input)</span>
<span class="ansi-green-intense-fg ansi-bold">    115</span>     <span class="ansi-green-fg">def</span> forward<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> input<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    116</span>         <span class="ansi-green-fg">for</span> module <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 117</span><span class="ansi-red-fg">             </span>input <span class="ansi-blue-fg">=</span> module<span class="ansi-blue-fg">(</span>input<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    118</span>         <span class="ansi-green-fg">return</span> input
<span class="ansi-green-intense-fg ansi-bold">    119</span> 

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_call_impl</span><span class="ansi-blue-fg">(self, *input, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    725</span>             result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_slow_forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    726</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 727</span><span class="ansi-red-fg">             </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    728</span>         for hook in itertools.chain(
<span class="ansi-green-intense-fg ansi-bold">    729</span>                 _global_forward_hooks<span class="ansi-blue-fg">.</span>values<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/kornia/augmentation/base.py</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">(self, input, params, return_transform)</span>
<span class="ansi-green-intense-fg ansi-bold">    243</span> 
<span class="ansi-green-intense-fg ansi-bold">    244</span>         self<span class="ansi-blue-fg">.</span>_params <span class="ansi-blue-fg">=</span> params
<span class="ansi-green-fg">--&gt; 245</span><span class="ansi-red-fg">         </span>output <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>apply_func<span class="ansi-blue-fg">(</span>in_tensor<span class="ansi-blue-fg">,</span> in_transform<span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>_params<span class="ansi-blue-fg">,</span> return_transform<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    246</span>         <span class="ansi-green-fg">return</span> _transform_output_shape<span class="ansi-blue-fg">(</span>output<span class="ansi-blue-fg">,</span> ori_shape<span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>keepdim <span class="ansi-green-fg">else</span> output
<span class="ansi-green-intense-fg ansi-bold">    247</span> 

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/kornia/augmentation/base.py</span> in <span class="ansi-cyan-fg">apply_func</span><span class="ansi-blue-fg">(self, in_tensor, in_transform, params, return_transform)</span>
<span class="ansi-green-intense-fg ansi-bold">    207</span>             output <span class="ansi-blue-fg">=</span> in_tensor<span class="ansi-blue-fg">.</span>clone<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    208</span>             trans_matrix <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>identity_matrix<span class="ansi-blue-fg">(</span>in_tensor<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 209</span><span class="ansi-red-fg">             </span>trans_matrix<span class="ansi-blue-fg">[</span>to_apply<span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>compute_transformation<span class="ansi-blue-fg">(</span>in_tensor<span class="ansi-blue-fg">[</span>to_apply<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span> params<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    210</span>             output<span class="ansi-blue-fg">[</span>to_apply<span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>apply_transform<span class="ansi-blue-fg">(</span>in_tensor<span class="ansi-blue-fg">[</span>to_apply<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span> params<span class="ansi-blue-fg">,</span> trans_matrix<span class="ansi-blue-fg">[</span>to_apply<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    211</span> 

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

