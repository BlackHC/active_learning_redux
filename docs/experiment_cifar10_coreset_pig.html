---

title: Experiment CIFAR-10: CoreSetPIG & CoreSetPIGBALD


keywords: fastai
sidebar: home_sidebar

summary: "Can we get better by training on our assumptions?"
description: "Can we get better by training on our assumptions?"
nb_path: "09b_experiment_cifar10_coreset_pig.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 09b_experiment_cifar10_coreset_pig.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Appended /home/blackhc/PycharmProjects/bald-ical/src to paths
Switched to directory /home/blackhc/PycharmProjects/bald-ical
%load_ext autoreload
%autoreload 2
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Import modules and functions were are going to use.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">dataclasses</span>
<span class="kn">import</span> <span class="nn">traceback</span>

<span class="kn">from</span> <span class="nn">blackhc.project</span> <span class="kn">import</span> <span class="n">is_run_from_ipython</span>
<span class="kn">from</span> <span class="nn">blackhc.project.experiment</span> <span class="kn">import</span> <span class="n">embedded_experiments</span>

<span class="kn">import</span> <span class="nn">batchbald_redux.acquisition_functions.bald</span>
<span class="kn">import</span> <span class="nn">batchbald_redux.acquisition_functions.coreset</span>
<span class="kn">from</span> <span class="nn">batchbald_redux</span> <span class="kn">import</span> <span class="n">acquisition_functions</span><span class="p">,</span> <span class="n">baseline_acquisition_functions</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.experiment_data</span> <span class="kn">import</span> <span class="n">StandardExperimentDataConfig</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.unified_experiment</span> <span class="kn">import</span> <span class="n">UnifiedExperiment</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.train_eval_model</span> <span class="kn">import</span> <span class="n">TrainExplicitEvalModel</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.resnet_models</span> <span class="kn">import</span> <span class="n">Cifar10ModelWorkshopPaperTrainer</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">configs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">UnifiedExperiment</span><span class="p">(</span>
        <span class="n">experiment_data_config</span><span class="o">=</span><span class="n">StandardExperimentDataConfig</span><span class="p">(</span>
            <span class="n">id_dataset_name</span><span class="o">=</span><span class="s2">&quot;CIFAR-10&quot;</span><span class="p">,</span>
            <span class="n">id_repetitions</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">initial_training_set_size</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">validation_set_size</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span>
            <span class="n">validation_split_random_state</span><span class="o">=</span><span class="n">seed</span> <span class="o">+</span> <span class="mi">8945</span><span class="p">,</span>
            <span class="n">evaluation_set_size</span><span class="o">=</span><span class="mi">20000</span><span class="p">,</span>
            <span class="n">add_dataset_noise</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">ood_dataset_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">seed</span> <span class="o">+</span> <span class="mi">8945</span><span class="p">,</span>
        <span class="n">acquisition_function</span><span class="o">=</span><span class="n">acquisition_function</span><span class="p">,</span>
        <span class="n">acquisition_size</span><span class="o">=</span><span class="n">acquisition_size</span><span class="p">,</span>
        <span class="n">num_pool_samples</span><span class="o">=</span><span class="n">num_pool_samples</span><span class="p">,</span>
        <span class="n">max_training_set</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
        <span class="n">train_eval_model</span><span class="o">=</span><span class="n">TrainExplicitEvalModel</span><span class="p">,</span>
        <span class="n">ensemble_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">disable_training_augmentations</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">cache_explicit_eval_model</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">model_trainer_factory</span><span class="o">=</span><span class="n">Cifar10ModelWorkshopPaperTrainer</span>
    <span class="p">)</span>
    <span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">acquisition_size</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">num_pool_samples</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">100</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">acquisition_function</span> <span class="ow">in</span> <span class="p">[</span>
        <span class="n">batchbald_redux</span><span class="o">.</span><span class="n">acquisition_functions</span><span class="o">.</span><span class="n">coreset</span><span class="o">.</span><span class="n">CoreSetPIGBALD</span><span class="p">,</span>
        <span class="n">batchbald_redux</span><span class="o">.</span><span class="n">acquisition_functions</span><span class="o">.</span><span class="n">bald</span><span class="o">.</span><span class="n">BALD</span><span class="p">,</span>
        <span class="n">batchbald_redux</span><span class="o">.</span><span class="n">acquisition_functions</span><span class="o">.</span><span class="n">coreset</span><span class="o">.</span><span class="n">CoreSetPIG</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">]</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">is_run_from_ipython</span><span class="p">()</span> <span class="ow">and</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">job_id</span><span class="p">,</span> <span class="n">store</span> <span class="ow">in</span> <span class="n">embedded_experiments</span><span class="p">(</span><span class="vm">__file__</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">configs</span><span class="p">)):</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">configs</span><span class="p">[</span><span class="n">job_id</span><span class="p">]</span>
        <span class="n">config</span><span class="o">.</span><span class="n">seed</span> <span class="o">+=</span> <span class="n">job_id</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataclasses</span><span class="o">.</span><span class="n">asdict</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;log&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">config</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">store</span><span class="o">=</span><span class="n">store</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="n">store</span><span class="p">[</span><span class="s2">&quot;exception&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">traceback</span><span class="o">.</span><span class="n">format_exc</span><span class="p">()</span>
            <span class="k">raise</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">configs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>15</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">prettyprinter</span>

<span class="n">prettyprinter</span><span class="o">.</span><span class="n">install_extras</span><span class="p">({</span><span class="s2">&quot;dataclasses&quot;</span><span class="p">})</span>
<span class="n">prettyprinter</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">configs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8945,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=0,
            validation_set_size=5000,
            validation_split_random_state=8945,
            evaluation_set_size=25000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.CoreSetPIGBALD,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        disable_training_augmentations=True,
        cache_explicit_eval_model=True
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8945,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=0,
            validation_set_size=5000,
            validation_split_random_state=8945,
            evaluation_set_size=25000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        disable_training_augmentations=True,
        cache_explicit_eval_model=True
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8945,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=0,
            validation_set_size=5000,
            validation_split_random_state=8945,
            evaluation_set_size=25000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.CoreSetPIG,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        disable_training_augmentations=True,
        cache_explicit_eval_model=True
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8946,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=0,
            validation_set_size=5000,
            validation_split_random_state=8946,
            evaluation_set_size=25000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.CoreSetPIGBALD,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        disable_training_augmentations=True,
        cache_explicit_eval_model=True
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8946,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=0,
            validation_set_size=5000,
            validation_split_random_state=8946,
            evaluation_set_size=25000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        disable_training_augmentations=True,
        cache_explicit_eval_model=True
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8946,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=0,
            validation_set_size=5000,
            validation_split_random_state=8946,
            evaluation_set_size=25000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.CoreSetPIG,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        disable_training_augmentations=True,
        cache_explicit_eval_model=True
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8947,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=0,
            validation_set_size=5000,
            validation_split_random_state=8947,
            evaluation_set_size=25000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.CoreSetPIGBALD,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        disable_training_augmentations=True,
        cache_explicit_eval_model=True
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8947,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=0,
            validation_set_size=5000,
            validation_split_random_state=8947,
            evaluation_set_size=25000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        disable_training_augmentations=True,
        cache_explicit_eval_model=True
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8947,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=0,
            validation_set_size=5000,
            validation_split_random_state=8947,
            evaluation_set_size=25000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.CoreSetPIG,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        disable_training_augmentations=True,
        cache_explicit_eval_model=True
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8948,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=0,
            validation_set_size=5000,
            validation_split_random_state=8948,
            evaluation_set_size=25000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.CoreSetPIGBALD,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        disable_training_augmentations=True,
        cache_explicit_eval_model=True
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8948,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=0,
            validation_set_size=5000,
            validation_split_random_state=8948,
            evaluation_set_size=25000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        disable_training_augmentations=True,
        cache_explicit_eval_model=True
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8948,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=0,
            validation_set_size=5000,
            validation_split_random_state=8948,
            evaluation_set_size=25000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.CoreSetPIG,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        disable_training_augmentations=True,
        cache_explicit_eval_model=True
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8949,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=0,
            validation_set_size=5000,
            validation_split_random_state=8949,
            evaluation_set_size=25000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.CoreSetPIGBALD,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        disable_training_augmentations=True,
        cache_explicit_eval_model=True
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8949,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=0,
            validation_set_size=5000,
            validation_split_random_state=8949,
            evaluation_set_size=25000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        disable_training_augmentations=True,
        cache_explicit_eval_model=True
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8949,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;CIFAR-10&#39;,
            id_repetitions=1,
            initial_training_set_size=0,
            validation_set_size=5000,
            validation_split_random_state=8949,
            evaluation_set_size=25000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.CoreSetPIG,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        # class
        model_trainer_factory=batchbald_redux.resnet_models.Cifar10ModelWorkshopPaperTrainer,
        disable_training_augmentations=True,
        cache_explicit_eval_model=True
    )
]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">store</span> <span class="o">=</span> <span class="p">{}</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">configs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">config</span><span class="o">.</span><span class="n">max_training_epochs</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">config</span><span class="o">.</span><span class="n">num_pool_samples</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">config</span><span class="o">.</span><span class="n">experiment_data_config</span><span class="o">.</span><span class="n">evaluation_set_size</span> <span class="o">=</span> <span class="mi">1024</span>
<span class="n">config</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">store</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>StandardExperimentDataConfig(id_dataset_name=&#39;CIFAR-10&#39;, id_repetitions=1, initial_training_set_size=0, validation_set_size=5000, validation_split_random_state=8945, evaluation_set_size=1024, add_dataset_noise=False, ood_dataset_config=None)
Files already downloaded and verified
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  return floored.astype(np.int)
/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  return floored.astype(np.int)
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Files already downloaded and verified
Creating: CoreSetPIGBALD(
	acquisition_size=1,
	num_pool_samples=5
)
Creating: Cifar10ModelWorkshopPaperTrainer(
	device=cuda,
	num_training_samples=1,
	num_validation_samples=20,
	max_training_epochs=1
)
Creating: TrainExplicitEvalModel(
	cache_explicit_eval_model=True
)
Training set size 0:
NeurIPS WOrkshop Style
Perf after training {&#39;accuracy&#39;: 0.1026, &#39;crossentropy&#39;: tensor(2.3253)}
NeurIPS WOrkshop Style
Epoch metrics: {&#39;accuracy&#39;: 0.222, &#39;crossentropy&#39;: 2.1405570266723632}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.222)
RestoringEarlyStopping: Restoring optimizer.
CandidateBatch(scores=[0.4518175258911179], indices=[22922])
[(&#39;id&#39;, 23438)]
Acquiring (label, score)s: 1 (0.4518)
Training set size 1:
NeurIPS WOrkshop Style
Epoch metrics: {&#39;accuracy&#39;: 0.1, &#39;crossentropy&#39;: 122.28322725830078}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.1)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.1, &#39;crossentropy&#39;: tensor(88.2817)}
Using cached fully trained model!
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-16-1f554a5e6e9e&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">      6</span> config<span class="ansi-blue-fg">.</span>num_pool_samples <span class="ansi-blue-fg">=</span> <span class="ansi-cyan-fg">5</span>
<span class="ansi-green-intense-fg ansi-bold">      7</span> config<span class="ansi-blue-fg">.</span>experiment_data_config<span class="ansi-blue-fg">.</span>evaluation_set_size <span class="ansi-blue-fg">=</span> <span class="ansi-cyan-fg">1024</span>
<span class="ansi-green-fg">----&gt; 8</span><span class="ansi-red-fg"> </span>config<span class="ansi-blue-fg">.</span>run<span class="ansi-blue-fg">(</span>store<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/unified_experiment.py</span> in <span class="ansi-cyan-fg">run</span><span class="ansi-blue-fg">(self, store)</span>
<span class="ansi-green-intense-fg ansi-bold">    266</span>         )
<span class="ansi-green-intense-fg ansi-bold">    267</span> 
<span class="ansi-green-fg">--&gt; 268</span><span class="ansi-red-fg">         </span>active_learner<span class="ansi-blue-fg">(</span>store<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    269</span> 
<span class="ansi-green-intense-fg ansi-bold">    270</span> <span class="ansi-red-fg"># Cell</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/unified_experiment.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, log)</span>
<span class="ansi-green-intense-fg ansi-bold">    157</span>                 )
<span class="ansi-green-intense-fg ansi-bold">    158</span> 
<span class="ansi-green-fg">--&gt; 159</span><span class="ansi-red-fg">                 candidate_batch = acquisition_function.compute_candidate_batch(
</span><span class="ansi-green-intense-fg ansi-bold">    160</span>                     trained_model<span class="ansi-blue-fg">,</span> trained_eval_model<span class="ansi-blue-fg">,</span> pool_loader<span class="ansi-blue-fg">,</span> device<span class="ansi-blue-fg">=</span>self<span class="ansi-blue-fg">.</span>device
<span class="ansi-green-intense-fg ansi-bold">    161</span>                 )

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/acquisition_functions.py</span> in <span class="ansi-cyan-fg">compute_candidate_batch</span><span class="ansi-blue-fg">(self, model, eval_model, pool_loader, device)</span>
<span class="ansi-green-intense-fg ansi-bold">    444</span>         self<span class="ansi-blue-fg">,</span> model<span class="ansi-blue-fg">:</span> TrainedModel<span class="ansi-blue-fg">,</span> eval_model<span class="ansi-blue-fg">:</span> TrainedModel<span class="ansi-blue-fg">,</span> pool_loader<span class="ansi-blue-fg">:</span> torch<span class="ansi-blue-fg">.</span>utils<span class="ansi-blue-fg">.</span>data<span class="ansi-blue-fg">.</span>DataLoader<span class="ansi-blue-fg">,</span> device
<span class="ansi-green-intense-fg ansi-bold">    445</span>     ) -&gt; CandidateBatch:
<span class="ansi-green-fg">--&gt; 446</span><span class="ansi-red-fg">         training_log_probs_N_K_C, training_labels_N = model.get_log_probs_N_K_C_labels_N(
</span><span class="ansi-green-intense-fg ansi-bold">    447</span>             pool_loader<span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>num_pool_samples<span class="ansi-blue-fg">,</span> device<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#34;cpu&#34;</span>
<span class="ansi-green-intense-fg ansi-bold">    448</span>         )

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/trained_model.py</span> in <span class="ansi-cyan-fg">get_log_probs_N_K_C_labels_N</span><span class="ansi-blue-fg">(self, loader, num_samples, device, storage_device)</span>
<span class="ansi-green-intense-fg ansi-bold">     50</span>         self<span class="ansi-blue-fg">,</span> loader<span class="ansi-blue-fg">:</span> DataLoader<span class="ansi-blue-fg">,</span> num_samples<span class="ansi-blue-fg">:</span> int<span class="ansi-blue-fg">,</span> device<span class="ansi-blue-fg">:</span> object<span class="ansi-blue-fg">,</span> storage_device<span class="ansi-blue-fg">:</span> object
<span class="ansi-green-intense-fg ansi-bold">     51</span>     ):
<span class="ansi-green-fg">---&gt; 52</span><span class="ansi-red-fg">         log_probs_N_K_C, labels_B = self.model.get_predictions_labels(
</span><span class="ansi-green-intense-fg ansi-bold">     53</span>             num_samples<span class="ansi-blue-fg">=</span>num_samples<span class="ansi-blue-fg">,</span> loader<span class="ansi-blue-fg">=</span>loader<span class="ansi-blue-fg">,</span> device<span class="ansi-blue-fg">=</span>device<span class="ansi-blue-fg">,</span> storage_device<span class="ansi-blue-fg">=</span>storage_device
<span class="ansi-green-intense-fg ansi-bold">     54</span>         )

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/consistent_mc_dropout.py</span> in <span class="ansi-cyan-fg">get_predictions_labels</span><span class="ansi-blue-fg">(self, num_samples, loader, device, storage_device)</span>
<span class="ansi-green-intense-fg ansi-bold">    147</span>         self<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span><span class="ansi-blue-fg">,</span> num_samples<span class="ansi-blue-fg">:</span> int<span class="ansi-blue-fg">,</span> loader<span class="ansi-blue-fg">:</span> data<span class="ansi-blue-fg">.</span>DataLoader<span class="ansi-blue-fg">,</span> device<span class="ansi-blue-fg">,</span> storage_device
<span class="ansi-green-intense-fg ansi-bold">    148</span>     ):
<span class="ansi-green-fg">--&gt; 149</span><span class="ansi-red-fg">         return bmodule_get_predictions_labels(
</span><span class="ansi-green-intense-fg ansi-bold">    150</span>             self<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    151</span>             num_samples<span class="ansi-blue-fg">=</span>num_samples<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/autograd/grad_mode.py</span> in <span class="ansi-cyan-fg">decorate_context</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">     24</span>         <span class="ansi-green-fg">def</span> decorate_context<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     25</span>             <span class="ansi-green-fg">with</span> self<span class="ansi-blue-fg">.</span>__class__<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">---&gt; 26</span><span class="ansi-red-fg">                 </span><span class="ansi-green-fg">return</span> func<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     27</span>         <span class="ansi-green-fg">return</span> cast<span class="ansi-blue-fg">(</span>F<span class="ansi-blue-fg">,</span> decorate_context<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     28</span> 

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/consistent_mc_dropout.py</span> in <span class="ansi-cyan-fg">bmodule_get_predictions_labels</span><span class="ansi-blue-fg">(self, num_samples, loader, device, storage_device)</span>
<span class="ansi-green-intense-fg ansi-bold">    374</span>     self<span class="ansi-blue-fg">:</span> BayesianModule<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span><span class="ansi-blue-fg">,</span> num_samples<span class="ansi-blue-fg">:</span> int<span class="ansi-blue-fg">,</span> loader<span class="ansi-blue-fg">:</span> data<span class="ansi-blue-fg">.</span>DataLoader<span class="ansi-blue-fg">,</span> device<span class="ansi-blue-fg">,</span> storage_device
<span class="ansi-green-intense-fg ansi-bold">    375</span> ):
<span class="ansi-green-fg">--&gt; 376</span><span class="ansi-red-fg">     </span>assert_no_shuffling_no_augmentations_dataloader<span class="ansi-blue-fg">(</span>loader<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    377</span> 
<span class="ansi-green-intense-fg ansi-bold">    378</span>     <span class="ansi-green-fg">if</span> num_samples <span class="ansi-blue-fg">==</span> <span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/consistent_mc_dropout.py</span> in <span class="ansi-cyan-fg">assert_no_shuffling_no_augmentations_dataloader</span><span class="ansi-blue-fg">(dataloader)</span>
<span class="ansi-green-intense-fg ansi-bold">    658</span>     batch_labels_B <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span>
<span class="ansi-green-intense-fg ansi-bold">    659</span> 
<span class="ansi-green-fg">--&gt; 660</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">for</span> batch_x_A<span class="ansi-blue-fg">,</span> batch_labels_A <span class="ansi-green-fg">in</span> dataloader<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    661</span>         <span class="ansi-green-fg">break</span>
<span class="ansi-green-intense-fg ansi-bold">    662</span> 

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/utils/data/dataloader.py</span> in <span class="ansi-cyan-fg">__next__</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    433</span>         <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>_sampler_iter <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    434</span>             self<span class="ansi-blue-fg">.</span>_reset<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 435</span><span class="ansi-red-fg">         </span>data <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_next_data<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    436</span>         self<span class="ansi-blue-fg">.</span>_num_yielded <span class="ansi-blue-fg">+=</span> <span class="ansi-cyan-fg">1</span>
<span class="ansi-green-intense-fg ansi-bold">    437</span>         <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>_dataset_kind <span class="ansi-blue-fg">==</span> _DatasetKind<span class="ansi-blue-fg">.</span>Iterable <span class="ansi-green-fg">and</span><span class="ansi-red-fg"> </span><span class="ansi-red-fg">\</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/utils/data/dataloader.py</span> in <span class="ansi-cyan-fg">_next_data</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">   1066</span> 
<span class="ansi-green-intense-fg ansi-bold">   1067</span>             <span class="ansi-green-fg">assert</span> <span class="ansi-green-fg">not</span> self<span class="ansi-blue-fg">.</span>_shutdown <span class="ansi-green-fg">and</span> self<span class="ansi-blue-fg">.</span>_tasks_outstanding <span class="ansi-blue-fg">&gt;</span> <span class="ansi-cyan-fg">0</span>
<span class="ansi-green-fg">-&gt; 1068</span><span class="ansi-red-fg">             </span>idx<span class="ansi-blue-fg">,</span> data <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_get_data<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1069</span>             self<span class="ansi-blue-fg">.</span>_tasks_outstanding <span class="ansi-blue-fg">-=</span> <span class="ansi-cyan-fg">1</span>
<span class="ansi-green-intense-fg ansi-bold">   1070</span>             <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>_dataset_kind <span class="ansi-blue-fg">==</span> _DatasetKind<span class="ansi-blue-fg">.</span>Iterable<span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/utils/data/dataloader.py</span> in <span class="ansi-cyan-fg">_get_data</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">   1022</span>         <span class="ansi-green-fg">elif</span> self<span class="ansi-blue-fg">.</span>_pin_memory<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1023</span>             <span class="ansi-green-fg">while</span> self<span class="ansi-blue-fg">.</span>_pin_memory_thread<span class="ansi-blue-fg">.</span>is_alive<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">-&gt; 1024</span><span class="ansi-red-fg">                 </span>success<span class="ansi-blue-fg">,</span> data <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_try_get_data<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1025</span>                 <span class="ansi-green-fg">if</span> success<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1026</span>                     <span class="ansi-green-fg">return</span> data

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/utils/data/dataloader.py</span> in <span class="ansi-cyan-fg">_try_get_data</span><span class="ansi-blue-fg">(self, timeout)</span>
<span class="ansi-green-intense-fg ansi-bold">    870</span>         <span class="ansi-red-fg">#   (bool: whether successfully get data, any: data if successful else None)</span>
<span class="ansi-green-intense-fg ansi-bold">    871</span>         <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 872</span><span class="ansi-red-fg">             </span>data <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_data_queue<span class="ansi-blue-fg">.</span>get<span class="ansi-blue-fg">(</span>timeout<span class="ansi-blue-fg">=</span>timeout<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    873</span>             <span class="ansi-green-fg">return</span> <span class="ansi-blue-fg">(</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">,</span> data<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    874</span>         <span class="ansi-green-fg">except</span> Exception <span class="ansi-green-fg">as</span> e<span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/queue.py</span> in <span class="ansi-cyan-fg">get</span><span class="ansi-blue-fg">(self, block, timeout)</span>
<span class="ansi-green-intense-fg ansi-bold">    177</span>                     <span class="ansi-green-fg">if</span> remaining <span class="ansi-blue-fg">&lt;=</span> <span class="ansi-cyan-fg">0.0</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    178</span>                         <span class="ansi-green-fg">raise</span> Empty
<span class="ansi-green-fg">--&gt; 179</span><span class="ansi-red-fg">                     </span>self<span class="ansi-blue-fg">.</span>not_empty<span class="ansi-blue-fg">.</span>wait<span class="ansi-blue-fg">(</span>remaining<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    180</span>             item <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_get<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    181</span>             self<span class="ansi-blue-fg">.</span>not_full<span class="ansi-blue-fg">.</span>notify<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/threading.py</span> in <span class="ansi-cyan-fg">wait</span><span class="ansi-blue-fg">(self, timeout)</span>
<span class="ansi-green-intense-fg ansi-bold">    304</span>             <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    305</span>                 <span class="ansi-green-fg">if</span> timeout <span class="ansi-blue-fg">&gt;</span> <span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 306</span><span class="ansi-red-fg">                     </span>gotit <span class="ansi-blue-fg">=</span> waiter<span class="ansi-blue-fg">.</span>acquire<span class="ansi-blue-fg">(</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">,</span> timeout<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    307</span>                 <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    308</span>                     gotit <span class="ansi-blue-fg">=</span> waiter<span class="ansi-blue-fg">.</span>acquire<span class="ansi-blue-fg">(</span><span class="ansi-green-fg">False</span><span class="ansi-blue-fg">)</span>

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">store</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;dataset_info&#39;: {&#39;training&#39;: &#34;&#39;CIFAR-10 (Train, seed=0, 50000 samples)&#39;&#34;,
  &#39;test&#39;: &#34;&#39;CIFAR-10 (Test)&#39;&#34;},
 &#39;initial_training_set_indices&#39;: [],
 &#39;evaluation_set_indices&#39;: [4214,
  9859,
  22257,
  29578,
  49656,
  4941,
  18436,
  34724,
  25144,
  32683,
  38208,
  21874,
  41900,
  35798,
  41243,
  10681,
  19945,
  19894,
  13068,
  41609,
  22579,
  940,
  32831,
  31756,
  46749,
  36353,
  39619,
  31098,
  23419,
  30141,
  44165,
  47766,
  47401,
  21144,
  34664,
  11989,
  3644,
  48419,
  8359,
  24057,
  9281,
  41651,
  5858,
  213,
  12072,
  18214,
  12325,
  30635,
  4477,
  42754,
  37233,
  22435,
  23485,
  17232,
  8774,
  30667,
  10215,
  49205,
  25538,
  14136,
  28699,
  30158,
  47711,
  33315,
  37867,
  29367,
  6920,
  27176,
  7002,
  439,
  37788,
  42869,
  47215,
  37728,
  28865,
  19116,
  3665,
  20349,
  48869,
  44145,
  9714,
  24792,
  1674,
  33510,
  46897,
  14335,
  26592,
  25905,
  2692,
  42073,
  11022,
  15622,
  18935,
  17257,
  8392,
  19030,
  4854,
  35973,
  35665,
  20602,
  1493,
  25807,
  10377,
  9578,
  28804,
  7707,
  24607,
  39771,
  31288,
  9932,
  10387,
  5895,
  27321,
  42954,
  26870,
  2185,
  7357,
  45810,
  31619,
  25363,
  45126,
  33196,
  10644,
  7145,
  26320,
  23060,
  40758,
  36879,
  44557,
  46461,
  4636,
  29205,
  1707,
  38929,
  2289,
  15386,
  28086,
  14844,
  21020,
  22043,
  7005,
  45599,
  15670,
  9998,
  31935,
  34993,
  1985,
  31251,
  37596,
  48279,
  48840,
  47162,
  17752,
  21947,
  38841,
  676,
  7442,
  7988,
  22451,
  12551,
  21073,
  44472,
  48749,
  43098,
  13156,
  35691,
  49937,
  31959,
  29744,
  38785,
  25181,
  43804,
  23428,
  8900,
  16770,
  14722,
  41091,
  45105,
  2094,
  6668,
  42237,
  10352,
  9042,
  3131,
  5747,
  17244,
  27576,
  21137,
  28530,
  41607,
  47588,
  4533,
  848,
  18594,
  28818,
  20494,
  41138,
  1455,
  42007,
  38515,
  15610,
  5722,
  37616,
  26578,
  5892,
  28814,
  13985,
  21942,
  11885,
  7336,
  43314,
  1844,
  26187,
  1936,
  33303,
  38451,
  20077,
  14595,
  42821,
  28994,
  17064,
  29853,
  25175,
  45006,
  34620,
  38030,
  23388,
  6296,
  3814,
  1990,
  41790,
  30224,
  22672,
  22797,
  18586,
  30111,
  538,
  28051,
  15146,
  13786,
  5343,
  26204,
  42564,
  10089,
  19359,
  17682,
  36125,
  21412,
  25467,
  6502,
  23315,
  21392,
  46607,
  25276,
  10360,
  15326,
  48894,
  22448,
  36300,
  20579,
  40244,
  11943,
  33023,
  4902,
  8438,
  5406,
  22587,
  23128,
  41925,
  49870,
  14421,
  4372,
  5132,
  35096,
  21824,
  48102,
  27895,
  24670,
  6685,
  28158,
  19384,
  17735,
  14266,
  9916,
  9403,
  40176,
  27580,
  42600,
  16402,
  2538,
  9348,
  31169,
  25628,
  27314,
  9921,
  12847,
  36339,
  4727,
  31803,
  1209,
  34023,
  49802,
  42532,
  1884,
  33881,
  7658,
  43565,
  34486,
  44987,
  27641,
  36647,
  14330,
  34741,
  20345,
  37204,
  35581,
  11434,
  8808,
  46231,
  1449,
  7121,
  14800,
  31499,
  46627,
  34172,
  31912,
  27698,
  27766,
  16273,
  48368,
  5553,
  46196,
  16411,
  43336,
  31050,
  41827,
  38679,
  34136,
  5870,
  49632,
  15129,
  34889,
  19580,
  14373,
  5705,
  25642,
  38364,
  15421,
  23266,
  25424,
  27556,
  49822,
  19994,
  15392,
  8503,
  35296,
  40624,
  16495,
  18647,
  42970,
  40263,
  34536,
  22007,
  33789,
  19352,
  2404,
  42133,
  10329,
  22850,
  44409,
  5455,
  7814,
  41992,
  40792,
  21769,
  28556,
  8986,
  31861,
  27114,
  29313,
  5192,
  34606,
  8710,
  19088,
  3843,
  42773,
  35205,
  36157,
  19117,
  38825,
  43598,
  34397,
  4302,
  26111,
  25055,
  5492,
  24384,
  28773,
  15467,
  21055,
  27904,
  32128,
  2164,
  18216,
  31542,
  29423,
  40127,
  22517,
  22391,
  26023,
  29329,
  22990,
  16994,
  18264,
  32803,
  47385,
  16007,
  18365,
  3821,
  24205,
  37903,
  4053,
  8236,
  25949,
  39803,
  40186,
  16702,
  7100,
  2329,
  4709,
  47147,
  66,
  43517,
  4998,
  27063,
  4561,
  29922,
  17266,
  28375,
  20904,
  15537,
  38794,
  35443,
  28478,
  6535,
  33743,
  30801,
  28613,
  15199,
  49981,
  47538,
  13663,
  36466,
  37656,
  4043,
  5739,
  48862,
  3533,
  33614,
  37942,
  40085,
  13279,
  15399,
  19521,
  43172,
  42080,
  13102,
  945,
  29172,
  14853,
  13513,
  22192,
  40301,
  46245,
  46968,
  38598,
  34229,
  25313,
  43681,
  4195,
  21307,
  711,
  20906,
  28739,
  25347,
  47487,
  25529,
  33253,
  48738,
  25435,
  37388,
  15508,
  3717,
  29605,
  7362,
  7623,
  38354,
  5894,
  11021,
  14396,
  3445,
  21197,
  36142,
  15734,
  48367,
  26844,
  46789,
  37193,
  36855,
  28349,
  49155,
  34451,
  45504,
  29758,
  1157,
  21126,
  33259,
  14160,
  16798,
  36962,
  996,
  1152,
  49547,
  19819,
  26079,
  3271,
  20445,
  31309,
  32122,
  11034,
  43801,
  35867,
  21810,
  19757,
  42174,
  2026,
  5335,
  30931,
  32895,
  21595,
  33889,
  46716,
  23782,
  45629,
  43345,
  32364,
  10082,
  8494,
  34757,
  36810,
  36259,
  3619,
  28652,
  13057,
  26134,
  19800,
  42348,
  29271,
  30133,
  26640,
  26143,
  34924,
  40992,
  42549,
  33747,
  35547,
  10484,
  36202,
  11637,
  17189,
  43851,
  42377,
  27797,
  35254,
  42076,
  8334,
  30342,
  45553,
  157,
  21059,
  28282,
  15485,
  15186,
  26747,
  23947,
  26479,
  3451,
  22336,
  27472,
  23335,
  35879,
  13375,
  8671,
  42286,
  45952,
  40776,
  18082,
  43153,
  9677,
  3604,
  5655,
  10740,
  14987,
  24126,
  36227,
  27912,
  35680,
  39712,
  14015,
  34003,
  43366,
  28677,
  34986,
  12692,
  11394,
  7958,
  20706,
  18494,
  33812,
  25638,
  8060,
  1484,
  49302,
  3528,
  35951,
  33018,
  39020,
  29426,
  31727,
  36493,
  18866,
  23881,
  11690,
  13441,
  46587,
  28542,
  13515,
  16606,
  42552,
  1023,
  42391,
  44536,
  7458,
  7650,
  32675,
  37865,
  41331,
  49041,
  72,
  17389,
  40879,
  15552,
  48022,
  39205,
  40264,
  29080,
  35620,
  37188,
  43601,
  4421,
  31984,
  14746,
  31384,
  49039,
  15026,
  30625,
  26428,
  46905,
  15800,
  7341,
  29798,
  15904,
  45751,
  13634,
  16887,
  3311,
  26135,
  23680,
  14267,
  26841,
  7003,
  32907,
  42671,
  19926,
  19501,
  18722,
  20278,
  13723,
  8597,
  45392,
  5318,
  39258,
  12214,
  6545,
  39617,
  2888,
  26192,
  27563,
  23025,
  15810,
  25406,
  10165,
  31834,
  36596,
  5661,
  34157,
  6526,
  10889,
  25134,
  12374,
  39982,
  12066,
  19641,
  39226,
  37810,
  17913,
  24004,
  8887,
  24645,
  13039,
  8604,
  10216,
  17575,
  20018,
  29350,
  37802,
  49310,
  32399,
  6194,
  14653,
  1412,
  16654,
  14976,
  7030,
  32696,
  26389,
  40234,
  12995,
  22739,
  16876,
  17242,
  9517,
  13547,
  6072,
  45065,
  23835,
  16183,
  20550,
  5401,
  10685,
  35120,
  7273,
  41620,
  24559,
  19931,
  10037,
  27363,
  28201,
  41735,
  20094,
  4736,
  46694,
  36562,
  43768,
  4820,
  34067,
  33652,
  2063,
  24468,
  20489,
  30121,
  46942,
  29526,
  2321,
  19089,
  37100,
  7568,
  23867,
  25890,
  43580,
  26628,
  42251,
  40604,
  47003,
  31671,
  42322,
  47665,
  3054,
  3598,
  36597,
  5385,
  13450,
  33553,
  18941,
  41517,
  23928,
  17929,
  49272,
  41426,
  8238,
  35696,
  4441,
  47383,
  2311,
  33150,
  37935,
  30036,
  10507,
  14692,
  38884,
  27635,
  38155,
  1776,
  25131,
  46348,
  5652,
  12954,
  15768,
  36579,
  12481,
  9866,
  46442,
  5283,
  28066,
  6740,
  5752,
  19402,
  30211,
  33225,
  44877,
  18950,
  3584,
  32933,
  31714,
  33240,
  27449,
  38081,
  12834,
  37703,
  34815,
  5573,
  15553,
  36405,
  45917,
  12403,
  29027,
  29746,
  30438,
  10065,
  34468,
  23960,
  6977,
  30745,
  17167,
  45726,
  26718,
  42203,
  585,
  22064,
  35150,
  5377,
  35084,
  28800,
  23085,
  17881,
  37994,
  28829,
  11001,
  30366,
  7046,
  5030,
  12868,
  24132,
  15346,
  21812,
  11309,
  36438,
  19102,
  20118,
  48481,
  24414,
  22234,
  26198,
  811,
  29428,
  6848,
  20455,
  48911,
  43699,
  12880,
  44681,
  519,
  16830,
  7947,
  48920,
  5378,
  42799,
  36391,
  24142,
  596,
  7440,
  38276,
  25951,
  27958,
  4303,
  48905,
  25796,
  25111,
  42066,
  25472,
  30770,
  21499,
  32876,
  21770,
  23149,
  17753,
  15811,
  21681,
  25461,
  15123,
  14661,
  12262,
  48151,
  43938,
  13474,
  26050,
  46227,
  28774,
  34175,
  40895,
  46327,
  27237,
  48439,
  27198,
  45614,
  32209,
  16267,
  46654,
  24089,
  14205,
  30936,
  26677,
  18498,
  3923,
  23975,
  1247,
  24627,
  26218,
  42289,
  4289,
  40233,
  39859,
  40777,
  39731,
  23633,
  28065,
  7791,
  17470,
  48442,
  45844,
  31869,
  16373,
  30369,
  36807,
  32242,
  28846,
  29825,
  27907,
  43901,
  4136,
  5851,
  25499,
  40729,
  306,
  24693,
  1073,
  1000,
  9412,
  47767,
  1725,
  41156,
  7414,
  24162,
  19377,
  16975,
  31335,
  9244,
  21520,
  49181,
  40810,
  8125,
  28604,
  7249,
  20095,
  29054,
  45107,
  40037,
  29519,
  42055,
  12456,
  ...],
 &#39;seed&#39;: 4566624498677956240,
 &#39;active_learning_steps&#39;: [{&#39;training&#39;: {0: {}, 1: {}, 2: {}, 3: {}, 4: {}},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.0995, &#39;crossentropy&#39;: tensor(2.3164)},
   &#39;eval_training&#39;: {0: {&#39;epochs&#39;: [{&#39;gpu:0 mem(%)&#39;: 74,
       &#39;gpu:0 util(%)&#39;: 92,
       &#39;training_crossentropy&#39;: 2.249681864029322}]},
    1: {&#39;epochs&#39;: [{&#39;gpu:0 mem(%)&#39;: 74,
       &#39;gpu:0 util(%)&#39;: 93,
       &#39;training_crossentropy&#39;: 2.2582407914675198}]},
    2: {&#39;epochs&#39;: [{&#39;gpu:0 mem(%)&#39;: 76,
       &#39;gpu:0 util(%)&#39;: 95,
       &#39;training_crossentropy&#39;: 2.2323788740696053}]},
    3: {&#39;epochs&#39;: [{&#39;gpu:0 mem(%)&#39;: 76,
       &#39;gpu:0 util(%)&#39;: 91,
       &#39;training_crossentropy&#39;: 2.2876995710226207}]},
    4: {&#39;epochs&#39;: [{&#39;gpu:0 mem(%)&#39;: 78,
       &#39;gpu:0 util(%)&#39;: 92,
       &#39;training_crossentropy&#39;: 2.2614798362438497}]}},
   &#39;acquisition&#39;: {&#39;indices&#39;: [(&#39;id&#39;, 38554)],
    &#39;labels&#39;: [8],
    &#39;scores&#39;: [0.7364909692936965]}},
  {&#39;training&#39;: {0: {&#39;epochs&#39;: [{&#39;gpu:0 mem(%)&#39;: 76,
       &#39;gpu:0 util(%)&#39;: 95,
       &#39;training_crossentropy&#39;: 0.17217564533020988}]},
    1: {&#39;epochs&#39;: [{&#39;gpu:0 mem(%)&#39;: 75,
       &#39;gpu:0 util(%)&#39;: 92,
       &#39;training_crossentropy&#39;: 0.1476529144875097}]},
    2: {&#39;epochs&#39;: [{&#39;gpu:0 mem(%)&#39;: 76,
       &#39;gpu:0 util(%)&#39;: 93,
       &#39;training_crossentropy&#39;: 0.17059984571010825}]},
    3: {&#39;epochs&#39;: [{&#39;gpu:0 mem(%)&#39;: 76,
       &#39;gpu:0 util(%)&#39;: 92,
       &#39;training_crossentropy&#39;: 0.12485586361575883}]},
    4: {&#39;epochs&#39;: [{&#39;gpu:0 mem(%)&#39;: 78,
       &#39;gpu:0 util(%)&#39;: 93,
       &#39;training_crossentropy&#39;: 0.16145577784635592}]}},
   &#39;evaluation_metrics&#39;: {&#39;accuracy&#39;: 0.1, &#39;crossentropy&#39;: tensor(138.2961)},
   &#39;eval_training&#39;: {},
   &#39;acquisition&#39;: {&#39;indices&#39;: [(&#39;id&#39;, 25697)],
    &#39;labels&#39;: [1],
    &#39;scores&#39;: [1.6092121068931065]}},
  {&#39;training&#39;: {0: {&#39;epochs&#39;: [{&#39;gpu:0 mem(%)&#39;: 74,
       &#39;gpu:0 util(%)&#39;: 92,
       &#39;training_crossentropy&#39;: 0.2399260918045678}]},
    1: {&#39;epochs&#39;: [{&#39;gpu:0 mem(%)&#39;: 74,
       &#39;gpu:0 util(%)&#39;: 94,
       &#39;training_crossentropy&#39;: 0.24620416147239993}]},
    2: {&#39;epochs&#39;: [{&#39;gpu:0 mem(%)&#39;: 76,
       &#39;gpu:0 util(%)&#39;: 93,
       &#39;training_crossentropy&#39;: 0.24399974542850544}]},
    3: {&#39;epochs&#39;: [{&#39;gpu:0 mem(%)&#39;: 76,
       &#39;gpu:0 util(%)&#39;: 96,
       &#39;training_crossentropy&#39;: 0.22790809078502114}]},
    4: {&#39;epochs&#39;: [{&#39;gpu:0 mem(%)&#39;: 78,
       &#39;gpu:0 util(%)&#39;: 96,
       &#39;training_crossentropy&#39;: 0.2429815231046702}]}}}]}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

