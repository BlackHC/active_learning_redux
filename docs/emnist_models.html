---

title: Some Models


keywords: fastai
sidebar: home_sidebar

summary: "To avoid copy-pasta #2"
description: "To avoid copy-pasta #2"
nb_path: "06b_emnist_models.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 06b_emnist_models.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span><span class="p">,</span> <span class="n">Module</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">Dataset</span>

<span class="kn">from</span> <span class="nn">batchbald_redux.active_learning</span> <span class="kn">import</span> <span class="n">RandomFixedLengthSampler</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.black_box_model_training</span> <span class="kn">import</span> <span class="n">train</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.consistent_mc_dropout</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">GradEmbeddingType</span><span class="p">,</span>
    <span class="n">BayesianModule</span><span class="p">,</span>
    <span class="n">ConsistentMCDropout</span><span class="p">,</span>
    <span class="n">ConsistentMCDropout2d</span><span class="p">,</span>
    <span class="n">freeze_encoder_context</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">batchbald_redux.model_optimizer_factory</span> <span class="kn">import</span> <span class="n">ModelOptimizer</span><span class="p">,</span> <span class="n">ModelOptimizerFactory</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BayesianEMNISTCNN" class="doc_header"><code>class</code> <code>BayesianEMNISTCNN</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/emnist_models.py#L32" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BayesianEMNISTCNN</code>(<strong><code>num_classes</code></strong>=<em><code>47</code></em>) :: <a href="/batchbald_redux/consistent_mc_dropout.html#BayesianModule"><code>BayesianModule</code></a></p>
</blockquote>
<p>A module that we can sample multiple times from given a single input batch.</p>
<p>To be efficient, the module allows for a part of the forward pass to be deterministic.</p>
<p>If we sample with "0" samples, we do a single deterministic forward pass with disabled dropout during evaluation.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">batchbald_redux.trained_model</span> <span class="kn">import</span> <span class="n">ModelTrainer</span><span class="p">,</span> <span class="n">TrainedModel</span><span class="p">,</span> <span class="n">TrainedBayesianModel</span>


<span class="k">class</span> <span class="nc">BayesianEMNISTCNN</span><span class="p">(</span><span class="n">BayesianModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">47</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1_drop</span> <span class="o">=</span> <span class="n">ConsistentMCDropout2d</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2_drop</span> <span class="o">=</span> <span class="n">ConsistentMCDropout2d</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv3_drop</span> <span class="o">=</span> <span class="n">ConsistentMCDropout2d</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1_drop</span> <span class="o">=</span> <span class="n">ConsistentMCDropout</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">mc_forward_impl</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">freeze_encoder</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">freeze_encoder_context</span><span class="p">(</span><span class="n">freeze_encoder</span><span class="p">):</span>
            <span class="nb">input</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1_drop</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="nb">input</span><span class="p">)),</span> <span class="mi">2</span><span class="p">))</span>
            <span class="nb">input</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2_drop</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="nb">input</span><span class="p">)))</span>
            <span class="nb">input</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv3_drop</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="nb">input</span><span class="p">)),</span> <span class="mi">2</span><span class="p">))</span>
            <span class="nb">input</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">128</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>
            <span class="nb">input</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1_drop</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="nb">input</span><span class="p">)))</span>

        <span class="n">embedding</span> <span class="o">=</span> <span class="nb">input</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">input</span><span class="p">,</span> <span class="n">embedding</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">BayesianEMNISTCNN</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>BayesianEMNISTCNN(
  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
  (conv1_drop): ConsistentMCDropout2d(p=0.5)
  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))
  (conv2_drop): ConsistentMCDropout2d(p=0.5)
  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))
  (conv3_drop): ConsistentMCDropout2d(p=0.5)
  (fc1): Linear(in_features=2048, out_features=512, bias=True)
  (fc1_drop): ConsistentMCDropout(p=0.5)
  (fc2): Linear(in_features=512, out_features=47, bias=True)
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="EMnistOptimizerFactory" class="doc_header"><code>class</code> <code>EMnistOptimizerFactory</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/emnist_models.py#L62" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>EMnistOptimizerFactory</code>() :: <code>ModelOptimizerFactory</code></p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="EMnistModelTrainer" class="doc_header"><code>class</code> <code>EMnistModelTrainer</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/emnist_models.py#L73" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>EMnistModelTrainer</code>(<strong><code>device</code></strong>:<code>str</code>, <strong><code>num_training_samples</code></strong>:<code>int</code>=<em><code>1</code></em>, <strong><code>num_validation_samples</code></strong>:<code>int</code>=<em><code>20</code></em>, <strong><code>num_patience_epochs</code></strong>:<code>int</code>=<em><code>20</code></em>, <strong><code>max_training_epochs</code></strong>:<code>int</code>=<em><code>120</code></em>, <strong><code>min_samples_per_epoch</code></strong>:<code>int</code>=<em><code>1024</code></em>, <strong><code>num_training_batch_size</code></strong>:<code>int</code>=<em><code>64</code></em>, <strong><code>num_evaluation_batch_size</code></strong>:<code>int</code>=<em><code>128</code></em>) :: <code>ModelTrainer</code></p>
</blockquote>
<p>EMnistModelTrainer(device: str, num_training_samples: int = 1, num_validation_samples: int = 20, num_patience_epochs: int = 20, max_training_epochs: int = 120, min_samples_per_epoch: int = 1024, num_training_batch_size: int = 64, num_evaluation_batch_size: int = 128)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">EMnistOptimizerFactory</span><span class="p">(</span><span class="n">ModelOptimizerFactory</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">create_model_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelOptimizer</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">BayesianEMNISTCNN</span><span class="p">()</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ModelOptimizer</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>


<span class="n">_dataloader_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">EMnistModelTrainer</span><span class="p">(</span><span class="n">ModelTrainer</span><span class="p">):</span>
    <span class="n">device</span><span class="p">:</span> <span class="nb">str</span>

    <span class="n">num_training_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">num_validation_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="n">num_patience_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="n">max_training_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">120</span>

    <span class="n">min_samples_per_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span>
    <span class="n">num_training_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">num_evaluation_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">create_model_optimizer</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">ModelOptimizer</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">BayesianEMNISTCNN</span><span class="p">()</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ModelOptimizer</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">:</span> <span class="n">Dataset</span><span class="p">):</span>
        <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
            <span class="n">dataset</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_training_batch_size</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">RandomFixedLengthSampler</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_samples_per_epoch</span><span class="p">),</span>
            <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="o">**</span><span class="n">_dataloader_kwargs</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">train_loader</span>

    <span class="k">def</span> <span class="nf">get_evaluation_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">:</span> <span class="n">Dataset</span><span class="p">):</span>
        <span class="n">evaluation_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
            <span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_evaluation_batch_size</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">_dataloader_kwargs</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">evaluation_loader</span>

    <span class="k">def</span> <span class="nf">get_trained</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">train_augmentations</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Module</span><span class="p">],</span>
                    <span class="n">validation_loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">log</span><span class="p">,</span> <span class="n">wandb_key_path</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">validation_loss</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TrainedModel</span><span class="p">:</span>
        <span class="n">model_optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_model_optimizer</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">validation_loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">validation_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>

        <span class="n">train</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">model_optimizer</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">optimizer</span><span class="o">=</span><span class="n">model_optimizer</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span>
            <span class="n">training_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_training_samples</span><span class="p">,</span>
            <span class="n">validation_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_validation_samples</span><span class="p">,</span>
            <span class="n">train_loader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span>
            <span class="n">train_augmentations</span><span class="o">=</span><span class="n">train_augmentations</span><span class="p">,</span>
            <span class="n">validation_loader</span><span class="o">=</span><span class="n">validation_loader</span><span class="p">,</span>
            <span class="n">patience</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_patience_epochs</span><span class="p">,</span>
            <span class="n">max_epochs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_training_epochs</span><span class="p">,</span>
            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
            <span class="n">validation_loss</span><span class="o">=</span><span class="n">validation_loss</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="n">training_log</span><span class="o">=</span><span class="n">log</span><span class="p">,</span>
            <span class="n">wandb_key_path</span><span class="o">=</span><span class="n">wandb_key_path</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">TrainedBayesianModel</span><span class="p">(</span><span class="n">model_optimizer</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">batchbald_redux</span> <span class="kn">import</span> <span class="n">datasets</span>

<span class="n">emnist_dataset_split</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">get_dataset</span><span class="p">(</span><span class="s2">&quot;EMNIST&quot;</span><span class="p">,</span> <span class="n">device_hint</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

<span class="n">model_trainer</span> <span class="o">=</span> <span class="n">EMnistModelTrainer</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">max_training_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_train_dataloader</span><span class="p">(</span><span class="n">emnist_dataset_split</span><span class="o">.</span><span class="n">train</span><span class="p">)</span>

<span class="n">test_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_evaluation_dataloader</span><span class="p">(</span><span class="n">emnist_dataset_split</span><span class="o">.</span><span class="n">test</span><span class="p">)</span>

<span class="n">log</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">trained_model</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_trained</span><span class="p">(</span><span class="n">train_loader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">train_augmentations</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">validation_loader</span><span class="o">=</span><span class="n">test_loader</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="n">log</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch metrics: {&#39;accuracy&#39;: 0.865684344454665, &#39;crossentropy&#39;: 0.44169508072350266}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.865684344454665)
RestoringEarlyStopping: Restoring optimizer.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">batchbald_redux</span> <span class="kn">import</span> <span class="n">datasets</span>

<span class="n">emnist_dataset_split</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">get_dataset</span><span class="p">(</span><span class="s2">&quot;EMNIST&quot;</span><span class="p">,</span> <span class="n">device_hint</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

<span class="n">model_trainer</span> <span class="o">=</span> <span class="n">EMnistModelTrainer</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">max_training_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_train_dataloader</span><span class="p">(</span><span class="n">emnist_dataset_split</span><span class="o">.</span><span class="n">train</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">)</span>

<span class="n">test_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_evaluation_dataloader</span><span class="p">(</span><span class="n">emnist_dataset_split</span><span class="o">.</span><span class="n">test</span><span class="p">)</span>

<span class="n">log</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">trained_model</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_trained</span><span class="p">(</span><span class="n">train_loader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">train_augmentations</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">validation_loader</span><span class="o">=</span><span class="n">test_loader</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="n">log</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(&#39;FastMNIST (Train)&#39;)~x0.2
Epoch metrics: {&#39;accuracy&#39;: 0.9388, &#39;crossentropy&#39;: 0.36818689460754395}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.9388)
RestoringEarlyStopping: Restoring optimizer.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trained_model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_embeddings</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">loader</span><span class="o">=</span><span class="n">test_loader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">storage_device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([10000, 1, 1024])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trained_model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_grad_embeddings</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">loader</span><span class="o">=</span><span class="n">test_loader</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">nll_loss</span><span class="p">,</span> <span class="n">grad_embedding_type</span><span class="o">=</span><span class="n">GradEmbeddingType</span><span class="o">.</span><span class="n">BIAS_LINEAR</span><span class="p">,</span> <span class="n">model_labels</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">storage_device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([10000, 1, 10250])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">trained_model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_grad_embeddings</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">loader</span><span class="o">=</span><span class="n">test_loader</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">nll_loss</span><span class="p">,</span> <span class="n">grad_embedding_type</span><span class="o">=</span><span class="n">GradEmbeddingType</span><span class="o">.</span><span class="n">BIAS_LINEAR</span><span class="p">,</span> <span class="n">model_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="n">storage_device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([10000, 1, 10250])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

