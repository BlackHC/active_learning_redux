---

title: Evaluate Predetermined Top-K Acquisitions


keywords: fastai
sidebar: home_sidebar

summary: "Resistance is futile."
description: "Resistance is futile."
nb_path: "U_predetermined_acquisitions_70.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: U_predetermined_acquisitions_70.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Appended /home/blackhc/PycharmProjects/bald-ical/src to paths
Switched to directory /home/blackhc/PycharmProjects/bald-ical
%load_ext autoreload
%autoreload 2
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Import modules and functions were are going to use.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">dataclasses</span>
<span class="kn">import</span> <span class="nn">traceback</span>
<span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Type</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.utils.data</span>
<span class="kn">from</span> <span class="nn">blackhc.project</span> <span class="kn">import</span> <span class="n">is_run_from_ipython</span>
<span class="kn">from</span> <span class="nn">blackhc.project.experiment</span> <span class="kn">import</span> <span class="n">embedded_experiments</span>

<span class="kn">import</span> <span class="nn">batchbald_redux.acquisition_functions.bald</span>
<span class="kn">from</span> <span class="nn">batchbald_redux</span> <span class="kn">import</span> <span class="n">acquisition_functions</span><span class="p">,</span> <span class="n">baseline_acquisition_functions</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.acquisition_functions</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">CandidateBatchComputer</span><span class="p">,</span>
    <span class="n">EvalDatasetBatchComputer</span><span class="p">,</span>
    <span class="n">EvalModelBatchComputer</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.joint_entropy</span> <span class="kn">import</span> <span class="n">compute_entropy</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.acquisition_functions.bald</span> <span class="kn">import</span> <span class="n">get_bald_scores</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.black_box_model_training</span> <span class="kn">import</span> <span class="n">evaluate</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.dataset_challenges</span> <span class="kn">import</span> <span class="n">get_base_dataset_index</span><span class="p">,</span> <span class="n">get_target</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.di</span> <span class="kn">import</span> <span class="n">DependencyInjection</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.experiment_data</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ExperimentData</span><span class="p">,</span>
    <span class="n">ExperimentDataConfig</span><span class="p">,</span>
    <span class="n">OoDDatasetConfig</span><span class="p">,</span>
    <span class="n">StandardExperimentDataConfig</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.models</span> <span class="kn">import</span> <span class="n">MnistModelTrainer</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.resnet_models</span> <span class="kn">import</span> <span class="n">Cifar10ModelTrainer</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.train_eval_model</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">TrainEvalModel</span><span class="p">,</span>
    <span class="n">TrainSelfDistillationEvalModel</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.trained_model</span> <span class="kn">import</span> <span class="n">BayesianEnsembleModelTrainer</span><span class="p">,</span> <span class="n">ModelTrainer</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">additional_initial_acquisitions</span> <span class="o">=</span> <span class="p">[</span>
    <span class="mi">26919</span><span class="p">,</span>
    <span class="mi">43627</span><span class="p">,</span>
    <span class="mi">1666</span><span class="p">,</span>
    <span class="mi">354</span><span class="p">,</span>
    <span class="mi">23669</span><span class="p">,</span>
    <span class="mi">48412</span><span class="p">,</span>
    <span class="mi">48486</span><span class="p">,</span>
    <span class="mi">18284</span><span class="p">,</span>
    <span class="mi">51745</span><span class="p">,</span>
    <span class="mi">8120</span><span class="p">,</span>
    <span class="mi">41099</span><span class="p">,</span>
    <span class="mi">11397</span><span class="p">,</span>
    <span class="mi">17942</span><span class="p">,</span>
    <span class="mi">38275</span><span class="p">,</span>
    <span class="mi">9674</span><span class="p">,</span>
    <span class="mi">7069</span><span class="p">,</span>
    <span class="mi">2810</span><span class="p">,</span>
    <span class="mi">35239</span><span class="p">,</span>
    <span class="mi">1279</span><span class="p">,</span>
    <span class="mi">11383</span><span class="p">,</span>
    <span class="mi">2271</span><span class="p">,</span>
    <span class="mi">921</span><span class="p">,</span>
    <span class="mi">15619</span><span class="p">,</span>
    <span class="mi">32386</span><span class="p">,</span>
    <span class="mi">17830</span><span class="p">,</span>
    <span class="mi">1385</span><span class="p">,</span>
    <span class="mi">20850</span><span class="p">,</span>
    <span class="mi">16780</span><span class="p">,</span>
    <span class="mi">15765</span><span class="p">,</span>
    <span class="mi">6786</span><span class="p">,</span>
    <span class="mi">18938</span><span class="p">,</span>
    <span class="mi">46468</span><span class="p">,</span>
    <span class="mi">54880</span><span class="p">,</span>
    <span class="mi">14885</span><span class="p">,</span>
    <span class="mi">15543</span><span class="p">,</span>
    <span class="mi">13091</span><span class="p">,</span>
    <span class="mi">39530</span><span class="p">,</span>
    <span class="mi">9241</span><span class="p">,</span>
    <span class="mi">21243</span><span class="p">,</span>
    <span class="mi">48253</span><span class="p">,</span>
    <span class="mi">42363</span><span class="p">,</span>
    <span class="mi">31951</span><span class="p">,</span>
    <span class="mi">6689</span><span class="p">,</span>
    <span class="mi">20219</span><span class="p">,</span>
    <span class="mi">17178</span><span class="p">,</span>
    <span class="mi">26621</span><span class="p">,</span>
    <span class="mi">27534</span><span class="p">,</span>
    <span class="mi">3889</span><span class="p">,</span>
    <span class="mi">48169</span><span class="p">,</span>
    <span class="mi">38735</span><span class="p">,</span>
<span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">predetermind_acquisition_base_indices</span> <span class="o">=</span> <span class="p">[</span>
    <span class="mi">31664</span><span class="p">,</span>
    <span class="mi">42015</span><span class="p">,</span>
    <span class="mi">20215</span><span class="p">,</span>
    <span class="mi">37591</span><span class="p">,</span>
    <span class="mi">34014</span><span class="p">,</span>
    <span class="mi">21701</span><span class="p">,</span>
    <span class="mi">51259</span><span class="p">,</span>
    <span class="mi">12610</span><span class="p">,</span>
    <span class="mi">31518</span><span class="p">,</span>
    <span class="mi">55509</span><span class="p">,</span>
    <span class="mi">16769</span><span class="p">,</span>
    <span class="mi">12950</span><span class="p">,</span>
    <span class="mi">35936</span><span class="p">,</span>
    <span class="mi">5873</span><span class="p">,</span>
    <span class="mi">15528</span><span class="p">,</span>
    <span class="mi">20884</span><span class="p">,</span>
    <span class="mi">41945</span><span class="p">,</span>
    <span class="mi">651</span><span class="p">,</span>
    <span class="mi">45732</span><span class="p">,</span>
    <span class="mi">29320</span><span class="p">,</span>
    <span class="mi">10657</span><span class="p">,</span>
    <span class="mi">15434</span><span class="p">,</span>
    <span class="mi">26053</span><span class="p">,</span>
    <span class="mi">935</span><span class="p">,</span>
    <span class="mi">32432</span><span class="p">,</span>
    <span class="mi">27276</span><span class="p">,</span>
    <span class="mi">33174</span><span class="p">,</span>
    <span class="mi">33543</span><span class="p">,</span>
    <span class="mi">50655</span><span class="p">,</span>
    <span class="mi">25653</span><span class="p">,</span>
    <span class="mi">52587</span><span class="p">,</span>
    <span class="mi">42685</span><span class="p">,</span>
    <span class="mi">33050</span><span class="p">,</span>
    <span class="mi">18699</span><span class="p">,</span>
    <span class="mi">38512</span><span class="p">,</span>
    <span class="mi">2582</span><span class="p">,</span>
    <span class="mi">16538</span><span class="p">,</span>
    <span class="mi">39818</span><span class="p">,</span>
    <span class="mi">47263</span><span class="p">,</span>
    <span class="mi">45455</span><span class="p">,</span>
    <span class="mi">10844</span><span class="p">,</span>
    <span class="mi">40072</span><span class="p">,</span>
    <span class="mi">29155</span><span class="p">,</span>
    <span class="mi">25988</span><span class="p">,</span>
    <span class="mi">20856</span><span class="p">,</span>
    <span class="mi">53605</span><span class="p">,</span>
    <span class="mi">7930</span><span class="p">,</span>
    <span class="mi">34293</span><span class="p">,</span>
    <span class="mi">42634</span><span class="p">,</span>
    <span class="mi">14520</span><span class="p">,</span>
    <span class="mi">54456</span><span class="p">,</span>
    <span class="mi">1921</span><span class="p">,</span>
    <span class="mi">55379</span><span class="p">,</span>
    <span class="mi">34009</span><span class="p">,</span>
    <span class="mi">53071</span><span class="p">,</span>
    <span class="mi">18117</span><span class="p">,</span>
    <span class="mi">16148</span><span class="p">,</span>
    <span class="mi">13289</span><span class="p">,</span>
    <span class="mi">14233</span><span class="p">,</span>
    <span class="mi">8605</span><span class="p">,</span>
    <span class="mi">39777</span><span class="p">,</span>
    <span class="mi">27896</span><span class="p">,</span>
    <span class="mi">18309</span><span class="p">,</span>
    <span class="mi">4650</span><span class="p">,</span>
    <span class="mi">22563</span><span class="p">,</span>
    <span class="mi">44135</span><span class="p">,</span>
    <span class="mi">50973</span><span class="p">,</span>
    <span class="mi">27305</span><span class="p">,</span>
    <span class="mi">8178</span><span class="p">,</span>
    <span class="mi">40552</span><span class="p">,</span>
    <span class="mi">27182</span><span class="p">,</span>
    <span class="mi">37730</span><span class="p">,</span>
    <span class="mi">46980</span><span class="p">,</span>
    <span class="mi">20842</span><span class="p">,</span>
    <span class="mi">43105</span><span class="p">,</span>
    <span class="mi">6755</span><span class="p">,</span>
    <span class="mi">43824</span><span class="p">,</span>
    <span class="mi">18844</span><span class="p">,</span>
    <span class="mi">50980</span><span class="p">,</span>
    <span class="mi">27382</span><span class="p">,</span>
    <span class="mi">52110</span><span class="p">,</span>
    <span class="mi">14680</span><span class="p">,</span>
    <span class="mi">22301</span><span class="p">,</span>
    <span class="mi">19650</span><span class="p">,</span>
    <span class="mi">36590</span><span class="p">,</span>
    <span class="mi">41017</span><span class="p">,</span>
    <span class="mi">4590</span><span class="p">,</span>
    <span class="mi">5672</span><span class="p">,</span>
    <span class="mi">35479</span><span class="p">,</span>
    <span class="mi">48975</span><span class="p">,</span>
    <span class="mi">49077</span><span class="p">,</span>
    <span class="mi">43109</span><span class="p">,</span>
    <span class="mi">42856</span><span class="p">,</span>
    <span class="mi">2273</span><span class="p">,</span>
    <span class="mi">4002</span><span class="p">,</span>
    <span class="mi">18055</span><span class="p">,</span>
    <span class="mi">54055</span><span class="p">,</span>
    <span class="mi">15867</span><span class="p">,</span>
    <span class="mi">54549</span><span class="p">,</span>
    <span class="mi">15192</span><span class="p">,</span>
    <span class="mi">39042</span><span class="p">,</span>
    <span class="mi">1525</span><span class="p">,</span>
    <span class="mi">38120</span><span class="p">,</span>
    <span class="mi">3057</span><span class="p">,</span>
    <span class="mi">20086</span><span class="p">,</span>
    <span class="mi">13057</span><span class="p">,</span>
    <span class="mi">7505</span><span class="p">,</span>
    <span class="mi">11657</span><span class="p">,</span>
    <span class="mi">24569</span><span class="p">,</span>
    <span class="mi">49364</span><span class="p">,</span>
    <span class="mi">30989</span><span class="p">,</span>
    <span class="mi">53456</span><span class="p">,</span>
    <span class="mi">7235</span><span class="p">,</span>
    <span class="mi">23671</span><span class="p">,</span>
    <span class="mi">45814</span><span class="p">,</span>
    <span class="mi">36550</span><span class="p">,</span>
    <span class="mi">53152</span><span class="p">,</span>
    <span class="mi">45304</span><span class="p">,</span>
    <span class="mi">32685</span><span class="p">,</span>
    <span class="mi">33228</span><span class="p">,</span>
    <span class="mi">51475</span><span class="p">,</span>
    <span class="mi">37468</span><span class="p">,</span>
    <span class="mi">44447</span><span class="p">,</span>
    <span class="mi">40218</span><span class="p">,</span>
    <span class="mi">534</span><span class="p">,</span>
    <span class="mi">36252</span><span class="p">,</span>
    <span class="mi">47000</span><span class="p">,</span>
    <span class="mi">34643</span><span class="p">,</span>
    <span class="mi">23067</span><span class="p">,</span>
    <span class="mi">33536</span><span class="p">,</span>
    <span class="mi">23213</span><span class="p">,</span>
    <span class="mi">5126</span><span class="p">,</span>
    <span class="mi">35791</span><span class="p">,</span>
    <span class="mi">23011</span><span class="p">,</span>
    <span class="mi">14709</span><span class="p">,</span>
    <span class="mi">7075</span><span class="p">,</span>
    <span class="mi">54995</span><span class="p">,</span>
    <span class="mi">7308</span><span class="p">,</span>
    <span class="mi">29994</span><span class="p">,</span>
    <span class="mi">37892</span><span class="p">,</span>
    <span class="mi">33361</span><span class="p">,</span>
    <span class="mi">20881</span><span class="p">,</span>
    <span class="mi">33282</span><span class="p">,</span>
    <span class="mi">45639</span><span class="p">,</span>
    <span class="mi">46699</span><span class="p">,</span>
    <span class="mi">35740</span><span class="p">,</span>
    <span class="mi">9412</span><span class="p">,</span>
    <span class="mi">54830</span><span class="p">,</span>
    <span class="mi">44191</span><span class="p">,</span>
    <span class="mi">35802</span><span class="p">,</span>
    <span class="mi">23061</span><span class="p">,</span>
    <span class="mi">44728</span><span class="p">,</span>
    <span class="mi">36421</span><span class="p">,</span>
    <span class="mi">48772</span><span class="p">,</span>
    <span class="mi">1009</span><span class="p">,</span>
    <span class="mi">55089</span><span class="p">,</span>
    <span class="mi">46336</span><span class="p">,</span>
    <span class="mi">5898</span><span class="p">,</span>
    <span class="mi">25672</span><span class="p">,</span>
    <span class="mi">5729</span><span class="p">,</span>
    <span class="mi">35894</span><span class="p">,</span>
    <span class="mi">48649</span><span class="p">,</span>
    <span class="mi">41716</span><span class="p">,</span>
    <span class="mi">46429</span><span class="p">,</span>
    <span class="mi">34903</span><span class="p">,</span>
    <span class="mi">2048</span><span class="p">,</span>
    <span class="mi">15100</span><span class="p">,</span>
    <span class="mi">20657</span><span class="p">,</span>
    <span class="mi">47788</span><span class="p">,</span>
    <span class="mi">36799</span><span class="p">,</span>
    <span class="mi">22143</span><span class="p">,</span>
    <span class="mi">18943</span><span class="p">,</span>
    <span class="mi">3910</span><span class="p">,</span>
    <span class="mi">23770</span><span class="p">,</span>
    <span class="mi">54559</span><span class="p">,</span>
    <span class="mi">47625</span><span class="p">,</span>
    <span class="mi">45886</span><span class="p">,</span>
    <span class="mi">39492</span><span class="p">,</span>
    <span class="mi">13150</span><span class="p">,</span>
    <span class="mi">15517</span><span class="p">,</span>
    <span class="mi">42365</span><span class="p">,</span>
    <span class="mi">15957</span><span class="p">,</span>
    <span class="mi">9998</span><span class="p">,</span>
    <span class="mi">27710</span><span class="p">,</span>
    <span class="mi">44947</span><span class="p">,</span>
    <span class="mi">41223</span><span class="p">,</span>
    <span class="mi">30797</span><span class="p">,</span>
    <span class="mi">34075</span><span class="p">,</span>
    <span class="mi">1746</span><span class="p">,</span>
    <span class="mi">936</span><span class="p">,</span>
    <span class="mi">29242</span><span class="p">,</span>
    <span class="mi">11607</span><span class="p">,</span>
    <span class="mi">1512</span><span class="p">,</span>
    <span class="mi">43561</span><span class="p">,</span>
    <span class="mi">21433</span><span class="p">,</span>
    <span class="mi">40354</span><span class="p">,</span>
    <span class="mi">49182</span><span class="p">,</span>
    <span class="mi">47826</span><span class="p">,</span>
    <span class="mi">48188</span><span class="p">,</span>
    <span class="mi">22556</span><span class="p">,</span>
    <span class="mi">32290</span><span class="p">,</span>
    <span class="mi">22715</span><span class="p">,</span>
    <span class="mi">42134</span><span class="p">,</span>
    <span class="mi">16732</span><span class="p">,</span>
    <span class="mi">46517</span><span class="p">,</span>
    <span class="mi">36151</span><span class="p">,</span>
    <span class="mi">53998</span><span class="p">,</span>
    <span class="mi">22282</span><span class="p">,</span>
    <span class="mi">48719</span><span class="p">,</span>
    <span class="mi">53914</span><span class="p">,</span>
    <span class="mi">12816</span><span class="p">,</span>
    <span class="mi">39033</span><span class="p">,</span>
    <span class="mi">50100</span><span class="p">,</span>
    <span class="mi">22013</span><span class="p">,</span>
    <span class="mi">6394</span><span class="p">,</span>
    <span class="mi">28314</span><span class="p">,</span>
    <span class="mi">46597</span><span class="p">,</span>
    <span class="mi">15518</span><span class="p">,</span>
    <span class="mi">50940</span><span class="p">,</span>
    <span class="mi">5448</span><span class="p">,</span>
    <span class="mi">26062</span><span class="p">,</span>
    <span class="mi">49161</span><span class="p">,</span>
    <span class="mi">51524</span><span class="p">,</span>
    <span class="mi">23881</span><span class="p">,</span>
    <span class="mi">27827</span><span class="p">,</span>
    <span class="mi">37421</span><span class="p">,</span>
    <span class="mi">50338</span><span class="p">,</span>
    <span class="mi">50342</span><span class="p">,</span>
    <span class="mi">15126</span><span class="p">,</span>
    <span class="mi">19795</span><span class="p">,</span>
    <span class="mi">43782</span><span class="p">,</span>
    <span class="mi">5827</span><span class="p">,</span>
    <span class="mi">31717</span><span class="p">,</span>
    <span class="mi">35617</span><span class="p">,</span>
    <span class="mi">5900</span><span class="p">,</span>
    <span class="mi">18764</span><span class="p">,</span>
    <span class="mi">51704</span><span class="p">,</span>
    <span class="mi">2961</span><span class="p">,</span>
    <span class="mi">14787</span><span class="p">,</span>
    <span class="mi">11637</span><span class="p">,</span>
    <span class="mi">15019</span><span class="p">,</span>
    <span class="mi">11895</span><span class="p">,</span>
    <span class="mi">52672</span><span class="p">,</span>
    <span class="mi">40474</span><span class="p">,</span>
    <span class="mi">22860</span><span class="p">,</span>
    <span class="mi">43123</span><span class="p">,</span>
    <span class="mi">31050</span><span class="p">,</span>
    <span class="mi">46590</span><span class="p">,</span>
    <span class="mi">4379</span><span class="p">,</span>
    <span class="mi">11972</span><span class="p">,</span>
    <span class="mi">23576</span><span class="p">,</span>
    <span class="mi">16893</span><span class="p">,</span>
    <span class="mi">12409</span><span class="p">,</span>
    <span class="mi">54716</span><span class="p">,</span>
    <span class="mi">33554</span><span class="p">,</span>
    <span class="mi">55040</span><span class="p">,</span>
    <span class="mi">1601</span><span class="p">,</span>
    <span class="mi">32576</span><span class="p">,</span>
    <span class="mi">30327</span><span class="p">,</span>
    <span class="mi">28526</span><span class="p">,</span>
    <span class="mi">3385</span><span class="p">,</span>
    <span class="mi">37937</span><span class="p">,</span>
    <span class="mi">18950</span><span class="p">,</span>
    <span class="mi">50683</span><span class="p">,</span>
    <span class="mi">43753</span><span class="p">,</span>
    <span class="mi">13339</span><span class="p">,</span>
    <span class="mi">26335</span><span class="p">,</span>
    <span class="mi">41237</span><span class="p">,</span>
    <span class="mi">17421</span><span class="p">,</span>
    <span class="mi">48792</span><span class="p">,</span>
    <span class="mi">35034</span><span class="p">,</span>
    <span class="mi">6553</span><span class="p">,</span>
    <span class="mi">36213</span><span class="p">,</span>
    <span class="mi">13189</span><span class="p">,</span>
    <span class="mi">15055</span><span class="p">,</span>
    <span class="mi">47037</span><span class="p">,</span>
    <span class="mi">14775</span><span class="p">,</span>
    <span class="mi">12995</span><span class="p">,</span>
    <span class="mi">37018</span><span class="p">,</span>
    <span class="mi">9467</span><span class="p">,</span>
    <span class="mi">35404</span><span class="p">,</span>
    <span class="mi">17462</span><span class="p">,</span>
    <span class="mi">25088</span><span class="p">,</span>
    <span class="mi">38942</span><span class="p">,</span>
    <span class="mi">14976</span><span class="p">,</span>
    <span class="mi">602</span><span class="p">,</span>
    <span class="mi">54047</span><span class="p">,</span>
    <span class="mi">15519</span><span class="p">,</span>
    <span class="mi">2598</span><span class="p">,</span>
    <span class="mi">366</span><span class="p">,</span>
    <span class="mi">49210</span><span class="p">,</span>
    <span class="mi">4257</span><span class="p">,</span>
    <span class="mi">351</span><span class="p">,</span>
    <span class="mi">13090</span><span class="p">,</span>
    <span class="mi">51921</span><span class="p">,</span>
    <span class="mi">3034</span><span class="p">,</span>
    <span class="mi">50274</span><span class="p">,</span>
    <span class="mi">50715</span><span class="p">,</span>
    <span class="mi">52259</span><span class="p">,</span>
    <span class="mi">46924</span><span class="p">,</span>
<span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ActiveLearner" class="doc_header"><code>class</code> <code>ActiveLearner</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/predetermined_acquisitions_70.py#L408" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ActiveLearner</code>(<strong><code>acquisition_size</code></strong>:<code>int</code>, <strong><code>num_validation_samples</code></strong>:<code>int</code>, <strong><code>num_pool_samples</code></strong>:<code>int</code>, <strong><code>train_eval_model</code></strong>:<code>TrainEvalModel</code>, <strong><code>model_trainer</code></strong>:<code>ModelTrainer</code>, <strong><code>data</code></strong>:<a href="/batchbald_redux/experiment_cifar10_xmi_labels_clean.html#ExperimentData"><code>ExperimentData</code></a>, <strong><code>disable_training_augmentations</code></strong>:<code>bool</code>, <strong><code>device</code></strong>:<code>Optional</code>)</p>
</blockquote>
<p>ActiveLearner(acquisition_size: int, num_validation_samples: int, num_pool_samples: int, train_eval_model: batchbald_redux.train_eval_model.TrainEvalModel, model_trainer: batchbald_redux.trained_model.ModelTrainer, data: batchbald_redux.experiment_data.ExperimentData, disable_training_augmentations: bool, device: Optional)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="UnifiedExperiment" class="doc_header"><code>class</code> <code>UnifiedExperiment</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/predetermined_acquisitions_70.py#L491" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>UnifiedExperiment</code>(<strong><code>seed</code></strong>:<code>int</code>, <strong><code>experiment_data_config</code></strong>:<a href="/batchbald_redux/experiment_cifar10_xmi_labels_clean.html#ExperimentDataConfig"><code>ExperimentDataConfig</code></a>, <strong><code>acquisition_size</code></strong>:<code>int</code>=<em><code>5</code></em>, <strong><code>max_training_epochs</code></strong>:<code>int</code>=<em><code>300</code></em>, <strong><code>num_pool_samples</code></strong>:<code>int</code>=<em><code>100</code></em>, <strong><code>num_validation_samples</code></strong>:<code>int</code>=<em><code>20</code></em>, <strong><code>num_training_samples</code></strong>:<code>int</code>=<em><code>1</code></em>, <strong><code>device</code></strong>:<code>str</code>=<em><code>'cuda'</code></em>, <strong><code>acquisition_function</code></strong>:<code>Union</code>[<code>Type</code>[<code>CandidateBatchComputer</code>], <code>Type</code>[<code>EvalModelBatchComputer</code>]]=<em><code>BALD</code></em>, <strong><code>train_eval_model</code></strong>:<code>Type</code>[<code>TrainEvalModel</code>]=<em><code>TrainSelfDistillationEvalModel</code></em>, <strong><code>model_trainer_factory</code></strong>:<code>Type</code>[<code>ModelTrainer</code>]=<em><code>Cifar10ModelTrainer</code></em>, <strong><code>ensemble_size</code></strong>:<code>int</code>=<em><code>1</code></em>, <strong><code>temperature</code></strong>:<code>float</code>=<em><code>0.0</code></em>, <strong><code>epig_bootstrap_type</code></strong>:<code>BootstrapType</code>=<em><code>&lt;BootstrapType.NO_BOOTSTRAP: 0&gt;</code></em>, <strong><code>epig_bootstrap_factor</code></strong>:<code>float</code>=<em><code>1.0</code></em>, <strong><code>epig_dtype</code></strong>:<code>dtype</code>=<em><code>torch.float64</code></em>, <strong><code>disable_training_augmentations</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>cache_explicit_eval_model</code></strong>:<code>bool</code>=<em><code>False</code></em>)</p>
</blockquote>
<p>UnifiedExperiment(seed: int, experiment_data_config: batchbald_redux.experiment_data.ExperimentDataConfig, acquisition_size: int = 5, max_training_epochs: int = 300, num_pool_samples: int = 100, num_validation_samples: int = 20, num_training_samples: int = 1, device: str = 'cuda', acquisition_function: Union[Type[batchbald_redux.acquisition_functions.candidate_batch_computers.CandidateBatchComputer], Type[batchbald_redux.acquisition_functions.candidate_batch_computers.EvalModelBatchComputer]] = &lt;class 'batchbald_redux.acquisition_functions.bald.BALD'&gt;, train_eval_model: Type[batchbald_redux.train_eval_model.TrainEvalModel] = &lt;class 'batchbald_redux.train_eval_model.TrainSelfDistillationEvalModel'&gt;, model_trainer_factory: Type[batchbald_redux.trained_model.ModelTrainer] = &lt;class 'batchbald_redux.resnet_models.Cifar10ModelTrainer'&gt;, ensemble_size: int = 1, temperature: float = 0.0, epig_bootstrap_type: batchbald_redux.acquisition_functions.epig.BootstrapType = &lt;BootstrapType.NO_BOOTSTRAP: 0&gt;, epig_bootstrap_factor: float = 1.0, epig_dtype: torch.dtype = torch.float64, disable_training_augmentations: bool = False, cache_explicit_eval_model: bool = False)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">ActiveLearner</span><span class="p">:</span>
    <span class="n">acquisition_size</span><span class="p">:</span> <span class="nb">int</span>

    <span class="n">num_validation_samples</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">num_pool_samples</span><span class="p">:</span> <span class="nb">int</span>

    <span class="n">train_eval_model</span><span class="p">:</span> <span class="n">TrainEvalModel</span>
    <span class="n">model_trainer</span><span class="p">:</span> <span class="n">ModelTrainer</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">ExperimentData</span>

    <span class="n">disable_training_augmentations</span><span class="p">:</span> <span class="nb">bool</span>

    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log</span><span class="p">):</span>
        <span class="n">log</span><span class="p">[</span><span class="s2">&quot;seed&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">seed</span><span class="p">()</span>

        <span class="c1"># Active Learning setup</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span>

        <span class="n">train_augmentations</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">train_augmentations</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">disable_training_augmentations</span> <span class="k">else</span> <span class="kc">None</span>

        <span class="n">model_trainer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_trainer</span>
        <span class="n">train_eval_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_eval_model</span>

        <span class="n">train_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_train_dataloader</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">training_dataset</span><span class="p">)</span>
        <span class="n">pool_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_evaluation_dataloader</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">pool_dataset</span><span class="p">)</span>
        <span class="n">validation_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_evaluation_dataloader</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">validation_dataset</span><span class="p">)</span>
        <span class="n">test_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_evaluation_dataloader</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">test_dataset</span><span class="p">)</span>

        <span class="n">log</span><span class="p">[</span><span class="s2">&quot;active_learning_steps&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">active_learning_steps</span> <span class="o">=</span> <span class="n">log</span><span class="p">[</span><span class="s2">&quot;active_learning_steps&quot;</span><span class="p">]</span>

        <span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">acquire_base_indices</span><span class="p">(</span><span class="n">additional_initial_acquisitions</span><span class="p">)</span>

        <span class="c1"># Active Training Loop</span>
        <span class="k">for</span> <span class="n">base_index</span> <span class="ow">in</span> <span class="n">predetermind_acquisition_base_indices</span><span class="p">:</span>
            <span class="n">training_set_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">training_dataset</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training set size </span><span class="si">{</span><span class="n">training_set_size</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>

            <span class="c1"># iteration_log = dict(training={}, pool_training={}, evaluation_metrics=None, acquisition=None)</span>
            <span class="n">active_learning_steps</span><span class="o">.</span><span class="n">append</span><span class="p">({})</span>
            <span class="n">iteration_log</span> <span class="o">=</span> <span class="n">active_learning_steps</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

            <span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;training&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

            <span class="c1"># TODO: this is a hack! :(</span>
            <span class="k">if</span> <span class="n">data</span><span class="o">.</span><span class="n">ood_dataset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">validation_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
            <span class="k">elif</span> <span class="n">data</span><span class="o">.</span><span class="n">ood_exposure</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">KLDivLoss</span><span class="p">(</span><span class="n">log_target</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;batchmean&quot;</span><span class="p">)</span>
                <span class="n">validation_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">validation_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>

            <span class="n">trained_model</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_trained</span><span class="p">(</span>
                <span class="n">train_loader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span>
                <span class="n">train_augmentations</span><span class="o">=</span><span class="n">train_augmentations</span><span class="p">,</span>
                <span class="n">validation_loader</span><span class="o">=</span><span class="n">validation_loader</span><span class="p">,</span>
                <span class="n">log</span><span class="o">=</span><span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;training&quot;</span><span class="p">],</span>
                <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
                <span class="n">validation_loss</span><span class="o">=</span><span class="n">validation_loss</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">evaluation_metrics</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">trained_model</span><span class="p">,</span>
                <span class="n">num_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_validation_samples</span><span class="p">,</span>
                <span class="n">loader</span><span class="o">=</span><span class="n">test_loader</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="n">storage_device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;evaluation_metrics&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">evaluation_metrics</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Perf after training </span><span class="si">{</span><span class="n">evaluation_metrics</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;acquisition&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="p">[</span><span class="n">base_index</span><span class="p">])</span>
            <span class="n">acquired_label</span> <span class="o">=</span> <span class="n">get_target</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">base_dataset</span><span class="p">,</span> <span class="n">base_index</span><span class="p">)</span>

            <span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">acquire_base_indices</span><span class="p">([</span><span class="n">base_index</span><span class="p">])</span>

            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Acquiring base index </span><span class="si">{</span><span class="n">base_index</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">acquired_label</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">UnifiedExperiment</span><span class="p">:</span>
    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span>

    <span class="n">experiment_data_config</span><span class="p">:</span> <span class="n">ExperimentDataConfig</span>

    <span class="n">acquisition_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span>

    <span class="n">max_training_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">300</span>

    <span class="n">num_pool_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">num_validation_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="n">num_training_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span>
    <span class="n">acquisition_function</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Type</span><span class="p">[</span><span class="n">CandidateBatchComputer</span><span class="p">],</span> <span class="n">Type</span><span class="p">[</span><span class="n">EvalModelBatchComputer</span><span class="p">]]</span> <span class="o">=</span> <span class="n">batchbald_redux</span>\
        <span class="o">.</span><span class="n">acquisition_functions</span><span class="o">.</span><span class="n">bald</span><span class="o">.</span><span class="n">BALD</span>
    <span class="n">train_eval_model</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">TrainEvalModel</span><span class="p">]</span> <span class="o">=</span> <span class="n">TrainSelfDistillationEvalModel</span>
    <span class="n">model_trainer_factory</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">ModelTrainer</span><span class="p">]</span> <span class="o">=</span> <span class="n">Cifar10ModelTrainer</span>
    <span class="n">ensemble_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">epig_bootstrap_type</span><span class="p">:</span> <span class="n">acquisition_functions</span><span class="o">.</span><span class="n">BootstrapType</span> <span class="o">=</span> <span class="n">acquisition_functions</span><span class="o">.</span><span class="n">BootstrapType</span><span class="o">.</span><span class="n">NO_BOOTSTRAP</span>
    <span class="n">epig_bootstrap_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">epig_dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">double</span>
    <span class="n">disable_training_augmentations</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">cache_explicit_eval_model</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">load_experiment_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ExperimentData</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">experiment_data_config</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">experiment_data_config</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Simple Dependency Injection</span>
    <span class="k">def</span> <span class="nf">create_train_eval_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TrainEvalModel</span><span class="p">:</span>
        <span class="n">di</span> <span class="o">=</span> <span class="n">DependencyInjection</span><span class="p">(</span><span class="nb">vars</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">di</span><span class="o">.</span><span class="n">create_dataclass_type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_eval_model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">create_model_trainer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelTrainer</span><span class="p">:</span>
        <span class="n">di</span> <span class="o">=</span> <span class="n">DependencyInjection</span><span class="p">(</span><span class="nb">vars</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">di</span><span class="o">.</span><span class="n">create_dataclass_type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_trainer_factory</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">store</span><span class="p">):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

        <span class="c1"># Active Learning setup</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_experiment_data</span><span class="p">()</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;dataset_info&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">training</span><span class="o">=</span><span class="nb">repr</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">base_dataset</span><span class="p">),</span> <span class="n">test</span><span class="o">=</span><span class="nb">repr</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">test_dataset</span><span class="p">))</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;initial_training_set_indices&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">initial_training_set_indices</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;evaluation_set_indices&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">evaluation_set_indices</span>

        <span class="n">model_trainer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_model_trainer</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ensemble_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">model_trainer</span> <span class="o">=</span> <span class="n">BayesianEnsembleModelTrainer</span><span class="p">(</span><span class="n">model_trainer</span><span class="o">=</span><span class="n">model_trainer</span><span class="p">,</span> <span class="n">ensemble_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ensemble_size</span><span class="p">)</span>
        <span class="n">train_eval_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_train_eval_model</span><span class="p">()</span>

        <span class="n">active_learner</span> <span class="o">=</span> <span class="n">ActiveLearner</span><span class="p">(</span>
            <span class="n">acquisition_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">acquisition_size</span><span class="p">,</span>
            <span class="n">num_validation_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_validation_samples</span><span class="p">,</span>
            <span class="n">num_pool_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_pool_samples</span><span class="p">,</span>
            <span class="n">disable_training_augmentations</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">disable_training_augmentations</span><span class="p">,</span>
            <span class="n">train_eval_model</span><span class="o">=</span><span class="n">train_eval_model</span><span class="p">,</span>
            <span class="n">model_trainer</span><span class="o">=</span><span class="n">model_trainer</span><span class="p">,</span>
            <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">active_learner</span><span class="p">(</span><span class="n">store</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="MNIST-only">MNIST only<a class="anchor-link" href="#MNIST-only"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># MNIST experiment (ood_exposure=False)</span>

<span class="n">configs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">UnifiedExperiment</span><span class="p">(</span>
        <span class="n">experiment_data_config</span><span class="o">=</span><span class="n">StandardExperimentDataConfig</span><span class="p">(</span>
            <span class="n">id_dataset_name</span><span class="o">=</span><span class="s2">&quot;MNIST&quot;</span><span class="p">,</span>
            <span class="n">id_repetitions</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">initial_training_set_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
            <span class="n">validation_set_size</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span>
            <span class="n">validation_split_random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">evaluation_set_size</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">add_dataset_noise</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">ood_dataset_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">trial</span><span class="p">,</span>
        <span class="n">max_training_epochs</span><span class="o">=</span><span class="mi">120</span><span class="p">,</span>
        <span class="n">model_trainer_factory</span><span class="o">=</span><span class="n">MnistModelTrainer</span><span class="p">,</span>
        <span class="n">num_pool_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">ensemble_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">for</span> <span class="n">trial</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="p">]</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">is_run_from_ipython</span><span class="p">()</span> <span class="ow">and</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">job_id</span><span class="p">,</span> <span class="n">store</span> <span class="ow">in</span> <span class="n">embedded_experiments</span><span class="p">(</span><span class="vm">__file__</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">configs</span><span class="p">)):</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">configs</span><span class="p">[</span><span class="n">job_id</span><span class="p">]</span>
        <span class="n">config</span><span class="o">.</span><span class="n">seed</span> <span class="o">+=</span> <span class="n">job_id</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataclasses</span><span class="o">.</span><span class="n">asdict</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;log&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">config</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">store</span><span class="o">=</span><span class="n">store</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="n">store</span><span class="p">[</span><span class="s2">&quot;exception&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">traceback</span><span class="o">.</span><span class="n">format_exc</span><span class="p">()</span>
            <span class="k">raise</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">configs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max_training_epochs</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">configs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">store</span><span class="o">=</span><span class="n">results</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>StandardExperimentDataConfig(id_dataset_name=&#39;MNIST&#39;, id_repetitions=1, initial_training_set_size=20, validation_set_size=4096, validation_split_random_state=0, evaluation_set_size=0, add_dataset_noise=False, ood_dataset_config=None)
Creating: MnistModelTrainer(
	device=cuda,
	num_training_samples=1,
	num_validation_samples=20,
	max_training_epochs=1
)
Creating: TrainSelfDistillationEvalModel(
	num_pool_samples=100
)
Training set size 70:
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  return floored.astype(np.int)
/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  return floored.astype(np.int)
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch metrics: {&#39;accuracy&#39;: 0.1826171875, &#39;crossentropy&#39;: 2.1524767875671387}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.1826171875)
RestoringEarlyStopping: Restoring optimizer.
Epoch metrics: {&#39;accuracy&#39;: 0.18212890625, &#39;crossentropy&#39;: 2.184953212738037}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.18212890625)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.1739, &#39;crossentropy&#39;: tensor(2.1584)}
Acquiring base index 31664 5
Training set size 71:
Epoch metrics: {&#39;accuracy&#39;: 0.18603515625, &#39;crossentropy&#39;: 2.135267972946167}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.18603515625)
RestoringEarlyStopping: Restoring optimizer.
Epoch metrics: {&#39;accuracy&#39;: 0.20166015625, &#39;crossentropy&#39;: 2.1497042179107666}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.20166015625)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.2105, &#39;crossentropy&#39;: tensor(2.1296)}
Acquiring base index 42015 3
Training set size 72:
Epoch metrics: {&#39;accuracy&#39;: 0.123046875, &#39;crossentropy&#39;: 2.2162139415740967}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.123046875)
RestoringEarlyStopping: Restoring optimizer.
Epoch metrics: {&#39;accuracy&#39;: 0.230712890625, &#39;crossentropy&#39;: 2.1572630405426025}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.230712890625)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.1707, &#39;crossentropy&#39;: tensor(2.1779)}
Acquiring base index 20215 4
Training set size 73:
Epoch metrics: {&#39;accuracy&#39;: 0.23291015625, &#39;crossentropy&#39;: 2.182281494140625}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.23291015625)
RestoringEarlyStopping: Restoring optimizer.
Epoch metrics: {&#39;accuracy&#39;: 0.155517578125, &#39;crossentropy&#39;: 2.195119857788086}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.155517578125)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.1639, &#39;crossentropy&#39;: tensor(2.2010)}
Acquiring base index 37591 2
Training set size 74:
Epoch metrics: {&#39;accuracy&#39;: 0.13720703125, &#39;crossentropy&#39;: 2.2123641967773438}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.13720703125)
RestoringEarlyStopping: Restoring optimizer.
Epoch metrics: {&#39;accuracy&#39;: 0.119140625, &#39;crossentropy&#39;: 2.188255786895752}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.119140625)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.1152, &#39;crossentropy&#39;: tensor(2.2007)}
Acquiring base index 34014 6
Training set size 75:
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Engine run is terminating due to exception: 
Engine run is terminating due to exception: 
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-9-ce5c8ef160d5&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> results <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">{</span><span class="ansi-blue-fg">}</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span> configs<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>max_training_epochs <span class="ansi-blue-fg">=</span> <span class="ansi-cyan-fg">1</span>
<span class="ansi-green-fg">----&gt; 3</span><span class="ansi-red-fg"> </span>configs<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>run<span class="ansi-blue-fg">(</span>store<span class="ansi-blue-fg">=</span>results<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">&lt;ipython-input-6-e784b37b2212&gt;</span> in <span class="ansi-cyan-fg">run</span><span class="ansi-blue-fg">(self, store)</span>
<span class="ansi-green-intense-fg ansi-bold">    150</span>         )
<span class="ansi-green-intense-fg ansi-bold">    151</span> 
<span class="ansi-green-fg">--&gt; 152</span><span class="ansi-red-fg">         </span>active_learner<span class="ansi-blue-fg">(</span>store<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">&lt;ipython-input-6-e784b37b2212&gt;</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, log)</span>
<span class="ansi-green-intense-fg ansi-bold">     58</span>                 loss <span class="ansi-blue-fg">=</span> validation_loss <span class="ansi-blue-fg">=</span> torch<span class="ansi-blue-fg">.</span>nn<span class="ansi-blue-fg">.</span>NLLLoss<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     59</span> 
<span class="ansi-green-fg">---&gt; 60</span><span class="ansi-red-fg">             trained_model = model_trainer.get_trained(
</span><span class="ansi-green-intense-fg ansi-bold">     61</span>                 train_loader<span class="ansi-blue-fg">=</span>train_loader<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">     62</span>                 train_augmentations<span class="ansi-blue-fg">=</span>train_augmentations<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/trained_model.py</span> in <span class="ansi-cyan-fg">get_trained</span><span class="ansi-blue-fg">(self, train_loader, train_augmentations, validation_loader, log, loss, validation_loss)</span>
<span class="ansi-green-intense-fg ansi-bold">    252</span>         <span class="ansi-green-fg">for</span> i <span class="ansi-green-fg">in</span> range<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>ensemble_size<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    253</span>             log<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">&#34;ensemble&#34;</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>append<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">{</span><span class="ansi-blue-fg">}</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 254</span><span class="ansi-red-fg">             model = self.model_trainer.get_trained(
</span><span class="ansi-green-intense-fg ansi-bold">    255</span>                 train_loader<span class="ansi-blue-fg">=</span>train_loader<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    256</span>                 train_augmentations<span class="ansi-blue-fg">=</span>train_augmentations<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/models.py</span> in <span class="ansi-cyan-fg">get_trained</span><span class="ansi-blue-fg">(self, train_loader, train_augmentations, validation_loader, log, loss, validation_loss)</span>
<span class="ansi-green-intense-fg ansi-bold">    137</span>             validation_loss <span class="ansi-blue-fg">=</span> torch<span class="ansi-blue-fg">.</span>nn<span class="ansi-blue-fg">.</span>NLLLoss<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    138</span> 
<span class="ansi-green-fg">--&gt; 139</span><span class="ansi-red-fg">         train(
</span><span class="ansi-green-intense-fg ansi-bold">    140</span>             model<span class="ansi-blue-fg">=</span>model_optimizer<span class="ansi-blue-fg">.</span>model<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    141</span>             optimizer<span class="ansi-blue-fg">=</span>model_optimizer<span class="ansi-blue-fg">.</span>optimizer<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/black_box_model_training.py</span> in <span class="ansi-cyan-fg">train</span><span class="ansi-blue-fg">(model, training_samples, validation_samples, train_loader, validation_loader, patience, max_epochs, device, training_log, loss, validation_loss, optimizer, prefer_accuracy, train_augmentations)</span>
<span class="ansi-green-intense-fg ansi-bold">    140</span> 
<span class="ansi-green-intense-fg ansi-bold">    141</span>     <span class="ansi-red-fg"># Kick everything off</span>
<span class="ansi-green-fg">--&gt; 142</span><span class="ansi-red-fg">     </span>trainer<span class="ansi-blue-fg">.</span>run<span class="ansi-blue-fg">(</span>train_loader<span class="ansi-blue-fg">,</span> max_epochs<span class="ansi-blue-fg">=</span>max_epochs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    143</span> 
<span class="ansi-green-intense-fg ansi-bold">    144</span>     <span class="ansi-green-fg">if</span> early_stopping<span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">run</span><span class="ansi-blue-fg">(self, data, max_epochs, epoch_length, seed)</span>
<span class="ansi-green-intense-fg ansi-bold">    696</span> 
<span class="ansi-green-intense-fg ansi-bold">    697</span>         self<span class="ansi-blue-fg">.</span>state<span class="ansi-blue-fg">.</span>dataloader <span class="ansi-blue-fg">=</span> data
<span class="ansi-green-fg">--&gt; 698</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_internal_run<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    699</span> 
<span class="ansi-green-intense-fg ansi-bold">    700</span>     <span class="ansi-blue-fg">@</span>staticmethod

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">_internal_run</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    769</span>             self<span class="ansi-blue-fg">.</span>_dataloader_iter <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span>
<span class="ansi-green-intense-fg ansi-bold">    770</span>             self<span class="ansi-blue-fg">.</span>logger<span class="ansi-blue-fg">.</span>error<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">f&#34;Engine run is terminating due to exception: {e}&#34;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 771</span><span class="ansi-red-fg">             </span>self<span class="ansi-blue-fg">.</span>_handle_exception<span class="ansi-blue-fg">(</span>e<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    772</span> 
<span class="ansi-green-intense-fg ansi-bold">    773</span>         self<span class="ansi-blue-fg">.</span>_dataloader_iter <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">_handle_exception</span><span class="ansi-blue-fg">(self, e)</span>
<span class="ansi-green-intense-fg ansi-bold">    464</span>             self<span class="ansi-blue-fg">.</span>_fire_event<span class="ansi-blue-fg">(</span>Events<span class="ansi-blue-fg">.</span>EXCEPTION_RAISED<span class="ansi-blue-fg">,</span> e<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    465</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 466</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">raise</span> e
<span class="ansi-green-intense-fg ansi-bold">    467</span> 
<span class="ansi-green-intense-fg ansi-bold">    468</span>     <span class="ansi-blue-fg">@</span>property

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">_internal_run</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    746</span>                     self<span class="ansi-blue-fg">.</span>_fire_event<span class="ansi-blue-fg">(</span>Events<span class="ansi-blue-fg">.</span>TERMINATE<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    747</span>                 <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 748</span><span class="ansi-red-fg">                     </span>self<span class="ansi-blue-fg">.</span>_fire_event<span class="ansi-blue-fg">(</span>Events<span class="ansi-blue-fg">.</span>EPOCH_COMPLETED<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    749</span>                 time_taken <span class="ansi-blue-fg">+=</span> time<span class="ansi-blue-fg">.</span>time<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">-</span> handlers_start_time
<span class="ansi-green-intense-fg ansi-bold">    750</span>                 <span class="ansi-red-fg"># update time wrt handlers</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">_fire_event</span><span class="ansi-blue-fg">(self, event_name, *event_args, **event_kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    419</span>             kwargs<span class="ansi-blue-fg">.</span>update<span class="ansi-blue-fg">(</span>event_kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    420</span>             first<span class="ansi-blue-fg">,</span> others <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">(</span>args<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> args<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">:</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">if</span> <span class="ansi-blue-fg">(</span>args <span class="ansi-green-fg">and</span> args<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">==</span> self<span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">else</span> <span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> args<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 421</span><span class="ansi-red-fg">             </span>func<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>first<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span><span class="ansi-blue-fg">(</span>event_args <span class="ansi-blue-fg">+</span> others<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    422</span> 
<span class="ansi-green-intense-fg ansi-bold">    423</span>     <span class="ansi-green-fg">def</span> fire_event<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> event_name<span class="ansi-blue-fg">:</span> Any<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">-&gt;</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/black_box_model_training.py</span> in <span class="ansi-cyan-fg">compute_metrics</span><span class="ansi-blue-fg">(engine)</span>
<span class="ansi-green-intense-fg ansi-bold">     84</span>     <span class="ansi-blue-fg">@</span>trainer<span class="ansi-blue-fg">.</span>on<span class="ansi-blue-fg">(</span>Events<span class="ansi-blue-fg">.</span>EPOCH_COMPLETED<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     85</span>     <span class="ansi-green-fg">def</span> compute_metrics<span class="ansi-blue-fg">(</span>engine<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">---&gt; 86</span><span class="ansi-red-fg">         </span>validation_evaluator<span class="ansi-blue-fg">.</span>run<span class="ansi-blue-fg">(</span>validation_loader<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     87</span> 
<span class="ansi-green-intense-fg ansi-bold">     88</span>     <span class="ansi-red-fg"># Only to look nicer.</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">run</span><span class="ansi-blue-fg">(self, data, max_epochs, epoch_length, seed)</span>
<span class="ansi-green-intense-fg ansi-bold">    696</span> 
<span class="ansi-green-intense-fg ansi-bold">    697</span>         self<span class="ansi-blue-fg">.</span>state<span class="ansi-blue-fg">.</span>dataloader <span class="ansi-blue-fg">=</span> data
<span class="ansi-green-fg">--&gt; 698</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_internal_run<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    699</span> 
<span class="ansi-green-intense-fg ansi-bold">    700</span>     <span class="ansi-blue-fg">@</span>staticmethod

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">_internal_run</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    769</span>             self<span class="ansi-blue-fg">.</span>_dataloader_iter <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span>
<span class="ansi-green-intense-fg ansi-bold">    770</span>             self<span class="ansi-blue-fg">.</span>logger<span class="ansi-blue-fg">.</span>error<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">f&#34;Engine run is terminating due to exception: {e}&#34;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 771</span><span class="ansi-red-fg">             </span>self<span class="ansi-blue-fg">.</span>_handle_exception<span class="ansi-blue-fg">(</span>e<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    772</span> 
<span class="ansi-green-intense-fg ansi-bold">    773</span>         self<span class="ansi-blue-fg">.</span>_dataloader_iter <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">_handle_exception</span><span class="ansi-blue-fg">(self, e)</span>
<span class="ansi-green-intense-fg ansi-bold">    464</span>             self<span class="ansi-blue-fg">.</span>_fire_event<span class="ansi-blue-fg">(</span>Events<span class="ansi-blue-fg">.</span>EXCEPTION_RAISED<span class="ansi-blue-fg">,</span> e<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    465</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 466</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">raise</span> e
<span class="ansi-green-intense-fg ansi-bold">    467</span> 
<span class="ansi-green-intense-fg ansi-bold">    468</span>     <span class="ansi-blue-fg">@</span>property

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">_internal_run</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    739</span>                     self<span class="ansi-blue-fg">.</span>_setup_engine<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    740</span> 
<span class="ansi-green-fg">--&gt; 741</span><span class="ansi-red-fg">                 </span>time_taken <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_run_once_on_dataset<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    742</span>                 <span class="ansi-red-fg"># time is available for handlers but must be update after fire</span>
<span class="ansi-green-intense-fg ansi-bold">    743</span>                 self<span class="ansi-blue-fg">.</span>state<span class="ansi-blue-fg">.</span>times<span class="ansi-blue-fg">[</span>Events<span class="ansi-blue-fg">.</span>EPOCH_COMPLETED<span class="ansi-blue-fg">.</span>name<span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> time_taken

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">_run_once_on_dataset</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    830</span>                 self<span class="ansi-blue-fg">.</span>_fire_event<span class="ansi-blue-fg">(</span>Events<span class="ansi-blue-fg">.</span>ITERATION_STARTED<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    831</span>                 self<span class="ansi-blue-fg">.</span>state<span class="ansi-blue-fg">.</span>output <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_process_function<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>state<span class="ansi-blue-fg">.</span>batch<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 832</span><span class="ansi-red-fg">                 </span>self<span class="ansi-blue-fg">.</span>_fire_event<span class="ansi-blue-fg">(</span>Events<span class="ansi-blue-fg">.</span>ITERATION_COMPLETED<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    833</span> 
<span class="ansi-green-intense-fg ansi-bold">    834</span>                 <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>should_terminate <span class="ansi-green-fg">or</span> self<span class="ansi-blue-fg">.</span>should_terminate_single_epoch<span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">_fire_event</span><span class="ansi-blue-fg">(self, event_name, *event_args, **event_kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    419</span>             kwargs<span class="ansi-blue-fg">.</span>update<span class="ansi-blue-fg">(</span>event_kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    420</span>             first<span class="ansi-blue-fg">,</span> others <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">(</span>args<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> args<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">:</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">if</span> <span class="ansi-blue-fg">(</span>args <span class="ansi-green-fg">and</span> args<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">==</span> self<span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">else</span> <span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> args<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 421</span><span class="ansi-red-fg">             </span>func<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>first<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span><span class="ansi-blue-fg">(</span>event_args <span class="ansi-blue-fg">+</span> others<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    422</span> 
<span class="ansi-green-intense-fg ansi-bold">    423</span>     <span class="ansi-green-fg">def</span> fire_event<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> event_name<span class="ansi-blue-fg">:</span> Any<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">-&gt;</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/autograd/grad_mode.py</span> in <span class="ansi-cyan-fg">decorate_context</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">     26</span>         <span class="ansi-green-fg">def</span> decorate_context<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     27</span>             <span class="ansi-green-fg">with</span> self<span class="ansi-blue-fg">.</span>__class__<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">---&gt; 28</span><span class="ansi-red-fg">                 </span><span class="ansi-green-fg">return</span> func<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     29</span>         <span class="ansi-green-fg">return</span> cast<span class="ansi-blue-fg">(</span>F<span class="ansi-blue-fg">,</span> decorate_context<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     30</span> 

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/metrics/metric.py</span> in <span class="ansi-cyan-fg">iteration_completed</span><span class="ansi-blue-fg">(self, engine)</span>
<span class="ansi-green-intense-fg ansi-bold">    319</span>                 self<span class="ansi-blue-fg">.</span>update<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">(</span>tensor_o1<span class="ansi-blue-fg">,</span> tensor_o2<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    320</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 321</span><span class="ansi-red-fg">             </span>self<span class="ansi-blue-fg">.</span>update<span class="ansi-blue-fg">(</span>output<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    322</span> 
<span class="ansi-green-intense-fg ansi-bold">    323</span>     <span class="ansi-green-fg">def</span> completed<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> engine<span class="ansi-blue-fg">:</span> Engine<span class="ansi-blue-fg">,</span> name<span class="ansi-blue-fg">:</span> str<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">-&gt;</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/metrics/metric.py</span> in <span class="ansi-cyan-fg">wrapper</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    603</span>     <span class="ansi-blue-fg">@</span>wraps<span class="ansi-blue-fg">(</span>func<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    604</span>     <span class="ansi-green-fg">def</span> wrapper<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">:</span> Metric<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">:</span> Any<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">:</span> Any<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">-&gt;</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 605</span><span class="ansi-red-fg">         </span>func<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    606</span>         self<span class="ansi-blue-fg">.</span>_is_reduced <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">False</span>
<span class="ansi-green-intense-fg ansi-bold">    607</span> 

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/metrics/accuracy.py</span> in <span class="ansi-cyan-fg">update</span><span class="ansi-blue-fg">(self, output)</span>
<span class="ansi-green-intense-fg ansi-bold">    162</span>             correct <span class="ansi-blue-fg">=</span> torch<span class="ansi-blue-fg">.</span>all<span class="ansi-blue-fg">(</span>y <span class="ansi-blue-fg">==</span> y_pred<span class="ansi-blue-fg">.</span>type_as<span class="ansi-blue-fg">(</span>y<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> dim<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">-</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    163</span> 
<span class="ansi-green-fg">--&gt; 164</span><span class="ansi-red-fg">         </span>self<span class="ansi-blue-fg">.</span>_num_correct <span class="ansi-blue-fg">+=</span> torch<span class="ansi-blue-fg">.</span>sum<span class="ansi-blue-fg">(</span>correct<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>to<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>_device<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    165</span>         self<span class="ansi-blue-fg">.</span>_num_examples <span class="ansi-blue-fg">+=</span> correct<span class="ansi-blue-fg">.</span>shape<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span>
<span class="ansi-green-intense-fg ansi-bold">    166</span> 

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

