---

title: Evaluate Predetermined Top-K Acquisitions


keywords: fastai
sidebar: home_sidebar

summary: "Resistance is futile."
description: "Resistance is futile."
nb_path: "U_predetermined_acquisitions_20.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: U_predetermined_acquisitions_20.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Appended /home/blackhc/PycharmProjects/bald-ical/src to paths
Switched to directory /home/blackhc/PycharmProjects/bald-ical
%load_ext autoreload
%autoreload 2
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Import modules and functions were are going to use.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">dataclasses</span>
<span class="kn">import</span> <span class="nn">traceback</span>
<span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Type</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.utils.data</span>
<span class="kn">from</span> <span class="nn">blackhc.project</span> <span class="kn">import</span> <span class="n">is_run_from_ipython</span>
<span class="kn">from</span> <span class="nn">blackhc.project.experiment</span> <span class="kn">import</span> <span class="n">embedded_experiments</span>

<span class="kn">import</span> <span class="nn">batchbald_redux.acquisition_functions.bald</span>
<span class="kn">from</span> <span class="nn">batchbald_redux</span> <span class="kn">import</span> <span class="n">acquisition_functions</span><span class="p">,</span> <span class="n">baseline_acquisition_functions</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.acquisition_functions</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">CandidateBatchComputer</span><span class="p">,</span>
    <span class="n">EvalDatasetBatchComputer</span><span class="p">,</span>
    <span class="n">EvalModelBatchComputer</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.joint_entropy</span> <span class="kn">import</span> <span class="n">compute_entropy</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.acquisition_functions.bald</span> <span class="kn">import</span> <span class="n">get_bald_scores</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.black_box_model_training</span> <span class="kn">import</span> <span class="n">evaluate</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.dataset_challenges</span> <span class="kn">import</span> <span class="n">get_base_dataset_index</span><span class="p">,</span> <span class="n">get_target</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.di</span> <span class="kn">import</span> <span class="n">DependencyInjection</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.experiment_data</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ExperimentData</span><span class="p">,</span>
    <span class="n">ExperimentDataConfig</span><span class="p">,</span>
    <span class="n">OoDDatasetConfig</span><span class="p">,</span>
    <span class="n">StandardExperimentDataConfig</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.models</span> <span class="kn">import</span> <span class="n">MnistModelTrainer</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.resnet_models</span> <span class="kn">import</span> <span class="n">Cifar10ModelTrainer</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.train_eval_model</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">TrainEvalModel</span><span class="p">,</span>
    <span class="n">TrainSelfDistillationEvalModel</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.trained_model</span> <span class="kn">import</span> <span class="n">BayesianEnsembleModelTrainer</span><span class="p">,</span> <span class="n">ModelTrainer</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">predetermind_acquisition_base_indices</span> <span class="o">=</span> <span class="p">[</span>
    <span class="mi">26919</span><span class="p">,</span>
    <span class="mi">44321</span><span class="p">,</span>
    <span class="mi">12604</span><span class="p">,</span>
    <span class="mi">18494</span><span class="p">,</span>
    <span class="mi">50811</span><span class="p">,</span>
    <span class="mi">52598</span><span class="p">,</span>
    <span class="mi">33588</span><span class="p">,</span>
    <span class="mi">8467</span><span class="p">,</span>
    <span class="mi">33962</span><span class="p">,</span>
    <span class="mi">6502</span><span class="p">,</span>
    <span class="mi">28779</span><span class="p">,</span>
    <span class="mi">12858</span><span class="p">,</span>
    <span class="mi">50958</span><span class="p">,</span>
    <span class="mi">30271</span><span class="p">,</span>
    <span class="mi">23652</span><span class="p">,</span>
    <span class="mi">52324</span><span class="p">,</span>
    <span class="mi">42837</span><span class="p">,</span>
    <span class="mi">24733</span><span class="p">,</span>
    <span class="mi">22071</span><span class="p">,</span>
    <span class="mi">18574</span><span class="p">,</span>
    <span class="mi">46819</span><span class="p">,</span>
    <span class="mi">9563</span><span class="p">,</span>
    <span class="mi">13559</span><span class="p">,</span>
    <span class="mi">53955</span><span class="p">,</span>
    <span class="mi">31962</span><span class="p">,</span>
    <span class="mi">26636</span><span class="p">,</span>
    <span class="mi">13170</span><span class="p">,</span>
    <span class="mi">3317</span><span class="p">,</span>
    <span class="mi">19463</span><span class="p">,</span>
    <span class="mi">8120</span><span class="p">,</span>
    <span class="mi">481</span><span class="p">,</span>
    <span class="mi">53117</span><span class="p">,</span>
    <span class="mi">31558</span><span class="p">,</span>
    <span class="mi">14832</span><span class="p">,</span>
    <span class="mi">21083</span><span class="p">,</span>
    <span class="mi">354</span><span class="p">,</span>
    <span class="mi">31063</span><span class="p">,</span>
    <span class="mi">16817</span><span class="p">,</span>
    <span class="mi">10231</span><span class="p">,</span>
    <span class="mi">19567</span><span class="p">,</span>
    <span class="mi">19118</span><span class="p">,</span>
    <span class="mi">17641</span><span class="p">,</span>
    <span class="mi">12329</span><span class="p">,</span>
    <span class="mi">7069</span><span class="p">,</span>
    <span class="mi">30911</span><span class="p">,</span>
    <span class="mi">3196</span><span class="p">,</span>
    <span class="mi">8051</span><span class="p">,</span>
    <span class="mi">37688</span><span class="p">,</span>
    <span class="mi">14302</span><span class="p">,</span>
    <span class="mi">30494</span><span class="p">,</span>
    <span class="mi">34143</span><span class="p">,</span>
    <span class="mi">45260</span><span class="p">,</span>
    <span class="mi">31056</span><span class="p">,</span>
    <span class="mi">13647</span><span class="p">,</span>
    <span class="mi">12752</span><span class="p">,</span>
    <span class="mi">7238</span><span class="p">,</span>
    <span class="mi">30174</span><span class="p">,</span>
    <span class="mi">43593</span><span class="p">,</span>
    <span class="mi">2025</span><span class="p">,</span>
    <span class="mi">49302</span><span class="p">,</span>
    <span class="mi">50877</span><span class="p">,</span>
    <span class="mi">38453</span><span class="p">,</span>
    <span class="mi">666</span><span class="p">,</span>
    <span class="mi">6382</span><span class="p">,</span>
    <span class="mi">39297</span><span class="p">,</span>
    <span class="mi">22938</span><span class="p">,</span>
    <span class="mi">28324</span><span class="p">,</span>
    <span class="mi">32880</span><span class="p">,</span>
    <span class="mi">28883</span><span class="p">,</span>
    <span class="mi">44904</span><span class="p">,</span>
    <span class="mi">34288</span><span class="p">,</span>
    <span class="mi">2129</span><span class="p">,</span>
    <span class="mi">7324</span><span class="p">,</span>
    <span class="mi">45973</span><span class="p">,</span>
    <span class="mi">36147</span><span class="p">,</span>
    <span class="mi">26508</span><span class="p">,</span>
    <span class="mi">1275</span><span class="p">,</span>
    <span class="mi">955</span><span class="p">,</span>
    <span class="mi">18612</span><span class="p">,</span>
    <span class="mi">22372</span><span class="p">,</span>
    <span class="mi">54800</span><span class="p">,</span>
    <span class="mi">55261</span><span class="p">,</span>
    <span class="mi">974</span><span class="p">,</span>
    <span class="mi">53928</span><span class="p">,</span>
    <span class="mi">14087</span><span class="p">,</span>
    <span class="mi">13276</span><span class="p">,</span>
    <span class="mi">45615</span><span class="p">,</span>
    <span class="mi">29587</span><span class="p">,</span>
    <span class="mi">1355</span><span class="p">,</span>
    <span class="mi">22543</span><span class="p">,</span>
    <span class="mi">44222</span><span class="p">,</span>
    <span class="mi">28479</span><span class="p">,</span>
    <span class="mi">16597</span><span class="p">,</span>
    <span class="mi">41976</span><span class="p">,</span>
    <span class="mi">32058</span><span class="p">,</span>
    <span class="mi">37236</span><span class="p">,</span>
    <span class="mi">37718</span><span class="p">,</span>
    <span class="mi">39817</span><span class="p">,</span>
    <span class="mi">8377</span><span class="p">,</span>
    <span class="mi">34370</span><span class="p">,</span>
    <span class="mi">44848</span><span class="p">,</span>
    <span class="mi">24996</span><span class="p">,</span>
    <span class="mi">31677</span><span class="p">,</span>
    <span class="mi">19090</span><span class="p">,</span>
    <span class="mi">19569</span><span class="p">,</span>
    <span class="mi">23272</span><span class="p">,</span>
    <span class="mi">50317</span><span class="p">,</span>
    <span class="mi">7021</span><span class="p">,</span>
    <span class="mi">32590</span><span class="p">,</span>
    <span class="mi">38665</span><span class="p">,</span>
    <span class="mi">8325</span><span class="p">,</span>
    <span class="mi">22749</span><span class="p">,</span>
    <span class="mi">33247</span><span class="p">,</span>
    <span class="mi">12608</span><span class="p">,</span>
    <span class="mi">14564</span><span class="p">,</span>
    <span class="mi">31500</span><span class="p">,</span>
    <span class="mi">5961</span><span class="p">,</span>
    <span class="mi">43342</span><span class="p">,</span>
    <span class="mi">2043</span><span class="p">,</span>
    <span class="mi">14842</span><span class="p">,</span>
    <span class="mi">39513</span><span class="p">,</span>
    <span class="mi">27211</span><span class="p">,</span>
    <span class="mi">16296</span><span class="p">,</span>
    <span class="mi">27638</span><span class="p">,</span>
    <span class="mi">19736</span><span class="p">,</span>
    <span class="mi">25089</span><span class="p">,</span>
    <span class="mi">41776</span><span class="p">,</span>
    <span class="mi">34984</span><span class="p">,</span>
    <span class="mi">15749</span><span class="p">,</span>
    <span class="mi">1190</span><span class="p">,</span>
    <span class="mi">47320</span><span class="p">,</span>
    <span class="mi">6995</span><span class="p">,</span>
    <span class="mi">6050</span><span class="p">,</span>
    <span class="mi">20300</span><span class="p">,</span>
    <span class="mi">46216</span><span class="p">,</span>
    <span class="mi">293</span><span class="p">,</span>
    <span class="mi">52393</span><span class="p">,</span>
    <span class="mi">29974</span><span class="p">,</span>
    <span class="mi">12033</span><span class="p">,</span>
    <span class="mi">44877</span><span class="p">,</span>
    <span class="mi">36287</span><span class="p">,</span>
    <span class="mi">11797</span><span class="p">,</span>
    <span class="mi">31127</span><span class="p">,</span>
    <span class="mi">51010</span><span class="p">,</span>
    <span class="mi">14711</span><span class="p">,</span>
    <span class="mi">39470</span><span class="p">,</span>
    <span class="mi">6778</span><span class="p">,</span>
    <span class="mi">26240</span><span class="p">,</span>
    <span class="mi">2649</span><span class="p">,</span>
    <span class="mi">36799</span><span class="p">,</span>
    <span class="mi">39714</span><span class="p">,</span>
    <span class="mi">24714</span><span class="p">,</span>
    <span class="mi">11803</span><span class="p">,</span>
    <span class="mi">4497</span><span class="p">,</span>
    <span class="mi">28859</span><span class="p">,</span>
    <span class="mi">18765</span><span class="p">,</span>
    <span class="mi">15544</span><span class="p">,</span>
    <span class="mi">8758</span><span class="p">,</span>
    <span class="mi">18212</span><span class="p">,</span>
    <span class="mi">17841</span><span class="p">,</span>
    <span class="mi">48971</span><span class="p">,</span>
    <span class="mi">28243</span><span class="p">,</span>
    <span class="mi">37043</span><span class="p">,</span>
    <span class="mi">44047</span><span class="p">,</span>
    <span class="mi">46562</span><span class="p">,</span>
    <span class="mi">21933</span><span class="p">,</span>
    <span class="mi">29090</span><span class="p">,</span>
    <span class="mi">12636</span><span class="p">,</span>
    <span class="mi">26512</span><span class="p">,</span>
    <span class="mi">36271</span><span class="p">,</span>
    <span class="mi">22945</span><span class="p">,</span>
    <span class="mi">49077</span><span class="p">,</span>
    <span class="mi">34918</span><span class="p">,</span>
    <span class="mi">29994</span><span class="p">,</span>
    <span class="mi">55020</span><span class="p">,</span>
    <span class="mi">26210</span><span class="p">,</span>
    <span class="mi">53029</span><span class="p">,</span>
    <span class="mi">53553</span><span class="p">,</span>
    <span class="mi">27512</span><span class="p">,</span>
    <span class="mi">7490</span><span class="p">,</span>
    <span class="mi">20898</span><span class="p">,</span>
    <span class="mi">17666</span><span class="p">,</span>
    <span class="mi">30887</span><span class="p">,</span>
    <span class="mi">5059</span><span class="p">,</span>
    <span class="mi">34869</span><span class="p">,</span>
    <span class="mi">31721</span><span class="p">,</span>
    <span class="mi">16628</span><span class="p">,</span>
    <span class="mi">20465</span><span class="p">,</span>
    <span class="mi">53400</span><span class="p">,</span>
    <span class="mi">3049</span><span class="p">,</span>
    <span class="mi">34885</span><span class="p">,</span>
    <span class="mi">22568</span><span class="p">,</span>
    <span class="mi">47915</span><span class="p">,</span>
    <span class="mi">42158</span><span class="p">,</span>
    <span class="mi">52077</span><span class="p">,</span>
    <span class="mi">26458</span><span class="p">,</span>
    <span class="mi">44333</span><span class="p">,</span>
    <span class="mi">50388</span><span class="p">,</span>
    <span class="mi">36837</span><span class="p">,</span>
    <span class="mi">24183</span><span class="p">,</span>
    <span class="mi">34890</span><span class="p">,</span>
    <span class="mi">41217</span><span class="p">,</span>
    <span class="mi">36471</span><span class="p">,</span>
    <span class="mi">7114</span><span class="p">,</span>
    <span class="mi">3559</span><span class="p">,</span>
    <span class="mi">45728</span><span class="p">,</span>
    <span class="mi">1306</span><span class="p">,</span>
    <span class="mi">32627</span><span class="p">,</span>
    <span class="mi">46860</span><span class="p">,</span>
    <span class="mi">9230</span><span class="p">,</span>
    <span class="mi">54921</span><span class="p">,</span>
    <span class="mi">5505</span><span class="p">,</span>
    <span class="mi">46507</span><span class="p">,</span>
    <span class="mi">24474</span><span class="p">,</span>
    <span class="mi">50461</span><span class="p">,</span>
    <span class="mi">23370</span><span class="p">,</span>
    <span class="mi">11472</span><span class="p">,</span>
    <span class="mi">48003</span><span class="p">,</span>
    <span class="mi">43627</span><span class="p">,</span>
    <span class="mi">44532</span><span class="p">,</span>
    <span class="mi">45509</span><span class="p">,</span>
    <span class="mi">43134</span><span class="p">,</span>
    <span class="mi">38829</span><span class="p">,</span>
    <span class="mi">12995</span><span class="p">,</span>
    <span class="mi">48278</span><span class="p">,</span>
    <span class="mi">26167</span><span class="p">,</span>
    <span class="mi">35733</span><span class="p">,</span>
    <span class="mi">22548</span><span class="p">,</span>
    <span class="mi">29346</span><span class="p">,</span>
    <span class="mi">24341</span><span class="p">,</span>
    <span class="mi">6756</span><span class="p">,</span>
    <span class="mi">13021</span><span class="p">,</span>
    <span class="mi">6732</span><span class="p">,</span>
    <span class="mi">47842</span><span class="p">,</span>
    <span class="mi">24974</span><span class="p">,</span>
    <span class="mi">3155</span><span class="p">,</span>
    <span class="mi">33543</span><span class="p">,</span>
    <span class="mi">38326</span><span class="p">,</span>
    <span class="mi">3105</span><span class="p">,</span>
    <span class="mi">11793</span><span class="p">,</span>
    <span class="mi">28897</span><span class="p">,</span>
    <span class="mi">5313</span><span class="p">,</span>
    <span class="mi">12221</span><span class="p">,</span>
    <span class="mi">18992</span><span class="p">,</span>
    <span class="mi">32672</span><span class="p">,</span>
    <span class="mi">22815</span><span class="p">,</span>
    <span class="mi">38098</span><span class="p">,</span>
    <span class="mi">10022</span><span class="p">,</span>
    <span class="mi">4736</span><span class="p">,</span>
    <span class="mi">52133</span><span class="p">,</span>
    <span class="mi">5190</span><span class="p">,</span>
    <span class="mi">7480</span><span class="p">,</span>
    <span class="mi">55130</span><span class="p">,</span>
    <span class="mi">32369</span><span class="p">,</span>
    <span class="mi">32756</span><span class="p">,</span>
    <span class="mi">48768</span><span class="p">,</span>
    <span class="mi">52248</span><span class="p">,</span>
    <span class="mi">241</span><span class="p">,</span>
    <span class="mi">48294</span><span class="p">,</span>
    <span class="mi">55407</span><span class="p">,</span>
    <span class="mi">48642</span><span class="p">,</span>
    <span class="mi">7688</span><span class="p">,</span>
    <span class="mi">54038</span><span class="p">,</span>
    <span class="mi">20243</span><span class="p">,</span>
    <span class="mi">1520</span><span class="p">,</span>
    <span class="mi">11382</span><span class="p">,</span>
    <span class="mi">9257</span><span class="p">,</span>
    <span class="mi">14018</span><span class="p">,</span>
    <span class="mi">6277</span><span class="p">,</span>
    <span class="mi">23889</span><span class="p">,</span>
    <span class="mi">52318</span><span class="p">,</span>
    <span class="mi">26143</span><span class="p">,</span>
    <span class="mi">51188</span><span class="p">,</span>
    <span class="mi">32907</span><span class="p">,</span>
    <span class="mi">15677</span><span class="p">,</span>
    <span class="mi">2349</span><span class="p">,</span>
    <span class="mi">48140</span><span class="p">,</span>
    <span class="mi">31314</span><span class="p">,</span>
    <span class="mi">18055</span><span class="p">,</span>
    <span class="mi">11270</span><span class="p">,</span>
    <span class="mi">40338</span><span class="p">,</span>
    <span class="mi">29173</span><span class="p">,</span>
    <span class="mi">53693</span><span class="p">,</span>
    <span class="mi">44834</span><span class="p">,</span>
    <span class="mi">14684</span><span class="p">,</span>
    <span class="mi">16314</span><span class="p">,</span>
    <span class="mi">54668</span><span class="p">,</span>
    <span class="mi">27606</span><span class="p">,</span>
    <span class="mi">234</span><span class="p">,</span>
    <span class="mi">54791</span><span class="p">,</span>
    <span class="mi">15428</span><span class="p">,</span>
    <span class="mi">51153</span><span class="p">,</span>
    <span class="mi">11254</span><span class="p">,</span>
    <span class="mi">51652</span><span class="p">,</span>
    <span class="mi">41140</span><span class="p">,</span>
    <span class="mi">26610</span><span class="p">,</span>
    <span class="mi">24878</span><span class="p">,</span>
    <span class="mi">38679</span><span class="p">,</span>
    <span class="mi">51566</span><span class="p">,</span>
    <span class="mi">33139</span><span class="p">,</span>
<span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ActiveLearner" class="doc_header"><code>class</code> <code>ActiveLearner</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/predetermined_acquisitions_20.py#L352" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ActiveLearner</code>(<strong><code>acquisition_size</code></strong>:<code>int</code>, <strong><code>num_validation_samples</code></strong>:<code>int</code>, <strong><code>num_pool_samples</code></strong>:<code>int</code>, <strong><code>train_eval_model</code></strong>:<code>TrainEvalModel</code>, <strong><code>model_trainer</code></strong>:<code>ModelTrainer</code>, <strong><code>data</code></strong>:<a href="/batchbald_redux/experiment_cifar10_xmi_labels_clean.html#ExperimentData"><code>ExperimentData</code></a>, <strong><code>disable_training_augmentations</code></strong>:<code>bool</code>, <strong><code>device</code></strong>:<code>Optional</code>)</p>
</blockquote>
<p>ActiveLearner(acquisition_size: int, num_validation_samples: int, num_pool_samples: int, train_eval_model: batchbald_redux.train_eval_model.TrainEvalModel, model_trainer: batchbald_redux.trained_model.ModelTrainer, data: batchbald_redux.experiment_data.ExperimentData, disable_training_augmentations: bool, device: Optional)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="UnifiedExperiment" class="doc_header"><code>class</code> <code>UnifiedExperiment</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/predetermined_acquisitions_20.py#L433" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>UnifiedExperiment</code>(<strong><code>seed</code></strong>:<code>int</code>, <strong><code>experiment_data_config</code></strong>:<a href="/batchbald_redux/experiment_cifar10_xmi_labels_clean.html#ExperimentDataConfig"><code>ExperimentDataConfig</code></a>, <strong><code>acquisition_size</code></strong>:<code>int</code>=<em><code>5</code></em>, <strong><code>max_training_epochs</code></strong>:<code>int</code>=<em><code>300</code></em>, <strong><code>num_pool_samples</code></strong>:<code>int</code>=<em><code>100</code></em>, <strong><code>num_validation_samples</code></strong>:<code>int</code>=<em><code>20</code></em>, <strong><code>num_training_samples</code></strong>:<code>int</code>=<em><code>1</code></em>, <strong><code>device</code></strong>:<code>str</code>=<em><code>'cuda'</code></em>, <strong><code>acquisition_function</code></strong>:<code>Union</code>[<code>Type</code>[<code>CandidateBatchComputer</code>], <code>Type</code>[<code>EvalModelBatchComputer</code>]]=<em><code>BALD</code></em>, <strong><code>train_eval_model</code></strong>:<code>Type</code>[<code>TrainEvalModel</code>]=<em><code>TrainSelfDistillationEvalModel</code></em>, <strong><code>model_trainer_factory</code></strong>:<code>Type</code>[<code>ModelTrainer</code>]=<em><code>Cifar10ModelTrainer</code></em>, <strong><code>ensemble_size</code></strong>:<code>int</code>=<em><code>1</code></em>, <strong><code>temperature</code></strong>:<code>float</code>=<em><code>0.0</code></em>, <strong><code>epig_bootstrap_type</code></strong>:<code>BootstrapType</code>=<em><code>&lt;BootstrapType.NO_BOOTSTRAP: 0&gt;</code></em>, <strong><code>epig_bootstrap_factor</code></strong>:<code>float</code>=<em><code>1.0</code></em>, <strong><code>epig_dtype</code></strong>:<code>dtype</code>=<em><code>torch.float64</code></em>, <strong><code>disable_training_augmentations</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>cache_explicit_eval_model</code></strong>:<code>bool</code>=<em><code>False</code></em>)</p>
</blockquote>
<p>UnifiedExperiment(seed: int, experiment_data_config: batchbald_redux.experiment_data.ExperimentDataConfig, acquisition_size: int = 5, max_training_epochs: int = 300, num_pool_samples: int = 100, num_validation_samples: int = 20, num_training_samples: int = 1, device: str = 'cuda', acquisition_function: Union[Type[batchbald_redux.acquisition_functions.candidate_batch_computers.CandidateBatchComputer], Type[batchbald_redux.acquisition_functions.candidate_batch_computers.EvalModelBatchComputer]] = &lt;class 'batchbald_redux.acquisition_functions.bald.BALD'&gt;, train_eval_model: Type[batchbald_redux.train_eval_model.TrainEvalModel] = &lt;class 'batchbald_redux.train_eval_model.TrainSelfDistillationEvalModel'&gt;, model_trainer_factory: Type[batchbald_redux.trained_model.ModelTrainer] = &lt;class 'batchbald_redux.resnet_models.Cifar10ModelTrainer'&gt;, ensemble_size: int = 1, temperature: float = 0.0, epig_bootstrap_type: batchbald_redux.acquisition_functions.epig.BootstrapType = &lt;BootstrapType.NO_BOOTSTRAP: 0&gt;, epig_bootstrap_factor: float = 1.0, epig_dtype: torch.dtype = torch.float64, disable_training_augmentations: bool = False, cache_explicit_eval_model: bool = False)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">ActiveLearner</span><span class="p">:</span>
    <span class="n">acquisition_size</span><span class="p">:</span> <span class="nb">int</span>

    <span class="n">num_validation_samples</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">num_pool_samples</span><span class="p">:</span> <span class="nb">int</span>

    <span class="n">train_eval_model</span><span class="p">:</span> <span class="n">TrainEvalModel</span>
    <span class="n">model_trainer</span><span class="p">:</span> <span class="n">ModelTrainer</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">ExperimentData</span>

    <span class="n">disable_training_augmentations</span><span class="p">:</span> <span class="nb">bool</span>

    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log</span><span class="p">):</span>
        <span class="n">log</span><span class="p">[</span><span class="s2">&quot;seed&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">seed</span><span class="p">()</span>

        <span class="c1"># Active Learning setup</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span>

        <span class="n">train_augmentations</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">train_augmentations</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">disable_training_augmentations</span> <span class="k">else</span> <span class="kc">None</span>

        <span class="n">model_trainer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_trainer</span>
        <span class="n">train_eval_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_eval_model</span>

        <span class="n">train_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_train_dataloader</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">training_dataset</span><span class="p">)</span>
        <span class="n">pool_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_evaluation_dataloader</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">pool_dataset</span><span class="p">)</span>
        <span class="n">validation_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_evaluation_dataloader</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">validation_dataset</span><span class="p">)</span>
        <span class="n">test_loader</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_evaluation_dataloader</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">test_dataset</span><span class="p">)</span>

        <span class="n">log</span><span class="p">[</span><span class="s2">&quot;active_learning_steps&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">active_learning_steps</span> <span class="o">=</span> <span class="n">log</span><span class="p">[</span><span class="s2">&quot;active_learning_steps&quot;</span><span class="p">]</span>

        <span class="c1"># Active Training Loop</span>
        <span class="k">for</span> <span class="n">base_index</span> <span class="ow">in</span> <span class="n">predetermind_acquisition_base_indices</span><span class="p">:</span>
            <span class="n">training_set_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">training_dataset</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training set size </span><span class="si">{</span><span class="n">training_set_size</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>

            <span class="c1"># iteration_log = dict(training={}, pool_training={}, evaluation_metrics=None, acquisition=None)</span>
            <span class="n">active_learning_steps</span><span class="o">.</span><span class="n">append</span><span class="p">({})</span>
            <span class="n">iteration_log</span> <span class="o">=</span> <span class="n">active_learning_steps</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

            <span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;training&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

            <span class="c1"># TODO: this is a hack! :(</span>
            <span class="k">if</span> <span class="n">data</span><span class="o">.</span><span class="n">ood_dataset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">validation_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
            <span class="k">elif</span> <span class="n">data</span><span class="o">.</span><span class="n">ood_exposure</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">KLDivLoss</span><span class="p">(</span><span class="n">log_target</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;batchmean&quot;</span><span class="p">)</span>
                <span class="n">validation_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">validation_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>

            <span class="n">trained_model</span> <span class="o">=</span> <span class="n">model_trainer</span><span class="o">.</span><span class="n">get_trained</span><span class="p">(</span>
                <span class="n">train_loader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span>
                <span class="n">train_augmentations</span><span class="o">=</span><span class="n">train_augmentations</span><span class="p">,</span>
                <span class="n">validation_loader</span><span class="o">=</span><span class="n">validation_loader</span><span class="p">,</span>
                <span class="n">log</span><span class="o">=</span><span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;training&quot;</span><span class="p">],</span>
                <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
                <span class="n">validation_loss</span><span class="o">=</span><span class="n">validation_loss</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">evaluation_metrics</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">trained_model</span><span class="p">,</span>
                <span class="n">num_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_validation_samples</span><span class="p">,</span>
                <span class="n">loader</span><span class="o">=</span><span class="n">test_loader</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="n">storage_device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;evaluation_metrics&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">evaluation_metrics</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Perf after training </span><span class="si">{</span><span class="n">evaluation_metrics</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="n">iteration_log</span><span class="p">[</span><span class="s2">&quot;acquisition&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="p">[</span><span class="n">base_index</span><span class="p">])</span>
            <span class="n">acquired_label</span> <span class="o">=</span> <span class="n">get_target</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">base_dataset</span><span class="p">,</span> <span class="n">base_index</span><span class="p">)</span>

            <span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">acquire_base_indices</span><span class="p">([</span><span class="n">base_index</span><span class="p">])</span>

            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Acquiring base index </span><span class="si">{</span><span class="n">base_index</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">acquired_label</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">UnifiedExperiment</span><span class="p">:</span>
    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span>

    <span class="n">experiment_data_config</span><span class="p">:</span> <span class="n">ExperimentDataConfig</span>

    <span class="n">acquisition_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span>

    <span class="n">max_training_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">300</span>

    <span class="n">num_pool_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">num_validation_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="n">num_training_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span>
    <span class="n">acquisition_function</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Type</span><span class="p">[</span><span class="n">CandidateBatchComputer</span><span class="p">],</span> <span class="n">Type</span><span class="p">[</span><span class="n">EvalModelBatchComputer</span><span class="p">]]</span> <span class="o">=</span> <span class="n">batchbald_redux</span>\
        <span class="o">.</span><span class="n">acquisition_functions</span><span class="o">.</span><span class="n">bald</span><span class="o">.</span><span class="n">BALD</span>
    <span class="n">train_eval_model</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">TrainEvalModel</span><span class="p">]</span> <span class="o">=</span> <span class="n">TrainSelfDistillationEvalModel</span>
    <span class="n">model_trainer_factory</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">ModelTrainer</span><span class="p">]</span> <span class="o">=</span> <span class="n">Cifar10ModelTrainer</span>
    <span class="n">ensemble_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">epig_bootstrap_type</span><span class="p">:</span> <span class="n">acquisition_functions</span><span class="o">.</span><span class="n">BootstrapType</span> <span class="o">=</span> <span class="n">acquisition_functions</span><span class="o">.</span><span class="n">BootstrapType</span><span class="o">.</span><span class="n">NO_BOOTSTRAP</span>
    <span class="n">epig_bootstrap_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">epig_dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">double</span>
    <span class="n">disable_training_augmentations</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">cache_explicit_eval_model</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">load_experiment_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ExperimentData</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">experiment_data_config</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">experiment_data_config</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Simple Dependency Injection</span>
    <span class="k">def</span> <span class="nf">create_train_eval_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TrainEvalModel</span><span class="p">:</span>
        <span class="n">di</span> <span class="o">=</span> <span class="n">DependencyInjection</span><span class="p">(</span><span class="nb">vars</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">di</span><span class="o">.</span><span class="n">create_dataclass_type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_eval_model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">create_model_trainer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelTrainer</span><span class="p">:</span>
        <span class="n">di</span> <span class="o">=</span> <span class="n">DependencyInjection</span><span class="p">(</span><span class="nb">vars</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">di</span><span class="o">.</span><span class="n">create_dataclass_type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_trainer_factory</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">store</span><span class="p">):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

        <span class="c1"># Active Learning setup</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_experiment_data</span><span class="p">()</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;dataset_info&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">training</span><span class="o">=</span><span class="nb">repr</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">active_learning</span><span class="o">.</span><span class="n">base_dataset</span><span class="p">),</span> <span class="n">test</span><span class="o">=</span><span class="nb">repr</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">test_dataset</span><span class="p">))</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;initial_training_set_indices&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">initial_training_set_indices</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;evaluation_set_indices&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">evaluation_set_indices</span>

        <span class="n">model_trainer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_model_trainer</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ensemble_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">model_trainer</span> <span class="o">=</span> <span class="n">BayesianEnsembleModelTrainer</span><span class="p">(</span><span class="n">model_trainer</span><span class="o">=</span><span class="n">model_trainer</span><span class="p">,</span> <span class="n">ensemble_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ensemble_size</span><span class="p">)</span>
        <span class="n">train_eval_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_train_eval_model</span><span class="p">()</span>

        <span class="n">active_learner</span> <span class="o">=</span> <span class="n">ActiveLearner</span><span class="p">(</span>
            <span class="n">acquisition_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">acquisition_size</span><span class="p">,</span>
            <span class="n">num_validation_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_validation_samples</span><span class="p">,</span>
            <span class="n">num_pool_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_pool_samples</span><span class="p">,</span>
            <span class="n">disable_training_augmentations</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">disable_training_augmentations</span><span class="p">,</span>
            <span class="n">train_eval_model</span><span class="o">=</span><span class="n">train_eval_model</span><span class="p">,</span>
            <span class="n">model_trainer</span><span class="o">=</span><span class="n">model_trainer</span><span class="p">,</span>
            <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">active_learner</span><span class="p">(</span><span class="n">store</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="MNIST-only">MNIST only<a class="anchor-link" href="#MNIST-only"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># MNIST experiment (ood_exposure=False)</span>

<span class="n">configs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">UnifiedExperiment</span><span class="p">(</span>
        <span class="n">experiment_data_config</span><span class="o">=</span><span class="n">StandardExperimentDataConfig</span><span class="p">(</span>
            <span class="n">id_dataset_name</span><span class="o">=</span><span class="s2">&quot;MNIST&quot;</span><span class="p">,</span>
            <span class="n">id_repetitions</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">initial_training_set_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
            <span class="n">validation_set_size</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span>
            <span class="n">validation_split_random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">evaluation_set_size</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">add_dataset_noise</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">ood_dataset_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">trial</span><span class="p">,</span>
        <span class="n">max_training_epochs</span><span class="o">=</span><span class="mi">120</span><span class="p">,</span>
        <span class="n">model_trainer_factory</span><span class="o">=</span><span class="n">MnistModelTrainer</span><span class="p">,</span>
        <span class="n">num_pool_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">ensemble_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">for</span> <span class="n">trial</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="p">]</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">is_run_from_ipython</span><span class="p">()</span> <span class="ow">and</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">job_id</span><span class="p">,</span> <span class="n">store</span> <span class="ow">in</span> <span class="n">embedded_experiments</span><span class="p">(</span><span class="vm">__file__</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">configs</span><span class="p">)):</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">configs</span><span class="p">[</span><span class="n">job_id</span><span class="p">]</span>
        <span class="n">config</span><span class="o">.</span><span class="n">seed</span> <span class="o">+=</span> <span class="n">job_id</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataclasses</span><span class="o">.</span><span class="n">asdict</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;log&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">config</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">store</span><span class="o">=</span><span class="n">store</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="n">store</span><span class="p">[</span><span class="s2">&quot;exception&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">traceback</span><span class="o">.</span><span class="n">format_exc</span><span class="p">()</span>
            <span class="k">raise</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">experiment</span><span class="o">.</span><span class="n">max_training_epochs</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">experiment</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">store</span><span class="o">=</span><span class="n">results</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>StandardExperimentDataConfig(id_dataset_name=&#39;MNIST&#39;, id_repetitions=1, initial_training_set_size=20, validation_set_size=4096, validation_split_random_state=0, evaluation_set_size=0, add_dataset_noise=False, ood_dataset_config=None)
Creating: MnistModelTrainer(
	device=cuda,
	num_training_samples=1,
	num_validation_samples=20,
	max_training_epochs=1
)
Creating: TrainSelfDistillationEvalModel(
	num_pool_samples=100
)
Training set size 20:
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  return floored.astype(np.int)
/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  return floored.astype(np.int)
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch metrics: {&#39;accuracy&#39;: 0.64697265625, &#39;crossentropy&#39;: 1.573607325553894}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.64697265625)
RestoringEarlyStopping: Restoring optimizer.
Epoch metrics: {&#39;accuracy&#39;: 0.60205078125, &#39;crossentropy&#39;: 1.5807950496673584}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.60205078125)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.702, &#39;crossentropy&#39;: tensor(1.5130)}
Acquiring base index 2271 7
Training set size 21:
Epoch metrics: {&#39;accuracy&#39;: 0.580078125, &#39;crossentropy&#39;: 1.5969536304473877}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.580078125)
RestoringEarlyStopping: Restoring optimizer.
Epoch metrics: {&#39;accuracy&#39;: 0.51318359375, &#39;crossentropy&#39;: 1.704433560371399}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.51318359375)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.5663, &#39;crossentropy&#39;: tensor(1.6511)}
Acquiring base index 46353 7
Training set size 22:
Epoch metrics: {&#39;accuracy&#39;: 0.44970703125, &#39;crossentropy&#39;: 1.7838995456695557}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.44970703125)
RestoringEarlyStopping: Restoring optimizer.
Epoch metrics: {&#39;accuracy&#39;: 0.5078125, &#39;crossentropy&#39;: 1.6589611768722534}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.5078125)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.5351, &#39;crossentropy&#39;: tensor(1.7031)}
Acquiring base index 50827 7
Training set size 23:
Epoch metrics: {&#39;accuracy&#39;: 0.515869140625, &#39;crossentropy&#39;: 1.7688831090927124}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.515869140625)
RestoringEarlyStopping: Restoring optimizer.
Epoch metrics: {&#39;accuracy&#39;: 0.509521484375, &#39;crossentropy&#39;: 1.7045642137527466}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.509521484375)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.5413, &#39;crossentropy&#39;: tensor(1.7480)}
Acquiring base index 7715 7
Training set size 24:
Epoch metrics: {&#39;accuracy&#39;: 0.494384765625, &#39;crossentropy&#39;: 1.6831252574920654}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.494384765625)
RestoringEarlyStopping: Restoring optimizer.
Epoch metrics: {&#39;accuracy&#39;: 0.470947265625, &#39;crossentropy&#39;: 1.7477726936340332}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.470947265625)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.5443, &#39;crossentropy&#39;: tensor(1.6521)}
Acquiring base index 55207 7
Training set size 25:
Epoch metrics: {&#39;accuracy&#39;: 0.341552734375, &#39;crossentropy&#39;: 1.8695029020309448}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.341552734375)
RestoringEarlyStopping: Restoring optimizer.
Epoch metrics: {&#39;accuracy&#39;: 0.34375, &#39;crossentropy&#39;: 1.891965627670288}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.34375)
RestoringEarlyStopping: Restoring optimizer.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Exception ignored in: &lt;function tqdm.__del__ at 0x7f230ca83700&gt;
Traceback (most recent call last):
  File &#34;/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/tqdm/std.py&#34;, line 1134, in __del__
    def __del__(self):
KeyboardInterrupt: 
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Perf after training {&#39;accuracy&#39;: 0.3636, &#39;crossentropy&#39;: tensor(1.8576)}
Acquiring base index 14505 4
Training set size 26:
Epoch metrics: {&#39;accuracy&#39;: 0.2734375, &#39;crossentropy&#39;: 2.033482551574707}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.2734375)
RestoringEarlyStopping: Restoring optimizer.
Epoch metrics: {&#39;accuracy&#39;: 0.23876953125, &#39;crossentropy&#39;: 1.9931480884552002}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.23876953125)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.2381, &#39;crossentropy&#39;: tensor(1.9896)}
Acquiring base index 41730 7
Training set size 27:
Epoch metrics: {&#39;accuracy&#39;: 0.33251953125, &#39;crossentropy&#39;: 1.8912001848220825}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.33251953125)
RestoringEarlyStopping: Restoring optimizer.
Epoch metrics: {&#39;accuracy&#39;: 0.379150390625, &#39;crossentropy&#39;: 1.8912718296051025}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.379150390625)
RestoringEarlyStopping: Restoring optimizer.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-28-150d5a6183ad&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> results <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">{</span><span class="ansi-blue-fg">}</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span> experiment<span class="ansi-blue-fg">.</span>max_training_epochs <span class="ansi-blue-fg">=</span> <span class="ansi-cyan-fg">1</span>
<span class="ansi-green-fg">----&gt; 3</span><span class="ansi-red-fg"> </span>experiment<span class="ansi-blue-fg">.</span>run<span class="ansi-blue-fg">(</span>store<span class="ansi-blue-fg">=</span>results<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">&lt;ipython-input-21-6fda4758118d&gt;</span> in <span class="ansi-cyan-fg">run</span><span class="ansi-blue-fg">(self, store)</span>
<span class="ansi-green-intense-fg ansi-bold">    147</span>         )
<span class="ansi-green-intense-fg ansi-bold">    148</span> 
<span class="ansi-green-fg">--&gt; 149</span><span class="ansi-red-fg">         </span>active_learner<span class="ansi-blue-fg">(</span>store<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">&lt;ipython-input-21-6fda4758118d&gt;</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, log)</span>
<span class="ansi-green-intense-fg ansi-bold">     64</span>             )
<span class="ansi-green-intense-fg ansi-bold">     65</span> 
<span class="ansi-green-fg">---&gt; 66</span><span class="ansi-red-fg">             evaluation_metrics = evaluate(
</span><span class="ansi-green-intense-fg ansi-bold">     67</span>                 model<span class="ansi-blue-fg">=</span>trained_model<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">     68</span>                 num_samples<span class="ansi-blue-fg">=</span>self<span class="ansi-blue-fg">.</span>num_validation_samples<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/black_box_model_training.py</span> in <span class="ansi-cyan-fg">evaluate</span><span class="ansi-blue-fg">(model, loader, num_samples, device, storage_device, loss)</span>
<span class="ansi-green-intense-fg ansi-bold">    517</span> 
<span class="ansi-green-intense-fg ansi-bold">    518</span> <span class="ansi-green-fg">def</span> evaluate<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span><span class="ansi-blue-fg">,</span> model<span class="ansi-blue-fg">:</span> TrainedModel<span class="ansi-blue-fg">,</span> loader<span class="ansi-blue-fg">,</span> num_samples<span class="ansi-blue-fg">,</span> device<span class="ansi-blue-fg">,</span> storage_device<span class="ansi-blue-fg">,</span> loss<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 519</span><span class="ansi-red-fg">     log_probs_N_K_C, labels_N = model.get_log_probs_N_K_C_labels_N(
</span><span class="ansi-green-intense-fg ansi-bold">    520</span>         loader<span class="ansi-blue-fg">=</span>loader<span class="ansi-blue-fg">,</span> num_samples<span class="ansi-blue-fg">=</span>num_samples<span class="ansi-blue-fg">,</span> device<span class="ansi-blue-fg">=</span>device<span class="ansi-blue-fg">,</span> storage_device<span class="ansi-blue-fg">=</span>storage_device
<span class="ansi-green-intense-fg ansi-bold">    521</span>     )

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/trained_model.py</span> in <span class="ansi-cyan-fg">get_log_probs_N_K_C_labels_N</span><span class="ansi-blue-fg">(self, loader, num_samples, device, storage_device)</span>
<span class="ansi-green-intense-fg ansi-bold">    110</span> 
<span class="ansi-green-intense-fg ansi-bold">    111</span>         <span class="ansi-green-fg">for</span> model <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">.</span>models<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 112</span><span class="ansi-red-fg">             log_probs_N_K_C, labels_B = model.get_log_probs_N_K_C_labels_N(
</span><span class="ansi-green-intense-fg ansi-bold">    113</span>                 loader<span class="ansi-blue-fg">=</span>loader<span class="ansi-blue-fg">,</span> num_samples<span class="ansi-blue-fg">=</span>member_num_samples<span class="ansi-blue-fg">,</span> device<span class="ansi-blue-fg">=</span>device<span class="ansi-blue-fg">,</span> storage_device<span class="ansi-blue-fg">=</span>storage_device
<span class="ansi-green-intense-fg ansi-bold">    114</span>             )

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/trained_model.py</span> in <span class="ansi-cyan-fg">get_log_probs_N_K_C_labels_N</span><span class="ansi-blue-fg">(self, loader, num_samples, device, storage_device)</span>
<span class="ansi-green-intense-fg ansi-bold">     50</span>         self<span class="ansi-blue-fg">,</span> loader<span class="ansi-blue-fg">:</span> DataLoader<span class="ansi-blue-fg">,</span> num_samples<span class="ansi-blue-fg">:</span> int<span class="ansi-blue-fg">,</span> device<span class="ansi-blue-fg">:</span> object<span class="ansi-blue-fg">,</span> storage_device<span class="ansi-blue-fg">:</span> object
<span class="ansi-green-intense-fg ansi-bold">     51</span>     ):
<span class="ansi-green-fg">---&gt; 52</span><span class="ansi-red-fg">         log_probs_N_K_C, labels_B = self.model.get_predictions_labels(
</span><span class="ansi-green-intense-fg ansi-bold">     53</span>             num_samples<span class="ansi-blue-fg">=</span>num_samples<span class="ansi-blue-fg">,</span> loader<span class="ansi-blue-fg">=</span>loader<span class="ansi-blue-fg">,</span> device<span class="ansi-blue-fg">=</span>device<span class="ansi-blue-fg">,</span> storage_device<span class="ansi-blue-fg">=</span>storage_device
<span class="ansi-green-intense-fg ansi-bold">     54</span>         )

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/consistent_mc_dropout.py</span> in <span class="ansi-cyan-fg">get_predictions_labels</span><span class="ansi-blue-fg">(self, num_samples, loader, device, storage_device)</span>
<span class="ansi-green-intense-fg ansi-bold">    147</span>         self<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span><span class="ansi-blue-fg">,</span> num_samples<span class="ansi-blue-fg">:</span> int<span class="ansi-blue-fg">,</span> loader<span class="ansi-blue-fg">:</span> data<span class="ansi-blue-fg">.</span>DataLoader<span class="ansi-blue-fg">,</span> device<span class="ansi-blue-fg">,</span> storage_device
<span class="ansi-green-intense-fg ansi-bold">    148</span>     ):
<span class="ansi-green-fg">--&gt; 149</span><span class="ansi-red-fg">         return bmodule_get_predictions_labels(
</span><span class="ansi-green-intense-fg ansi-bold">    150</span>             self<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    151</span>             num_samples<span class="ansi-blue-fg">=</span>num_samples<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/autograd/grad_mode.py</span> in <span class="ansi-cyan-fg">decorate_context</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">     26</span>         <span class="ansi-green-fg">def</span> decorate_context<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     27</span>             <span class="ansi-green-fg">with</span> self<span class="ansi-blue-fg">.</span>__class__<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">---&gt; 28</span><span class="ansi-red-fg">                 </span><span class="ansi-green-fg">return</span> func<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     29</span>         <span class="ansi-green-fg">return</span> cast<span class="ansi-blue-fg">(</span>F<span class="ansi-blue-fg">,</span> decorate_context<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     30</span> 

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/consistent_mc_dropout.py</span> in <span class="ansi-cyan-fg">bmodule_get_predictions_labels</span><span class="ansi-blue-fg">(self, num_samples, loader, device, storage_device)</span>
<span class="ansi-green-intense-fg ansi-bold">    391</span> 
<span class="ansi-green-intense-fg ansi-bold">    392</span>     <span class="ansi-blue-fg">@</span>toma<span class="ansi-blue-fg">.</span>execute<span class="ansi-blue-fg">.</span>range<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">,</span> num_samples<span class="ansi-blue-fg">,</span> <span class="ansi-cyan-fg">128</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 393</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">def</span> get_prediction_batch<span class="ansi-blue-fg">(</span>start<span class="ansi-blue-fg">,</span> end<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    394</span>         <span class="ansi-green-fg">nonlocal</span> predictions
<span class="ansi-green-intense-fg ansi-bold">    395</span>         <span class="ansi-green-fg">nonlocal</span> labels

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/toma/__init__.py</span> in <span class="ansi-cyan-fg">execute_range</span><span class="ansi-blue-fg">(func)</span>
<span class="ansi-green-intense-fg ansi-bold">    184</span> 
<span class="ansi-green-intense-fg ansi-bold">    185</span>             <span class="ansi-green-fg">def</span> execute_range<span class="ansi-blue-fg">(</span>func<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 186</span><span class="ansi-red-fg">                 </span><span class="ansi-green-fg">return</span> explicit<span class="ansi-blue-fg">.</span>range<span class="ansi-blue-fg">(</span>func<span class="ansi-blue-fg">,</span> start<span class="ansi-blue-fg">,</span> end<span class="ansi-blue-fg">,</span> initial_step<span class="ansi-blue-fg">,</span> toma_cache_type<span class="ansi-blue-fg">=</span>cache_type<span class="ansi-blue-fg">,</span> toma_context<span class="ansi-blue-fg">=</span>context<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    187</span> 
<span class="ansi-green-intense-fg ansi-bold">    188</span>             <span class="ansi-green-fg">return</span> execute_range

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/toma/__init__.py</span> in <span class="ansi-cyan-fg">range</span><span class="ansi-blue-fg">(func, start, end, initial_step, toma_context, toma_cache_type, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    267</span>         <span class="ansi-green-fg">while</span> current <span class="ansi-blue-fg">&lt;</span> end<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    268</span>             <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 269</span><span class="ansi-red-fg">                 </span>func<span class="ansi-blue-fg">(</span>current<span class="ansi-blue-fg">,</span> min<span class="ansi-blue-fg">(</span>current <span class="ansi-blue-fg">+</span> batchsize<span class="ansi-blue-fg">.</span>get<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> end<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    270</span>                 current <span class="ansi-blue-fg">+=</span> batchsize<span class="ansi-blue-fg">.</span>get<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    271</span>                 gc_cuda<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/consistent_mc_dropout.py</span> in <span class="ansi-cyan-fg">get_prediction_batch</span><span class="ansi-blue-fg">(start, end)</span>
<span class="ansi-green-intense-fg ansi-bold">    421</span>                 labels <span class="ansi-blue-fg">=</span> torch<span class="ansi-blue-fg">.</span>empty<span class="ansi-blue-fg">(</span>labels_shape<span class="ansi-blue-fg">,</span> dtype<span class="ansi-blue-fg">=</span>batch_labels<span class="ansi-blue-fg">.</span>dtype<span class="ansi-blue-fg">,</span> device<span class="ansi-blue-fg">=</span>storage_device<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    422</span> 
<span class="ansi-green-fg">--&gt; 423</span><span class="ansi-red-fg">             </span>predictions<span class="ansi-blue-fg">[</span>data_start<span class="ansi-blue-fg">:</span>data_end<span class="ansi-blue-fg">,</span> start<span class="ansi-blue-fg">:</span>end<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>copy_<span class="ansi-blue-fg">(</span>batch_predictions<span class="ansi-blue-fg">,</span> non_blocking<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    424</span>             <span class="ansi-green-fg">if</span> start <span class="ansi-blue-fg">==</span> <span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    425</span>                 labels<span class="ansi-blue-fg">[</span>data_start<span class="ansi-blue-fg">:</span>data_end<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>copy_<span class="ansi-blue-fg">(</span>batch_labels<span class="ansi-blue-fg">,</span> non_blocking<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">)</span>

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

