---

title: Experiment MNIST: CoreSetPIG & CoreSetPIGBALD


keywords: fastai
sidebar: home_sidebar

summary: "Can we get better by training on our assumptions?"
description: "Can we get better by training on our assumptions?"
nb_path: "09b_experiment_mnist_coreset_pig.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 09b_experiment_mnist_coreset_pig.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Appended /home/blackhc/PycharmProjects/bald-ical/src to paths
Switched to directory /home/blackhc/PycharmProjects/bald-ical
%load_ext autoreload
%autoreload 2
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Import modules and functions were are going to use.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">dataclasses</span>
<span class="kn">import</span> <span class="nn">traceback</span>

<span class="kn">from</span> <span class="nn">blackhc.project</span> <span class="kn">import</span> <span class="n">is_run_from_ipython</span>
<span class="kn">from</span> <span class="nn">blackhc.project.experiment</span> <span class="kn">import</span> <span class="n">embedded_experiments</span>

<span class="kn">import</span> <span class="nn">batchbald_redux.acquisition_functions.bald</span>
<span class="kn">import</span> <span class="nn">batchbald_redux.acquisition_functions.coreset</span>
<span class="kn">from</span> <span class="nn">batchbald_redux</span> <span class="kn">import</span> <span class="n">acquisition_functions</span><span class="p">,</span> <span class="n">baseline_acquisition_functions</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.experiment_data</span> <span class="kn">import</span> <span class="n">StandardExperimentDataConfig</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.models</span> <span class="kn">import</span> <span class="n">MnistModelTrainer</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.unified_experiment</span> <span class="kn">import</span> <span class="n">UnifiedExperiment</span>
<span class="kn">from</span> <span class="nn">batchbald_redux.train_eval_model</span> <span class="kn">import</span> <span class="n">TrainExplicitEvalModel</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">configs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">UnifiedExperiment</span><span class="p">(</span>
        <span class="n">experiment_data_config</span><span class="o">=</span><span class="n">StandardExperimentDataConfig</span><span class="p">(</span>
            <span class="n">id_dataset_name</span><span class="o">=</span><span class="s2">&quot;MNIST&quot;</span><span class="p">,</span>
            <span class="n">id_repetitions</span><span class="o">=</span><span class="n">id_repetitions</span><span class="p">,</span>
            <span class="n">initial_training_set_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
            <span class="n">validation_set_size</span><span class="o">=</span><span class="mi">4000</span><span class="p">,</span>
            <span class="n">validation_split_random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">evaluation_set_size</span><span class="o">=</span><span class="mi">4000</span><span class="p">,</span>
            <span class="n">add_dataset_noise</span><span class="o">=</span><span class="n">id_repetitions</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">ood_dataset_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">seed</span> <span class="o">+</span> <span class="mi">8945</span><span class="p">,</span>
        <span class="n">acquisition_function</span><span class="o">=</span><span class="n">acquisition_function</span><span class="p">,</span>
        <span class="n">acquisition_size</span><span class="o">=</span><span class="n">acquisition_size</span><span class="p">,</span>
        <span class="n">num_pool_samples</span><span class="o">=</span><span class="n">num_pool_samples</span><span class="p">,</span>
        <span class="n">max_training_set</span><span class="o">=</span><span class="mi">120</span><span class="p">,</span>
        <span class="n">model_trainer_factory</span><span class="o">=</span><span class="n">MnistModelTrainer</span><span class="p">,</span>
        <span class="n">train_eval_model</span><span class="o">=</span><span class="n">TrainExplicitEvalModel</span>
    <span class="p">)</span>
    <span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">acquisition_size</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">num_pool_samples</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">100</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">id_repetitions</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">acquisition_function</span> <span class="ow">in</span> <span class="p">[</span>
        <span class="n">batchbald_redux</span><span class="o">.</span><span class="n">acquisition_functions</span><span class="o">.</span><span class="n">bald</span><span class="o">.</span><span class="n">BALD</span><span class="p">,</span>
        <span class="n">batchbald_redux</span><span class="o">.</span><span class="n">acquisition_functions</span><span class="o">.</span><span class="n">coreset</span><span class="o">.</span><span class="n">CoreSetPIG</span><span class="p">,</span>
        <span class="n">batchbald_redux</span><span class="o">.</span><span class="n">acquisition_functions</span><span class="o">.</span><span class="n">coreset</span><span class="o">.</span><span class="n">CoreSetPIGBALD</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">]</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">is_run_from_ipython</span><span class="p">()</span> <span class="ow">and</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">job_id</span><span class="p">,</span> <span class="n">store</span> <span class="ow">in</span> <span class="n">embedded_experiments</span><span class="p">(</span><span class="vm">__file__</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">configs</span><span class="p">)):</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">configs</span><span class="p">[</span><span class="n">job_id</span><span class="p">]</span>
        <span class="n">config</span><span class="o">.</span><span class="n">seed</span> <span class="o">+=</span> <span class="n">job_id</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataclasses</span><span class="o">.</span><span class="n">asdict</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="n">store</span><span class="p">[</span><span class="s2">&quot;log&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">config</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">store</span><span class="o">=</span><span class="n">store</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="n">store</span><span class="p">[</span><span class="s2">&quot;exception&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">traceback</span><span class="o">.</span><span class="n">format_exc</span><span class="p">()</span>
            <span class="k">raise</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">configs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>15</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">prettyprinter</span>

<span class="n">prettyprinter</span><span class="o">.</span><span class="n">install_extras</span><span class="p">({</span><span class="s2">&quot;dataclasses&quot;</span><span class="p">})</span>
<span class="n">prettyprinter</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">configs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8945,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;MNIST&#39;,
            id_repetitions=1,
            initial_training_set_size=20,
            validation_set_size=4000,
            validation_split_random_state=0,
            evaluation_set_size=4000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        max_training_set=120,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8945,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;MNIST&#39;,
            id_repetitions=1,
            initial_training_set_size=20,
            validation_set_size=4000,
            validation_split_random_state=0,
            evaluation_set_size=4000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        max_training_set=120,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.CoreSetPIG,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8945,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;MNIST&#39;,
            id_repetitions=1,
            initial_training_set_size=20,
            validation_set_size=4000,
            validation_split_random_state=0,
            evaluation_set_size=4000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        max_training_set=120,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.CoreSetPIGBALD,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8946,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;MNIST&#39;,
            id_repetitions=1,
            initial_training_set_size=20,
            validation_set_size=4000,
            validation_split_random_state=0,
            evaluation_set_size=4000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        max_training_set=120,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8946,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;MNIST&#39;,
            id_repetitions=1,
            initial_training_set_size=20,
            validation_set_size=4000,
            validation_split_random_state=0,
            evaluation_set_size=4000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        max_training_set=120,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.CoreSetPIG,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8946,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;MNIST&#39;,
            id_repetitions=1,
            initial_training_set_size=20,
            validation_set_size=4000,
            validation_split_random_state=0,
            evaluation_set_size=4000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        max_training_set=120,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.CoreSetPIGBALD,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8947,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;MNIST&#39;,
            id_repetitions=1,
            initial_training_set_size=20,
            validation_set_size=4000,
            validation_split_random_state=0,
            evaluation_set_size=4000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        max_training_set=120,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8947,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;MNIST&#39;,
            id_repetitions=1,
            initial_training_set_size=20,
            validation_set_size=4000,
            validation_split_random_state=0,
            evaluation_set_size=4000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        max_training_set=120,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.CoreSetPIG,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8947,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;MNIST&#39;,
            id_repetitions=1,
            initial_training_set_size=20,
            validation_set_size=4000,
            validation_split_random_state=0,
            evaluation_set_size=4000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        max_training_set=120,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.CoreSetPIGBALD,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8948,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;MNIST&#39;,
            id_repetitions=1,
            initial_training_set_size=20,
            validation_set_size=4000,
            validation_split_random_state=0,
            evaluation_set_size=4000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        max_training_set=120,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8948,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;MNIST&#39;,
            id_repetitions=1,
            initial_training_set_size=20,
            validation_set_size=4000,
            validation_split_random_state=0,
            evaluation_set_size=4000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        max_training_set=120,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.CoreSetPIG,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8948,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;MNIST&#39;,
            id_repetitions=1,
            initial_training_set_size=20,
            validation_set_size=4000,
            validation_split_random_state=0,
            evaluation_set_size=4000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        max_training_set=120,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.CoreSetPIGBALD,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8949,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;MNIST&#39;,
            id_repetitions=1,
            initial_training_set_size=20,
            validation_set_size=4000,
            validation_split_random_state=0,
            evaluation_set_size=4000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        max_training_set=120,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8949,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;MNIST&#39;,
            id_repetitions=1,
            initial_training_set_size=20,
            validation_set_size=4000,
            validation_split_random_state=0,
            evaluation_set_size=4000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        max_training_set=120,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.CoreSetPIG,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class
    ),
    batchbald_redux.unified_experiment.UnifiedExperiment(
        seed=8949,
        experiment_data_config=batchbald_redux.experiment_data.StandardExperimentDataConfig(
            id_dataset_name=&#39;MNIST&#39;,
            id_repetitions=1,
            initial_training_set_size=20,
            validation_set_size=4000,
            validation_split_random_state=0,
            evaluation_set_size=4000,
            add_dataset_noise=False,
            ood_dataset_config=None
        ),
        acquisition_size=1,
        max_training_set=120,
        # class
        acquisition_function=batchbald_redux.acquisition_functions.CoreSetPIGBALD,
        # class
        train_eval_model=batchbald_redux.train_eval_model.TrainExplicitEvalModel,
        model_trainer_factory=batchbald_redux.models.MnistModelTrainer  # class
    )
]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">store</span> <span class="o">=</span> <span class="p">{}</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">configs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">config</span><span class="o">.</span><span class="n">max_training_epochs</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">config</span><span class="o">.</span><span class="n">num_pool_samples</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">config</span><span class="o">.</span><span class="n">evaluation_set_size</span> <span class="o">=</span> <span class="mi">1024</span>
<span class="n">config</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">store</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Creating: CoreSetPIG(
	acquisition_size=1,
	num_pool_samples=5
)
Creating: MnistModelTrainer(
	device=cuda,
	num_training_samples=1,
	num_validation_samples=20,
	max_training_epochs=1
)
Creating: TrainExplicitEvalModel(

)
Training set size 20:
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  return floored.astype(np.int)
/home/blackhc/anaconda3/envs/active_learning/lib/python3.8/site-packages/sklearn/utils/__init__.py:1102: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  return floored.astype(np.int)
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch metrics: {&#39;accuracy&#39;: 0.50775, &#39;crossentropy&#39;: 2.027818820953369}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.50775)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.5381, &#39;crossentropy&#39;: tensor(1.8999)}
Epoch metrics: {&#39;accuracy&#39;: 0.87375, &#39;crossentropy&#39;: 0.7254682092666626}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.87375)
RestoringEarlyStopping: Restoring optimizer.
CandidateBatch(scores=[3.4029453145453905], indices=[5187])
[(&#39;id&#39;, 5622)]
Acquiring (label, score)s: 4 (3.403)
Training set size 21:
Epoch metrics: {&#39;accuracy&#39;: 0.43475, &#39;crossentropy&#39;: 2.0010089168548584}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.43475)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.4817, &#39;crossentropy&#39;: tensor(1.8615)}
Epoch metrics: {&#39;accuracy&#39;: 0.88325, &#39;crossentropy&#39;: 0.6899634265899658}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.88325)
RestoringEarlyStopping: Restoring optimizer.
CandidateBatch(scores=[3.2870225197199927], indices=[12329])
[(&#39;id&#39;, 13281)]
Acquiring (label, score)s: 6 (3.287)
Training set size 22:
Epoch metrics: {&#39;accuracy&#39;: 0.45275, &#39;crossentropy&#39;: 2.0014082069396975}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.45275)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.4649, &#39;crossentropy&#39;: tensor(1.7827)}
Epoch metrics: {&#39;accuracy&#39;: 0.87025, &#39;crossentropy&#39;: 0.7399074931144715}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.87025)
RestoringEarlyStopping: Restoring optimizer.
CandidateBatch(scores=[3.5933495657599286], indices=[29580])
[(&#39;id&#39;, 31871)]
Acquiring (label, score)s: 7 (3.593)
Training set size 23:
Epoch metrics: {&#39;accuracy&#39;: 0.4025, &#39;crossentropy&#39;: 2.065183280944824}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.4025)
RestoringEarlyStopping: Restoring optimizer.
Perf after training {&#39;accuracy&#39;: 0.4233, &#39;crossentropy&#39;: tensor(1.9657)}
Epoch metrics: {&#39;accuracy&#39;: 0.8875, &#39;crossentropy&#39;: 0.6935156860351562}
RestoringEarlyStopping: Restoring best parameters. (Score: 0.8875)
RestoringEarlyStopping: Restoring optimizer.
CandidateBatch(scores=[2.996783156697127], indices=[1972])
[(&#39;id&#39;, 2139)]
Acquiring (label, score)s: 8 (2.997)
Training set size 24:
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Engine run is terminating due to exception: .
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-20-a84afaeb26ea&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">      6</span> config<span class="ansi-blue-fg">.</span>num_pool_samples <span class="ansi-blue-fg">=</span> <span class="ansi-cyan-fg">5</span>
<span class="ansi-green-intense-fg ansi-bold">      7</span> config<span class="ansi-blue-fg">.</span>evaluation_set_size <span class="ansi-blue-fg">=</span> <span class="ansi-cyan-fg">1024</span>
<span class="ansi-green-fg">----&gt; 8</span><span class="ansi-red-fg"> </span>config<span class="ansi-blue-fg">.</span>run<span class="ansi-blue-fg">(</span>store<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/unified_experiment.py</span> in <span class="ansi-cyan-fg">run</span><span class="ansi-blue-fg">(self, store)</span>
<span class="ansi-green-intense-fg ansi-bold">    252</span>         )
<span class="ansi-green-intense-fg ansi-bold">    253</span> 
<span class="ansi-green-fg">--&gt; 254</span><span class="ansi-red-fg">         </span>active_learner<span class="ansi-blue-fg">(</span>store<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    255</span> 
<span class="ansi-green-intense-fg ansi-bold">    256</span> <span class="ansi-red-fg"># Cell</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/unified_experiment.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, log)</span>
<span class="ansi-green-intense-fg ansi-bold">    100</span>                 loss <span class="ansi-blue-fg">=</span> validation_loss <span class="ansi-blue-fg">=</span> torch<span class="ansi-blue-fg">.</span>nn<span class="ansi-blue-fg">.</span>NLLLoss<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    101</span> 
<span class="ansi-green-fg">--&gt; 102</span><span class="ansi-red-fg">             trained_model = model_trainer.get_trained(
</span><span class="ansi-green-intense-fg ansi-bold">    103</span>                 train_loader<span class="ansi-blue-fg">=</span>train_loader<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    104</span>                 train_augmentations<span class="ansi-blue-fg">=</span>data<span class="ansi-blue-fg">.</span>train_augmentations<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/models.py</span> in <span class="ansi-cyan-fg">get_trained</span><span class="ansi-blue-fg">(self, train_loader, train_augmentations, validation_loader, log, loss, validation_loss)</span>
<span class="ansi-green-intense-fg ansi-bold">    137</span>             validation_loss <span class="ansi-blue-fg">=</span> torch<span class="ansi-blue-fg">.</span>nn<span class="ansi-blue-fg">.</span>NLLLoss<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    138</span> 
<span class="ansi-green-fg">--&gt; 139</span><span class="ansi-red-fg">         train(
</span><span class="ansi-green-intense-fg ansi-bold">    140</span>             model<span class="ansi-blue-fg">=</span>model_optimizer<span class="ansi-blue-fg">.</span>model<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    141</span>             optimizer<span class="ansi-blue-fg">=</span>model_optimizer<span class="ansi-blue-fg">.</span>optimizer<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/black_box_model_training.py</span> in <span class="ansi-cyan-fg">train</span><span class="ansi-blue-fg">(model, training_samples, validation_samples, train_loader, validation_loader, patience, max_epochs, device, training_log, loss, validation_loss, optimizer, prefer_accuracy, train_augmentations)</span>
<span class="ansi-green-intense-fg ansi-bold">    136</span> 
<span class="ansi-green-intense-fg ansi-bold">    137</span>     <span class="ansi-red-fg"># Kick everything off</span>
<span class="ansi-green-fg">--&gt; 138</span><span class="ansi-red-fg">     </span>trainer<span class="ansi-blue-fg">.</span>run<span class="ansi-blue-fg">(</span>train_loader<span class="ansi-blue-fg">,</span> max_epochs<span class="ansi-blue-fg">=</span>max_epochs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    139</span> 
<span class="ansi-green-intense-fg ansi-bold">    140</span>     <span class="ansi-green-fg">if</span> early_stopping<span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">run</span><span class="ansi-blue-fg">(self, data, max_epochs, epoch_length, seed)</span>
<span class="ansi-green-intense-fg ansi-bold">    689</span> 
<span class="ansi-green-intense-fg ansi-bold">    690</span>         self<span class="ansi-blue-fg">.</span>state<span class="ansi-blue-fg">.</span>dataloader <span class="ansi-blue-fg">=</span> data
<span class="ansi-green-fg">--&gt; 691</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_internal_run<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    692</span> 
<span class="ansi-green-intense-fg ansi-bold">    693</span>     <span class="ansi-blue-fg">@</span>staticmethod

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">_internal_run</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    760</span>             self<span class="ansi-blue-fg">.</span>_dataloader_iter <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span>
<span class="ansi-green-intense-fg ansi-bold">    761</span>             self<span class="ansi-blue-fg">.</span>logger<span class="ansi-blue-fg">.</span>error<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#34;Engine run is terminating due to exception: %s.&#34;</span><span class="ansi-blue-fg">,</span> str<span class="ansi-blue-fg">(</span>e<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 762</span><span class="ansi-red-fg">             </span>self<span class="ansi-blue-fg">.</span>_handle_exception<span class="ansi-blue-fg">(</span>e<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    763</span> 
<span class="ansi-green-intense-fg ansi-bold">    764</span>         self<span class="ansi-blue-fg">.</span>_dataloader_iter <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">_handle_exception</span><span class="ansi-blue-fg">(self, e)</span>
<span class="ansi-green-intense-fg ansi-bold">    465</span>             self<span class="ansi-blue-fg">.</span>_fire_event<span class="ansi-blue-fg">(</span>Events<span class="ansi-blue-fg">.</span>EXCEPTION_RAISED<span class="ansi-blue-fg">,</span> e<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    466</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 467</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">raise</span> e
<span class="ansi-green-intense-fg ansi-bold">    468</span> 
<span class="ansi-green-intense-fg ansi-bold">    469</span>     <span class="ansi-blue-fg">@</span>property

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">_internal_run</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    728</span>                     self<span class="ansi-blue-fg">.</span>_setup_engine<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    729</span> 
<span class="ansi-green-fg">--&gt; 730</span><span class="ansi-red-fg">                 </span>time_taken <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_run_once_on_dataset<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    731</span>                 <span class="ansi-red-fg"># time is available for handlers but must be update after fire</span>
<span class="ansi-green-intense-fg ansi-bold">    732</span>                 self<span class="ansi-blue-fg">.</span>state<span class="ansi-blue-fg">.</span>times<span class="ansi-blue-fg">[</span>Events<span class="ansi-blue-fg">.</span>EPOCH_COMPLETED<span class="ansi-blue-fg">.</span>name<span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> time_taken

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/ignite/engine/engine.py</span> in <span class="ansi-cyan-fg">_run_once_on_dataset</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    777</span>                     <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>last_event_name <span class="ansi-blue-fg">!=</span> Events<span class="ansi-blue-fg">.</span>DATALOADER_STOP_ITERATION<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    778</span>                         self<span class="ansi-blue-fg">.</span>_fire_event<span class="ansi-blue-fg">(</span>Events<span class="ansi-blue-fg">.</span>GET_BATCH_STARTED<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 779</span><span class="ansi-red-fg">                     </span>self<span class="ansi-blue-fg">.</span>state<span class="ansi-blue-fg">.</span>batch <span class="ansi-blue-fg">=</span> next<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>_dataloader_iter<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    780</span>                     self<span class="ansi-blue-fg">.</span>_fire_event<span class="ansi-blue-fg">(</span>Events<span class="ansi-blue-fg">.</span>GET_BATCH_COMPLETED<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    781</span>                     iter_counter <span class="ansi-blue-fg">+=</span> <span class="ansi-cyan-fg">1</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/utils/data/dataloader.py</span> in <span class="ansi-cyan-fg">__next__</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    433</span>         <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>_sampler_iter <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    434</span>             self<span class="ansi-blue-fg">.</span>_reset<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 435</span><span class="ansi-red-fg">         </span>data <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_next_data<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    436</span>         self<span class="ansi-blue-fg">.</span>_num_yielded <span class="ansi-blue-fg">+=</span> <span class="ansi-cyan-fg">1</span>
<span class="ansi-green-intense-fg ansi-bold">    437</span>         <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>_dataset_kind <span class="ansi-blue-fg">==</span> _DatasetKind<span class="ansi-blue-fg">.</span>Iterable <span class="ansi-green-fg">and</span><span class="ansi-red-fg"> </span><span class="ansi-red-fg">\</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/utils/data/dataloader.py</span> in <span class="ansi-cyan-fg">_next_data</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    473</span>     <span class="ansi-green-fg">def</span> _next_data<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    474</span>         index <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_next_index<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># may raise StopIteration</span>
<span class="ansi-green-fg">--&gt; 475</span><span class="ansi-red-fg">         </span>data <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_dataset_fetcher<span class="ansi-blue-fg">.</span>fetch<span class="ansi-blue-fg">(</span>index<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># may raise StopIteration</span>
<span class="ansi-green-intense-fg ansi-bold">    476</span>         <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>_pin_memory<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    477</span>             data <span class="ansi-blue-fg">=</span> _utils<span class="ansi-blue-fg">.</span>pin_memory<span class="ansi-blue-fg">.</span>pin_memory<span class="ansi-blue-fg">(</span>data<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py</span> in <span class="ansi-cyan-fg">fetch</span><span class="ansi-blue-fg">(self, possibly_batched_index)</span>
<span class="ansi-green-intense-fg ansi-bold">     42</span>     <span class="ansi-green-fg">def</span> fetch<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> possibly_batched_index<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     43</span>         <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>auto_collation<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">---&gt; 44</span><span class="ansi-red-fg">             </span>data <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">[</span>self<span class="ansi-blue-fg">.</span>dataset<span class="ansi-blue-fg">[</span>idx<span class="ansi-blue-fg">]</span> <span class="ansi-green-fg">for</span> idx <span class="ansi-green-fg">in</span> possibly_batched_index<span class="ansi-blue-fg">]</span>
<span class="ansi-green-intense-fg ansi-bold">     45</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     46</span>             data <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>dataset<span class="ansi-blue-fg">[</span>possibly_batched_index<span class="ansi-blue-fg">]</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py</span> in <span class="ansi-cyan-fg">&lt;listcomp&gt;</span><span class="ansi-blue-fg">(.0)</span>
<span class="ansi-green-intense-fg ansi-bold">     42</span>     <span class="ansi-green-fg">def</span> fetch<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> possibly_batched_index<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     43</span>         <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>auto_collation<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">---&gt; 44</span><span class="ansi-red-fg">             </span>data <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">[</span>self<span class="ansi-blue-fg">.</span>dataset<span class="ansi-blue-fg">[</span>idx<span class="ansi-blue-fg">]</span> <span class="ansi-green-fg">for</span> idx <span class="ansi-green-fg">in</span> possibly_batched_index<span class="ansi-blue-fg">]</span>
<span class="ansi-green-intense-fg ansi-bold">     45</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     46</span>             data <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>dataset<span class="ansi-blue-fg">[</span>possibly_batched_index<span class="ansi-blue-fg">]</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/utils/data/dataset.py</span> in <span class="ansi-cyan-fg">__getitem__</span><span class="ansi-blue-fg">(self, idx)</span>
<span class="ansi-green-intense-fg ansi-bold">    270</span> 
<span class="ansi-green-intense-fg ansi-bold">    271</span>     <span class="ansi-green-fg">def</span> __getitem__<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> idx<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 272</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>dataset<span class="ansi-blue-fg">[</span>self<span class="ansi-blue-fg">.</span>indices<span class="ansi-blue-fg">[</span>idx<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">]</span>
<span class="ansi-green-intense-fg ansi-bold">    273</span> 
<span class="ansi-green-intense-fg ansi-bold">    274</span>     <span class="ansi-green-fg">def</span> __len__<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/dataset_challenges.py</span> in <span class="ansi-cyan-fg">__getitem__</span><span class="ansi-blue-fg">(self, idx)</span>
<span class="ansi-green-intense-fg ansi-bold">     45</span> 
<span class="ansi-green-intense-fg ansi-bold">     46</span>     <span class="ansi-green-fg">def</span> __getitem__<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> idx<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">---&gt; 47</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>dataset<span class="ansi-blue-fg">[</span>idx<span class="ansi-blue-fg">]</span>
<span class="ansi-green-intense-fg ansi-bold">     48</span> 
<span class="ansi-green-intense-fg ansi-bold">     49</span>     <span class="ansi-green-fg">def</span> __len__<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/utils/data/dataset.py</span> in <span class="ansi-cyan-fg">__getitem__</span><span class="ansi-blue-fg">(self, idx)</span>
<span class="ansi-green-intense-fg ansi-bold">    270</span> 
<span class="ansi-green-intense-fg ansi-bold">    271</span>     <span class="ansi-green-fg">def</span> __getitem__<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> idx<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 272</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>dataset<span class="ansi-blue-fg">[</span>self<span class="ansi-blue-fg">.</span>indices<span class="ansi-blue-fg">[</span>idx<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">]</span>
<span class="ansi-green-intense-fg ansi-bold">    273</span> 
<span class="ansi-green-intense-fg ansi-bold">    274</span>     <span class="ansi-green-fg">def</span> __len__<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">~/PycharmProjects/bald-ical/batchbald_redux/fast_mnist.py</span> in <span class="ansi-cyan-fg">__getitem__</span><span class="ansi-blue-fg">(self, index)</span>
<span class="ansi-green-intense-fg ansi-bold">     42</span>             tuple<span class="ansi-blue-fg">:</span> <span class="ansi-blue-fg">(</span>image<span class="ansi-blue-fg">,</span> target<span class="ansi-blue-fg">)</span> where target <span class="ansi-green-fg">is</span> index of the target <span class="ansi-green-fg">class</span><span class="ansi-blue-fg">.</span>
<span class="ansi-green-intense-fg ansi-bold">     43</span>         &#34;&#34;&#34;
<span class="ansi-green-fg">---&gt; 44</span><span class="ansi-red-fg">         </span>img<span class="ansi-blue-fg">,</span> target <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>data<span class="ansi-blue-fg">[</span>index<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>targets<span class="ansi-blue-fg">[</span>index<span class="ansi-blue-fg">]</span>
<span class="ansi-green-intense-fg ansi-bold">     45</span> 
<span class="ansi-green-intense-fg ansi-bold">     46</span>         <span class="ansi-green-fg">return</span> img<span class="ansi-blue-fg">,</span> target

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

