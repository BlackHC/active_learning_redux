{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment CIFAR-10\n",
    "> Can we get better by training on our assumptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp experiment_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended /home/blackhc/PycharmProjects/bald-ical/src to paths\n",
      "Switched to directory /home/blackhc/PycharmProjects/bald-ical\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "import blackhc.project.script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules and functions were are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "import dataclasses\n",
    "import traceback\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Type, Union\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from blackhc.project import is_run_from_ipython\n",
    "from blackhc.project.experiment import embedded_experiments\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import batchbald_redux.acquisition_functions as acquisition_functions\n",
    "from batchbald_redux.acquisition_functions import (\n",
    "    CandidateBatchComputer,\n",
    "    EvalCandidateBatchComputer,\n",
    ")\n",
    "from batchbald_redux.active_learning import ActiveLearningData, RandomFixedLengthSampler\n",
    "from batchbald_redux.black_box_model_training import evaluate_old, train, train_with_schedule\n",
    "from batchbald_redux.dataset_challenges import (\n",
    "    NamedDataset,\n",
    "    create_repeated_MNIST_dataset,\n",
    "    get_balanced_sample_indices,\n",
    "    get_base_dataset_index,\n",
    "    get_target, AdditiveGaussianNoise, AliasDataset, get_balanced_sample_indices_by_class,\n",
    ")\n",
    "from batchbald_redux.datasets import get_dataset\n",
    "from batchbald_redux.datasets import train_validation_split\n",
    "from batchbald_redux.di import DependencyInjection\n",
    "from batchbald_redux.fast_mnist import FastMNIST\n",
    "from batchbald_redux.model_optimizer_factory import ModelOptimizerFactory\n",
    "from batchbald_redux.resnet_models import Cifar10BayesianResnetFactory\n",
    "from batchbald_redux.train_eval_model import (\n",
    "    TrainEvalModel,\n",
    "    TrainSelfDistillationEvalModel,\n",
    "    TrainSelfDistillationEvalModelWithSchedule\n",
    ")\n",
    "from batchbald_redux.trained_model import TrainedBayesianModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "@dataclass\n",
    "class ExperimentData:\n",
    "    active_learning: ActiveLearningData\n",
    "    train_dataset: Dataset\n",
    "    train_augmentations: nn.Module\n",
    "    validation_dataset: Dataset\n",
    "    test_dataset: Dataset\n",
    "    evaluation_dataset: Dataset\n",
    "    initial_training_set_indices: [int]\n",
    "    evaluation_set_indices: [int]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ExperimentDataConfig:\n",
    "    id_dataset_name: str\n",
    "    initial_training_set_size: int\n",
    "    validation_set_size: int\n",
    "    evaluation_set_size: int\n",
    "    id_repetitions: float\n",
    "    add_dataset_noise: bool\n",
    "    validation_split_random_state: int\n",
    "\n",
    "    device: str\n",
    "\n",
    "    def load(self) -> ExperimentData:\n",
    "        return load_experiment_data(\n",
    "            id_dataset_name=self.id_dataset_name,\n",
    "            initial_training_set_size=self.initial_training_set_size,\n",
    "            validation_set_size=self.validation_set_size,\n",
    "            evaluation_set_size=self.evaluation_set_size,\n",
    "            id_repetitions=self.id_repetitions,\n",
    "            add_dataset_noise=self.add_dataset_noise,\n",
    "            validation_split_random_state=self.validation_split_random_state,\n",
    "            device=self.device,\n",
    "        )\n",
    "\n",
    "\n",
    "def load_experiment_data(\n",
    "    *,\n",
    "    id_dataset_name: str,\n",
    "    initial_training_set_size: int,\n",
    "    validation_set_size: int,\n",
    "    evaluation_set_size: int,\n",
    "    id_repetitions: float,\n",
    "    add_dataset_noise: bool,\n",
    "    validation_split_random_state: int,\n",
    "    device: str,\n",
    ") -> ExperimentData:\n",
    "    split_dataset = get_dataset(id_dataset_name, root=\"data\", validation_set_size=validation_set_size,\n",
    "                                validation_split_random_state=validation_split_random_state, normalize_like_cifar10=True)\n",
    "\n",
    "    train_dataset = split_dataset.train\n",
    "\n",
    "    # If we reduce the train set, we need to do so before picking the initial train set.\n",
    "    if id_repetitions < 1:\n",
    "        train_dataset = train_dataset * id_repetitions\n",
    "\n",
    "    num_classes = train_dataset.get_num_classes()\n",
    "    initial_samples_per_class = initial_training_set_size // num_classes\n",
    "    evaluation_set_samples_per_class = evaluation_set_size // num_classes\n",
    "    samples_per_class = initial_samples_per_class + evaluation_set_samples_per_class\n",
    "    balanced_samples_indices = get_balanced_sample_indices_by_class(\n",
    "        train_dataset,\n",
    "        num_classes=num_classes,\n",
    "        samples_per_class=samples_per_class,\n",
    "        seed=validation_split_random_state,\n",
    "    )\n",
    "\n",
    "    initial_training_set_indices = [\n",
    "        idx for by_class in balanced_samples_indices.values() for idx in by_class[:initial_samples_per_class]\n",
    "    ]\n",
    "    evaluation_set_indices = [\n",
    "        idx for by_class in balanced_samples_indices.values() for idx in by_class[initial_samples_per_class:]\n",
    "    ]\n",
    "\n",
    "    # If we over-sample the train set, we do so after picking the initial train set to avoid duplicates.\n",
    "    if id_repetitions > 1:\n",
    "        train_dataset = train_dataset * id_repetitions\n",
    "\n",
    "    if add_dataset_noise:\n",
    "        train_dataset = AdditiveGaussianNoise(train_dataset, 0.1)\n",
    "\n",
    "    active_learning_data = ActiveLearningData(train_dataset)\n",
    "\n",
    "    active_learning_data.acquire_base_indices(initial_training_set_indices)\n",
    "\n",
    "    evaluation_dataset = AliasDataset(\n",
    "        active_learning_data.extract_dataset_from_base_indices(evaluation_set_indices),\n",
    "        f\"Evaluation Set ({len(evaluation_set_indices)} samples)\",\n",
    "    )\n",
    "\n",
    "    return ExperimentData(\n",
    "        active_learning=active_learning_data,\n",
    "        train_dataset=train_dataset,\n",
    "        train_augmentations=split_dataset.train_augmentations,\n",
    "        validation_dataset=split_dataset.validation,\n",
    "        test_dataset=split_dataset.test,\n",
    "        evaluation_dataset=evaluation_dataset,\n",
    "        initial_training_set_indices=initial_training_set_indices,\n",
    "        evaluation_set_indices=evaluation_set_indices,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "@dataclass\n",
    "class Experiment:\n",
    "    seed: int\n",
    "    acquisition_function: Union[\n",
    "        Type[CandidateBatchComputer], Type[EvalCandidateBatchComputer]\n",
    "    ]\n",
    "\n",
    "    id_dataset_name: str = \"CIFAR-10\"\n",
    "    initial_training_set_size: int = 5000\n",
    "    validation_set_size: int = 5000\n",
    "    evaluation_set_size: int = 0\n",
    "    id_repetitions: float = 1\n",
    "    add_dataset_noise: bool = False\n",
    "    validation_split_random_state: int = 0\n",
    "\n",
    "    acquisition_size: int = 2500\n",
    "    max_training_set: int = 40000\n",
    "    num_pool_samples: int = 20\n",
    "    num_validation_samples: int = 20\n",
    "    num_training_samples: int = 1\n",
    "    max_training_epochs: int = 120\n",
    "    training_batch_size: int = 128\n",
    "    device: str = \"cuda\"\n",
    "    min_samples_per_epoch: int = 5056\n",
    "    patience_schedule: [int] = (6, 4, 2)\n",
    "    factor_schedule: [int] = (0.1,)\n",
    "    train_eval_model: Type[TrainEvalModel] = TrainSelfDistillationEvalModelWithSchedule\n",
    "    model_optimizer_factory: Type[ModelOptimizerFactory] = Cifar10BayesianResnetFactory\n",
    "    acquisition_function_args: dict = None\n",
    "    temperature: float = 0.0\n",
    "    prefer_accuracy: bool = True\n",
    "\n",
    "    def load_experiment_data(self) -> ExperimentData:\n",
    "        di = DependencyInjection(vars(self))\n",
    "        edc: ExperimentDataConfig = di.create_dataclass_type(ExperimentDataConfig)\n",
    "        return edc.load()\n",
    "\n",
    "    # Simple Dependency Injection\n",
    "    def create_acquisition_function(self):\n",
    "        di = DependencyInjection(vars(self))\n",
    "        return di.create_dataclass_type(self.acquisition_function)\n",
    "\n",
    "    def create_train_eval_model(self, runtime_config) -> TrainEvalModel:\n",
    "        config = {**vars(self), **runtime_config}\n",
    "        di = DependencyInjection(config, [])\n",
    "        return di.create_dataclass_type(self.train_eval_model)\n",
    "\n",
    "    def run(self, store):\n",
    "        torch.manual_seed(self.seed)\n",
    "\n",
    "        # Active Learning setup\n",
    "        data = self.load_experiment_data()\n",
    "        store[\"dataset_info\"] = dict(training=repr(data.active_learning.base_dataset), test=repr(data.test_dataset))\n",
    "        store[\"initial_training_set_indices\"] = data.initial_training_set_indices\n",
    "        store[\"evaluation_set_indices\"] = data.evaluation_set_indices\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            data.active_learning.training_dataset,\n",
    "            batch_size=self.training_batch_size,\n",
    "            sampler=RandomFixedLengthSampler(data.active_learning.training_dataset, self.min_samples_per_epoch),\n",
    "            drop_last=True,\n",
    "        )\n",
    "        pool_loader = torch.utils.data.DataLoader(\n",
    "            data.active_learning.pool_dataset, batch_size=128, drop_last=False, shuffle=False\n",
    "        )\n",
    "\n",
    "        validation_loader = torch.utils.data.DataLoader(data.validation_dataset, batch_size=512, drop_last=False)\n",
    "        test_loader = torch.utils.data.DataLoader(data.test_dataset, batch_size=512, drop_last=False)\n",
    "\n",
    "        store[\"active_learning_steps\"] = []\n",
    "        active_learning_steps = store[\"active_learning_steps\"]\n",
    "\n",
    "        acquisition_function = self.create_acquisition_function()\n",
    "\n",
    "        # Active Training Loop\n",
    "        while True:\n",
    "            training_set_size = len(data.active_learning.training_dataset)\n",
    "            print(f\"Training set size {training_set_size}:\")\n",
    "\n",
    "            # iteration_log = dict(training={}, pool_training={}, evaluation_metrics=None, acquisition=None)\n",
    "            active_learning_steps.append({})\n",
    "            iteration_log = active_learning_steps[-1]\n",
    "\n",
    "            iteration_log[\"training\"] = {}\n",
    "\n",
    "            model_optimizer = self.model_optimizer_factory().create_model_optimizer()\n",
    "\n",
    "            if training_set_size > 0:\n",
    "                train_with_schedule(\n",
    "                    model=model_optimizer.model,\n",
    "                    optimizer=model_optimizer.optimizer,\n",
    "                    train_augmentations=data.train_augmentations,\n",
    "                    training_samples=self.num_training_samples,\n",
    "                    validation_samples=self.num_validation_samples,\n",
    "                    train_loader=train_loader,\n",
    "                    validation_loader=validation_loader,\n",
    "                    patience_schedule = self.patience_schedule,\n",
    "                    factor_schedule = self.factor_schedule,\n",
    "                    max_epochs=self.max_training_epochs,\n",
    "                    device=self.device,\n",
    "                    training_log=iteration_log[\"training\"],\n",
    "                    prefer_accuracy=self.prefer_accuracy\n",
    "                )\n",
    "\n",
    "            evaluation_metrics = evaluate_old(\n",
    "                model=model_optimizer.model,\n",
    "                num_samples=self.num_validation_samples,\n",
    "                loader=test_loader,\n",
    "                device=self.device,\n",
    "            )\n",
    "            iteration_log[\"evaluation_metrics\"] = evaluation_metrics\n",
    "            print(f\"Perf after training {evaluation_metrics}\")\n",
    "\n",
    "            if training_set_size >= self.max_training_set:\n",
    "                print(\"Done.\")\n",
    "                break\n",
    "\n",
    "            trained_model = TrainedBayesianModel(model=model_optimizer.model)\n",
    "\n",
    "            if isinstance(acquisition_function, CandidateBatchComputer):\n",
    "                candidate_batch = acquisition_function.compute_candidate_batch(trained_model, pool_loader, self.device)\n",
    "            elif isinstance(acquisition_function, EvalCandidateBatchComputer):\n",
    "                current_max_epochs = len(iteration_log[\"training\"][\"epochs\"])\n",
    "\n",
    "                if self.evaluation_set_size:\n",
    "                    eval_dataset = data.evaluation_dataset\n",
    "                else:\n",
    "                    eval_dataset = data.active_learning.pool_dataset\n",
    "\n",
    "                train_eval_model = self.create_train_eval_model(\n",
    "                    dict(\n",
    "                        max_epochs=current_max_epochs + 2,\n",
    "                        training_dataset=data.active_learning.training_dataset,\n",
    "                        eval_dataset=eval_dataset,\n",
    "                        validation_loader=validation_loader,\n",
    "                        trained_model=trained_model,\n",
    "                        train_augmentations=data.train_augmentations\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                iteration_log[\"eval_training\"] = {}\n",
    "                trained_eval_model = train_eval_model(training_log=iteration_log[\"eval_training\"], device=self.device)\n",
    "\n",
    "                candidate_batch = acquisition_function.compute_candidate_batch(\n",
    "                    trained_model, trained_eval_model, pool_loader, device=self.device\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown acquisition function {acquisition_function}!\")\n",
    "\n",
    "            candidate_global_indices = [\n",
    "                get_base_dataset_index(data.active_learning.pool_dataset, index).index\n",
    "                for index in candidate_batch.indices\n",
    "            ]\n",
    "            candidate_labels = [\n",
    "                get_target(data.active_learning.pool_dataset, index).item() for index in candidate_batch.indices\n",
    "            ]\n",
    "\n",
    "            iteration_log[\"acquisition\"] = dict(\n",
    "                indices=candidate_global_indices, labels=candidate_labels, scores=candidate_batch.scores\n",
    "            )\n",
    "\n",
    "            data.active_learning.acquire(candidate_batch.indices)\n",
    "\n",
    "            ls = \", \".join(f\"{label} ({score:.4})\" for label, score in zip(candidate_labels, candidate_batch.scores))\n",
    "            print(f\"Acquiring (label, score)s: {ls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating: ExperimentDataConfig(\n",
      "\tid_dataset_name=CIFAR-10,\n",
      "\tinitial_training_set_size=20000,\n",
      "\tvalidation_set_size=5000,\n",
      "\tevaluation_set_size=0,\n",
      "\tid_repetitions=1,\n",
      "\tadd_dataset_noise=False,\n",
      "\tvalidation_split_random_state=0,\n",
      "\tdevice=cuda\n",
      ")\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Creating: EvalBALD(\n",
      "\tacquisition_size=5\n",
      ")\n",
      "Training set size 20000:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708f95653ed54ca683bc81e157a266c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/39]   3%|2          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/10]  10%|#          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.1998, 'crossentropy': 2.38129228515625}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/20]   5%|5          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.1965, 'crossentropy': 2.36414514465332}\n",
      "Creating: TrainSelfDistillationEvalModelWithSchedule(\n",
      "\tnum_pool_samples=20,\n",
      "\tnum_training_samples=1,\n",
      "\tnum_validation_samples=20,\n",
      "\tpatience_schedule=(6, 4, 2),\n",
      "\tfactor_schedule=(0.1,),\n",
      "\tmax_epochs=3,\n",
      "\ttraining_dataset=<torch.utils.data.dataset.Subset object at 0x7f687bbd9d90>,\n",
      "\teval_dataset=<torch.utils.data.dataset.Subset object at 0x7f687bbd9af0>,\n",
      "\tvalidation_loader=<torch.utils.data.dataloader.DataLoader object at 0x7f687bbf1e20>,\n",
      "\ttraining_batch_size=128,\n",
      "\tmodel_optimizer_factory=<class 'batchbald_redux.resnet_models.Cifar10BayesianResnetFactory'>,\n",
      "\ttrained_model=TrainedMCDropoutModel(num_samples=20, model=BayesianResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): Identity()\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): ConsistentMCDropout(p=0.5)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): ConsistentMCDropout(p=0.5)\n",
      "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (5): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")),\n",
      "\tmin_samples_per_epoch=5000,\n",
      "\tprefer_accuracy=True,\n",
      "\ttrain_augmentations=Sequential(\n",
      "  (0): RandomCrop(crop_size=(32, 32), padding=4, fill=0, pad_if_needed=False, padding_mode=constant, resample=BILINEAR, p=1.0, p_batch=1.0, same_on_batch=False, return_transform=False)\n",
      "  (1): RandomHorizontalFlip(p=0.5, p_batch=1.0, same_on_batch=False, return_transform=None)\n",
      ")\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/900000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fbe3812494f4b1ca5357b1f394cd01a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " 33%|###3      | 1/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/39]   3%|2          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/10]  10%|#          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.1992, 'crossentropy': 2.42520475769043}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/39]   3%|2          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/10]  10%|#          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.155, 'crossentropy': 2.468776754760742}\n",
      "Epoch 2: 0.155 worse than 0.1992, patience: 1/6!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/39]   3%|2          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/10]  10%|#          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.2074, 'crossentropy': 2.1420733009338377}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/500000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions_labels:   0%|          | 0/500000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquiring (label, score)s: 1 (0.1945), 1 (0.1942), 9 (0.1849), 9 (0.1817), 1 (0.181)\n",
      "Training set size 20005:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d3d8cc8e054a78a688fa55c96a524b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/39]   3%|2          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/10]  10%|#          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch metrics: {'accuracy': 0.2416, 'crossentropy': 2.68387165145874}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/20]   5%|5          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.2411, 'crossentropy': 2.77079727935791}\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# experiment\n",
    "\n",
    "experiment = Experiment(\n",
    "    seed=1120,\n",
    "    max_training_epochs=1,\n",
    "    max_training_set=20005,\n",
    "    acquisition_function=acquisition_functions.EvalBALD,\n",
    "    acquisition_size=5,\n",
    "    num_pool_samples=20,\n",
    "    initial_training_set_size=20000,\n",
    "    temperature=8,\n",
    "    min_samples_per_epoch=5000,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "results = {}\n",
    "experiment.run(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_info': {'training': \"'CIFAR-10 (Train, seed=0, 45000 samples)'\",\n",
       "  'test': \"'CIFAR-10 (Test)'\"},\n",
       " 'initial_training_set_indices': [28964,\n",
       "  11411,\n",
       "  14886,\n",
       "  9609,\n",
       "  39292,\n",
       "  398,\n",
       "  3431,\n",
       "  21404,\n",
       "  44846,\n",
       "  11777,\n",
       "  6361,\n",
       "  36817,\n",
       "  5044,\n",
       "  37231,\n",
       "  14346,\n",
       "  24286,\n",
       "  4294,\n",
       "  28590,\n",
       "  16297,\n",
       "  12733,\n",
       "  19940,\n",
       "  27283,\n",
       "  27046,\n",
       "  17495,\n",
       "  4417,\n",
       "  40795,\n",
       "  10717,\n",
       "  3957,\n",
       "  14535,\n",
       "  20341,\n",
       "  27604,\n",
       "  43757,\n",
       "  26320,\n",
       "  40449,\n",
       "  10574,\n",
       "  12396,\n",
       "  14656,\n",
       "  21304,\n",
       "  44149,\n",
       "  12180,\n",
       "  27762,\n",
       "  22949,\n",
       "  32997,\n",
       "  11309,\n",
       "  29865,\n",
       "  36001,\n",
       "  20338,\n",
       "  24032,\n",
       "  34368,\n",
       "  9137,\n",
       "  23376,\n",
       "  13769,\n",
       "  44858,\n",
       "  15640,\n",
       "  40594,\n",
       "  407,\n",
       "  40764,\n",
       "  7166,\n",
       "  17277,\n",
       "  15347,\n",
       "  7175,\n",
       "  10233,\n",
       "  14617,\n",
       "  35065,\n",
       "  39662,\n",
       "  32385,\n",
       "  28273,\n",
       "  15891,\n",
       "  26145,\n",
       "  27266,\n",
       "  38700,\n",
       "  14319,\n",
       "  31039,\n",
       "  4596,\n",
       "  21831,\n",
       "  6428,\n",
       "  27461,\n",
       "  6582,\n",
       "  518,\n",
       "  20455,\n",
       "  6795,\n",
       "  21079,\n",
       "  30299,\n",
       "  33470,\n",
       "  38939,\n",
       "  27229,\n",
       "  22701,\n",
       "  33968,\n",
       "  19425,\n",
       "  6796,\n",
       "  5874,\n",
       "  32641,\n",
       "  32181,\n",
       "  5994,\n",
       "  43189,\n",
       "  38244,\n",
       "  32894,\n",
       "  18469,\n",
       "  34402,\n",
       "  20303,\n",
       "  20904,\n",
       "  19437,\n",
       "  19853,\n",
       "  6790,\n",
       "  8342,\n",
       "  43214,\n",
       "  24483,\n",
       "  33362,\n",
       "  40584,\n",
       "  17997,\n",
       "  33578,\n",
       "  12676,\n",
       "  31641,\n",
       "  31235,\n",
       "  12662,\n",
       "  9416,\n",
       "  15505,\n",
       "  7356,\n",
       "  24351,\n",
       "  6257,\n",
       "  19463,\n",
       "  34371,\n",
       "  11603,\n",
       "  31585,\n",
       "  30538,\n",
       "  416,\n",
       "  43804,\n",
       "  19344,\n",
       "  31015,\n",
       "  6733,\n",
       "  23802,\n",
       "  24971,\n",
       "  49,\n",
       "  7955,\n",
       "  36097,\n",
       "  19334,\n",
       "  405,\n",
       "  38730,\n",
       "  42603,\n",
       "  41854,\n",
       "  34837,\n",
       "  38924,\n",
       "  34801,\n",
       "  40353,\n",
       "  36714,\n",
       "  35815,\n",
       "  22182,\n",
       "  25721,\n",
       "  23813,\n",
       "  12880,\n",
       "  21635,\n",
       "  40072,\n",
       "  22294,\n",
       "  34000,\n",
       "  37455,\n",
       "  42716,\n",
       "  21093,\n",
       "  40312,\n",
       "  28710,\n",
       "  6767,\n",
       "  43087,\n",
       "  16196,\n",
       "  27712,\n",
       "  38407,\n",
       "  28582,\n",
       "  26042,\n",
       "  10937,\n",
       "  519,\n",
       "  29985,\n",
       "  27425,\n",
       "  29609,\n",
       "  33141,\n",
       "  10494,\n",
       "  32557,\n",
       "  4065,\n",
       "  13156,\n",
       "  15588,\n",
       "  44030,\n",
       "  3463,\n",
       "  35891,\n",
       "  16499,\n",
       "  23973,\n",
       "  40061,\n",
       "  42773,\n",
       "  15887,\n",
       "  31153,\n",
       "  34937,\n",
       "  32751,\n",
       "  39984,\n",
       "  12847,\n",
       "  38797,\n",
       "  12885,\n",
       "  11143,\n",
       "  41977,\n",
       "  13638,\n",
       "  24924,\n",
       "  43417,\n",
       "  5722,\n",
       "  14870,\n",
       "  31444,\n",
       "  27218,\n",
       "  28078,\n",
       "  18175,\n",
       "  26426,\n",
       "  30144,\n",
       "  28349,\n",
       "  21674,\n",
       "  31955,\n",
       "  25359,\n",
       "  9070,\n",
       "  30189,\n",
       "  9348,\n",
       "  34744,\n",
       "  39019,\n",
       "  17848,\n",
       "  27648,\n",
       "  24578,\n",
       "  1666,\n",
       "  22402,\n",
       "  9152,\n",
       "  20908,\n",
       "  43080,\n",
       "  21102,\n",
       "  43724,\n",
       "  28423,\n",
       "  31454,\n",
       "  38785,\n",
       "  31387,\n",
       "  2651,\n",
       "  17565,\n",
       "  38256,\n",
       "  21261,\n",
       "  35598,\n",
       "  14608,\n",
       "  16748,\n",
       "  13806,\n",
       "  36300,\n",
       "  8234,\n",
       "  25580,\n",
       "  19944,\n",
       "  6336,\n",
       "  16242,\n",
       "  42250,\n",
       "  1964,\n",
       "  21016,\n",
       "  33529,\n",
       "  35899,\n",
       "  26113,\n",
       "  18956,\n",
       "  23652,\n",
       "  39705,\n",
       "  33483,\n",
       "  28084,\n",
       "  17109,\n",
       "  35848,\n",
       "  38306,\n",
       "  40542,\n",
       "  41006,\n",
       "  10186,\n",
       "  43716,\n",
       "  42836,\n",
       "  1413,\n",
       "  26334,\n",
       "  20155,\n",
       "  27558,\n",
       "  17689,\n",
       "  32329,\n",
       "  30846,\n",
       "  7577,\n",
       "  3656,\n",
       "  30333,\n",
       "  2221,\n",
       "  10120,\n",
       "  16573,\n",
       "  9205,\n",
       "  44843,\n",
       "  43329,\n",
       "  37219,\n",
       "  24986,\n",
       "  17082,\n",
       "  44759,\n",
       "  31491,\n",
       "  19800,\n",
       "  38767,\n",
       "  22309,\n",
       "  20409,\n",
       "  23360,\n",
       "  26634,\n",
       "  1506,\n",
       "  9429,\n",
       "  41909,\n",
       "  41320,\n",
       "  43865,\n",
       "  10870,\n",
       "  11980,\n",
       "  44064,\n",
       "  19118,\n",
       "  39120,\n",
       "  39856,\n",
       "  23870,\n",
       "  16157,\n",
       "  41469,\n",
       "  42212,\n",
       "  23006,\n",
       "  12308,\n",
       "  17356,\n",
       "  24174,\n",
       "  1166,\n",
       "  31129,\n",
       "  3614,\n",
       "  4821,\n",
       "  43723,\n",
       "  13779,\n",
       "  10928,\n",
       "  31063,\n",
       "  15904,\n",
       "  25314,\n",
       "  25124,\n",
       "  44327,\n",
       "  26227,\n",
       "  5381,\n",
       "  4722,\n",
       "  3478,\n",
       "  23331,\n",
       "  42285,\n",
       "  33348,\n",
       "  32288,\n",
       "  22761,\n",
       "  1325,\n",
       "  17789,\n",
       "  40759,\n",
       "  5240,\n",
       "  32520,\n",
       "  9035,\n",
       "  29320,\n",
       "  4229,\n",
       "  40761,\n",
       "  66,\n",
       "  16580,\n",
       "  19311,\n",
       "  23139,\n",
       "  2535,\n",
       "  14638,\n",
       "  44930,\n",
       "  3225,\n",
       "  7442,\n",
       "  14012,\n",
       "  43801,\n",
       "  25323,\n",
       "  15194,\n",
       "  4100,\n",
       "  34973,\n",
       "  18927,\n",
       "  36334,\n",
       "  5158,\n",
       "  18869,\n",
       "  15994,\n",
       "  5936,\n",
       "  21756,\n",
       "  978,\n",
       "  42758,\n",
       "  3359,\n",
       "  27537,\n",
       "  21487,\n",
       "  42188,\n",
       "  32438,\n",
       "  7967,\n",
       "  20869,\n",
       "  15344,\n",
       "  13949,\n",
       "  19005,\n",
       "  25249,\n",
       "  40805,\n",
       "  21216,\n",
       "  27895,\n",
       "  28624,\n",
       "  7738,\n",
       "  14131,\n",
       "  40250,\n",
       "  38393,\n",
       "  35552,\n",
       "  25076,\n",
       "  39065,\n",
       "  39222,\n",
       "  24536,\n",
       "  44057,\n",
       "  43532,\n",
       "  17726,\n",
       "  9435,\n",
       "  38212,\n",
       "  14758,\n",
       "  19041,\n",
       "  20688,\n",
       "  7029,\n",
       "  10430,\n",
       "  20632,\n",
       "  3570,\n",
       "  21015,\n",
       "  33317,\n",
       "  2528,\n",
       "  34100,\n",
       "  42315,\n",
       "  7484,\n",
       "  26489,\n",
       "  27794,\n",
       "  27013,\n",
       "  35019,\n",
       "  31190,\n",
       "  30955,\n",
       "  25226,\n",
       "  18970,\n",
       "  22775,\n",
       "  23134,\n",
       "  38152,\n",
       "  3926,\n",
       "  37278,\n",
       "  547,\n",
       "  5695,\n",
       "  23011,\n",
       "  26409,\n",
       "  41674,\n",
       "  652,\n",
       "  8440,\n",
       "  15399,\n",
       "  42509,\n",
       "  10486,\n",
       "  19538,\n",
       "  40855,\n",
       "  38007,\n",
       "  35274,\n",
       "  1138,\n",
       "  40785,\n",
       "  9977,\n",
       "  35774,\n",
       "  41990,\n",
       "  17604,\n",
       "  3224,\n",
       "  6149,\n",
       "  44785,\n",
       "  194,\n",
       "  32573,\n",
       "  11814,\n",
       "  10484,\n",
       "  6655,\n",
       "  24704,\n",
       "  14580,\n",
       "  10710,\n",
       "  2871,\n",
       "  2118,\n",
       "  9651,\n",
       "  3845,\n",
       "  24330,\n",
       "  34104,\n",
       "  14237,\n",
       "  28993,\n",
       "  11342,\n",
       "  27222,\n",
       "  42235,\n",
       "  4953,\n",
       "  43672,\n",
       "  43410,\n",
       "  4726,\n",
       "  43871,\n",
       "  32463,\n",
       "  7142,\n",
       "  22811,\n",
       "  10837,\n",
       "  41075,\n",
       "  17748,\n",
       "  33801,\n",
       "  18164,\n",
       "  19222,\n",
       "  30092,\n",
       "  41144,\n",
       "  30923,\n",
       "  9209,\n",
       "  8542,\n",
       "  19777,\n",
       "  17936,\n",
       "  10907,\n",
       "  39103,\n",
       "  37653,\n",
       "  29470,\n",
       "  10215,\n",
       "  42176,\n",
       "  22991,\n",
       "  20430,\n",
       "  8803,\n",
       "  29871,\n",
       "  21202,\n",
       "  26388,\n",
       "  28347,\n",
       "  21098,\n",
       "  38751,\n",
       "  31084,\n",
       "  7877,\n",
       "  18644,\n",
       "  39614,\n",
       "  40801,\n",
       "  10720,\n",
       "  33568,\n",
       "  619,\n",
       "  40363,\n",
       "  42136,\n",
       "  2353,\n",
       "  11376,\n",
       "  36776,\n",
       "  1766,\n",
       "  26030,\n",
       "  6375,\n",
       "  43089,\n",
       "  17910,\n",
       "  14945,\n",
       "  14097,\n",
       "  8139,\n",
       "  34389,\n",
       "  28634,\n",
       "  43480,\n",
       "  11304,\n",
       "  8430,\n",
       "  5338,\n",
       "  23128,\n",
       "  41654,\n",
       "  36480,\n",
       "  32783,\n",
       "  4419,\n",
       "  31900,\n",
       "  11562,\n",
       "  39197,\n",
       "  44506,\n",
       "  43330,\n",
       "  39899,\n",
       "  16922,\n",
       "  35906,\n",
       "  20799,\n",
       "  40691,\n",
       "  9823,\n",
       "  2068,\n",
       "  42597,\n",
       "  16195,\n",
       "  38354,\n",
       "  41731,\n",
       "  42277,\n",
       "  31021,\n",
       "  15343,\n",
       "  44596,\n",
       "  30274,\n",
       "  29447,\n",
       "  15275,\n",
       "  37335,\n",
       "  14389,\n",
       "  23387,\n",
       "  13716,\n",
       "  14830,\n",
       "  11840,\n",
       "  20494,\n",
       "  33765,\n",
       "  39741,\n",
       "  4067,\n",
       "  8901,\n",
       "  35352,\n",
       "  41885,\n",
       "  1545,\n",
       "  30007,\n",
       "  12273,\n",
       "  42486,\n",
       "  44218,\n",
       "  19189,\n",
       "  26126,\n",
       "  15478,\n",
       "  12292,\n",
       "  2327,\n",
       "  33242,\n",
       "  29935,\n",
       "  19133,\n",
       "  43141,\n",
       "  8473,\n",
       "  37991,\n",
       "  7988,\n",
       "  13898,\n",
       "  17887,\n",
       "  10875,\n",
       "  28507,\n",
       "  4208,\n",
       "  8953,\n",
       "  21621,\n",
       "  36276,\n",
       "  35405,\n",
       "  17030,\n",
       "  5413,\n",
       "  41198,\n",
       "  6318,\n",
       "  42701,\n",
       "  29355,\n",
       "  29236,\n",
       "  10899,\n",
       "  5747,\n",
       "  19496,\n",
       "  5573,\n",
       "  26639,\n",
       "  39247,\n",
       "  41940,\n",
       "  29013,\n",
       "  16976,\n",
       "  35463,\n",
       "  23169,\n",
       "  44115,\n",
       "  5244,\n",
       "  29140,\n",
       "  36393,\n",
       "  6320,\n",
       "  11729,\n",
       "  13381,\n",
       "  24017,\n",
       "  36548,\n",
       "  41639,\n",
       "  38255,\n",
       "  16999,\n",
       "  25818,\n",
       "  40613,\n",
       "  781,\n",
       "  33034,\n",
       "  22647,\n",
       "  4690,\n",
       "  20727,\n",
       "  25069,\n",
       "  1467,\n",
       "  16310,\n",
       "  34726,\n",
       "  42622,\n",
       "  10638,\n",
       "  39046,\n",
       "  5699,\n",
       "  17017,\n",
       "  8994,\n",
       "  6624,\n",
       "  34861,\n",
       "  8719,\n",
       "  17926,\n",
       "  8159,\n",
       "  19099,\n",
       "  33180,\n",
       "  3263,\n",
       "  8428,\n",
       "  9210,\n",
       "  26389,\n",
       "  39666,\n",
       "  37024,\n",
       "  38875,\n",
       "  14547,\n",
       "  34555,\n",
       "  14458,\n",
       "  37862,\n",
       "  16402,\n",
       "  15523,\n",
       "  6247,\n",
       "  34330,\n",
       "  41799,\n",
       "  32058,\n",
       "  27426,\n",
       "  1337,\n",
       "  30239,\n",
       "  31787,\n",
       "  17801,\n",
       "  44815,\n",
       "  23208,\n",
       "  25289,\n",
       "  10293,\n",
       "  25446,\n",
       "  39833,\n",
       "  189,\n",
       "  30168,\n",
       "  37838,\n",
       "  28849,\n",
       "  1909,\n",
       "  41204,\n",
       "  13887,\n",
       "  2169,\n",
       "  37128,\n",
       "  36621,\n",
       "  7791,\n",
       "  33783,\n",
       "  44811,\n",
       "  39852,\n",
       "  8881,\n",
       "  2067,\n",
       "  18232,\n",
       "  4303,\n",
       "  24926,\n",
       "  5873,\n",
       "  39613,\n",
       "  39487,\n",
       "  1434,\n",
       "  24900,\n",
       "  7263,\n",
       "  44489,\n",
       "  16744,\n",
       "  13438,\n",
       "  19575,\n",
       "  30544,\n",
       "  20248,\n",
       "  26297,\n",
       "  16987,\n",
       "  32432,\n",
       "  40416,\n",
       "  20371,\n",
       "  17818,\n",
       "  43119,\n",
       "  18754,\n",
       "  19028,\n",
       "  14136,\n",
       "  12914,\n",
       "  41089,\n",
       "  19156,\n",
       "  22717,\n",
       "  7053,\n",
       "  24626,\n",
       "  9103,\n",
       "  42023,\n",
       "  1808,\n",
       "  23291,\n",
       "  3697,\n",
       "  20960,\n",
       "  18324,\n",
       "  13113,\n",
       "  15553,\n",
       "  4893,\n",
       "  593,\n",
       "  15073,\n",
       "  9690,\n",
       "  36176,\n",
       "  25784,\n",
       "  9281,\n",
       "  10286,\n",
       "  21330,\n",
       "  12197,\n",
       "  18574,\n",
       "  41613,\n",
       "  25617,\n",
       "  9174,\n",
       "  37332,\n",
       "  18924,\n",
       "  1926,\n",
       "  39635,\n",
       "  5116,\n",
       "  27649,\n",
       "  10260,\n",
       "  13255,\n",
       "  34003,\n",
       "  18906,\n",
       "  41697,\n",
       "  22298,\n",
       "  39768,\n",
       "  36446,\n",
       "  27939,\n",
       "  28103,\n",
       "  41851,\n",
       "  43927,\n",
       "  7054,\n",
       "  25767,\n",
       "  33334,\n",
       "  5613,\n",
       "  32408,\n",
       "  28856,\n",
       "  9343,\n",
       "  1670,\n",
       "  31309,\n",
       "  9397,\n",
       "  13314,\n",
       "  16781,\n",
       "  35121,\n",
       "  36359,\n",
       "  44564,\n",
       "  39070,\n",
       "  28668,\n",
       "  24629,\n",
       "  15828,\n",
       "  15670,\n",
       "  30906,\n",
       "  26413,\n",
       "  37114,\n",
       "  30901,\n",
       "  38981,\n",
       "  37006,\n",
       "  5414,\n",
       "  22781,\n",
       "  24139,\n",
       "  29925,\n",
       "  15359,\n",
       "  39064,\n",
       "  43676,\n",
       "  13225,\n",
       "  20323,\n",
       "  12714,\n",
       "  26210,\n",
       "  40581,\n",
       "  10863,\n",
       "  21553,\n",
       "  40659,\n",
       "  13235,\n",
       "  36536,\n",
       "  14806,\n",
       "  28348,\n",
       "  37800,\n",
       "  31459,\n",
       "  3603,\n",
       "  38468,\n",
       "  35470,\n",
       "  33859,\n",
       "  41923,\n",
       "  42524,\n",
       "  13946,\n",
       "  28418,\n",
       "  42335,\n",
       "  35783,\n",
       "  26496,\n",
       "  21343,\n",
       "  15770,\n",
       "  21977,\n",
       "  35796,\n",
       "  20109,\n",
       "  8002,\n",
       "  11155,\n",
       "  43122,\n",
       "  2533,\n",
       "  33092,\n",
       "  44205,\n",
       "  13865,\n",
       "  4746,\n",
       "  21123,\n",
       "  39309,\n",
       "  29389,\n",
       "  23545,\n",
       "  34605,\n",
       "  39982,\n",
       "  41945,\n",
       "  28439,\n",
       "  17046,\n",
       "  41044,\n",
       "  10531,\n",
       "  2254,\n",
       "  41518,\n",
       "  31773,\n",
       "  3994,\n",
       "  31526,\n",
       "  21337,\n",
       "  37786,\n",
       "  27894,\n",
       "  3744,\n",
       "  22573,\n",
       "  10620,\n",
       "  19608,\n",
       "  38947,\n",
       "  29496,\n",
       "  33928,\n",
       "  28743,\n",
       "  12751,\n",
       "  36758,\n",
       "  10919,\n",
       "  39610,\n",
       "  1681,\n",
       "  26035,\n",
       "  11564,\n",
       "  38174,\n",
       "  29551,\n",
       "  26989,\n",
       "  20461,\n",
       "  44349,\n",
       "  38491,\n",
       "  2696,\n",
       "  14683,\n",
       "  12631,\n",
       "  4337,\n",
       "  17637,\n",
       "  38257,\n",
       "  20707,\n",
       "  15824,\n",
       "  16050,\n",
       "  44047,\n",
       "  4516,\n",
       "  6458,\n",
       "  11377,\n",
       "  30121,\n",
       "  26958,\n",
       "  8154,\n",
       "  11577,\n",
       "  39125,\n",
       "  41106,\n",
       "  37253,\n",
       "  793,\n",
       "  26429,\n",
       "  29696,\n",
       "  12849,\n",
       "  43091,\n",
       "  13857,\n",
       "  26506,\n",
       "  395,\n",
       "  35436,\n",
       "  7548,\n",
       "  14746,\n",
       "  42225,\n",
       "  2375,\n",
       "  18746,\n",
       "  42922,\n",
       "  2742,\n",
       "  10767,\n",
       "  40164,\n",
       "  2216,\n",
       "  14621,\n",
       "  23223,\n",
       "  36624,\n",
       "  2744,\n",
       "  17892,\n",
       "  21468,\n",
       "  29004,\n",
       "  18511,\n",
       "  19749,\n",
       "  35893,\n",
       "  27806,\n",
       "  3755,\n",
       "  12187,\n",
       "  15604,\n",
       "  16920,\n",
       "  42460,\n",
       "  35720,\n",
       "  35872,\n",
       "  8098,\n",
       "  29907,\n",
       "  44268,\n",
       "  15520,\n",
       "  15312,\n",
       "  28620,\n",
       "  42253,\n",
       "  7963,\n",
       "  38004,\n",
       "  20180,\n",
       "  460,\n",
       "  10136,\n",
       "  28327,\n",
       "  22704,\n",
       "  10461,\n",
       "  20635,\n",
       "  37349,\n",
       "  25330,\n",
       "  2414,\n",
       "  14840,\n",
       "  20533,\n",
       "  29840,\n",
       "  13880,\n",
       "  39117,\n",
       "  3736,\n",
       "  7644,\n",
       "  44561,\n",
       "  44966,\n",
       "  27143,\n",
       "  9775,\n",
       "  43551,\n",
       "  25257,\n",
       "  30394,\n",
       "  43428,\n",
       "  5330,\n",
       "  10771,\n",
       "  37152,\n",
       "  526,\n",
       "  37362,\n",
       "  20182,\n",
       "  37526,\n",
       "  38365,\n",
       "  5218,\n",
       "  17149,\n",
       "  17758,\n",
       "  40536,\n",
       "  33731,\n",
       "  39718,\n",
       "  3488,\n",
       "  31252,\n",
       "  31677,\n",
       "  4316,\n",
       "  12735,\n",
       "  20586,\n",
       "  19024,\n",
       "  11109,\n",
       "  44318,\n",
       "  4824,\n",
       "  19215,\n",
       "  38,\n",
       "  21909,\n",
       "  17337,\n",
       "  23585,\n",
       "  40304,\n",
       "  39307,\n",
       "  14695,\n",
       "  25034,\n",
       "  6332,\n",
       "  21904,\n",
       "  3312,\n",
       "  23065,\n",
       "  29526,\n",
       "  35860,\n",
       "  17131,\n",
       "  ...],\n",
       " 'evaluation_set_indices': [],\n",
       " 'active_learning_steps': [{'training': {'epochs': [{'accuracy': 0.1998,\n",
       "      'crossentropy': 2.38129228515625}],\n",
       "    'era_epochs': []},\n",
       "   'evaluation_metrics': {'accuracy': 0.1965,\n",
       "    'crossentropy': 2.36414514465332},\n",
       "   'eval_training': {'epochs': [{'accuracy': 0.1992,\n",
       "      'crossentropy': 2.42520475769043},\n",
       "     {'accuracy': 0.155, 'crossentropy': 2.468776754760742},\n",
       "     {'accuracy': 0.2074, 'crossentropy': 2.1420733009338377}],\n",
       "    'era_epochs': []},\n",
       "   'acquisition': {'indices': [24299, 28709, 14051, 32871, 41993],\n",
       "    'labels': [1, 1, 9, 9, 1],\n",
       "    'scores': [0.19450080394744873,\n",
       "     0.19415390491485596,\n",
       "     0.1849052906036377,\n",
       "     0.18168413639068604,\n",
       "     0.18099915981292725]}},\n",
       "  {'training': {'epochs': [{'accuracy': 0.2416,\n",
       "      'crossentropy': 2.68387165145874}],\n",
       "    'era_epochs': []},\n",
       "   'evaluation_metrics': {'accuracy': 0.2411,\n",
       "    'crossentropy': 2.77079727935791}}]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size 20:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3fc327793734c0eb2f361164ad86451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/384]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/64]   2%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RestoringEarlyStopping: Restoring best parameters. (Score: -6.529030114412308)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/157]   1%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.5367, 'crossentropy': 6.438035237884521}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions:   0%|          | 0/463616 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382711f4f7ad4ec7980c856e0f9d229e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1811]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/64]   2%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RestoringEarlyStopping: Restoring best parameters. (Score: -5.1637596152722836)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions:   0%|          | 0/2317680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "get_predictions:   0%|          | 0/2317680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/115884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/115884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Conditional Entropy:   0%|          | 0/115884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Entropy:   0%|          | 0/115884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquiring (label, score)s: 8 (0.8711), 8 (0.8687), 3 (0.876), 3 (0.8465), 3 (0.8811)\n",
      "Training set size 25:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c326c4165e48eab908014b4064f795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "100%|##########| 1/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/384]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/64]   2%|1          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RestoringEarlyStopping: Restoring best parameters. (Score: -4.6851686127483845)\n",
      "RestoringEarlyStopping: Restoring optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/157]   1%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perf after training {'accuracy': 0.6256, 'crossentropy': 4.484497045135498}\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'initial_training_set_indices': [38043,\n",
       "  40091,\n",
       "  17418,\n",
       "  2094,\n",
       "  39879,\n",
       "  3133,\n",
       "  5011,\n",
       "  40683,\n",
       "  54379,\n",
       "  24287,\n",
       "  9849,\n",
       "  59305,\n",
       "  39508,\n",
       "  39356,\n",
       "  8758,\n",
       "  52579,\n",
       "  13655,\n",
       "  7636,\n",
       "  21562,\n",
       "  41329],\n",
       " 'active_learning_steps': [{'training': {'epochs': [{'accuracy': 0.538818359375,\n",
       "      'crossentropy': 6.529030114412308}],\n",
       "    'best_epoch': 1},\n",
       "   'evalution_metrics': {'accuracy': 0.5367,\n",
       "    'crossentropy': 6.438035237884521},\n",
       "   'pool_training': {'epochs': [{'accuracy': 0.531005859375,\n",
       "      'crossentropy': 5.1637596152722836}],\n",
       "    'best_epoch': 1},\n",
       "   'acquisition': {'indices': [63338, 10856, 63452, 81864, 109287],\n",
       "    'labels': [8, 8, 3, 3, 3],\n",
       "    'scores': [0.8710822958846325,\n",
       "     0.8687216999221631,\n",
       "     0.8759664372823723,\n",
       "     0.8464646732511746,\n",
       "     0.8810812784952251]}},\n",
       "  {'training': {'epochs': [{'accuracy': 0.62255859375,\n",
       "      'crossentropy': 4.6851686127483845}],\n",
       "    'best_epoch': 1},\n",
       "   'evalution_metrics': {'accuracy': 0.6256,\n",
       "    'crossentropy': 4.484497045135498}}]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment\n",
    "\n",
    "experiment = Experiment(\n",
    "    max_training_epochs=1, max_training_set=25, acquisition_function=AcquisitionFunction.randombaldical\n",
    ")\n",
    "\n",
    "results = {}\n",
    "experiment.run(results)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "configs = [\n",
    "    Experiment(\n",
    "        seed=seed + 8945,\n",
    "        acquisition_function=acquisition_function,\n",
    "        acquisition_size=acquisition_size,\n",
    "        num_pool_samples=num_pool_samples,\n",
    "        initial_training_set_size=5000,\n",
    "        evaluation_set_size=0,\n",
    "        max_training_set=20000,\n",
    "        temperature=temperature,\n",
    "        id_repetitions=id_repetitions,\n",
    "        add_dataset_noise=True\n",
    "\n",
    "    )\n",
    "    for seed in range(5)\n",
    "    for acquisition_function in [\n",
    "        acquisition_functions.SoftmaxBALD,\n",
    "    ]\n",
    "    for acquisition_size in [200]\n",
    "    for num_pool_samples in [100]\n",
    "    for temperature in [1/64]\n",
    "    for id_repetitions in [1,5,10,20]\n",
    "] + [\n",
    "    Experiment(\n",
    "        seed=seed + 8945,\n",
    "        acquisition_function=acquisition_function,\n",
    "        acquisition_size=acquisition_size,\n",
    "        num_pool_samples=num_pool_samples,\n",
    "        initial_training_set_size=5000,\n",
    "        evaluation_set_size=0,\n",
    "        max_training_set=20000,\n",
    "        temperature=temperature,\n",
    "        id_repetitions=id_repetitions,\n",
    "        add_dataset_noise=True\n",
    "    )\n",
    "    for seed in range(5)\n",
    "    for acquisition_function in [\n",
    "        acquisition_functions.BALD,\n",
    "    ]\n",
    "    for acquisition_size in [200]\n",
    "    for num_pool_samples in [100]\n",
    "    for temperature in [0]\n",
    "    for id_repetitions in [1,5,10,20]\n",
    "]\n",
    "\n",
    "if not is_run_from_ipython() and __name__ == \"__main__\":\n",
    "    for job_id, store in embedded_experiments(__file__, len(configs)):\n",
    "        config = configs[job_id]\n",
    "        config.seed += job_id\n",
    "        print(config)\n",
    "        store[\"config\"] = dataclasses.asdict(config)\n",
    "        store[\"log\"] = {}\n",
    "\n",
    "        try:\n",
    "            config.run(store=store)\n",
    "        except Exception:\n",
    "            store[\"exception\"] = traceback.format_exc()\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    Experiment(\n",
      "        seed=8945,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100,\n",
      "        temperature=0.015625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8945,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        id_repetitions=5,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100,\n",
      "        temperature=0.015625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8945,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        id_repetitions=10,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100,\n",
      "        temperature=0.015625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8945,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        id_repetitions=20,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100,\n",
      "        temperature=0.015625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8946,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100,\n",
      "        temperature=0.015625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8946,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        id_repetitions=5,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100,\n",
      "        temperature=0.015625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8946,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        id_repetitions=10,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100,\n",
      "        temperature=0.015625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8946,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        id_repetitions=20,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100,\n",
      "        temperature=0.015625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8947,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100,\n",
      "        temperature=0.015625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8947,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        id_repetitions=5,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100,\n",
      "        temperature=0.015625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8947,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        id_repetitions=10,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100,\n",
      "        temperature=0.015625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8947,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        id_repetitions=20,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100,\n",
      "        temperature=0.015625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8948,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100,\n",
      "        temperature=0.015625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8948,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        id_repetitions=5,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100,\n",
      "        temperature=0.015625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8948,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        id_repetitions=10,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100,\n",
      "        temperature=0.015625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8948,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        id_repetitions=20,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100,\n",
      "        temperature=0.015625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8949,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100,\n",
      "        temperature=0.015625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8949,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        id_repetitions=5,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100,\n",
      "        temperature=0.015625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8949,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        id_repetitions=10,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100,\n",
      "        temperature=0.015625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8949,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.SoftmaxBALD,\n",
      "        id_repetitions=20,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100,\n",
      "        temperature=0.015625\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8945,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.BALD,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8945,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.BALD,\n",
      "        id_repetitions=5,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8945,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.BALD,\n",
      "        id_repetitions=10,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8945,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.BALD,\n",
      "        id_repetitions=20,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8946,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.BALD,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8946,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.BALD,\n",
      "        id_repetitions=5,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8946,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.BALD,\n",
      "        id_repetitions=10,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8946,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.BALD,\n",
      "        id_repetitions=20,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8947,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.BALD,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8947,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.BALD,\n",
      "        id_repetitions=5,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8947,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.BALD,\n",
      "        id_repetitions=10,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8947,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.BALD,\n",
      "        id_repetitions=20,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8948,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.BALD,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8948,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.BALD,\n",
      "        id_repetitions=5,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8948,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.BALD,\n",
      "        id_repetitions=10,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8948,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.BALD,\n",
      "        id_repetitions=20,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8949,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.BALD,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8949,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.BALD,\n",
      "        id_repetitions=5,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8949,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.BALD,\n",
      "        id_repetitions=10,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100\n",
      "    ),\n",
      "    Experiment(\n",
      "        seed=8949,\n",
      "        # class\n",
      "        acquisition_function=batchbald_redux.acquisition_functions.BALD,\n",
      "        id_repetitions=20,\n",
      "        add_dataset_noise=True,\n",
      "        acquisition_size=100,\n",
      "        max_training_set=20000,\n",
      "        num_pool_samples=100\n",
      "    )\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import prettyprinter\n",
    "prettyprinter.install_extras({\"dataclasses\"})\n",
    "prettyprinter.pprint(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:active_learning]",
   "language": "python",
   "name": "conda-env-active_learning-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
